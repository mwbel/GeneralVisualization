# 概率论与数理统计

第五版

# 概率论与数理统计

第五版

□浙江大学 盛 骤 谢式干 潘承毅 编

# 内容提要

本书是普通高等教育"十一五"国家级规划教材,在2008年出版的《概率论与数理统计》(第四版)的基础上增订而成。本次修订改写和新增的内容有:在数理统计中应用R软件、bootstrap假设检验方法举例、时间序列分析等。

本书主要内容包括概率论、数理统计、随机过程三部分,每章附有习题;同时涵盖了《全国硕士研究生入学统一考试数学考试大纲》的所有知识点。本书可作为高等学校工科、理科(非数学类专业)各专业的教材和研究生入学考试的参考书,也可供工程技术人员、科技工作者参考。

# 图书在版编目(CIP)数据

概率论与数理统计/盛骤,谢式千,潘承毅编.- - 5版.- - 北京:高等教育出版社,2019.12(2021.1重印)

ISBN978- 7- 04- 051660- 9

I.  $①$  概Ⅱ.  $①$  盛…  $②$  谢…  $③$  潘… Ⅲ.  $①$  概率论-高等学校-教材  $②$  数理统计-高等学校-教材 IV.  $①$  O21

中国版本图书馆CIP数据核字(2019)第055877号

Gailulun yu Shuli Tongji

策划编辑 李蕊 责任编辑 田玲 封面设计 王凌波 版式设计 童丹插图绘制 于博 责任校对 张薇 责任印制 刁毅

出版发行 高等教育出版社

社址 北京市西城区德外大街4号

邮政编码 100120

印刷 山东韵杰文化科技有限公司

开本 787mm×960mm 1/16

印张 27.75

字数 510千字

购书热线 010- 58581118

咨询电话 400- 810- 0598

本书如有缺页、倒页、脱页等质量问题,请到所购图书销售部门联系调换

版权所有 侵权必究

物料号 51660- 00

# 第五版前言

本书第五版与第四版比较,在内容上有以下的改动:

1. bootstrap方法(自助法)一章中增加了一节"bootstrap假设检验方法举例"。全章选配了习题。

2. 本书第四版中使用Excel软件,本版改为使用R软件。R软件使用更为方便,功能更强,资源更丰富,且R软件可免费下载。

3. 随机过程部分增加了"时间序列分析"一章。第十二章至第十四章作了一些改写,整个随机过程部分的内容所占篇幅并未增加。

朱其吉教授参加了本书的编写工作,编写了"时间序列分析"一章。

本版中新的第十一章"在数理统计中应用R软件"是由浙江大学于渤教授编写的。

诚恳地希望读者批评指正。

盛骤谢式千潘承毅  2019年4月

# 第四版前言

本书自1979年3月初版至今,已发行近三十年。历经多年教学实践的检验,得到了国内广大院校和任课教师的认可,发行量为国内同类教材中最多的。

第四版是普通高等教育"十一五"国家级规划教材,在第三版的基础上修订编写而成。在编写之前,高等教育出版社在全国有关高校作过相当广泛的调查,本版的编写吸取了相关的意见。

教材应该力求与时俱进。本版新增加了以下内容:

(1)介绍了bootstrap方法的基本思想和方法,介绍了用bootstrap方法求参数点估计和区间估计的具体做法。bootstrap方法是近代统计中的一种用于数据处理的重要的实用方法。

(2)新增了"在数理统计中应用Excel软件"一章。介绍了Excel软件及其在数理统计中的应用,举例介绍了应用VBA语言编写"宏"求解具体的数理统计问题。

(3)新增了假设检验问题的  $\boldsymbol{\mathscr{p}}$  值检验法。新增了箱线图,箱线图能大致描述随机变量分布的一些重要性质,还能检测疑似异常点。

(4)对第三版原有的例题和习题作了一些调整,增加了有关加强基本概念、基本运算的习题,在例题和习题的选择上扩大了涉及的范围,例如,农业、保险业、医学、商业、管理学、体育,等等。

选用本教材的院校类别较为广泛,专业不一,学生程度不一。我们认为,教材内容要比教学大纲多一些,要比教师在课堂讲授的多一些,这样能照顾到各类学校各个专业的需要,能满足不同程度的学生的学习需要。

我们在目录中打上了一些  $\divideontimes$  号,在学时限制下,有  $\divideontimes$  号的内容可以不学。这些内容是相对独立的,删去不学不影响全书的讲授。在概率论与数理统计部分中打  $\divideontimes$  号的内容有:基于截尾样本的最大似然估计,置信区间与假设检验之间的关系,样本容量的选取,秩和检验。此外还有偏度、峰度检验,以及这一版新增的部分或全部内容。随机过程部分视教学计划中有无这一门课决定取舍。

本次修订也包括配套辅导书,它们将与教材同时出版。

本书中新增的有关在数理统计中应用Excel软件的内容由浙江大学于渤教授编写。

本书由浙江大学范大茵教授审阅,对此我们表示衷心的感谢。

高等教育出版社蒋青、李蕊、兰莹莹同志为本版教材作了很多认真、细致的工作,对此,我们表示诚挚的感谢。诚恳地希望读者批评指正。

诚恳地希望读者批评指正。

盛骤谢式千潘承毅

2008年4月

# 第三版前言

这一版我们对于本书第二版中的一些疏漏和不妥之处作了修改,增加了"基于截尾样本的最大似然估计"和"置信区间与假设检验之间的关系"两小节,对各章的例题和习题作了少量的增减。

为了帮助读者抓住要点,提高学习质量与效率,在各章末增写了"小结"。小结中所包含的内容,有的是用来说明概念的现实背景和含义,对某些概念与方法所基于的概率和统计思想作了进一步的阐述;有的则阐明一章内容的重点和基本要求;有的则指出学习时应注意之点。小结也能起到提纲挈领的作用。

书末还增加了两个参读材料:(一)随机变量样本值的产生,(二)标准正态变量分布函数  $\Phi (x)$  的数值计算。这些内容在解决实际问题时是常会用到的。

本书这一版承柴根象教授、王静龙教授、谢国瑞教授、范大茵教授审阅,他们提出了许多宝贵意见,对此我们表示衷心的感谢。

盛骤谢式千潘承毅  2000年8月

# 第二版前言

本书是在1979年出版的第一版的基础上修订的,可作为高等学校工科、理科(非数学类专业)概率论与数理统计课程的教材,也可供工程技术人员参考。

本书分三部分。概率论部分(第一章至第五章)作为基础知识,为读者提供了必要的理论基础;数理统计部分(第六章至第九章)主要讲述了参数估计和假设检验,并介绍了方差分析和回归分析;随机过程部分(第十章至第十二章)在讲清基本知识的基础上主要讨论了平稳随机过程,还介绍了马尔可夫过程。数理统计和随机过程这两部分内容是相互独立的,可根据专业的需要选用。

在本书第一版出版后,我们经过进一步的教学实践,积累了不少的经验,并吸收了广大读者的意见,修订稿是在这一基础上写出的。我们修改了第一版中存在的不当之处,并致力于教材质量的提高。我们在选材和叙述上尽量做到联系工科专业的实际,注重应用,力图将概念写得清晰易懂,做到便于教学。我们在例题和习题的选择上作了努力,这些题目既具有启发性,又有广泛的应用性,从题目的广泛性也可看到本门课程涉及生活和技术应用领域的广泛性。读者将会发现,这些例题和习题是饶有趣味的。为适应经济建设的需要,我们加强了数理统计的内容,例如编写了"矩估计法""样本容量的选取"和"正态分布的偏度、峰度检验"等,并有意识地加强读者统计计算能力的培养。

书中的一部分内容能直接应用于解决实际课题,另一部分内容为读者今后进一步学习有关课程或在实际应用方面提供一定的基础。

黄纪青同志曾参加过本书第一版编写大纲的讨论,撰写过第一版第一章的初稿。

本书的全部插图是由张礼明同志描绘的。

本书第二版承魏宗舒教授、林少宫教授、沈恒范教授、范大苗副教授、樊孝述副教授和汪振鹏副教授审阅,他们提出了很多宝贵意见,对此我们表示衷心的感谢。

书中不足之处,诚恳地希望读者批评指正。

# 目录

# 第一章 概率论的基本概念

$\S 1$  随机试验

$\S 2$  样本空间、随机事件

$\S 3$  频率与概率

$\S 4$  等可能概型(古典概型)

$\S 5$  条件概率

$\S 6$  独立性

小结

习题

# 第二章 随机变量及其分布

$\S 1$  随机变量

$\S 2$  离散型随机变量及其分布律

$\S 3$  随机变量的分布函数

$\S 4$  连续型随机变量及其概率密度

$\S 5$  随机变量的函数的分布

小结

习题

# 第三章 多维随机变量及其分布

$\S 1$  二维随机变量

$\S 2$  边缘分布

$\S 3$  条件分布

$\S 4$  相互独立的随机变量

$\S 5$  两个随机变量的函数的分布

小结

习题

# 第四章 随机变量的数字特征

$\S 1$  数学期望

$\S 2$  方差

$\S 3$  协方差及相关系数

$\S 4$  矩、协方差矩阵 112

小结 114

习题 115

# 第五章 大数定律及中心极限定理 121

$\S 1$  大数定律 121

$\S 2$  中心极限定理 123

小结 128

习题 128

# 第六章 样本及抽样分布 131

$\S 1$  随机样本 131

$\S 2$  直方图和箱线图 133

$\S 3$  抽样分布 139

小结 148

习题 149

# 第七章 参数估计 151

$\S 1$  点估计 151

*  $\S 2$  基于截尾样本的最大似然估计 158

$\S 3$  估计量的评选标准 160

$\S 4$  区间估计 163

$\S 5$  正态总体均值与方差的区间估计 166

$\S 6$  (0- 1)分布参数的区间估计 170

$\S 7$  单侧置信区间 171

小结 173

习题 176

# 第八章 假设检验 181

$\S 1$  假设检验 181

$\S 2$  正态总体均值的假设检验 186

$\S 3$  正态总体方差的假设检验 191

*  $\S 4$  置信区间与假设检验之间的关系 195

*  $\S 5$  样本容量的选取 197

$\S 6$  分布拟合检验 202

$\S 7$  假设检验问题的  $p$  值法 210

小结 214

习题 215

# 第九章 方差分析及回归分析 221

$\S 1$  单因素试验的方差分析 221

$\S 2$  双因素试验的方差分析 231

$\S 3$  一元线性回归 241

$\S 4$  多元线性回归 255

小结 259

附录  $\S 3$  中有关统计量结果的证明 261

习题 261

# 第十章 bootstrap方法(自助法) 267

$\S 1$  非参数bootstrap方法 267

$\S 2$  参数bootstrap方法 273

$\S 3$  bootstrap假设检验方法举例 277

小结 280

习题 280

# 第十一章 在数理统计中应用R软件 283

$\S 1$  概述 283

$\S 2$  箱线图 285

$\S 3$  假设检验 286

$\S 4$  方差分析 288

$\S 5$  线性回归 293

$\S 6$  bootstrap方法 296

附录 R软件的一些介绍 305

习题 307

本章参考文献 307

# 第十二章 随机过程 308

$\S 1$  随机过程的概念 308

$\S 2$  随机过程的统计描述 309

$\S 3$  泊松过程和维纳过程 315

小结 321

习题 321

# 第十三章 马尔可夫链 323

$\S 1$  定义与例子 323

$\S 2$  多步转移概率的确定 327

$\S 3$  遍历性 330

小结 334

习题 335

# 第十四章 平稳随机过程 337

$\S 1$  平稳随机过程的概念 337

$\S 2$  各态历经性 339

$\S 3$  相关函数的性质 345

$\S 4$  平稳随机过程的功率谱密度 347

小结 354

习题 354

# 第十五章 时间序列分析 357

$\S 1$  平稳时间序列 357

$\S 2$  线性自回归滑动平均模型 358

$\S 3$  模型的应用 364

小结 373

附录 差分方程的解 374

习题 374

# 选做习题 375

# 参读材料一 随机变量样本值的产生 387

# 参读材料二 蒙特卡罗方法 390

# 附表 394

附表1 几种常用的概率分布表 394

附表2 标准正态分布表 397

附表3 泊松分布表 398

附表4  $t$  分布表 399

附表5  $\chi^{2}$  分布表 400

附表6  $F$  分布表 401

附表7 均值的  $t$  检验的样本容量 405

附表8 均值差的  $t$  检验的样本容量 407

# 习题答案 409

# 第一章 概率论的基本概念

自然界和社会上发生的现象是多种多样的。有一类现象,在一定条件下必然发生,例如,向上抛一石子必然下落,同性电荷必相互排斥,等等。这类现象称为确定性现象。在自然界和社会上存在着另一类现象,例如,在相同条件下抛同一枚硬币,其结果可能是正面朝上,也可能是反面朝上,并且在每次抛掷之前无法肯定抛掷的结果是什么;用同一门炮向同一目标射击,各次弹着点不尽相同,在一次射击之前无法预测弹着点的确切位置。这类现象,在一定的条件下,可能出现这样的结果,也可能出现那样的结果,而在试验或观察之前不能预知确切的结果。但人们经过长期实践并深入研究之后,发现这类现象在大量重复试验或观察下,它的结果却呈现出某种规律性。例如,多次重复抛一枚硬币得到正面朝上大致有一半,同一门炮射击同一目标的弹着点按照一定规律分布,等等。这种在大量重复试验或观察中所呈现出的固有规律性,就是我们以后所说的统计规律性。这种在个别试验中其结果呈现出不确定性,在大量重复试验中其结果又具有统计规律性的现象,我们称之为随机现象。概率论与数理统计是研究和揭示随机现象统计规律性的一门数学学科。

这种在个别试验中其结果呈现出不确定性,在大量重复试验中其结果又具有统计规律性的现象,我们称之为随机现象.概率论与数理统计是研究和揭示随机现象统计规律性的一门数学学科.

# §1 随机试验

我们遇到过各种试验。在这里,我们把试验作为一个含义广泛的术语。它包括各种各样的科学实验,甚至对某一事物的某一特征的观察也认为是一种试验。下面举一些试验的例子。

$E_{1}$  :抛一枚硬币,观察正面  $H$  、反面  $T$  出现的情况。

$E_{2}$  :将一枚硬币抛掷三次,观察正面  $H$  、反面  $T$  出现的情况。

$E_{3}$  :将一枚硬币抛掷三次,观察出现正面的次数。

$E_{4}$  :抛一颗骰子,观察出现的点数。

$E_{5}$  :记录某城市120急救电话台一昼夜接到的呼唤次数。

$E_{6}$  :在一批灯泡中任意抽取一只,测试它的寿命。

$E_{7}$  :记录某地一昼夜的最高温度和最低温度。

上面举出了七个试验的例子,它们有着共同的特点。例如,试验  $E_{1}$  有两种

可能结果, 出现  $H$  或者出现  $T$ , 但在抛掷之前不能确定出现  $H$  还是出现  $T$ , 这个试验可以在相同的条件下重复地进行. 又如试验  $E_{6}$ , 我们知道灯泡的寿命 (以 h 计)  $t \geqslant 0$ , 但在测试之前不能确定它的寿命有多长. 这一试验也可以在相同的条件下重复地进行. 概括起来, 这些试验具有以下的特点:

$1^{\circ}$  可以在相同的条件下重复地进行.

$2^{\circ}$  每次试验的可能结果不止一个, 并且能事先明确试验的所有可能结果.

$3^{\circ}$  进行一次试验之前不能确定哪一个结果会出现.

在概率论中, 我们将具有上述三个特点的试验称为随机试验.

本书中以后提到的试验都是指随机试验.

我们是通过研究随机试验来研究随机现象的.

# $\S 2$  样本空间、随机事件

# (一) 样本空间

对于随机试验, 尽管在每次试验之前不能预知试验的结果, 但试验的所有可能结果组成的集合是已知的. 我们将随机试验  $E$  的所有可能结果组成的集合称为  $E$  的样本空间, 记为  $S$ . 样本空间的元素, 即  $E$  的每个结果, 称为样本点.

下面写出  $\S 1$  中试验  $E_{k}(k = 1,2,\dots ,7)$  的样本空间  $S_{k}$

$S_{1}:\{H,T\}$

$S_{2}:\{HHH,HHT,HTH,THH,HTT,HTT,TTH,TTT\}$ .

$S_{3}:\{0,1,2,3\}$

$S_{4}:\{1,2,3,4,5,6\}$

$S_{5}:\{0,1,2,3,\dots \}$

$S_{6}:\{t\mid t\geqslant 0\}$

$S_{7}:\{(x,y)\mid T_{0}\leqslant x\leqslant y\leqslant T_{1}\}$ , 这里  $x$  表示最低温度 (以  $C$  计),  $y$  表示最高温度 (以  $C$  计). 并设这一地区的温度不会小于  $T_{0}$ , 也不会大于  $T_{1}$ .

# (二) 随机事件

在实际中, 当进行随机试验时, 人们常常关心满足某种条件的那些样本点所组成的集合. 例如, 若规定某种灯泡的寿命 (以 h 计) 小于 500 为次品, 则在  $E_{6}$  中我们关心灯泡的寿命是否有  $t \geqslant 500$ . 满足这一条件的样本点组成  $S_{6}$  的一个子集:  $A = \{t\mid t \geqslant 500\}$ . 我们称  $A$  为试验  $E_{6}$  的一个随机事件. 显然, 当且仅当子集

$A$  中的一个样本点出现时, 有  $t \geqslant 500$ .

一般, 我们称试验  $E$  的样本空间  $S$  的子集为  $E$  的随机事件, 简称事件  $①$ . 在每次试验中, 当且仅当这一子集中的一个样本点出现时, 称这一事件发生.

特别, 由一个样本点组成的单点集, 称为基本事件. 例如, 试验  $E_{1}$  有两个基本事件  $\{H\}$  和  $\{T\}$ ; 试验  $E_{4}$  有 6 个基本事件  $\{1\} , \{2\} , \dots , \{6\}$ .

样本空间  $S$  包含所有的样本点, 它是  $S$  自身的子集, 在每次试验中它总是发生的,  $S$  称为必然事件. 空集  $\varnothing$  不包含任何样本点, 它也作为样本空间的子集, 它在每次试验中都不发生,  $\varnothing$  称为不可能事件.

下面举几个事件的例子.

例1 在  $E_{2}$  中事件  $A_{1}$  :"第一次出现的是  $H$  ", 即

$$
A_{1} = \{H H H,H H T,H T H,H T T\} .
$$

事件  $A_{2}$  :"三次出现同一面", 即

$$
A_{2} = \{H H H,T T T\} .
$$

在  $E_{6}$  中, 事件  $A_{3}$  :"寿命小于  $1000 \mathrm{~h}$  ", 即

$$
A_{3} = \{t \mid 0 \leqslant t < 1000 \} .
$$

在  $E_{7}$  中, 事件  $A_{4}$  :"最高温度与最低温度相差  $10^{\circ} \mathrm{C}$  ", 即

$$
A_{4} = \{(x, y) \mid y - x = 10, T_{0} \leqslant x \leqslant y \leqslant T_{1} \} .
$$

# (三) 事件间的关系与事件的运算

事件是一个集合, 因而事件间的关系与事件的运算自然按照集合论中集合之间的关系和集合运算来处理. 下面给出这些关系和运算在概率论中的提法. 并根据"事件发生"的含义, 给出它们在概率论中的含义.

设试验  $E$  的样本空间为  $S$ , 而  $A, B, A_{k} (k = 1,2, \dots)$  是  $S$  的子集.

$1^{\circ}$  若  $A \subset B$ , 则称事件  $B$  包含事件  $A$ , 这指的是事件  $A$  发生必导致事件  $B$  发生.

若  $A \subset B$  且  $B \subset A$ , 即  $A = B$ , 则称事件  $A$  与事件  $B$  相等.

$2^{\circ}$  事件  $A \cup B = \{x \mid x \in A$  或  $x \in B \}$  称为事件  $A$  与事件  $B$  的和事件. 当且仅当  $A, B$  中至少有一个发生时, 事件  $A \cup B$  发生.

类似地, 称  $\bigcup_{k = 1}^{n} A_{k}$  为  $n$  个事件  $A_{1}, A_{2}, \dots , A_{n}$  的和事件; 称  $\bigcup_{k = 1}^{\infty} A_{k}$  为可列个

事件  $A_{1}, A_{2}, \dots$  的和事件.

$3^{\circ}$  事件  $A \cap B = \{x \mid x \in A$  且  $x \in B\}$  称为事件  $A$  与事件  $B$  的积事件. 当且仅当  $A, B$  同时发生时, 事件  $A \cap B$  发生.  $A \cap B$  也记作  $AB$ .

类似地, 称  $\bigcap_{k = 1}^{n} A_{k}$  为  $n$  个事件  $A_{1}, A_{2}, \dots , A_{n}$  的积事件; 称  $\bigcap_{k = 1}^{\infty} A_{k}$  为可列个事件  $A_{1}, A_{2}, \dots$  的积事件.

$4^{\circ}$  事件  $A - B = \{x \mid x \in A$  且  $x \notin B\}$  称为事件  $A$  与事件  $B$  的差事件. 当且仅当  $A$  发生,  $B$  不发生时事件  $A - B$  发生.

$5^{\circ}$  若  $A \cap B = \emptyset$ , 则称事件  $A$  与  $B$  是互不相容的, 或互斥的. 这指的是事件  $A$  与事件  $B$  不能同时发生. 基本事件是两两互不相容的.

$6^{\circ}$  若  $A \cup B = S$  且  $A \cap B = \emptyset$ , 则称事件  $A$  与事件  $B$  互为逆事件, 又称事件  $A$  与事件  $B$  互为对立事件. 这指的是对每次试验而言, 事件  $A, B$  中必有一个发生, 且仅有一个发生.  $A$  的对立事件记为  $\overline{A}, \overline{A} = S - A$ .

用图1一1至图1一6可直观地表示以上事件之间的关系与运算.例如,在图1一1中长方形表示样本空间  $s$  ,圆  $A$  与圆  $B$  分别表示事件  $A$  与事件  $B$  ,事件  $B$  包含事件  $A$  .又如在图1一2中长方形表示样本空间  $s$  ,圆  $A$  与圆  $B$  分别表示事件  $A$  与事件  $B$  ,而阴影部分表示和事件  $A\cup B$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
ACB

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
AUB

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
A∩B

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
图1-1 图1-4 图1-5 图1-6

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
图1-2 图1-3

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
$B \cup \overline{B} = S, B \cap \overline{B} = \emptyset$  图1-6

在进行事件运算时,经常要用到下述定律.设  $A,B,C$  为事件,则有

交换律:  $A\cup B = B\cup A$  ;  $A\cap B = B\cap A$

结合律:  $A\cup (B\cup C) = (A\cup B)\cup C$  ;  $A\cap (B\cap C) = (A\cap B)\cap C.$

分配律:  $A\cup (B\cap C) = (A\cup B)\cap (A\cup C)$  ;  $A\cap (B\cup C) = (A\cap B)\cup (A\cap C).$

德摩根律:  $\overline{A\cup B} = \overline{A}\cap \overline{B}$  ;  $\overline{A\cap B} = \overline{A}\cup \overline{B}.$

例2 在例1中有

$$
A_{1}\cup A_{2} = \{H H H,H H T,H T H,H T T,T T T\} ,
$$

$$
A_{1}\cap A_{2} = \{H H H\} ,
$$

$$
A_{2} - A_{1} = \{T T T\} ,
$$

$$
\overline{{A_{1}\cup A_{2}}} = \{T H T,T T H,T H H\} .
$$

例3如图1一7所示的电路中,以  $A$  表示"信号灯亮"这一事件,以  $B,C,D$  分别表示事件:继电器接点I,Ⅱ,Ⅲ闭合,那么容易知道  $B C\subset A,B D\subset A$ $B C\cup B D = A$  ,而  $\overline{{B}} A = \mathcal{D}$  ,即事件  $\overline{{B}}$  与事件  $A$  互不相容.又,  $\overline{{B}}\cup \overline{{C}} = \overline{{B}}\cap \overline{{C}}$  左边表示事件"I,Ⅱ至少有一个闭合"的逆事件,也就是I,Ⅱ都不闭合,即  $\overline{{B}},\overline{{C}}$  同时发生).

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
图1-7

# $\S 3$  频率与概率

对于一个事件(除必然事件和不可能事件外)来说,它在一次试验中可能发生,也可能不发生.我们常常希望知道某些事件在一次试验中发生的可能性究竟有多大.例如,为了确定水坝的高度,就要知道河流在造水坝地段每年最大洪水达到某一高度这一事件发生的可能性大小.我们希望找到一个合适的数来表征事件在一次试验中发生的可能性大小.为此,首先引入频率,它描述了事件发生的频繁程度,进而引出表征事件在一次试验中发生的可能性大小的数概率.

# (一)频率

定义在相同的条件下,进行了  $n$  次试验,在这  $n$  次试验中,事件  $A$  发生的次数  $n_{A}$  称为事件  $A$  发生的频数.比值  $n_{A} / n$  称为事件  $A$  发生的频率,并记成 $f_{n}(A)$

由定义,易见频率具有下述基本性质:

$$
1^{\circ}0\leqslant f_{n}(A)\leqslant 1.
$$

$2^{\circ} f_{n}(S) = 1$ .

$3^{\circ}$  若  $A_{1}, A_{2}, \dots , A_{k}$  是两两互不相容的事件, 则

$$
f_{n}(A_{1} \cup A_{2} \cup \dots \cup A_{k}) = f_{n}(A_{1}) + f_{n}(A_{2}) + \dots + f_{n}(A_{k}).
$$

由于事件  $A$  发生的频率是它发生的次数与试验次数之比, 其大小表示  $A$  发生的频繁程度. 频率大, 事件  $A$  发生就频繁, 这意味着事件  $A$  在一次试验中发生的可能性就大. 反之亦然. 因而, 直观的想法是用频率来表示事件  $A$  在一次试验中发生的可能性的大小. 但是否可行, 先看下面的例子.

例1 考虑"抛硬币"这个试验, 我们将一枚硬币抛掷 5 次、50 次、500 次, 各做 10 遍. 得到数据如表 1- 1 所示 (其中  $n_{H}$  表示  $H$  发生的频数,  $f_{n}(H)$  表示  $H$  发生的频率).

表1-1  

<table><tr><td rowspan="2">试验序号</td><td colspan="2">n=5</td><td colspan="2">n=50</td><td colspan="2">n=500</td></tr><tr><td>nH</td><td>fn(H)</td><td>nH</td><td>fn(H)</td><td>nH</td><td>fn(H)</td></tr><tr><td>1</td><td>2</td><td>0.4</td><td>22</td><td>0.44</td><td>251</td><td>0.502</td></tr><tr><td>2</td><td>3</td><td>0.6</td><td>25</td><td>0.50</td><td>249</td><td>0.498</td></tr><tr><td>3</td><td>1</td><td>0.2</td><td>21</td><td>0.42</td><td>256</td><td>0.512</td></tr><tr><td>4</td><td>5</td><td>1.0</td><td>25</td><td>0.50</td><td>253</td><td>0.506</td></tr><tr><td>5</td><td>1</td><td>0.2</td><td>24</td><td>0.48</td><td>251</td><td>0.502</td></tr><tr><td>6</td><td>2</td><td>0.4</td><td>21</td><td>0.42</td><td>246</td><td>0.492</td></tr><tr><td>7</td><td>4</td><td>0.8</td><td>18</td><td>0.36</td><td>244</td><td>0.488</td></tr><tr><td>8</td><td>2</td><td>0.4</td><td>24</td><td>0.48</td><td>258</td><td>0.516</td></tr><tr><td>9</td><td>3</td><td>0.6</td><td>27</td><td>0.54</td><td>262</td><td>0.524</td></tr><tr><td>10</td><td>3</td><td>0.6</td><td>31</td><td>0.62</td><td>247</td><td>0.494</td></tr></table>

这种试验历史上有人做过, 得到如表 1- 2 所示的数据.

表1-2  

<table><tr><td>试验者</td><td>n</td><td>nH</td><td>fn(H)</td></tr><tr><td>德摩根</td><td>2 048</td><td>1 061</td><td>0.518 1</td></tr><tr><td>蒲 丰</td><td>4 040</td><td>2 048</td><td>0.506 9</td></tr><tr><td>K. 皮尔逊</td><td>12 000</td><td>6 019</td><td>0.501 6</td></tr><tr><td>K. 皮尔逊</td><td>24 000</td><td>12 012</td><td>0.500 5</td></tr></table>

从上述数据可以看出:抛硬币次数  $n$  较小时,频率  $f_{n}(H)$  在0与1之间随机波动,其幅度较大,但随着  $n$  增大,频率  $f_{n}(H)$  呈现出稳定性.即当  $n$  逐渐增大时 $f_{n}(H)$  总是在0.5附近摆动,而逐渐稳定于0.5. 口

例2考察英语中特定字母出现的频率.当观察字母的个数  $n$  (试验的次数)较小时,频率有较大幅度的随机波动.但当  $n$  增大时,频率呈现出稳定性.表1一3就是一份英文字母频率的统计表①:

表1-3  

<table><tr><td>字母</td><td>频率</td><td>字母</td><td>频率</td><td>字母</td><td>频率</td></tr><tr><td>E</td><td>0.126 8</td><td>L</td><td>0.039 4</td><td>P</td><td>0.018 6</td></tr><tr><td>T</td><td>0.097 8</td><td>D</td><td>0.038 9</td><td>B</td><td>0.015 6</td></tr><tr><td>A</td><td>0.078 8</td><td>U</td><td>0.028 0</td><td>V</td><td>0.010 2</td></tr><tr><td>O</td><td>0.077 6</td><td>C</td><td>0.026 8</td><td>K</td><td>0.006 0</td></tr><tr><td>I</td><td>0.070 7</td><td>F</td><td>0.025 6</td><td>X</td><td>0.001 6</td></tr><tr><td>N</td><td>0.070 6</td><td>M</td><td>0.024 4</td><td>J</td><td>0.001 0</td></tr><tr><td>S</td><td>0.063 4</td><td>W</td><td>0.021 4</td><td>Q</td><td>0.000 9</td></tr><tr><td>R</td><td>0.059 4</td><td>Y</td><td>0.020 2</td><td>Z</td><td>0.000 6</td></tr><tr><td>H</td><td>0.057 3</td><td>G</td><td>0.018 7</td><td></td><td></td></tr></table>

大量试验证实,当重复试验的次数  $n$  逐渐增大时,频率  $f_{n}(A)$  呈现出稳定性,逐渐稳定于某个常数.这种"频率稳定性"即通常所说的统计规律性.我们让试验重复大量次数,计算频率  $f_{n}(A)$  ,以它来表征事件  $A$  发生可能性的大小是合适的.

但是,在实际中,我们不可能对每一个事件都做大量的试验,然后求得事件的频率,用以表征事件发生可能性的大小.同时,为了理论研究的需要,我们从频率的稳定性和频率的性质得到启发,给出如下表征事件发生可能性大小的概率的定义.

# (二)概率

定义设  $E$  是随机试验,S是它的样本空间.对于  $E$  的每一事件  $A$  赋予一

个实数, 记为  $P(A)$ , 称为事件  $A$  的概率, 如果集合函数  $P(\cdot)$  满足下列条件:

$1^{\circ}$  非负性: 对于每一个事件  $A$ , 有  $P(A) \geqslant 0$

$2^{\circ}$  规范性: 对于必然事件  $S$ , 有  $P(S) = 1$

$3^{\circ}$  可列可加性: 设  $A_{1}, A_{2}, \dots$  是两两互不相容的事件, 即对于  $A_{i}A_{j} = \varnothing$ ,  $i \neq j, i, j = 1,2, \dots$ , 有

$$
P(A_{1} \cup A_{2} \cup \dots) = P(A_{1}) + P(A_{2}) + \dots . \tag{3.1}
$$

在第五章中将证明, 当  $n \to \infty$  时频率  $f_{n}(A)$  在一定意义下接近于概率  $P(A)$ . 基于这一事实, 我们就有理由将概率  $P(A)$  用来表征事件  $A$  在一次试验中发生的可能性的大小.

由概率的定义, 可以推得概率的一些重要性质,

性质i  $P(\mathcal{D}) = 0$

证令  $A_{n} = \mathcal{O}$ $(n = 1,2,\dots)$  ,则  $\bigcup_{n = 1}^{\infty}A_{n} = \mathcal{O}$  ,且  $A_{i}A_{j} = \mathcal{O},i\neq j,i,j = 1,2,\dots .$  由概率的可列可加性(3.1)得

$$
P(\mathcal{D}) = P\Big(\bigcup_{n = 1}^{\infty}A_{n}\Big) = \sum_{n = 1}^{\infty}P(A_{n}) = \sum_{n = 1}^{\infty}P(\mathcal{D}).
$$

由概率的非负性知,  $P(\mathcal{D}) \geqslant 0$ , 故由上式知  $P(\mathcal{D}) = 0$

性质ii(有限可加性)若  $A_{1}, A_{2}, \dots , A_{n}$  是两两互不相容的事件, 则有

$$
P(A_{1} \cup A_{2} \cup \dots \cup A_{n}) = P(A_{1}) + P(A_{2}) + \dots + P(A_{n}). \tag{3.2}
$$

(3.2)式称为概率的有限可加性.

证令  $A_{n + 1} = A_{n + 2} = \dots = \mathcal{D}$ , 即有  $A_{i}A_{j} = \mathcal{D}, i \neq j, i, j = 1,2, \dots$ . 由(3.1)式得

$$
\begin{array}{c}{{P(A_{1}\bigcup A_{2}\bigcup\cdots\bigcup A_{n})=P\Big(\bigcup_{k=1}^{\infty}A_{k}\Big)=\sum_{k=1}^{\infty}P(A_{k})=\sum_{k=1}^{n}P(A_{k})+0}}\\ {{=P(A_{1})+P(A_{2})+\cdots+P(A_{n}).}}\end{array}
$$

(3.2)式得证.

性质iii 设  $A, B$  是两个事件, 若  $A \subset B$ , 则有

$$
P(B - A) = P(B) - P(A), \tag{3.3}
$$

$$
P(B) \geqslant P(A). \tag{3.4}
$$

证由  $A \subset B$  知  $B = A \cup (B - A)$  (参见图1- 1), 且  $A(B - A) = \mathcal{D}$ , 再由概率的有限可加性(3.2), 得

$$
P(B) = P(A) + P(B - A),
$$

(3.3)得证; 又由概率的非负性  $1^{\circ}, P(B - A) \geqslant 0$  知

$$
P(B)\geqslant P(A).
$$

性质iv 对于任一事件  $A$ ,

$$
P(A) \leqslant 1.
$$

证因  $A\subset S$  ,由性质iii得

$$
P(A) \leqslant P(S) = 1.
$$

性质  $\mathbf{v}$  (逆事件的概率) 对于任一事件  $A$ , 有

$$
P(\overline{A}) = 1 - P(A).
$$

证因  $A\cup \overline{A} = S$  ,且  $A\overline{A} = \emptyset$  ,由(3.2)式,得

$$
1 = P(S) = P(A\bigcup \overline{A}) = P(A) + P(\overline{A}).
$$

性质  $\mathbf{v}$  得证.

性质vi(加法公式) 对于任意两事件  $A, B$ , 有

$$
P(A\bigcup B) = P(A) + P(B) - P(AB). \tag{3.5}
$$

证因  $A\bigcup B = A\bigcup (B - AB)$  (参见图1一2),且  $A(B - AB) = \emptyset$ ,  $AB \subset B$ , 故由(3.2)式及(3.3)式得

$$
\begin{array}{c}P(A\bigcup B) = P(A) + P(B - AB) \\ = P(A) + P(B) - P(AB). \end{array}
$$

(3.5)式还能推广到多个事件的情况.例如,设  $A_{1},A_{2},A_{3}$  为任意三个事件,则有

$$
\begin{array}{c}P(A_{1}\bigcup A_{2}\bigcup A_{3}) = P(A_{1}) + P(A_{2}) + P(A_{3}) - P(A_{1}A_{2}) \\ -P(A_{1}A_{3}) - P(A_{2}A_{3}) + P(A_{1}A_{2}A_{3}). \end{array} \tag{3.6}
$$

一般,对于任意  $n$  个事件  $A_{1}, A_{2}, \dots , A_{n}$ , 可以用数学归纳法证得

$$
\begin{array}{l}P(A_{1}\bigcup A_{2}\bigcup \dots \bigcup A_{n}) = \sum_{i = 1}^{n}P(A_{i}) - \sum_{1\leqslant i< j\leqslant n}P(A_{i}A_{j}) \\ +\sum_{1\leqslant i< j< k\leqslant n}P(A_{i}A_{j}A_{k}) + \dots +(-1)^{n - 1}P(A_{1}A_{2}\dots A_{n}). \end{array}
$$

(3.7)

# $\S 4$  等可能概型(古典概型)

$\S 1$  中所说的试验  $E_{1}, E_{4}$ , 它们具有两个共同的特点:

$1^{\circ}$  试验的样本空间只包含有限个元素,

$2^{\circ}$  试验中每个基本事件发生的可能性相同,

具有以上两个特点的试验是大量存在的. 这种试验称为等可能概型. 它在概率论发展初期曾是主要的研究对象, 所以也称为古典概型. 等可能概型的一些概念具有直观、容易理解的特点, 有着广泛的应用.

下面我们来讨论等可能概型中事件概率的计算公式。

设试验的样本空间为  $S = \{e_{1},e_{2},\dots ,e_{n}\}$ 。由于在试验中每个基本事件发生的可能性相同,即有

$$
P(\{e_{1}\}) = P(\{e_{2}\}) = \dots = P(\{e_{n}\}),
$$

又由于基本事件是两两互不相容的,于是

$$
1 = P(S) = P(\{e_{1}\} \cup \{e_{2}\} \cup \dots \cup \{e_{n}\})
$$

$$
= P(\{e_{1}\}) + P(\{e_{2}\}) + \dots +P(\{e_{n}\}) = nP(\{e_{i}\}),
$$

$$
P(\{e_{i}\}) = \frac{1}{n}, \quad i = 1,2,\dots ,n.
$$

若事件  $A$  包含  $k$  个基本事件,即  $A = \{e_{i_{1}}\} \cup \{e_{i_{2}}\} \cup \dots \cup \{e_{i_{k}}\}$ ,这里  $i_{1}, i_{2}, \dots , i_{k}$  是  $1,2,\dots ,n$  中某  $k$  个不同的数,则有

$$
P(A) = \sum_{j = 1}^{k}P(\{e_{i_{j}}\}) = \frac{k}{n} = \frac{A}{S} \text{包含的基本事件数}. \tag{4.1}
$$

(4.1)式就是等可能概型中事件  $A$  的概率的计算公式  $①$

例1将一枚硬币抛掷三次.(1)设事件  $A_{1}$  为"恰有一次出现正面",求  $P(A_{1})$ 。(2)设事件  $A_{2}$  为"至少有一次出现正面",求  $P(A_{2})$

解(1)我们考虑  $\S 1$  中  $E_{2}$  的样本空间:

$$
S_{2} = \{H H H,H H T,H T H,T H H,H T T,T H T,T T H,T T T\} ,
$$

而  $A_{1} = \{H T T,T H T,T T H\}$

$S_{2}$  中包含有限个元素,且由对称性知每个基本事件发生的可能性相同。故由(4.1)式,得

$$
P(A_{1}) = \frac{3}{8}.
$$

(2)由于  $\overline{A}_{2} = \{T T T\}$ ,于是

$$
P(A_{2}) = 1 - P(\overline{A}_{2}) = 1 - \frac{1}{8} = \frac{7}{8}.
$$

当样本空间的元素较多时,我们一般不再将  $S$  中的元素一一列出,而只需分别求出  $S$  中与  $A$  中包含的元素的个数(即基本事件的个数),再由(4.1)式即可求出  $A$  的概率。

例2一个口袋装有6只球,其中4只白球、2只红球。从袋中取球两次,每次随机地取一只。考虑两种取球方式:(a)第一次取一只球,观察其颜色后放回

袋中, 搅匀后再取一球. 这种取球方式叫做放回抽样. (b) 第一次取一球不放回袋中, 第二次从剩余的球中再取一球. 这种取球方式叫做不放回抽样. 试分别就上面两种情况求: (1) 取到的两只球都是白球的概率. (2) 取到的两只球颜色相同的概率. (3) 取到的两只球中至少有一只是白球的概率.

解 (a) 放回抽样的情况.

以  $A, B, C$  分别表示事件"取到的两只球都是白球""取到的两只球都是红球""取到的两只球中至少有一只是白球". 易知"取到两只颜色相同的球"这一事件即为  $A \cup B$ , 而  $C = \overline{B}$ .

在袋中依次取两只球, 每一种取法为一个基本事件, 显然此时样本空间中仅包含有限个元素. 且由对称性知每个基本事件发生的可能性相同, 因而可利用 (4.1) 式来计算事件的概率.

第一次从袋中取球有6只球可供抽取, 第二次也有6只球可供抽取. 由组合法的乘法原理, 共有  $6 \times 6$  种取法. 即样本空间中元素总数为  $6 \times 6$ . 对于事件  $A$  而言, 由于第一次有4只白球可供抽取, 第二次也有4只白球可供抽取, 由乘法原理共有  $4 \times 4$  种取法, 即  $A$  中包含  $4 \times 4$  个元素. 同理,  $B$  中包含  $2 \times 2$  个元素. 于是

$$
P(A) = \frac{4 \times 4}{6 \times 6} = \frac{4}{9}.
$$

$$
P(B) = \frac{2 \times 2}{6 \times 6} = \frac{1}{9}.
$$

由于  $A B = \emptyset$ , 得

$$
P(A \cup B) = P(A) + P(B) = \frac{5}{9}.
$$

$$
P(C) = P(\overline{B}) = 1 - P(B) = \frac{8}{9}.
$$

(b) 不放回抽样的情况.

由读者自己完成.

例3 将  $n$  只球随机地放入  $N$  ( $N \geq n$ ) 个盒子中去, 试求每个盒子至多有一只球的概率 (设盒子的容量不限).

解 将  $n$  只球放入  $N$  个盒子中去, 每一种放法是一基本事件. 易知, 这是古典概型问题. 因每一只球都可以放入  $N$  个盒子中的任一个盒子, 故共有  $N \times N \times \dots \times N = N^n$  种不同的放法, 而每个盒子中至多放一只球共有  $N(N - 1) \dots [N - (n - 1)]$  种不同放法. 因而所求的概率为

$$
p = \frac{N(N - 1) \cdots(N - n + 1)}{N^n} = \frac{A_N^n}{N^n}.
$$

有许多问题和本例具有相同的数学模型。例如,假设每人的生日在一年365天中的任一天是等可能的,即都等于1/365,那么随机选取  $n$  (  $n \leqslant 365$  ) 个人,他们的生日各不相同的概率为

$$
\frac{365 \times 364 \times \cdots \times (365 - n + 1)}{365^n}.
$$

因而,  $n$  个人中至少有两人生日相同的概率为

$$
p = 1 - \frac{365 \times 364 \times \cdots \times (365 - n + 1)}{365^n}.
$$

经计算可得下述结果:

<table><tr><td>n</td><td>20</td><td>23</td><td>30</td><td>40</td><td>50</td><td>64</td><td>100</td></tr><tr><td>p</td><td>0.411</td><td>0.507</td><td>0.706</td><td>0.891</td><td>0.970</td><td>0.997</td><td>0.999 999 7</td></tr></table>

从上表可看出,在仅有64人的班级里,"至少有两人生日相同"这一事件的概率与1相差无几,因此,如作调查的话,几乎总是会出现的。读者不妨试一试。

例4 设有  $N$  件产品,其中有  $D$  件次品,今从中任取  $n$  件,问其中恰有  $k$  (  $k \leqslant D$  ) 件次品的概率是多少?

解在  $N$  件产品中抽取  $n$  件(这里是指不放回抽样),所有可能的取法共有  $\binom{N}{n}^{\textregistered}$  种,每一种取法为一基本事件,且由于对称性知每个基本事件发生的可能性相同.又因在  $D$  件次品中取  $k$  件,所有可能的取法有  $\binom{D}{k}$  种.在  $N - D$  件正品中取  $n - k$  件所有可能的取法有  $\binom{N- D}{n- k}$  种,由乘法原理知在  $N$  件产品中取  $n$  件,其中恰有  $k$  件次品的取法共有  $\binom{D}{k}\binom{N- D}{n- k}$  种,于是所求概率为

$$
p = \binom{D}{k}\binom{N- D}{n- k} \Big/ \binom{N}{n}. \tag{4.2}
$$

(4.2)式即所谓超几何分布的概率公式。

例5 袋中有  $a$  只白球、  $b$  只红球,  $k$  个人依次在袋中取一只球,(1)作放回抽样;(2)作不放回抽样,求第  $i$ $(i = 1,2,\dots ,k)$  人取到白球(记为事件  $B$  )的概率  $(k\leqslant a + b)$ 。

解(1)放回抽样的情况,显然有

$$
P(B) = \frac{a}{a + b}.
$$

(2)不放回抽样的情况,各人取一只球,每种取法是一个基本事件,共有  $(a + b)(a + b - 1)\dots (a + b - k + 1) = A_{a + b}^{k}$  个基本事件,且由于对称性知每个基本事件发生的可能性相同,当事件  $B$  发生时,第  $i$  人取的应是白球,它可以是  $a$  只白球中的任一只,有  $a$  种取法,其余被取的  $k - 1$  只球可以是其余  $a + b - 1$  只球中的任意  $k - 1$  只,共有  $(a + b - 1)(a + b - 2)\dots [a + b - 1 - (k - 1) + 1] = A_{a + b - 1}^{k - 1}$  种取法,于是事件  $B$  中包含  $a\cdot A_{a + b - 1}^{k - 1}$  个基本事件,故由(4.1)式得到

$$
P(B) = a\cdot A_{a + b - 1}^{k - 1} / A_{a + b}^{k} = \frac{a}{a + b}.
$$

值得注意的是  $P(B)$  与  $i$  无关,即  $k$  个人取球,尽管取球的先后次序不同,各人取到白球的概率是一样的,大家机会相同(例如在购买福利彩票时,各人得奖的机会是一样的).另外还值得注意的是放回抽样的情况与不放回抽样的情况下  $P(B)$  是一样的.

例6 在  $1\sim 2000$  的整数中随机地取一个数,问取到的整数既不能被6整除,又不能被8整除的概率是多少?

解设  $A$  为事件"取到的数能被6整除",  $B$  为事件"取到的数能被8整除",则所求概率为

$$
\begin{array}{c}{{P(\overline{{{A}}}\overline{{{B}}})=P(\overline{{{A}}}\overline{{{U}}}\overline{{{B}}})=1-P(A\bigcup B)}}\\ {{=1-[P(A)+P(B)-P(A B)].}}\end{array}
$$

由于  $333< \frac{2000}{6} < 334$

故得  $P(A) = \frac{333}{2000}$ .

由于  $\frac{2000}{8} = 250$

故得  $P(B) = \frac{250}{2000}$ .

又由于一个数同时能被6与8整除,就相当于能被24整除,因此,由

$$
83< \frac{2000}{24} < 84,
$$

得  $P(AB) = \frac{83}{2000}$ .

于是所求概率为

$$
\scriptstyle p = 1 - \left(\frac{333}{2000} +\frac{250}{2000} -\frac{83}{2000}\right) = \frac{3}{4}.
$$

例7 将15名新生随机地平均分配到三个班级中去, 这15名新生中有3名是优秀生. 问(1)每个班级各分配到一名优秀生的概率是多少?(2)3名优秀生分配在同一班级的概率是多少?

解 15名新生平均分配到三个班级中的分法总数为

$$
\binom{15}{5}\binom{10}{5}\binom{5}{5}=\frac{15!}{5!5!5!}.
$$

每一种分配法为一基本事件, 且由对称性易知每个基本事件发生的可能性相同.

(1)将3名优秀生分配到三个班级使每个班级都有一名优秀生的分法共3!种. 对于这每一种分法, 其余12名新生平均分配到三个班级中的分法共有  $\frac{12!}{4!4!4!}$  种. 因此, 每一班级各分配到一名优秀生的分法共有  $\frac{3!12!}{4!4!4!}$  种. 于是所求概率为

$$
p_{1} = \frac{3!12!}{4!4!4!}\Big / \frac{15!}{5!5!5!} = \frac{25}{91}.
$$

(2)将3名优秀生分配在同一班级的分法共有3种. 对于这每一种分法, 其余12名新生的分法(一个班级2名, 另两个班级各5名)有  $\frac{12!}{2!5!5!}$  种. 因此3名优秀生分配在同一班级的分法共有  $\frac{3\times12!}{2!5!5!}$  种, 于是, 所求概率为

$$
p_{2} = \frac{3\times12!}{2!5!5!}\Big / \frac{15!}{5!5!5!} = \frac{6}{91}.
$$

例8 某接待站在某一周曾接待过12次来访, 已知所有这12次接待都是在周二和周四进行的, 问是否可以推断接待时间是有规定的?

解 假设接待站的接待时间没有规定, 而各来访者在一周的任一天中去接待站是等可能的, 那么, 12次接待来访者都在周二、周四的概率为

$$
\frac{2^{12}}{7^{12}} = 0.0000003.
$$

人们在长期的实践中总结得到"概率很小的事件在一次试验中实际上几乎是不发生的"(称之为实际推断原理). 现在概率很小的事件在一次试验中竟然发生了, 因此有理由怀疑假设的正确性, 从而推断接待站不是每天都接待来访者, 即认为其接待时间是有规定的.

# $\S 5$  条件概率

# (一)条件概率

条件概率是概率论中的一个重要而实用的概念.所考虑的是事件  $A$  已发生的条件下事件  $B$  发生的概率.先举一个例子.

例1将一枚硬币抛掷两次,观察其出现正反面的情况.设事件  $A$  为"至少有一次为  $H^{\prime \prime}$  ,事件  $B$  为"两次掷出同一面".现在来求已知事件  $A$  已经发生的条件下事件  $B$  发生的概率.

这里,样本空间为  $S = \{H H,H T,T H,T T\} ,A = \{H H,H T,T H\} ,B =$ $\{H H,T T\}$  .易知此属古典概型问题.已知事件  $A$  已发生,有了这一信息,知道TT不可能发生,即知试验所有可能结果所成的集合就是A.A中共有3个元素,其中只有  $H H\in B$  .于是,在事件  $A$  发生的条件下事件  $B$  发生的概率(记为 $P(B|A))$  为

$$
P(B|A) = \frac{1}{3}.
$$

在这里,我们看到  $P(B) = 2 / 4\neq P(B|A)$  .这是很容易理解的,因为在求 $P(B|A)$  时我们是限制在事件  $A$  已经发生的条件下考虑事件  $B$  发生的概率的.

另外,易知

$$
P(A) = \frac{3}{4},\quad P(AB) = \frac{1}{4},\quad P(B|A) = \frac{1}{3} = \frac{1 / 4}{3 / 4},
$$

故有

$$
P(B|A) = \frac{P(AB)}{P(A)}. \tag{5.1}
$$

对于一般古典概型问题,若仍以  $P(B|A)$  记事件  $A$  已经发生的条件下事件 $B$  发生的概率,则关系式(5.1)仍然成立.事实上,设试验的基本事件总数为  $n,A$  所包含的基本事件数为  $m$ $(m > 0)$  ,AB所包含的基本事件数为  $k$  ,即有

$$
P(B|A) = \frac{k}{m} = \frac{k / n}{m / n} = \frac{P(AB)}{P(A)}.
$$

在一般场合,我们将上述关系式作为条件概率的定义,

定义设  $A,B$  是两个事件,且  $P(A) > 0$  ,称

$$
P(B|A) = \frac{P(AB)}{P(A)} \tag{5.2}
$$

为在事件  $A$  发生的条件下事件  $B$  发生的条件概率,

不难验证,条件概率  $P(\cdot |A)$  符合概率定义中的三个条件,即

$1^{\circ}$  非负性:对于每一事件  $B$ ,有  $P(B|A) \geq 0$

$2^{\circ}$  规范性:对于必然事件  $S$ ,有  $P(S|A) = 1$

$3^{\circ}$  可列可加性:设  $B_{1}, B_{2}, \dots$  是两两互不相容的事件,则有

$$
P\Big(\bigcup_{i = 1}^{\infty}B_{i}\big|A\Big) = \sum_{i = 1}^{\infty}P(B_{i}\mid A).
$$

由于条件概率符合上述三个条件,故 §3 中对概率所证明的一些重要结果都适用于条件概率。例如,对于任意事件  $B_{1}, B_{2}$  有

$$
P(B_{1} \bigcup B_{2} |A) = P(B_{1} |A) + P(B_{2} |A) - P(B_{1} B_{2} |A).
$$

例2一盒子装有4只产品,其中有3只一等品,1只二等品。从中取产品两次,每次任取一只,作不放回抽样。设事件  $A$  为"第一次取到的是一等品",事件  $B$  为"第二次取到的是一等品"。试求条件概率  $P(B|A)$ 。

解易知此属古典概型问题.将产品编号,1,2,3号为一等品;4号为二等品.以  $(i,j)$  表示第一次、第二次分别取到第  $i$  号、第  $j$  号产品.试验  $E$  (取产品两次,记录其号码)的样本空间为

$$
S = \{(1,2), (1,3), (1,4), (2,1), (2,3), (2,4), \dots , (4,1), (4,2), (4,3)\} ,
$$

$$
A = \{(1,2), (1,3), (1,4), (2,1), (2,3), (2,4), (3,1), (3,2), (3,4)\} ,
$$

$$
A B = \{(1,2), (1,3), (2,1), (2,3), (3,1), (3,2)\} .
$$

按(5.2)式,得条件概率

$$
P(B|A) = \frac{P(AB)}{P(A)} = \frac{6 / 12}{9 / 12} = \frac{2}{3}.
$$

也可以直接按条件概率的含义来求  $P(B|A)$ 。我们知道,当事件  $A$  发生以后,试验  $E$  所有可能结果的集合就是  $A, A$  中有9个元素,其中只有(1,2),  $(1,3), (2,1), (2,3), (3,1), (3,2)$  属于  $B$ ,故可得

$$
P(B|A) = \frac{6}{9} = \frac{2}{3}.
$$

# (二)乘法定理

由条件概率的定义(5.2),立即可得下述定理

乘法定理 设  $P(A) > 0$ ,则有

$$
P(AB) = P(B|A)P(A). \tag{5.3}
$$

(5.3)式称为乘法公式。

(5.3)式容易推广到多个事件的积事件的情况。例如,设  $A, B, C$  为事件,且  $P(AB) > 0$ ,则有

$$
P(ABC) = P(C|AB)P(B|A)P(A). \tag{5.4}
$$

在这里,注意到由假设  $P(AB) > 0$  可推得  $P(A) \geqslant P(AB) > 0$ .

一般,设  $A_{1},A_{2},\dots ,A_{n}$  为  $n$  个事件,  $n\geqslant 2$  ,且  $P(A_{1}A_{2}\dots A_{n - 1}) > 0$  ,则有

$$
P(A_{1}A_{2}\dots A_{n}) = P(A_{n}|A_{1}A_{2}\dots A_{n - 1})P(A_{n - 1}|A_{1}A_{2}\dots A_{n - 2})\dots P(A_{2}|A_{1})P(A_{1}).
$$

(5.5)

例3 设袋中装有  $r$  只红球,  $t$  只白球. 每次自袋中任取一只球, 观察其颜色然后放回, 并再放入  $a$  只与所取出的那只球同色的球. 若在袋中连续取球四次, 试求第一、二次取到红球且第三、四次取到白球的概率.

解以  $A_{i}(i = 1,2,3,4)$  表示事件"第  $i$  次取到红球",则  $\overline{{A}}_{3},\overline{{A}}_{4}$  分别表示事件第三、四次取到白球.所求概率为

$$
\begin{array}{c}{{P(A_{1}A_{2}\overline{{{A}}}_{3}\overline{{{A}}}_{4})=P(\overline{{{A}}}_{4}\mid A_{1}A_{2}\overline{{{A}}}_{3})P(\overline{{{A}}}_{3}\mid A_{1}A_{2})P(A_{2}\mid A_{1})P(A_{1})}}\\ {{=\frac{t+a}{r+t+3a}\cdot\frac{t}{r+t+2a}\cdot\frac{r+a}{r+t+a}\cdot\frac{r}{r+t}.}}\end{array}
$$

例4 设某光学仪器厂制造的透镜,第一次落下时打破的概率为  $1 / 2$ ,若第一次落下未打破,第二次落下打破的概率为  $7 / 10$ ,若前两次落下未打破,第三次落下打破的概率为  $9 / 10$ . 试求透镜落下三次而未打破的概率.

解以  $A_{i}(i = 1,2,3)$  表示事件"透镜第  $i$  次落下打破",以  $B$  表示事件"透镜落下三次而未打破". 因为  $B = \overline{{A}}_{1}\overline{{A}}_{2}\overline{{A}}_{3}$ ,故有

$$
\begin{array}{c}{{P(B)=P(\overline{{{A}}}_{1}\overline{{{A}}}_{2}\overline{{{A}}}_{3})=P(\overline{{{A}}}_{3}\mid\overline{{{A}}}_{1}\overline{{{A}}}_{2})P(\overline{{{A}}}_{2}\mid\overline{{{A}}}_{1})P(\overline{{{A}}}_{1})}}\\ {{=\left(1-\frac{9}{10}\right)\left(1-\frac{7}{10}\right)\left(1-\frac{1}{2}\right)=\frac{3}{200}.}}\end{array}
$$

另解,按题意

$$
\overline{{B}} = A_{1}\cup \overline{{A}}_{1}A_{2}\cup \overline{{A}}_{1}\overline{{A}}_{2}A_{3}.
$$

而  $A_{1},\overline{{A}}_{1}A_{2},\overline{{A}}_{1}\overline{{A}}_{2}A_{3}$  是两两互不相容的事件,故有

$$
P(\overline{{B}}) = P(A_{1}) + P(\overline{{A}}_{1}A_{2}) + P(\overline{{A}}_{1}\overline{{A}}_{2}A_{3}).
$$

已知  $P(A_{1}) = \frac{1}{2},P(A_{2}\mid \overline{{A}}_{1}) = \frac{7}{10},P(A_{3}\mid \overline{{A}}_{1}\overline{{A}}_{2}) = \frac{9}{10}$ ,即有

$$
P(\overline{{A}}_{1}A_{2}) = P(A_{2}\mid \overline{{A}}_{1})P(\overline{{A}}_{1}) = \frac{7}{10}\left(1 - \frac{1}{2}\right) = \frac{7}{20},
$$

$$
P(\overline{{A}}_{1}\overline{{A}}_{2}A_{3}) = P(A_{3}\mid \overline{{A}}_{1}\overline{{A}}_{2})P(\overline{{A}}_{2}\mid \overline{{A}}_{1})P(\overline{{A}}_{1})
$$

$$
= \frac{9}{10}\left(1 - \frac{7}{10}\right)\left(1 - \frac{1}{2}\right) = \frac{27}{200}.
$$

故得  $P(\overline{{B}}) = \frac{1}{2} +\frac{7}{20} +\frac{27}{200} = \frac{197}{200},$

$$
P(B) = 1 - \frac{197}{200} = \frac{3}{200}.
$$

# (三)全概率公式和贝叶斯公式

下面建立两个用来计算概率的重要公式.先介绍样本空间的划分的定义.

定义设  $s$  为试验  $E$  的样本空间,  $B_{1},B_{2},\dots ,B_{n}$  为  $E$  的一组事件.若

(i)  $B_{i}B_{j} = \emptyset ,i\neq j,i\neq j = 1,2,\dots ,n.$

(ii)  $B_{1}\cup B_{2}\cup \dots \cup B_{n} = S$

则称  $B_{1},B_{2},\dots ,B_{n}$  为样本空间  $s$  的一个划分.

若  $B_{1},B_{2},\dots ,B_{n}$  是样本空间的一个划分,那么,对每次试验,事件  $B_{1}$ $B_{2},\dots ,B_{n}$  中必有一个且仅有一个发生.

例如,设试验  $E$  为"掷一颗骰子观察其点数".它的样本空间为  $S = \{1,2,3$ $4,5,6\} .E$  的一组事件  $B_{1} = \{1,2,3\} ,B_{2} = \{4,5\} ,B_{3} = \{6\}$  是  $s$  的一个划分.而事件组  $C_{1} = \{1,2,3\} ,C_{2} = \{3,4\} ,C_{3} = \{5,6\}$  不是  $s$  的划分.

定理1设试验  $E$  的样本空间为  $s,A$  为  $E$  的事件,  $B_{1},B_{2},\dots ,B_{n}$  为  $s$  的一个划分,且  $P(B_{i}) > 0(i = 1,2,\dots ,n)$  ,则

$$
P(A) = P(A|B_{1})P(B_{1}) + P(A|B_{2})P(B_{2}) + \dots +P(A|B_{n})P(B_{n}). \tag{5.6}
$$

(5.6)式称为全概率公式.

在很多实际问题中  $P(A)$  不易直接求得,但却容易找到  $s$  的一个划分  $B_{1}$ $B_{2},\dots ,B_{n}$  ,且  $P(B_{i})$  和  $P(A|B_{i})$  或为已知,或容易求得,那么就可以根据(5.6)式求出  $P(A)$

证因为

$$
A = A S = A(B_{1}\bigcup B_{2}\bigcup \dots \bigcup B_{n}) = A B_{1}\bigcup A B_{2}\bigcup \dots \bigcup A B_{n},
$$

由假设  $P(B_{i}) > 0(i = 1,2,\dots ,n)$  ,且  $(A B_{i})(A B_{j}) = \emptyset ,i\neq j,i,j = 1,2,\dots ,n$  得到

$$
\begin{array}{r l} & {P(A) = P(A B_{1}) + P(A B_{2}) + \dots +P(A B_{n})}\\ & {\qquad = P(A|B_{1})P(B_{1}) + P(A|B_{2})P(B_{2}) + \dots +P(A|B_{n})P(B_{n}).} \end{array}
$$

另一个重要公式是下述的贝叶斯公式,

定理2设试验  $E$  的样本空间为  $s.A$  为  $E$  的事件,  $B_{1},B_{2},\dots ,B_{n}$  为  $s$  的一个划分,且  $P(A) > 0,P(B_{i}) > 0(i = 1,2,\dots ,n)$  ,则

$$
P(B_{i}\mid A) = \frac{P(A\mid B_{i})P(B_{i})}{\sum_{j = 1}^{n}P(A\mid B_{j})P(B_{j})},\quad i = 1,2,\dots ,n. \tag{5.7}
$$

(5.7)式称为贝叶斯(Bayes)公式  $①$

证 由条件概率的定义及全概率公式即得

$$
P(B_{i} \mid A) = \frac{P(B_{i}A)}{P(A)} = \frac{P(A \mid B_{i})P(B_{i})}{\sum_{j = 1}^{n}P(A \mid B_{j})P(B_{j})}, \quad i = 1,2,\dots ,n.
$$

特别在(5.6)式,(5.7)式中取  $n = 2$ ,并将  $B_{1}$  记为  $B_{2}$ ,此时  $B_{2}$  就是  $\overline{B}$ ,那么,全概率公式和贝叶斯公式分别成为

$$
P(A) = P(A \mid B)P(B) + P(A \mid \overline{B})P(\overline{B}), \tag{5.8}
$$

$$
P(B \mid A) = \frac{P(AB)}{P(A)} = \frac{P(A \mid B)P(B)}{P(A \mid B)P(B) + P(A \mid \overline{B})P(\overline{B})}. \tag{5.9}
$$

这两个公式是常用的.

例5 某电子设备制造厂所用的元件是由三家元件制造厂提供的.根据以往的记录有以下的数据:

<table><tr><td>元件制造厂</td><td>次品率</td><td>提供元件的份额</td></tr><tr><td>1</td><td>0.02</td><td>0.15</td></tr><tr><td>2</td><td>0.01</td><td>0.80</td></tr><tr><td>3</td><td>0.03</td><td>0.05</td></tr></table>

设这三家工厂的产品在仓库中是均匀混合的,且无区别的标志.(1)在仓库中随机地取一只元件,求它是次品的概率.(2)在仓库中随机地取一只元件,若已知取到的是次品,为分析此次品出自何厂,需求出此次品由三家工厂生产的概率分别是多少.试求这些概率.

解 设  $A$  表示"取到的是一只次品",  $B_{i}(i = 1,2,3)$  表示"所取到的产品是由第  $i$  家工厂提供的".易知,  $B_{1},B_{2},B_{3}$  是样本空间  $S$  的一个划分,且有

$$
P(B_{1}) = 0.15, \quad P(B_{2}) = 0.80, \quad P(B_{3}) = 0.05,
$$

$$
P(A|B_{1}) = 0.02, \quad P(A|B_{2}) = 0.01, \quad P(A|B_{3}) = 0.03.
$$

(1)由全概率公式,

$$
P(A) = P(A|B_{1})P(B_{1}) + P(A|B_{2})P(B_{2}) + P(A|B_{3})P(B_{3}) = 0.0125.
$$

(2)由贝叶斯公式,

$$
P(B_{1} \mid A) = \frac{P(A|B_{1})P(B_{1})}{P(A)} = \frac{0.02 \times 0.15}{0.0125} = 0.24.
$$

$$
P(B_{2} \mid A) = 0.64, \quad P(B_{3} \mid A) = 0.12.
$$

以上结果表明,这只次品来自第2家工厂的可能性最大.

例6 据美国的一份资料报道,在美国总的来说患肺癌的概率约为  $0.1\%$ ,

在人群中有  $20\%$  是吸烟者, 他们患肺癌的概率约为  $0.4\%$ , 求不吸烟者患肺癌的概率是多少.

解以  $c$  记事件"患肺癌",以  $A$  记事件"吸烟",按题意  $P(C) = 0.001$ $P(A) = 0.20,P(C|A) = 0.004.$  需要求条件概率  $P(C|\overline{{A}})$  .由全概率公式有

$$
P(C) = P(C|A)P(A) + P(C|\overline{{A}})P(\overline{{A}}).
$$

将数据代入, 得

$$
\begin{array}{r l} & {0.001 = 0.004\times 0.20 + P(C|\overline{{A}})P(\overline{{A}})}\\ & {\qquad = 0.004\times 0.20 + P(C|\overline{{A}})\times 0.80,}\\ & {P(C|\overline{{A}}) = 0.00025.} \end{array}
$$

例7对以往数据分析结果表明, 当机器调整得良好时, 产品的合格率为  $98\%$ , 而当机器发生某种故障时, 其合格率为  $55\%$ . 每天早上机器开动时, 机器调整良好的概率为  $95\%$ . 试求已知某日早上第一件产品是合格品时, 机器调整良好的概率是多少.

解设  $A$  为事件"产品合格",  $B$  为事件"机器调整良好". 已知  $P(A|B) = 0.98, P(A|\overline{B}) = 0.55, P(\overline{B}) = 0.95, P(\overline{B}) = 0.05$ , 所需求的概率为  $P(B|A)$ . 由贝叶斯公式

$$
\begin{array}{r l} & {P(B|A) = \frac{P(A|B)P(B)}{P(A|B)P(B) + P(A|\overline{{B}})P(\overline{{B}})}}\\ & {\qquad = \frac{0.98\times0.95}{0.98\times0.95 + 0.55\times0.05} = 0.97.} \end{array}
$$

这就是说, 当生产出第一件产品是合格品时, 此时机器调整良好的概率为  $0.97$ . 这里, 概率  $0.95$  是由以往的数据分析得到的, 叫做先验概率. 而在得到信息 (即生产出的第一件产品是合格品) 之后再重新加以修正的概率 (即  $0.97$ ) 叫做后验概率. 有了后验概率我们就能对机器的情况有进一步的了解.  $\square$

例8根据以往的临床记录,某种诊断癌症的试验具有如下的效果:若以 $A$  表示事件"试验反应为阳性",以  $c$  表示事件"被诊断者患有癌症",则有 $P(A|C) = 0.95,P(\overline{{A}} |\overline{{C}}) = 0.95.$  现在对自然人群进行普查,设被试验的人患有癌症的概率为0.005,即  $P(C) = 0.005$  ,试求  $P(C|A)$

解已知  $P(A|C) = 0.95,P(A|\overline{{C}}) = 1 - P(\overline{{A}} |\overline{{C}}) = 0.05,P(C) = 0.005,$ $P(\overline{{C}}) = 0.995$  ,由贝叶斯公式,

$$
P(C|A) = \frac{P(A|C)P(C)}{P(A|C)P(C) + P(A|\overline{{C}})P(\overline{{C}})} = 0.087.
$$

本题的结果表明, 虽然  $P(A|C) = 0.95, P(\overline{A} |\overline{C}) = 0.95$ , 这两个概率都比较高. 但若将此试验用于普查, 则有  $P(C|A) = 0.087$ , 亦即其正确性只有  $8.7\%$  (平均

1000个具有阳性反应的人中大约只有87人确患有癌症).如果不注意这一点,将会得出错误的诊断,这也说明,若将  $P(A|C)$  和  $P(C|A)$  混淆则会造成不良的后果.  $\square$

# $\S 6$  独立性

设  $A,B$  是试验  $E$  的两事件.若  $P(A) > 0$  ,可以定义  $P(B|A)$  .一般,  $A$  的发生对  $B$  发生的概率是有影响的,这时  $P(B|A)\neq P(B)$  ,只有在这种影响不存在时才会有  $P(B|A) = P(B)$  ,这时有

$$
P(A B) = P(B|A)P(A) = P(A)P(B).
$$

例1设试验  $E$  为"抛甲、乙两枚硬币,观察正反面出现的情况".设事件  $A$  为"甲币出现  $H^{\prime \prime}$  ,事件  $B$  为"乙币出现  $H^{\prime \prime}.E$  的样本空间为

$$
S = \{H H,H T,T H,T T\} .
$$

由(4.1)式得

$$
P(A) = \frac{2}{4} = \frac{1}{2}, P(B) = \frac{2}{4} = \frac{1}{2},
$$

$$
P(B|A) = \frac{1}{2}, P(AB) = \frac{1}{4}.
$$

在这里我们看到  $P(B|A) = P(B)$  ,而  $P(AB) = P(A)P(B)$  .事实上,由题意,显然甲币是否出现正面与乙币是否出现正面是互不影响的.  $\square$

定义设  $A,B$  是两事件,如果满足等式

$$
P(AB) = P(A)P(B), \tag{6.1}
$$

则称事件  $A,B$  相互独立,简称  $A,B$  独立.

容易知道,若  $P(A) > 0,P(B) > 0$  ,则  $A,B$  相互独立与  $A,B$  互不相容不能同时成立.

定理1设  $A,B$  是两事件,且  $P(A) > 0$  .若  $A,B$  相互独立,则  $P(B|A) =$ $P(B)$  .反之亦然.

定理1的正确性是显然的.

定理2若事件  $A$  与  $B$  相互独立,则下列各对事件也相互独立:

证因为  $A = A(B\bigcup \overline{{B}}) = A B\bigcup A\overline{{B}}$  ,得

$$
P(A) = P(AB\bigcup A\overline{{B}}) = P(AB) + P(A\overline{{B}})
$$

$$
= P(A)P(B) + P(A\overline{{B}}),
$$

$$
P(A\overline{{B}}) = P(A)\big[1 - P(B)\big] = P(A)P(\overline{{B}}).
$$

因此  $A$  与  $\overline{B}$  相互独立. 由此可立即推出  $\overline{A}$  与  $\overline{B}$  相互独立. 再由  $\overline{B} = B$ , 又推出  $\overline{A}$  与  $B$  相互独立.  $\square$

下面我们将独立性的概念推广到三个事件的情况,

定义 设  $A, B, C$  是三个事件, 如果满足等式

$$
\left. \begin{array}{l}P(AB) = P(A)P(B), \\ P(BC) = P(B)P(C), \\ P(AC) = P(A)P(C), \\ P(ABC) = P(A)P(B)P(C), \end{array} \right\} \tag{6.2}
$$

则称事件  $A, B, C$  相互独立.

一般, 设  $A_{1}, A_{2}, \dots , A_{n}$  是  $n$ $(n \geqslant 2)$  个事件, 如果对于其中任意 2 个, 任意 3 个,  $\dots$ , 任意  $n$  个事件的积事件的概率, 都等于各事件概率之积, 则称事件  $A_{1}, A_{2}, \dots , A_{n}$  相互独立.

由定义, 可以得到以下两个推论.

$1^{\circ}$  若事件  $A_{1}, A_{2}, \dots , A_{n} (n \geqslant 2)$  相互独立, 则其中任意  $k$ $(2 \leqslant k \leqslant n)$  个事件也是相互独立的.

$2^{\circ}$  若  $n$  个事件  $A_{1}, A_{2}, \dots , A_{n} (n \geqslant 2)$  相互独立, 则将  $A_{1}, A_{2}, \dots , A_{n}$  中任意多个事件换成它们各自的对立事件, 所得的  $n$  个事件仍相互独立.

$1^{\circ}$  由独立性定义可直接推出.  $2^{\circ}$  从直观上看是显然的. 对于  $n = 2$  时, 在定理 2 处已作了证明, 一般的情况由数学归纳法容易证得, 此处略.

两事件相互独立的含义是它们中一个已发生, 不影响另一个发生的概率. 在实际应用中, 对于事件的独立性常常是根据事件的实际意义去判断. 一般, 若由实际情况分析,  $A, B$  两事件之间没有关联或关联很微弱, 那就认为它们是相互独立的. 例如  $A, B$  分别表示甲、乙两人患感冒. 如果甲、乙两人的活动范围相距甚远, 就认为  $A, B$  相互独立. 若甲、乙两人是同住在一个房间里的, 那就不能认为  $A, B$  相互独立了.

例2一个元件(或系统)能正常工作的概率称为元件(或系统)的可靠性.如图1一8,设有4个独立工作的元件1,2,3,4按先串联再并联的方式连接(称为串并联系统).设第  $i$  个元件的可靠性为  $\boldsymbol{\mathscr{p}}_{i}(i = 1,2,3,4)$  ,试求系统的可靠性.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
图1-8

解 以  $A_{i} (i = 1,2,3,4)$  表示事件"第  $i$  个元件正常工作", 以  $A$  表示事件"系统正常工作".

系统由两条线路 I 和 II 组成 (如图 1- 8). 当且仅当至少有一条线路中的两

个元件均正常工作时这一系统正常工作,故有

$$
A = A_{1}A_{2} \cup A_{3}A_{4}.
$$

由事件的独立性,得系统的可靠性

$$
\begin{array}{r l} & {P(A) = P(A_{1}A_{2}) + P(A_{3}A_{4}) - P(A_{1}A_{2}A_{3}A_{4})}\\ & {\qquad = P(A_{1})P(A_{2}) + P(A_{3})P(A_{4}) - P(A_{1})P(A_{2})P(A_{3})P(A_{4})}\\ & {\qquad = p_{1}p_{2} + p_{3}p_{4} - p_{1}p_{2}p_{3}p_{4}.} \end{array}
$$

例3要验收一批(100件)乐器.验收方案如下:自该批乐器中随机地取3件测试(设3件乐器的测试的结果是相互独立的),如果3件中至少有一件在测试中被认为音色不纯,则这批乐器就被拒绝接收.设一件音色不纯的乐器经测试查出其为音色不纯的概率为0.95,而一件音色纯的乐器经测试被误认为不纯的概率为0.01. 如果已知这100件乐器中恰有4件是音色不纯的,试问这批乐器被接收的概率是多少?

解设以  $H_{i}(i = 0,1,2,3)$  表示事件"随机地取出3件乐器,其中恰有  $i$  件音色不纯",  $H_{0}, H_{1}, H_{2}, H_{3}$  是  $S$  的一个划分,以  $A$  表示事件"这批乐器被接收"已知一件音色纯的乐器,经测试被认为音色纯的概率为0.99,而一件音色不纯的乐器,经测试被误认为音色纯的概率为0.05,并且3件乐器的测试的结果是相互独立的,于是有

$$
P(A \mid H_{0}) = 0.99^{3}, \quad P(A \mid H_{1}) = 0.99^{2} \times 0.05,
$$

$$
P(A \mid H_{2}) = 0.99 \times 0.05^{2}, \quad P(A \mid H_{3}) = 0.05^{3},
$$

而

$$
P(H_{0})=\binom{96}{3}\binom{100}{3}, \quad P(H_{1})=\binom{4}{1}\binom{96}{2}\binom{100}{3},
$$

$$
P(H_{2})=\binom{4}{2}\binom{96}{1}\binom{100}{3}, \quad P(H_{3})=\binom{4}{3}\binom{100}{3}.
$$

故  $P(A) = \sum_{i = 0}^{3} P(A \mid H_{i}) P(H_{i}) = 0.8574 + 0.0055 + 0 + 0 = 0.8629$ .

例4甲、乙两人进行乒乓球比赛,每局甲胜的概率为  $\boldsymbol {\mathscr{p}}, \boldsymbol {\mathscr{p}} \geqslant 1 / 2$  问对甲而言,采用三局二胜制有利,还是采用五局三胜制有利?设各局胜负相互独立.

解采用三局二胜制,甲最终获胜,其胜局的情况是:"甲甲"或"乙甲甲"或"甲乙甲"。而这3种结局互不相容,于是由独立性得甲最终获胜的概率为

$$
p_{1} = p^{2} + 2p^{2}(1 - p).
$$

采用五局三胜制,甲最终获胜,至少需比赛三局(可能赛三局,也可能赛四局或五局),且最后一局必须是甲胜,而前面甲需胜二局。例如,共赛四局,则甲的胜局情况是:"甲乙甲甲""乙甲甲甲""甲甲乙甲",且这3种结局互不相容。由独

立性得在五局三胜制下甲最终获胜的概率为

$$
p_{2} = p^{3} + \binom{3}{2} p^{3}(1 - p) + \binom{4}{2} p^{3}(1 - p)^{2},
$$

而

$$
p_{2} - p_{1} = p^{2}(6p^{3} - 15p^{2} + 12p - 3) = 3p^{2}(p - 1)^{2}(2p - 1).
$$

当  $p > \frac{1}{2}$  时  $p_{2} > p_{1}$ ,当  $p = \frac{1}{2}$  时  $p_{2} = p_{1} = \frac{1}{2}$ . 故当  $p > \frac{1}{2}$  时,对甲来说采用五局三胜制更为有利.当  $p = \frac{1}{2}$  时两种赛制甲、乙最终获胜的概率是相同的,都是  $50\%$ .

# 小结

随机试验的全部可能结果组成的集合  $S$  称为样本空间.样本空间  $S$  的子集称为事件,当且仅当这一子集中的一个样本点出现时,称这一事件发生,事件是一个集合,因而事件间的关系与事件的运算自然按照集合论中集合之间的关系和集合的运算来处理,集合间的关系和集合的运算,读者是熟悉的,重要的是要知道它们在概率论中的含义.

在一次试验中,一个事件(除必然事件与不可能事件外)可能发生也可能不发生,其发生的可能性的大小是客观存在的,事件发生的频率以及它的稳定性,表明能用一个数来表征事件在一次试验中发生的可能性的大小,我们从频率的稳定性及频率的性质得到启发和抽象,给出了概率的定义,我们定义了一个集合(事件)的函数  $P(\cdot)$ ,它满足三条基本性质:  $1^{\circ}$  非负性,  $2^{\circ}$  规范性,  $3^{\circ}$  可列可加性,这一函数的函数值  $P(A)$  就定义为事件  $A$  的概率.

概率的定义只给出概率必须满足的三条基本性质,并未对事件  $A$  的概率  $P(A)$  给定一个具体的数.只在古典概型的情况,对于每个事件  $A$  给出了概率  $P(A) = k / n$  ((4.1)式).一般,我们可以进行大量的重复试验,得到事件  $A$  的频率,而以频率作为  $P(A)$  的近似值.或者根据概率的性质分析,得到  $P(A)$  的取值.

在古典概型中,我们证明了条件概率的公式

$$
P(B\mid A) = \frac{P(AB)}{P(A)},\qquad P(A) > 0. \tag{5.2}
$$

在一般的情况,(5.2)式则作为条件概率的定义.固定  $A$ ,条件概率  $P(\cdot \mid A)$  具有概率定义中的三条基本性质,因而条件概率是一种概率.

有两种计算条件概率  $P(B\mid A)$  的方法:(1)按条件概率的含义,直接求出  $P(B\mid A)$ .注意到,在求  $P(B\mid A)$  时已知事件  $A$  已发生,样本空间  $S$  中所有不属于  $A$  的样本点都被排除,原有的样本空间  $S$  缩减成为  $S^{\prime} = A$ .在缩减了的样本空间  $S^{\prime} = A$  中计算事件  $B$  的概率就得到  $P(B\mid A)$ .(2)在  $S$  中计算  $P(AB)$  及  $P(A)$ ,再按(5.2)式求得  $P(B\mid A)$ .

将(5.2)式写成

$$
P(AB) = P(B\mid A)P(A),\qquad P(A) > 0. \tag{5.3}
$$

这就是乘法公式.我们常按上述第一种方法求出条件概率,从而按(5.3)可求得  $P(AB)$ .

事件的独立性是概率论中的一个非常重要的概念。概率论与数理统计中的很多内容都是在独立的前提下讨论的。应该注意到,在实际应用中,对于事件的独立性,我们往往不是根据定义来验证而是根据实际意义来加以判断的。根据实际背景判断事件的独立性,往往并不困难。

# 重要术语及主题

下面列出了本章的重要术语及主题,请读者写出它们的定义或内容,然后与教材中的陈述校核,看看你是否写对了。这样做旨在使读者在复习时收到较好的效果。

随机试验 样本空间 随机事件 基本事件 频率 概率 古典概型 A 的对立事件  $\overline{A}$  及其概率 两个互不相容事件的和事件的概率 概率的加法定理 条件概率 概率的乘法公式 全概率公式 贝叶斯公式 事件的独立性 实际推断原理

# 习题

1. 写出下列随机试验的样本空间  $S$

(1) 记录一个班一次数学考试的平均分数(设以百分制记分)。

(2) 生产产品直到有 10 件正品为止,记录生产产品的总件数。

(3) 对某工厂出厂的产品进行检查,合格的记上"正品",不合格的记上"次品",如连续查出了 2 件次品就停止检查,或检查了 4 件产品就停止检查,记录检查的结果。

(4) 在单位圆内任意取一点,记录它的坐标。

2. 设  $A, B, C$  为三个事件,用  $A, B, C$  的运算关系表示下列各事件:

(1)  $A$  发生,  $B$  与  $C$  不发生。

(2)  $A$  与  $B$  都发生,而  $C$  不发生。

(3)  $A, B, C$  中至少有一个发生。

(4)  $A, B, C$  都发生。

(5)  $A, B, C$  都不发生。

(6)  $A, B, C$  中不多于一个发生。

(7)  $A, B, C$  中不多于两个发生。

(8)  $A, B, C$  中至少有两个发生。

3. (1) 设  $A, B, C$  是三个事件,且  $P(A) = P(B) = P(C) = 1 / 4, P(AB) = P(BC) = 0, P(AC) = 1 / 8$ ,求  $A, B, C$  至少有一个发生的概率。

(2)已知  $P(A) = 1 / 2,P(B) = 1 / 3,P(C) = 1 / 5,P(A B) = 1 / 10,P(A C) = 1 / 15,P(B C) =$ $1 / 20,P(A B C) = 1 / 30$  ,求  $A\bigcup B,\overline{{A}}\overline{{B}},A\bigcup B\bigcup C,\overline{{A}}\overline{{B}}\overline{{C}},\overline{{A}}\overline{{B}} C,\overline{{A}}\overline{{B}}\bigcup C$  的概率.

(3)已知  $P(A) = 1 / 2$  ,(i)若  $A,B$  互不相容,求  $P(A\overline{{B}})$  ,(ii)若  $P(A B) = 1 / 8$  ,求  $P(A\overline{{B}})$

4. 设  $A, B$  是两个事件。

(1)已知  $A\overline{{B}} = \overline{{A}} B$  ,验证  $A = B$

(2) 验证事件  $A$  和事件  $B$  恰有一个发生的概率为  $P(A) + P(B) - 2P(AB)$ 。

5. 10 片药片中有 5 片是安慰剂。

(1) 从中任意抽取 5 片,求其中至少有 2 片是安慰剂的概率。

(2) 从中每次取一片, 作不放回抽样, 求前 3 次都取到安慰剂的概率.

6. 在房间里有 10 个人, 分别佩戴从 1 号到 10 号的纪念章, 任选 3 人记录其纪念章的号码.

(1) 求最小号码为 5 的概率.

(2) 求最大号码为 5 的概率.

7. 某油漆公司发出 17 桶油漆, 其中白漆 10 桶、黑漆 4 桶、红漆 3 桶, 在搬运中所有标签脱落, 交货人随意将这些油漆发给顾客. 问一个订货为 4 桶白漆、3 桶黑漆和 2 桶红漆的顾客, 能按所订颜色如数得到订货的概率是多少?

8. 在 1500 件产品中有 400 件次品、1100 件正品. 任取 200 件.

(1) 求恰有 90 件次品的概率.

(2) 求至少有 2 件次品的概率.

9. 从 5 双不同的鞋子中任取 4 只, 问这 4 只鞋子中至少有两只配成一双的概率是多少?

10. 在 11 张卡片上分别写上 probability 这 11 个字母, 从中任意连抽 7 张, 求其排列结果为 ability 的概率.

11. 将 3 只球随机地放入 4 个杯子中去, 求杯子中球的最大个数分别为 1, 2, 3 的概率.

12. 50 只铆钉随机地取来用在 10 个部件上, 其中有 3 只铆钉强度太弱. 每个部件用 3 只铆钉. 若将 3 只强度太弱的铆钉都装在一个部件上, 则这个部件强度就太弱. 问发生一个部件强度太弱的概率是多少?

13. 一俱乐部有 5 名一年级学生, 2 名二年级学生, 3 名三年级学生, 2 名四年级学生.

(1) 在其中任选 4 名学生, 求一、二、三、四年级的学生各一名的概率.

(2) 在其中任选 5 名学生, 求一、二、三、四年级的学生均包含在内的概率.

14. (1) 已知  $P(\overline{A}) = 0.3, P(B) = 0.4, P(A\overline{B}) = 0.5$ , 求条件概率  $P(B|A\cup \overline{B})$ .

(2) 已知  $P(A) = 1 / 4, P(B|A) = 1 / 3, P(A|B) = 1 / 2$ , 求  $P(A\cup B)$ .

15. 掷两颗骰子, 已知两颗骰子点数之和为 7, 求其中有一颗为 1 点的概率 (用两种方法).

16. 据以往资料表明, 某一 3 口之家, 患某种传染病的概率有以下规律:

$P\{$  孩子得病  $\} = 0.6$  ,  $P\{$  母亲得病|孩子得病  $\} = 0.5$

$P\{$  父亲得病|母亲及孩子得病  $\} = 0.4$

求母亲及孩子得病但父亲未得病的概率.

17. 已知在 10 件产品中有 2 件次品, 在其中取两次, 每次任取一件, 作不放回抽样. 求下列事件的概率:

(1) 两件都是正品.

(2) 两件都是次品.

(3) 一件是正品, 一件是次品.

(4) 第二次取出的是次品.

18. 某人忘记了电话号码的最后一个数字, 因而他随意地拨号、求他拨号不超过三次而接通所需电话的概率. 若已知最后一个数字是奇数, 则此概率是多少?

19. (1) 设甲袋中装有  $n$  只白球、 $m$  只红球, 乙袋中装有  $N$  只白球、 $M$  只红球. 今从甲袋中任意取一只球放入乙袋中, 再从乙袋中任意取一只球. 问取到白球的概率是多少?

(2) 第一只盒子装有 5 只红球、4 只白球, 第二只盒子装有 4 只红球、5 只白球. 先从第一盒中任取 2 只球放入第二盒中去, 然后从第二盒中任取一只球. 求取到白球的概率.

20. 某种产品的商标为"MAXAM", 其中有 2 个字母脱落, 有人捡起随意放回, 求放回后仍为"MAXAM"的概率.

21. 已知男子有  $5\%$  是色盲患者, 女子有  $0.25\%$  是色盲患者. 今从男女人数相等的人群中随机地挑选一人, 恰好是色盲患者, 问此人是男性的概率是多少?

22. 一学生接连参加同一课程的两次考试. 第一次及格的概率为  $p$ , 若第一次及格则第二次及格的概率也为  $p$ ; 若第一次不及格则第二次及格的概率为  $p / 2$ .

(1) 若至少有一次及格则他能取得某种资格, 求他取得该资格的概率.

(2) 若已知他第二次已经及格, 求他第一次及格的概率.

23. 将两信息分别编码为  $A$  和  $B$  传送出去, 接收站收到时,  $A$  被误收作  $B$  的概率为 0.02, 而  $B$  被误收作  $A$  的概率为 0.01. 信息  $A$  与信息  $B$  传送的频繁程度为  $2:1$ . 若接收站收到的信息是  $A$ , 问原发信息是  $A$  的概率是多少?

24. 有两箱同种类的零件, 第一箱装 50 只, 其中 10 只一等品; 第二箱装 30 只, 其中 18 只一等品. 今从两箱中任挑出一箱, 然后从该箱中取零件两次, 每次任取一只, 作不放回抽样. 求

(1) 第一次取到的零件是一等品的概率.

(2) 在第一次取到的零件是一等品的条件下, 第二次取到的也是一等品的概率.

25. 某人下午 5:00 下班, 他所积累的资料表明:

<table><tr><td>到家时间</td><td>5:35～5:39</td><td>5:40～5:44</td><td>5:45～5:49</td><td>5:50～5:54</td><td>迟于5:54</td></tr><tr><td>乘地铁的概率</td><td>0.10</td><td>0.25</td><td>0.45</td><td>0.15</td><td>0.05</td></tr><tr><td>乘汽车的概率</td><td>0.30</td><td>0.35</td><td>0.20</td><td>0.10</td><td>0.05</td></tr></table>

某日他抛一枚硬币决定乘地铁还是乘汽车, 结果他是 5:47 到家的. 试求他乘地铁回家的概率.

26. 病树的主人外出, 委托邻居浇水, 设已知如果不浇水, 树死去的概率为 0.8. 若浇水则树死去的概率为 0.15. 有 0.9 的把握确定邻居会记得浇水.

(1) 求主人回来时树还活着的概率.

(2) 若主人回来时树已死去, 求邻居忘记浇水的概率.

27. 设本题涉及的事件均有意义. 设  $A, B$  都是事件.

(1) 已知  $P(A) > 0$ , 证明  $P(AB|A) \geqslant P(AB|A \cup B)$ .

(2) 若  $P(A|B) = 1$ , 证明  $P(\overline{B} |A) = 1$ .

(3) 若设  $C$  也是事件, 且有  $P(A|C) \geqslant P(B|C)$ ,  $P(A|\overline{C}) \geqslant P(B|\overline{C})$ , 证明  $P(A) \geqslant P(B)$ .

28. 有两种花籽, 发芽率分别为 0.8, 0.9, 从中各取一颗, 设各花籽是否发芽相互独立. 求

(1) 这两颗花籽都能发芽的概率.

(2) 至少有一颗能发芽的概率.

(3) 恰有一颗能发芽的概率.

29. 根据报道美国人血型的分布近似地为: A 型为  $37\%$ , O 型为  $44\%$ , B 型为  $13\%$ , AB 型为  $6\%$ . 夫妻拥有的血型是相互独立的.

(1) B型的人只有输入 B, O 两种血型才安全。若妻为 B 型,夫为何种血型未知,求夫是妻的安全输血者的概率。

(2) 随机地取一对夫妇,求妻为 B 型,夫为 A 型的概率。

(3) 随机地取一对夫妇,求其中一人为 A 型,另一人为 B 型的概率。

(4) 随机地取一对夫妇,求其中至少有一人是 O 型的概率。

30. (1) 给出事件  $A, B$  的例子,使得

$$
P(A|B) < P(A), \quad (\mathrm{ii}) P(A|B) = P(A), \quad (\mathrm{iii}) P(A|B) > P(A).
$$

(2) 设事件  $A, B, C$  相互独立,证明 
(i)  $C$  与  $AB$  相互独立; (ii)  $C$  与  $A \cup B$  相互独立。

(3) 设事件  $A$  的概率  $P(A) = 0$ ,证明对于任意另一事件  $B$ ,有  $A, B$  相互独立。

(4) 证明事件  $A, B$  相互独立的充要条件是  $P(A|B) = P(A|\overline{B})$ 。

31. 设事件  $A, B$  的概率均大于零,说明以下的叙述 (a) 必然对, (b) 必然错, (c) 可能对。并说明理由。

(1) 若  $A$  与  $B$  互不相容,则它们相互独立。

(2) 若  $A$  与  $B$  相互独立,则它们互不相容。

(3)  $P(A) = P(B) = 0.6$ ,且  $A, B$  互不相容。

(4)  $P(A) = P(B) = 0.6$ ,且  $A, B$  相互独立。

32. 有一种检验艾滋病毒的检验法,其结果有概率 0.005 误认为假阳性(即不带艾滋病毒者,经此检验法有 0.005 的概率被认为带艾滋病毒)。今有 140 名不带艾滋病毒的正常人全部接受此种检验,被报道至少有一人带艾滋病毒的概率为多少?

33. 盒中有编号为 1,2,3,4 的 4 只球,随机地自盒中取一只球,事件  $A$  为"取得的是 1 号或 2 号球",事件  $B$  为"取得的是 1 号或 3 号球",事件  $C$  为"取得的是 1 号或 4 号球"。验证:

$$
P(AB) = P(A)P(B), \quad P(AC) = P(A)P(C), \quad P(BC) = P(B)P(C),
$$

但  $P(ABC) \neq P(A)P(B)P(C)$ ,

即事件  $A, B, C$  两两独立,但  $A, B, C$  不是相互独立的。

34. 试分别求以下两个系统的可靠性:

(1) 设有 4 个独立工作的元件 1,2,3,4。它们的可靠性分别为  $p_1, p_2, p_3, p_4$ ,将它们按题 34 图(1)的方式连接(称为并串联系统)。

(2) 设有 5 个独立工作的元件 1,2,3,4,5。它们的可靠性均为  $p$ ,将它们按题 34 图(2)的方式连接(称为桥式系统)。

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
题 34 图

35. 如果一危险情况  $C$  发生时,一电路闭合并发出警报,我们可以借用两个或多个开关并联以改善可靠性。在  $C$  发生时这些开关每一个都应闭合,且若至少一个开关闭合了,警报就发出。如果两个这样的开关并联连接,它们每个具有 0.96 的可靠性(即在情况  $C$  发生时闭合的概率),问这时系统的可靠性(即电路闭合的概率)是多少?如果需要有一个可靠性至少为 0.9999 的系统,则至少需要用多少只开关并联?设各开关闭合与否是相互独立的。

36. 三人独立地去破译一份密码,已知各人能译出的概率分别为  $1 / 5, 1 / 3, 1 / 4$ 。问三人中至少有一人能将此密码译出的概率是多少?

37. 设第一只盒子中装有 3 只蓝色球、2 只绿色球、2 只白色球,第二只盒子中装有 2 只蓝色球、3 只绿色球、4 只白色球。独立地分别在两只盒子中各取一只球。

(1) 求至少有一只蓝色球的概率。

(2) 求有一只蓝色球、一只白色球的概率。

(3) 已知至少有一只蓝色球,求有一只蓝色球、一只白色球的概率。

38. 袋中装有  $m$  枚正品硬币、 $n$  枚次品硬币(次品硬币的两面均印有国徽),在袋中任取一枚,将它投掷  $r$  次,已知每次都得到国徽。问这枚硬币是正品的概率为多少?

39. 设根据以往记录的数据分析,某船只运输的某种物品损坏的情况共有三种:损坏  $2\%$  (这一事件记为  $A_{1}$ ),损坏  $10\%$  (事件  $A_{2}$ ),损坏  $90\%$  (事件  $A_{3}$ ),且知  $P(A_{1}) = 0.8, P(A_{2}) = 0.15, P(A_{3}) = 0.05$ 。现在从已被运输的物品中随机地取 3 件,发现这 3 件都是好的(这一事件记为  $B$ )。试求  $P(A_{1} \mid B), P(A_{2} \mid B), P(A_{3} \mid B)$  (这里设物品件数很多,取出一件后不影响取后一件是否为好品的概率)。

40. 将 A,B,C 三个字母之一输入信道,输出为原字母的概率是  $\alpha$ ,而输出为其他某一字母的概率都是  $(1 - \alpha) / 2$ 。今将字母串 AAAA,BBBB,CCCC 之一输入信道,输入 AAAA,BBBB,CCCC 的概率分别为  $p_{1}, p_{2}, p_{3} (p_{1} + p_{2} + p_{3} = 1)$ ,已知输出为 ABCA,问输入的是 AAAA 的概率是多少?(设信道传输各个字母的工作是相互独立的。)

# 第二章 随机变量及其分布

# $\S 1$  随机变量

在第一章我们看到一些随机试验, 它们的结果可以用数来表示. 此时样本空间  $S$  的元素是一个数, 如  $S_{3}, S_{5}$ ; 但有些则不然, 如  $S_{1}, S_{2}$ . 当样本空间  $S$  的元素不是一个数时, 人们对于  $S$  就难以描述和研究. 现在来讨论如何引入一个法则, 将随机试验的每一个结果, 即将  $S$  的每个元素  $e$  与实数  $x$  对应起来, 从而引入了随机变量的概念. 我们从例题开始讨论.

例1 在第一章  $\S 4$  例1中, 将一枚硬币抛掷三次, 观察出现正面和反面的情况, 样本空间是

$$
S = \{H H H,H H T,H T H,T H H,H T T,T H T,T T H,T T T\} .
$$

以  $X$  记三次投掷得到正面  $H$  的总数, 那么, 对于样本空间  $S = \{e\} ①$  中的每一个样本点  $e, X$  都有一个数与之对应.  $X$  是定义在样本空间  $S$  上的一个实值单值函数. 它的定义域是样本空间  $S$ , 值域是实数集合  $\{0,1,2,3\}$ . 使用函数记号可将  $X$  写成

$$
X = X(e) = \left\{ \begin{array}{ll}3, & e = H H H, \\ 2, & e = H H T, H T H, T H H, \\ 1, & e = H T T, T H T, T T H, \\ 0, & e = T T T. \end{array} \right.
$$

例2 袋中有编号分别为1,2,3的3只球. 在袋中任取一球, 放回, 再任取一球, 记录它们的号码. 试验的样本空间为  $S = \{e\} = \{(i,j) \mid i,j = 1,2,3\} , i,j$  分别为第1, 第2次取到的球的号码. 以  $X$  记两球号码之和. 我们看到, 对于试验的每一个结果  $e = (i,j) \in S, X$  都有一个指定的值  $i + j$  与之对应 (如图2- 1).  $X$  是定义在样本空间  $S$  上的单值实值函数. 它的定义域是样本空间  $S$ . 值域是实数集合

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
图2-1

$\{2,3,4,5,6\}$ .  $X$  可写成

$$
X = X(e) = X((i,j)) = i + j, \quad i, j = 1,2,3.
$$

一般有以下的定义.

定义 设随机试验的样本空间为  $S = \{e\}$ .  $X = X(e)$  是定义在样本空间  $S$  上的实值单值函数. 称  $X = X(e)$  为随机变量  $①$ .

图2一2画出了样本点  $e$  与实数  $X = X(e)$  对应的示意图.

有许多随机试验, 它们的结果本身是一个数, 即样本点  $e$  本身是一个数. 我们令  $X = X(e) = e$ , 那么  $X$  就是一个随机变量. 例如, 用  $Y$  记某车间一天的缺勤人数, 以  $W$  记某地区第一季度的降雨量, 以  $Z$  记某工厂一天的耗电量, 以  $N$  记某医院一天的挂号人数. 那么  $Y, W, Z, N$  都是随机变量.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
图2-2

一天的耗电量, 以  $N$  记某医院一天的挂号人数. 那么  $Y, W, Z, N$  都是随机变量.

本书中, 我们一般以大写的字母如  $X, Y, Z, W, \dots$  表示随机变量, 而以小写字母  $x, y, z, w, \dots$  表示实数.

随机变量的取值随试验的结果而定, 而试验的各个结果出现有一定的概率, 因而随机变量的取值有一定的概率. 例如, 在例1中  $X$  取值为2, 记成  $\{X = 2\}$ , 对应于样本点的集合  $A = \{HHT, HTH, THH\}$ , 这是一个事件, 当且仅当事件  $A$  发生时有  $\{X = 2\}$ . 我们称概率  $P(A) = P\{HHT, HTH, THH\}$  为  $\{X = 2\}$  的概率, 即  $P\{X = 2\} = P(A) = 3 / 8$ . 以后, 还将事件  $A = \{HHT, HTH, THH\}$  说成是事件  $\{X = 2\}$ . 类似地有

$$
P\{X \leqslant 1\} = P\{HTT, THT, TTH, TTT\} = \frac{1}{2}.
$$

一般, 若  $L$  是一个实数集合, 将  $X$  在  $L$  上取值写成  $\{X \in L\}$ . 它表示事件  $B = \{e \mid X(e) \in L\}$ , 即  $B$  是由  $S$  中使得  $X(e) \in L$  的所有样本点  $e$  所组成的事件, 此时有

$$
P\{X \in L\} = P(B) = P\{e \mid X(e) \in L\} .
$$

随机变量的取值随试验的结果而定, 在试验之前不能预知它取什么值, 且它的取值有一定的概率. 这些性质显示了随机变量与普通函数有着本质的差异.

随机变量的引入, 使我们能用随机变量来描述各种随机现象, 并能利用数学分析的方法对随机试验的结果进行深入广泛的研究和讨论.

# $\S 2$  离散型随机变量及其分布律

有些随机变量,它全部可能取到的值是有限个或可列无限多个,这种随机变量称为离散型随机变量.例如  $\S 1$  例1中的随机变量  $X$  ,它只可能取0,1,2,3四个值,它是一个离散型随机变量.又如某城市的120急救电话台一昼夜收到的呼唤次数也是离散型随机变量.若以  $T$  记某元件的寿命,它所可能取的值充满一个区间,是无法按一定次序一一列举出来的,因而它是一个非离散型的随机变量.本节只讨论离散型随机变量.

容易知道,要掌握一个离散型随机变量  $X$  的统计规律,必须且只需知道  $X$  的所有可能取值以及取每一个可能值的概率.

设离散型随机变量  $X$  所有可能取的值为  $x_{k}(k = 1,2,\dots),X$  取各个可能值的概率,即事件  $\{X = x_{k}\}$  的概率,为

$$
P\{X = x_{k}\} = p_{k},k = 1,2,\dots . \tag{2.1}
$$

由概率的定义,  $\boldsymbol{\mathscr{p}}_{k}$  满足如下两个条件:

$$
1^{\circ}p_{k}\geqslant 0,k = 1,2,\dots . \tag{2.2}
$$

$$
2^{\circ}\sum_{k = 1}p_{k} = 1. \tag{2.3}
$$

$2^{\circ}$  是由于  $\{X = x_{1}\} \cup \{X = x_{2}\} \cup \dots$  为必然事件,且  $\{X = x_{j}\} \cap \{X = x_{k}\} =$ $\varnothing ,k\neq j$  ,故  $1 = P\Big(\bigcup_{k = 1}^{\infty}\{X = x_{k}\} \Big) = \sum_{k = 1}^{\infty}P\{X = x_{k}\}$  ,即  $\sum_{k = 1}^{\infty}p_{k} = 1.$

我们称(2.1)式为离散型随机变量  $X$  的分布律.分布律也可以用表格的形式来表示:

$$
\frac{\begin{array}{c}{{X}}\\ {{\begin{array}{c}{{x_{1}}}\end{array}}}\end{array}}{\begin{array}{c}{{x_{1}}}\end{array}}\begin{array}{c}{{x_{2}}}\end{array}\begin{array}{c}{{\cdots}}\\ {{\cdots}}\end{array}\begin{array}{c}{{x_{n}}}\end{array}\begin{array}{c}{{\cdots}}\\ {{\cdots}}\end{array}} \tag{2.4}
$$

(2.4)直观地表示了随机变量  $X$  取各个值的概率的规律.  $X$  取各个值各占一些概率,这些概率合起来是1. 可以想象成:概率1以一定的规律分布在各个可能值上.这就是(2.4)称为分布律的缘故.

例1设一汽车在开往目的地的道路上需经过四组信号灯,每组信号灯以1/2的概率允许或禁止汽车通过.以  $X$  表示汽车首次停下时,它已通过的信号灯的组数(设各组信号灯的工作是相互独立的),求  $X$  的分布律.

解以  $\boldsymbol{\mathscr{p}}$  表示每组信号灯禁止汽车通过的概率,易知  $X$  的分布律为

<table><tr><td>X</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>p k</td><td>p</td><td>(1-p) p</td><td>(1-p)² p</td><td>(1-p)³ p</td><td>(1-p)⁴</td></tr></table>

或写成

$$
P\{X = k\} = (1 - p)^{k}p, \quad k = 0,1,2,3, \quad P\{X = 4\} = (1 - p)^{4}.
$$

以  $\scriptstyle{p = 1 / 2}$  代入得

<table><tr><td>X</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>p k</td><td>0.5</td><td>0.25</td><td>0.125</td><td>0.062 5</td><td>0.062 5</td></tr></table>

下面介绍三种重要的离散型随机变量.

(一)  $(0 - 1)$  分布

设随机变量  $X$  只可能取0与1两个值,它的分布律是

$$
P\{X = k\} = p^{k}(1 - p)^{1 - k}, \quad k = 0,1 \quad (0< p< 1),
$$

则称  $X$  服从以  $\boldsymbol{p}$  为参数的(0一1)分布或两点分布.

(0一1)分布的分布律也可写成

<table><tr><td>X</td><td>0</td><td>1</td></tr><tr><td>p k</td><td>1-p</td><td>p</td></tr></table>

对于一个随机试验,如果它的样本空间只包含两个元素,即  $S = \{e_{1},e_{2}\}$ ,我们总能在  $S$  上定义一个服从(0一1)分布的随机变量

$$
X = X(e) = \left\{ \begin{array}{ll}0, & \text{当} e = e_{1}, \\ 1, & \text{当} e = e_{2} \end{array} \right.
$$

来描述这个随机试验的结果。例如,对新生婴儿的性别进行登记,检查产品的质量是否合格,某车间的电力消耗是否超过负荷以及前面多次讨论过的"抛硬币"试验等都可以用(0一1)分布的随机变量来描述。(0一1)分布是经常遇到的一种分布。

# (二) 伯努利试验、二项分布

设试验  $E$  只有两个可能结果:  $A$  及  $\overline{A}$ ,则称  $E$  为伯努利(Bernoulli)试验。设  $P(A) = p$ $(0< p< 1)$ ,此时  $P(\overline{A}) = 1 - p$ 。将  $E$  独立重复地进行  $n$  次,则称这一串重复的独立试验为  $n$  重伯努利试验。

这里"重复"是指在每次试验中  $P(A) = p$  保持不变;"独立"是指各次试验的结果互不影响,即若以  $C_{i}$  记第  $i$  次试验的结果,  $C_{i}$  为  $A$  或  $\overline{A}, i = 1,2,\dots ,n$ . "独立"是指

$$
P(C_{1}C_{2}\dots C_{n}) = P(C_{1})P(C_{2})\dots P(C_{n}). \tag{2.5}
$$

$n$  重伯努利试验是一种很重要的数学模型,它有广泛的应用,是研究极多的模型之一.

例如,  $E$  是抛一枚硬币观察得到正面或反面.  $A$  表示得正面,这是一个伯努利试验.如将硬币抛  $n$  次,就是  $n$  重伯努利试验.又如抛一颗骰子,若  $A$  表示得到"1点",  $\overline{A}$  表示得到"非1点".将骰子抛  $n$  次,就是  $n$  重伯努利试验.再如在袋中装有  $a$  只白球,  $b$  只黑球.试验  $E$  是在袋中任取一只球,观察其颜色.以  $A$  表示"取到白球",  $P(A) = a / (a + b)$ .若连续取球  $n$  次作放回抽样,这就是  $n$  重伯努利试验.然而,若作不放回抽样,虽则每次试验都有  $P(A) = a / (a + b)$  (见第一章 §4 例5),但各次试验不再相互独立  $①$ ,因而不再是  $n$  重伯努利试验了.

以  $X$  表示  $n$  重伯努利试验中事件  $A$  发生的次数,  $X$  是一个随机变量,我们来求它的分布律.  $X$  所有可能取的值为  $0,1,2,\dots ,n$ . 由于各次试验是相互独立的,因此事件  $A$  在指定的  $k$ $(0\leqslant k\leqslant n)$  次试验中发生,在其他  $n - k$  次试验中  $A$  不发生(例如在前  $k$  次试验中  $A$  发生,而后  $n - k$  次试验中  $A$  不发生)的概率为

$$
\frac{p\bullet p\bullet\cdots\bullet p\bullet(1 - p)\bullet(1 - p)\bullet\cdots\bullet(1 - p)}{k\uparrow} = p^{k}(1 - p)^{n - k}.
$$

这种指定的方式共有  $\binom{n}{k}$  种,它们是两两互不相容的,故在  $n$  次试验中  $A$  发生  $k$  次的概率为  $\binom{n}{k} p^{k}(1 - p)^{n - k}$ ,记  $q = 1 - p$ ,即有

$$
P\{X = k\} = \binom{n}{k} p^{k}q^{n - k},\quad k = 0,1,2,\dots ,n. \tag{2.6}
$$

显然

$$
P\{X = k\} \geqslant 0,\quad k = 0,1,2,\dots ,n;
$$

$$
\sum_{k = 0}^{n}P\{X = k\} = \sum_{k = 0}^{n}\binom{n}{k}p^{k}q^{n - k} = (p + q)^{n} = 1.
$$

即  $P\{X = k\}$  满足条件(2.2),(2.3).注意到  $\binom{n}{k}p^{k}q^{n- k}$  刚好是二项式  $(p + q)^{n}$  的展开式中出现  $\boldsymbol{\mathbf{\mathit{p}}}^{k}$  的那一项,我们称随机变量  $X$  服从参数为  $n,p$  的二项分布,并记为  $X\sim b(n,p)$

特别,当  $n = 1$  时二项分布(2.6)化为

$$
P\{X = k\} = p^{k}q^{1 - k},\quad k = 0,1.
$$

这就是  $(0 - 1)$  分布.

例2按规定,某种型号电子元件的使用寿命超过  $1500\mathrm{~h~}$  的为一级品.已知某一大批产品的一级品率为0.2,现在从中随机地抽查20只.问20只元件中恰有  $k$  只  $(k = 0,1,\dots ,20)$  为一级品的概率是多少?

解这是不放回抽样.但由于这批元件的总数很大,且抽查的元件的数量相对于元件的总数来说又很小,因而可以当作放回抽样来处理,这样做会有一些误差,但误差不大.我们将检查一只元件看它是否为一级品看成是一次试验,检查20只元件相当于做20重伯努利试验.以  $X$  记20只元件中一级品的只数,那么, $X$  是一个随机变量,且有  $X\sim b(20,0.2)$  .由(2.6)式即得所求概率为

$$
P\{X = k\} = \binom{20}{k}0.2^{k}0.8^{20 - k},\quad k = 0,1,\dots ,20.
$$

将计算结果列表如下:

<table><tr><td>P{X=0} = 0.012</td><td>P{X=4} = 0.218</td><td>P{X=8} = 0.022</td></tr><tr><td>P{X=1} = 0.058</td><td>P{X=5} = 0.175</td><td>P{X=9} = 0.007</td></tr><tr><td>P{X=2} = 0.137</td><td>P{X=6} = 0.109</td><td>P{X=10} = 0.002</td></tr><tr><td>P{X=3} = 0.205</td><td>P{X=7} = 0.055</td><td></td></tr></table>

当  $k\geqslant 11$  时,  $P\{X = k\} < 0.001$

为了对本题的结果有一个直观了解,我们作出上表的图形,如图2一3所示.

从图2一3中看到,当  $k$  增加时,概率  $P\{X = k\}$  先是随之增加,直至达到最大值(本例中当  $k = 4$  时取到最大值),随后单调减少.我们指出,一般,对于固定的  $n$  及  $\boldsymbol{\mathscr{p}}$  ,二项分布  $b(n,p)$  都具有这一性质. 口

例3某人进行射击,设每次射击的命中率为0.02,独立射击400次,试

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_1.pdf-8f798178-3cf0-4e67-ac82-3da23e2c24d6_fc3e2b1b9a43ae33c0ab35d02153c185aa35428ed3d1518cb7b91d5a2d6e7d4a.jpg)  
图2-3

求至少击中两次的概率.

解 将一次射击看成是一次试验. 设击中的次数为  $X$ , 则  $X \sim b(400,0.02)$ .  $X$  的分布律为

$$
P\{X = k\} = \binom{400}{k} 0.02^{k} 0.98^{400 - k}, \quad k = 0,1, \dots , 400.
$$

于是所求概率为

$$
\begin{array}{r l} & {P\{X\geqslant 2\} = 1 - P\{X = 0\} -P\{X = 1\}}\\ & {\qquad = 1 - 0.98^{400} - 400\times 0.02\times 0.98^{399} = 0.9972.} \end{array}
$$

这个概率很接近于1. 我们从两方面来讨论这一结果的实际意义. 其一, 虽然每次射击的命中率很小 (为0.02), 但如果射击400次, 则击中目标至少两次是几乎可以肯定的. 这一事实说明, 一个事件尽管在一次试验中发生的概率很小, 但只要试验次数很多, 而且试验是独立地进行的, 那么这一事件的发生几乎是肯定的. 这也告诉人们绝不能轻视小概率事件. 其二, 如果射手在400次射击中, 击中目标的次数竟不到两次, 那么由于概率  $P\{X< 2\} \approx 0.003$  很小, 根据实际推断原理, 我们将怀疑"每次射击的命中率为0.02"这一假设, 即认为该射手射击的命中率达不到0.02.

例4 设有80台同类型设备, 各台工作是相互独立的, 发生故障的概率都是0.01, 且一台设备的故障能由一个人处理. 考虑两种配备维修工人的方法, 其一是由4人维护, 每人负责20台; 其二是由3人共同维护80台. 试比较这两种方法在设备发生故障时不能及时维修的概率的大小.

解 按第一种方法. 以  $X$  记"第1人维护的20台中同一时刻发生故障的台数", 以  $A_{i}(i = 1,2,3,4)$  表示事件"第  $i$  人维护的20台中发生故障不能及时维修", 则知80台中发生故障而不能及时维修的概率为

$$
P(A_{1} \cup A_{2} \cup A_{3} \cup A_{4}) \geqslant P(A_{1}) = P\{X \geqslant 2\} .
$$

而  $X \sim b(20,0.01)$ , 故有

$$
\begin{array}{l}{{P\{X\geqslant2\}=1-\sum_{k=0}^{1}P\{X=k\}}}\\ {{\qquad=1-\sum_{k=0}^{1}\binom{20}{k}0.01^{k}0.99^{20-k}=0.0169.}}\end{array}
$$

即有  $P(A_{1} \cup A_{2} \cup A_{3} \cup A_{4}) \geqslant 0.0169$ .

按第二种方法. 以  $Y$  记80台中同一时刻发生故障的台数. 此时,  $Y \sim b(80,0.01)$ , 故80台中发生故障而不能及时维修的概率为

$$
P\{Y \geqslant 4\} = 1 - \sum_{k = 0}^{3}\binom{80}{k} 0.01^{k} 0.99^{80 - k} = 0.0087.
$$

我们发现,在后一种情况尽管任务重了(每人平均维护约27台),但工作效率不仅没有降低,反而提高了.  $\square$

# (三)泊松分布

设随机变量  $X$  所有可能取的值为  $0,1,2,\dots$ ,而取各个值的概率为

$$
P\{X = k\} = \frac{\lambda^{k}\mathrm{e}^{-\lambda}}{k!}, k = 0,1,2,\dots ,
$$

其中  $\lambda >0$  是常数.则称  $X$  服从参数为  $\lambda$  的泊松分布,记为  $X\sim \pi (\lambda)$

易知,  $P\{X = k\} \geqslant 0,k = 0,1,2,\dots$ ,且有

$$
\sum_{k = 0}^{\infty}P\{X = k\} = \sum_{k = 0}^{\infty}\frac{\lambda^{k}\mathrm{e}^{-\lambda}}{k!} = \mathrm{e}^{-\lambda}\sum_{k = 0}^{\infty}\frac{\lambda^{k}}{k!} = \mathrm{e}^{-\lambda}\cdot \mathrm{e}^{\lambda} = 1.
$$

即  $P\{X = k\}$  满足条件(2.2),(2.3).

参数  $\lambda$  的意义将在第四章说明,有关服从泊松分布的随机变量的数学模型将在第十二章中讨论.

具有泊松分布的随机变量在实际应用中是很多的.例如,一本书一页中的印刷错误数,某地区在一天内邮递遗失的信件数,某一医院在一天内的急诊病人数,某一地区一个时间间隔内发生交通事故的次数,在一个时间间隔内某种放射性物质发出的、经过计数器的  $\alpha$  粒子数等都服从泊松分布.泊松分布也是概率论中的一种重要分布.

下面介绍一个用泊松分布来逼近二项分布的定理,

泊松定理设  $\lambda >0$  是一个常数,  $n$  是任意正整数,设  $n p_{n} = \lambda$ ,则对于任一固定的非负整数  $k$ ,有

$$
\lim_{n\to \infty}\binom{n}{k}p_{n}^{k}(1-p_{n})^{n-k}=\frac{\lambda^{k}\mathrm{e}^{-\lambda}}{k!}.
$$

证由  $p_{n} = \frac{\lambda}{n}$ ,有

$$
\begin{array}{r l r}{{\binom{n}{k}}p_{n}^{k}(1-p_{n})^{n-k}=\frac{n(n-1)\cdots(n-k+1)}{k!}\Big(\frac{\lambda}{n}\Big)^{k}\Big(1-\frac{\lambda}{n}\Big)^{n-k}}}\\ &{}&{=\frac{\lambda^{k}}{k!}\Bigg[1\bullet\Big(1-\frac{1}{n}\Big)\cdots\Big(1-\frac{k-1}{n}\Big)\Bigg]\Big(1-\frac{\lambda}{n}\Big)^{n}\Big(1-\frac{\lambda}{n}\Big)^{-k}.}\end{array}
$$

对于任意固定的  $k$ ,当  $n\to \infty$  时,

$$
1\bullet \left(1 - \frac{1}{n}\right)\dots \left(1 - \frac{k - 1}{n}\right)\to 1,\quad \left(1 - \frac{\lambda}{n}\right)^{n}\to \mathrm{e}^{-\lambda},\quad \left(1 - \frac{\lambda}{n}\right)^{-k}\to 1.
$$

故有

$$
\lim_{n\to \infty}{\binom{n}{k}}\phi_{n}^{k}(1-p_{n})^{n-k}=\frac{\lambda^{k}\mathrm{e}^{-\lambda}}{k!}.
$$

定理的条件  $n p_{n} = \lambda$  (常数)意味着当  $n$  很大时  $\boldsymbol{\mathscr{p}}_{n}$  必定很小,因此,上述定理表明当  $n$  很大,  $\boldsymbol{\mathscr{p}}$  很小  $(n p = \lambda)$  时有以下近似式

$$
{\binom{n}{k}}\phi^{k}(1-p)^{n-k}{\approx}{\frac{\lambda^{k}\mathrm{e}^{-\lambda}}{k!}}\quad({\mathbb{H}}{\mathbb{H}}\lambda=n p). \tag{2.7}
$$

也就是说以  $n,p$  为参数的二项分布的概率值可以由参数为  $\lambda = n p$  的泊松分布的概率值近似.上式也能用来作二项分布概率的近似计算.

例5计算机硬件公司制造某种特殊型号的微型芯片,次品率达  $0.1\%$  ,各芯片成为次品相互独立.求在1000只产品中至少有2只次品的概率.以  $X$  记产品中的次品数,  $X\sim b(1000,0.001)$

解所求概率为

$$
\begin{array}{r l} & {P\{X\geqslant 2\} = 1 - P\{X = 0\} -P\{X = 1\}}\\ & {\qquad = 1 - 0.999^{1000} - \binom{1000}{1} 0.999^{999}\times 0.001}\\ & {\qquad \approx 1 - 0.3676954 - 0.3680635 = 0.2642411} \end{array}
$$

利用(2.7)式来计算得,  $\lambda = 1000\times 0.001 = 1$

$$
\begin{array}{r l} & {P\{X\geqslant 2\} = 1 - P\{X = 0\} -P\{X = 1\}}\\ & {\qquad \approx 1 - \mathrm{e}^{-1} - \mathrm{e}^{-1}\approx 0.264 241 1.} \end{array}
$$

显然利用(2.7)式的计算来得方便.一般,当  $n\geqslant 20,p\leqslant 0.05$  时,用  $\frac{\lambda^{k}\mathrm{e}^{- \lambda}}{k!}$ $\lambda =$ $n p)$  作为  ${\binom{n}{k}}\phi^{k}(1- p)^{n- k}$  的近似值效果颇佳.

# §3 随机变量的分布函数

对于非离散型随机变量  $X$  ,由于其可能取的值不能一一列举出来,因而就不能像离散型随机变量那样可以用分布律来描述它.另外,我们通常所遇到的非离散型随机变量取任一指定的实数值的概率都等于0(这一点在下一节将会讲到).再者,在实际中,对于这样的随机变量,例如误差  $\epsilon$  、元件的寿命  $T$  等,我们并不会对误差  $\epsilon = 0.05 \mathrm{mm}$  ,寿命  $T = 1251.3 \mathrm{h}$  的概率感兴趣,而是考虑误差落在某个区间内的概率,寿命  $T$  大于某个数的概率.因而我们转而去研究随机变量所取的值落在一个区间  $(x_{1},x_{2}]$  的概率:  $P\{x_{1}< X\leqslant x_{2}\}$  .但由于

$$
P\{x_{1}< X\leqslant x_{2}\} = P\{X\leqslant x_{2}\} -P\{X\leqslant x_{1}\} ,
$$

所以我们只需知道  $P\{X \leqslant x_{2}\}$  和  $P\{X \leqslant x_{1}\}$  就可以了。下面引入随机变量的分布函数的概念①。

定义 设  $X$  是一个随机变量,  $x$  是任意实数, 函数

$$
F(x) = P\{X \leqslant x\} , -\infty < x < \infty
$$

称为  $X$  的分布函数.

对于任意实数  $x_{1}, x_{2}\left(x_{1} < x_{2}\right)$ , 有

$$
P\{x_{1} < X \leqslant x_{2}\} = P\{X \leqslant x_{2}\} - P\{X \leqslant x_{1}\} = F\left(x_{2}\right) - F\left(x_{1}\right), \tag{3.1}
$$

因此, 若已知  $X$  的分布函数, 我们就知道  $X$  落在任一区间  $\left(x_{1}, x_{2}\right]$  上的概率, 从这个意义上说, 分布函数完整地描述了随机变量的统计规律性.

分布函数是一个普通的函数, 正是通过它, 我们将能用数学分析的方法来研究随机变量.

如果将  $X$  看成是数轴上的随机点的坐标, 那么, 分布函数  $F(x)$  在  $x$  处的函数值就表示  $X$  落在区间  $(- \infty , x]$  上的概率.

分布函数  $F(x)$  具有以下的基本性质:

$1^{\circ} F(x)$  是一个不减函数.

事实上, 由 (3.1) 式对于任意实数  $x_{1}, x_{2}\left(x_{1} < x_{2}\right)$ , 有

$$
F(x_{2}) - F(x_{1}) = P\{x_{1} < X \leqslant x_{2}\} \geqslant 0.
$$

$2^{\circ} 0 \leqslant F(x) \leqslant 1$ , 且

$$
F(-\infty) = \lim_{x \to -\infty} F(x) = 0, \quad F(\infty) = \lim_{x \to \infty} F(x) = 1.
$$

上面两个式子, 我们只从几何上加以说明. 在图 2- 4 中, 将区间端点  $x$  沿数轴无限向左移动 (即  $x \to - \infty$ ), 则"随机点  $X$  落在点  $x$  左边"这一事件趋于不

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-4

可能事件, 从而其概率趋于 0, 即有  $F(- \infty) = 0$ ; 又若将点  $x$  无限右移 (即  $x \to \infty$ ), 则"随机点  $X$  落在点  $x$  左边"这一事件趋于必然事件, 从而其概率趋于 1, 即有  $F(\infty) = 1$

$3^{\circ} F(x + 0) = F(x)$ , 即  $F(x)$  是右连续的. (证略.)

反之, 可证具备性质  $1^{\circ}, 2^{\circ}, 3^{\circ}$  的函数  $F(x)$  必是某个随机变量的分布函数.

例1 设随机变量  $X$  的分布律为

<table><tr><td>X</td><td>-1</td><td>2</td><td>3</td></tr><tr><td>p k</td><td>1/4</td><td>1/2</td><td>1/4</td></tr></table>

求  $X$  的分布函数,并求  $P\left\{X \leqslant \frac{1}{2}\right\} , P\left\{\frac{3}{2} < X \leqslant \frac{5}{2}\right\} , P\{2 \leqslant X \leqslant 3\}$ .

解  $X$  仅在  $x = - 1,2,3$  三点处其概率  $\neq 0$  ,而  $F(x)$  的值是  $X \leqslant x$  的累积概率值,由概率的有限可加性,知它即为小于或等于  $x$  的那些  $x_{k}$  处的概率  $\boldsymbol{\mathscr{p}}_{k}$  之和,有

$$
F(x) = \left\{ \begin{array}{ll}0 & x < -1, \\ P\{X = -1\} , & -1 \leqslant x < 2, \\ P\{X = -1\} + P\{X = 2\} , & 2 \leqslant x < 3, \\ 1, & x \geqslant 3. \end{array} \right.
$$

即

$$
F(x) = \left\{ \begin{array}{ll}0, & x < -1, \\ \frac{1}{4}, & -1 \leqslant x < 2, \\ \frac{3}{4}, & 2 \leqslant x < 3, \\ 1, & x \geqslant 3. \end{array} \right.
$$

$F(x)$  的图形如图2一5所示,它是一条阶梯形的曲线,在  $x = - 1,2,3$  处有跳跃点,跳跃值分别为  $\frac{1}{4}, \frac{1}{2}, \frac{1}{4}$ . 又

$$
\begin{array}{l}{{P\Big\{X\leqslant\frac{1}{2}\Big\}=F\Big(\frac{1}{2}\Big)=\frac{1}{4},}}\\ {{P\Big\{\frac{3}{2}{< }X\leqslant\frac{5}{2}\Big\}=F\Big(\frac{5}{2}\Big)-F\Big(\frac{3}{2}\Big)}}\\ {{\qquad=\frac{3}{4}-\frac{1}{4}=\frac{1}{2}.}}\end{array}
$$

$$
\begin{array}{c}{{P\{2\leqslant X\leqslant3\}=F(3)-F(2)+P\{X=2\}}}\\ {{{}}}\\ {{=1-\frac{3}{4}+\frac{1}{2}=\frac{3}{4}.}}\end{array}
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-5

一般,设离散型随机变量  $X$  的分布律为

$$
P\{X = x_{k}\} = p_{k}, \quad k = 1,2, \dots .
$$

由概率的可列可加性得  $X$  的分布函数为

$$
F(x) = P\{X \leqslant x\} = \sum_{x_{k} \leqslant x} P\{X = x_{k}\} ,
$$

即  $F(x) = \sum_{x_{k} \leqslant x} p_{k},$  (3.2)

这里和式是对于所有满足  $x_{k} \leqslant x$  的  $k$  求和的. 分布函数  $F(x)$  在  $x = x_{k}(k = 1$

$2, \dots)$  处有跳跃, 其跳跃值为  $p_{k} = P\{X = x_{k}\}$ .

例2 一个靶子是半径为  $2 \mathrm{~m}$  的圆盘, 设击中靶上任一同心圆盘上的点的概率与该圆盘的面积成正比, 并设射击都能中靶, 以  $X$  表示弹着点与圆心的距离. 试求随机变量  $X$  的分布函数.

解 若  $x< 0$ , 则  $\{X \leqslant x\}$  是不可能事件, 于是

$$
F(x) = P\{X \leqslant x\} = 0.
$$

若  $0 \leqslant x \leqslant 2$ , 由题意,  $P\{0 \leqslant X \leqslant x\} = k x^{2}, k$  是某一常数, 为了确定  $k$  的值, 取  $x = 2$ , 有  $P\{0 \leqslant X \leqslant 2\} = 2^{2} k$ , 但已知  $P\{0 \leqslant X \leqslant 2\} = 1$ , 故得  $k = 1 / 4$ , 即

$$
P\{0 \leqslant X \leqslant x\} = \frac{x^{2}}{4}.
$$

于是

$$
\begin{array}{c}{{F(x)=P\{X\leqslant x\}=P\{X{< }0\}+P\{0\leqslant X\leqslant x\}}}\\ {{{}}}\\ {{={\frac{x^{2}}{4}}.}}\end{array}
$$

若  $x \geqslant 2$ , 由题意  $\{X \leqslant x\}$  是必然事件, 于是

$$
F(x) = P\{X \leqslant x\} = 1.
$$

综合上述, 即得  $X$  的分布函数为

$$
F(x) = \left\{ \begin{array}{ll}0, & x< 0, \\ \frac{x^{2}}{4}, & 0 \leqslant x< 2, \\ 1, & x \geqslant 2. \end{array} \right.
$$

它的图形是一条连续曲线, 如图 2- 6 所示,

另外, 容易看到本例中的分布函数  $F(x)$ , 对于任意  $x$  可以写成形式

$$
F(x) = \int_{-\infty}^{x} f(t) \mathrm{d} t,
$$

其中

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-6

$$
f(t) = \left\{ \begin{array}{ll} \frac{t}{2}, & 0< t< 2, \\ 0, & \text {其他.} \end{array} \right.
$$

这就是说,  $F(x)$  恰是非负函数  $f(t)$  在区间  $(- \infty , x]$  上的积分, 在这种情况我们称  $X$  为连续型随机变量. 下一节我们将给出连续型随机变量的一般定义.  $\square$

# $\S 4$  连续型随机变量及其概率密度

一般,如上节例2中的随机变量那样,如果对于随机变量  $X$  的分布函数 $F(x)$ ,存在非负可积函数  $f(x)$ ,使对于任意实数  $x$  有

$$
F(x) = \int_{-\infty}^{x}f(t)\mathrm{d}t, \tag{4.1}
$$

则称  $X$  为连续型随机变量,  $f(x)$  称为  $X$  的概率密度函数,简称概率密度  $①$

由(4.1)式,据数学分析的知识知连续型随机变量的分布函数是连续函数.

在实际应用中遇到的基本上是离散型或连续型随机变量.本书只讨论这两种随机变量.

由定义知道,概率密度  $f(x)$  具有以下性质:

$1^{\circ}f(x)\geqslant 0$

$$
2^{\circ}\int_{-\infty}^{\infty}f(x)\mathrm{d}x = 1.
$$

$3^{\circ}$  对于任意实数  $x_{1},x_{2}(x_{1}\leqslant x_{2})$

$$
P\{x_{1}< X\leqslant x_{2}\} = F(x_{2}) - F(x_{1}) = \int_{x_{1}}^{x_{2}}f(x)\mathrm{d}x.
$$

$4^{\circ}$  若  $f(x)$  在点  $x$  处连续,则有  $F^{\prime}(x) = f(x)$

反之,若  $f(x)$  具备性质  $1^{\circ},2^{\circ}$  ,引入

$$
G(x) = \int_{-\infty}^{x}f(t)\mathrm{d}t,
$$

它是某一随机变量  $X$  的分布函数,  $f(x)$  是  $X$  的概率密度.

由性质  $2^{\circ}$  知道介于曲线  $y = f(x)$  与  $Ox$  轴之间的面积等于1(图2一7).由  $3^{\circ}$  知道  $X$  落在区间  $(x_{1},x_{2}]$  的概率  $P\{x_{1}< X\leqslant x_{2}\}$  等于区间  $(x_{1},x_{2}]$  上曲线 $y = f(x)$  之下的曲边梯形的面积(图2一8).由性质  $4^{\circ}$  知道在  $f(x)$  的连续点  $x$  处有

$$
f(x) = \lim_{\Delta x\to 0^{+}}{\frac{F(x + \Delta x) - F(x)}{\Delta x}} = \lim_{\Delta x\to 0^{+}}{\frac{P\{x< X\leqslant x + \Delta x\}}{\Delta x}}. \tag{4.2}
$$

从这里我们看到概率密度的定义与物理学中的线密度的定义相类似,这就是称 $f(x)$  为概率密度的缘故.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-7

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-8

由(4.2)式知道,若不计高阶无穷小,有

$$
P\{x< X\leqslant x + \Delta x\} \approx f(x)\Delta x. \tag{4.3}
$$

这表示  $X$  落在小区间  $(x,x + \Delta x]$  上的概率近似地等于  $f(x)\Delta x$

例1 设随机变量  $X$  具有概率密度

$$
f(x) = \left\{ \begin{array}{ll}k x, & 0\leqslant x< 3, \\ 2 - \frac{x}{2}, & 3\leqslant x\leqslant 4, \\ 0, & \text{其他}. \end{array} \right.
$$

(1)确定常数  $k$  ,(2)求  $X$  的分布函数  $F(x)$  ,(3)求  $P\left\{1< X\leqslant \frac{7}{2}\right\}$

解(1)由  $\int_{- \infty}^{\infty}f(x)\mathrm{d}x = 1$  ,得

$$
\int_{0}^{3}k x\mathrm{d}x + \int_{3}^{4}\left(2 - \frac{x}{2}\right)\mathrm{d}x = 1,
$$

解得  $k = \frac{1}{6}$  ,于是  $X$  的概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{x}{6}, & 0\leqslant x< 3, \\ 2 - \frac{x}{2}, & 3\leqslant x< 4, \\ 0, & \text{其他}. \end{array} \right.
$$

(2)  $X$  的分布函数为

$$
F(x) = \left\{ \begin{array}{ll}0, & x< 0, \\ \int_{0}^{x}\frac{x}{6}\mathrm{d}x, & 0\leqslant x< 3, \\ \int_{0}^{3}\frac{x}{6}\mathrm{d}x + \int_{3}^{x}\left(2 - \frac{x}{2}\right)\mathrm{d}x, & 3\leqslant x< 4, \\ 1, & x\geqslant 4. \end{array} \right.
$$

即

$$
F(x) = \left\{ \begin{array}{ll}0, & x< 0, \\ \frac{x^{2}}{12}, & 0\leqslant x< 3, \\ -3 + 2x - \frac{x^{2}}{4}, & 3\leqslant x< 4, \\ 1, & x\geqslant 4. \end{array} \right.
$$

$$
P\left\{1< X\leqslant \frac{7}{2}\right\} = F\left(\frac{7}{2}\right) - F(1) = \frac{41}{48}. \tag{3}
$$

需要指出的是,对于连续型随机变量  $X$  来说,它取任一指定实数值  $a$  的概率均为0,即  $P\{X = a\} = 0$  .事实上,设  $X$  的分布函数为  $F(x),\Delta x > 0$  ,则由  $\{X = a\} \subset$ $\{a - \Delta x< X\leqslant a\}$  得

$$
0\leqslant P\{X = a\} \leqslant P\{a - \Delta x< X\leqslant a\} = F(a) - F(a - \Delta x).
$$

在上述不等式中令  $\Delta x\rightarrow 0$  ,并注意到  $X$  为连续型随机变量,其分布函数  $F(x)$  是连续的,即得

$$
P\{X = a\} = 0. \tag{4.4}
$$

据此,在计算连续型随机变量落在某一区间的概率时,可以不必区分该区间是开区间或闭区间或半闭区间.例如有

$$
P\{a< X\leqslant b\} = P\{a\leqslant X\leqslant b\} = P\{a< X< b\} .
$$

在这里,事件  $\{X = a\}$  并非不可能事件,但有  $P\{X = a\} = 0$  .这就是说,若  $A$  是不可能事件,则有  $P(A) = 0$  ;反之,若  $P(A) = 0$  ,并不一定意味着  $A$  是不可能事件.

以后当我们提到一个随机变量  $X$  的"概率分布"时,指的是它的分布函数;或者,当  $X$  是连续型随机变量时,指的是它的概率密度,当  $X$  是离散型随机变量时,指的是它的分布律.

下面介绍三种重要的连续型随机变量,

# (一)均匀分布

若连续型随机变量  $X$  具有概率密度

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{b - a}, & a< x< b, \\ 0, & \text{其他}, \end{array} \right. \tag{4.5}
$$

则称  $X$  在区间  $(a,b)$  上服从均匀分布,记为  $X\sim U(a,b)$

易知  $f(x)\geqslant 0$  ,且  $\int_{- \infty}^{\infty}f(x)\mathrm{d}x = 1.$

在区间  $(a,b)$  上服从均匀分布的随机变量  $X$  ,具有下述意义的等可能性,即它落在区间  $(a,b)$  中任意等长度的子区间内的可能性是相同的.或者说它落在

$(a, b)$  的子区间内的概率只依赖于子区间的长度而与子区间的位置无关. 事实上, 对于任一长度为  $l$  的子区间  $(c, c + l)$ ,  $a \leqslant c < c + l \leqslant b$ , 有

$$
P\{c< X\leqslant c + l\} = \int_{c}^{c + l}f(x)\mathrm{d}x = \int_{c}^{c + l}\frac{1}{b - a}\mathrm{d}x = \frac{l}{b - a}.
$$

由(4.1)式得  $X$  的分布函数为

$$
F(x) = \left\{ \begin{array}{ll}0, & x < a, \\ \frac{c - a}{b - a}, & a \leqslant x < b, \\ 1, & x \geqslant b. \end{array} \right. \tag{4.6}
$$

$f(x)$  及  $F(x)$  的图形分别如图2- 9, 图2- 10所示.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-9

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-10

例2 设电阻值  $R$  是一个随机变量, 均匀分布在  $900 \sim 1100 \Omega$ . 求  $R$  的概率密度及  $R$  落在  $950 \sim 1050 \Omega$  的概率.

解 按题意,  $R$  的概率密度为

$$
f(r) = \left\{ \begin{array}{ll} \frac{1}{100 - 900}, & 900 < r < 1100, \\ 0, & \text{其他}. \end{array} \right.
$$

故有  $P\{950 < R \leqslant 1050\} = \int_{950}^{1050} \frac{1}{200} \mathrm{d}r = 0.5$ .

# (二) 指数分布

若连续型随机变量  $X$  的概率密度为

$$
f(x) = \left\{ \begin{array}{ll} \frac{1}{\theta} \mathrm{e}^{-x / \theta}, & x > 0, \\ 0, & \text{其他}, \end{array} \right. \tag{4.7}
$$

其中  $\theta > 0$  为常数, 则称  $X$  服从参数为  $\theta$  的指数分布.

易知  $f(x) \geqslant 0$ , 且  $\int_{- \infty}^{\infty} f(x) \mathrm{d}x = 1$ . 图2- 11中分别画出了  $\theta = 1 / 3, \theta = 1$ ,

$\theta = 2$  时  $f(x)$  的图形.

由(4.7)式容易得到随机变量  $X$  的分布函数为

$$
F(x)={\binom{1-\mathrm{e}^{-x/\theta},\quad x>0,}{0,}} \tag{4.8}
$$

服从指数分布的随机变量  $X$  具有以下有趣的性质:

对于任意  $s, t > 0$ , 有  $P\{X > s + t \mid X > s\} = P\{X > t\}$ . (4.9)

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-11

事实上

$$
\begin{array}{r l} & {P\{X > s + t\mid X > s\} = \frac{P\{(X > s + t)\bigcap(X > s)\}}{P\{X > s\}}}\\ & {\qquad = \frac{P\{X > s + t\}}{P\{X > s\}} = \frac{1 - F(s + t)}{1 - F(s)}}\\ & {\qquad = \frac{\mathrm{e}^{-(s + t) / \theta}}{\mathrm{e}^{-s / \theta}} = \mathrm{e}^{-t / \theta}}\\ & {\qquad = P\{X > t\} .} \end{array}
$$

性质(4.9)称为无记忆性,如果  $X$  是某一元件的寿命,那么(4.9)式表明:已知元件已使用了  $s \mathrm{~h}$ ,它总共能使用至少  $(s + t) \mathrm{~h}$  的条件概率,与从开始使用时算起它至少能使用  $t \mathrm{~h}$  的概率相等,这就是说,元件对它已使用过  $s \mathrm{~h}$  没有记忆,具有这一性质是指数分布有广泛应用的重要原因.

指数分布在可靠性理论与排队论中有广泛的应用,

# (三)正态分布

若连续型随机变量  $X$  的概率密度为

$$
f(x) = \frac{1}{\sqrt{2\pi \sigma}} \mathrm{e}^{-\frac{(x - \mu)^2}{2\sigma^2}}, \quad -\infty < x < \infty , \tag{4.10}
$$

其中  $\mu , \sigma (\sigma > 0)$  为常数,则称  $X$  服从参数为  $\mu , \sigma$  的正态分布或高斯(Gauss)分布,记为  $X \sim N(\mu , \sigma^2)$

显然  $f(x) \geqslant 0$ ,下面来证明  $\int_{- \infty}^{\infty} f(x) \mathrm{d}x = 1$ . 令  $(x - \mu) / \sigma = t$ ,得到

$$
\int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi \sigma}} \mathrm{e}^{-\frac{(x - \mu)^2}{2\sigma^2}} \mathrm{d}x = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} \mathrm{e}^{-t^2 /2} \mathrm{d}t,
$$

记  $I = \int_{- \infty}^{\infty} \mathrm{e}^{- t^2 /2} \mathrm{d}t$ ,则有  $I^2 = \int_{- \infty}^{\infty} \int_{- \infty}^{\infty} \mathrm{e}^{- (t^2 + u^2) / 2} \mathrm{d}t \mathrm{d}u$ ,利用极坐标将它化成累次积分,得到

$$
I^{2} = \int_{0}^{2\pi}\int_{0}^{\infty}r\mathrm{e}^{-r^{2} / 2}\mathrm{d}r\mathrm{d}\theta = 2\pi .
$$

而  $I > 0$  ,故有  $I = \sqrt{2\pi}$  ,即有

$$
\int_{-\infty}^{\infty}\mathrm{e}^{-t^{2} / 2}\mathrm{d}t = \sqrt{2\pi}, \tag{4.11}
$$

于是

$$
\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}\mathrm{e}^{-\frac{(x - \mu)^{2}}{2\sigma^{2}}}\mathrm{d}x = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}\mathrm{e}^{-t\epsilon /2}\mathrm{d}t = 1.
$$

参数  $\mu ,\sigma$  的意义将在第四章中说明.  $f(x)$  的图形如图2一12所示,它具有以下性质.

$1^{\circ}$  曲线关于  $x = \mu$  对称.这表明对于任意  $h > 0$  有(图2一12)

$$
P\{\mu -h{<}X\leqslant \mu \} = P\{\mu {<}X\leqslant \mu +h\} .
$$

$2^{\circ}$  当  $x = \mu$  时取到最大值

$$
f(\mu) = \frac{1}{\sqrt{2\pi}\sigma}.
$$

$x$  离  $\mu$  越远,  $f(x)$  的值越小.这表明对于同样长度的区间,当区间离  $\mu$  越远时,  $X$  落在这个区间上的概率越小.

在  $x = \mu \pm \sigma$  处曲线有拐点.曲线以  $Ox$  轴为渐近线.

另外,如果固定  $\sigma$  ,改变  $\mu$  的值,则图形沿着  $Ox$  轴平移,而不改变其形状(如图2一12),可见正态分布的概率密度曲线  $y = f(x)$  的位置完全由参数  $\mu$  所确定.  $\mu$  称为位置参数.

如果固定  $\mu$  ,改变  $\sigma$  ,由于最大值  $f(\mu) = \frac{1}{\sqrt{2\pi}\sigma}$  ,可知当  $\sigma$  越小时图形变得越尖(如图2一13),因而  $X$  落在  $\mu$  附近的概率越大.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-12

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-13

由(4.10)式得  $X$  的分布函数为(如图2一14)

$$
F(x) = \frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{x}\mathrm{e}^{-\frac{(t - \mu)^{2}}{2\sigma^{2}}}\mathrm{d}t, \tag{4.12}
$$

特别,当  $\mu = 0,\sigma = 1$  时称随机变量  $X$  服从标准正态分布.其概率密度和分布函数分别用  $\phi (x),\Phi (x)$  表示,即有

$$
\phi (x) = \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-x^{2} / 2}, \tag{4.13}
$$

$$
\Phi (x) = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}\mathrm{e}^{-t^{2} / 2}\mathrm{d}t. \tag{4.14}
$$

易知  $\Phi (- x) = 1 - \Phi (x)$  (4.15)

(参见图2一15).

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-14

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-15

人们已编制了  $\Phi (x)$  的函数表,可供查用(见附表2).

一般,若随机变量  $X\sim N(\mu ,\sigma^{2})$  ,我们只要通过一个线性变换就能将它化成标准正态分布.

引理 若随机变量  $X\sim N(\mu ,\sigma^{2})$  ,则  $Z = \frac{X - \mu}{\sigma}\sim N(0,1)$

证  $Z = \frac{X - \mu}{\sigma}$  的分布函数为

$$
P\{Z\leqslant x\} = P\left\{\frac{X - \mu}{\sigma}\leqslant x\right\} = P\{X\leqslant \mu +\sigma x\} = \frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{(\mu +\mu)}\mathrm{e}^{-\frac{(t - \mu)^{2}}{2\sigma^{2}}}\mathrm{d}t,
$$

令  $\frac{t - \mu}{\sigma} = u$  ,得

$$
P\{Z\leqslant x\} = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}\mathrm{e}^{-u^{2} / 2}\mathrm{d}u = \Phi (x),
$$

由此知  $Z = \frac{X - \mu}{\sigma}\sim N(0,1)$

于是,若随机变量  $X\sim N(\mu ,\sigma^{2})$  ,则它的分布函数  $F(x)$  可写成

$$
F(x) = P\{X \leqslant x\} = P\left\{\frac{X - \mu}{\sigma} \leqslant \frac{x - \mu}{\sigma}\right\} = \Phi \left(\frac{x - \mu}{\sigma}\right). \tag{4.16}
$$

对于任意区间  $(x_{1}, x_{2}]$ , 有

$$
\begin{array}{r}{P\{x_{1}< X\leqslant x_{2}\} = P\Big\{\frac{x_{1} - \mu}{\sigma}{<}\frac{X - \mu}{\sigma}{\leqslant}\frac{x_{1} - \mu}{\sigma}\Big\}}\\ {= \Phi \Big(\frac{x_{2} - \mu}{\sigma}\Big) - \Phi \Big(\frac{x_{1} - \mu}{\sigma}\Big).} \end{array} \tag{4.17}
$$

例如, 设随机变量  $X \sim N(1,4)$ , 查表得

$$
\begin{array}{r l} & {P\{0< X\leqslant 1.6\} = \Phi \Big(\frac{1.6 - 1}{2}\Big) - \Phi \Big(\frac{0 - 1}{2}\Big) = \Phi (0.3) - \Phi (-0.5)}\\ & {\qquad = 0.617 9 - [1 - \Phi (0.5)] = 0.617 9 - 1 + 0.691 5 = 0.309 4.} \end{array}
$$

设  $X \sim N(\mu , \sigma^{2})$ , 由  $\Phi (x)$  的函数表还能得到 (图 2- 16):

$$
P\{\mu - \sigma < X < \mu + \sigma \} = \Phi (1) - \Phi (-1) = 2\Phi (1) - 1 = 68.26\% ,
$$

$$
P\{\mu - 2\sigma < X < \mu + 2\sigma \} = \Phi (2) - \Phi (-2) = 95.44\% ,
$$

$$
P\{\mu - 3\sigma < X < \mu + 3\sigma \} = \Phi (3) - \Phi (-3) = 99.74\% .
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-16

我们看到, 尽管正态变量的取值范围是  $(- \infty , \infty)$ , 但它的值落在  $(\mu - 3\sigma , \mu + 3\sigma)$  内几乎是肯定的事. 这就是人们所说的"3σ"法则.

例3 将一温度调节器放置在贮存着某种液体的容器内. 调节器整定在  $d^{\circ}C$ , 液体的温度  $X$  (以  $^{\circ}C$  计) 是一个随机变量, 且  $X \sim N(d, 0.5^{2})$ . (1) 若  $d = 90^{\circ}C$ , 求  $X$  小于  $89^{\circ}C$  的概率. (2) 若要求保持液体的温度至少为  $80^{\circ}C$  的概率不低于 0.99, 问  $d$  至少为多少?

解 (1) 所求概率为

$$
\begin{array}{c}{{P\{X< 89\}=P\Big\{\frac{X-90}{0.5}< \frac{89-90}{0.5}\Big\}=\Phi\Big(\frac{89-90}{0.5}\Big)=\Phi(-2)}}\\ {{=1-\Phi(2)=1-0.9772=0.0228.}}\end{array}
$$

(2) 按题意需求  $d$  满足

$$
\begin{array}{l}{{0.99\leqslant P\{X\geqslant80\}=P\Big\{\frac{X-d}{0.5}\geqslant\frac{80-d}{0.5}\Big\}}}\\ {{=1-P\Big\{\frac{X-d}{0.5}< \frac{80-d}{0.5}\Big\}=1-\Phi\Big(\frac{80-d}{0.5}\Big).}}\end{array}
$$

即  $\Phi \Big(\frac{d - 80}{0.5}\Big) \geqslant 0.99 = \Phi (2.327)$ ,

亦即  $\frac{d - 80}{0.5} \geqslant 2.327$ .

故需  $d \geqslant 81.1635$ .

为了便于今后在数理统计中的应用,对于标准正态随机变量,我们引入上  $\alpha$  分位数的定义.

设  $X \sim N(0,1)$ ,若  $z_{a}$  满足条件

$$
P\{X > z_{a}\} = a, 0 < \alpha < 1, \tag{4.18}
$$

则称  $z_{a}$  为标准正态分布的上  $\alpha$  分位数(如图2- 17).下面列出了几个常用的  $z_{a}$  的值:

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图2-17

<table><tr><td>α</td><td>0.001</td><td>0.005</td><td>0.01</td><td>0.025</td><td>0.05</td><td>0.10</td></tr><tr><td>zα</td><td>3.090</td><td>2.576</td><td>2.326</td><td>1.960</td><td>1.645</td><td>1.282</td></tr></table>

另外,由  $\phi (x)$  图形的对称性知道  $z_{1 - \alpha} = - z_{\alpha}$

在自然现象和社会现象中,大量随机变量都服从或近似服从正态分布.例如,一个地区的男性成年人的身高、测量某零件长度的误差、海洋波浪的高度、半导体器件中的热噪声电流或电压等,都服从正态分布.在概率论与数理统计的理论研究和实际应用中正态随机变量起着特别重要的作用.在第五章我们将进一步说明正态随机变量的重要性.

# §5 随机变量的函数的分布

在实际中,我们常对某些随机变量的函数更感兴趣.例如,在一些试验中,所关心的随机变量往往不能由直接测量得到,而它却是某个能直接测量的随机变量的函数.比如我们能测量圆轴截面的直径  $d$ ,而关心的却是截面面积  $A = \frac{1}{4} \pi d^{2}$ .这里,随机变量  $A$  是随机变量  $d$  的函数.在这一节中,我们将讨论如何由已知的随机变量  $X$  的概率分布去求得它的函数  $Y = g(X) (g(\cdot)$  是已知的连续函数)的概率分布.这里  $Y$  是这样的随机变量,当  $X$  取值  $x$  时, $Y$  取值  $g(x)$ .

例1 设随机变量  $X$  具有以下的分布律:

试求  $Y = (X - 1)^{2}$  的分布律.

解  $Y$  所有可能取的值为0,1,4. 由

$$
P\{Y = 0\} = P\{(X - 1)^{2} = 0\} = P\{X = 1\} = 0.1,
$$

$$
P\{Y = 1\} = P\{X = 0\} +P\{X = 2\} = 0.7,
$$

$$
P\{Y = 4\} = P\{X = -1\} = 0.2,
$$

即得  $Y$  的分布律为

$$
\frac{Y}{\begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c} & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \end{array} \begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c} & & & & \end{array} \begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c} & & & & & & & & & & & & & & \end{array} \begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c} & & & & & & & & & & & & & & & & & & & & & & & & \end{array} \end{array}
$$

例2 设随机变量  $X$  具有概率密度

$$
f_{X}(x) = \left\{{\frac{x}{8}},\quad 0< x< 4,\right.
$$

求随机变量  $Y = 2X + 8$  的概率密度.

解分别记  $X,Y$  的分布函数为  $F_{X}(x),F_{Y}(y)$  .下面先来求  $F_{Y}(y)$

$$
F_{Y}(y) = P\{Y\leqslant y\} = P\{2X + 8\leqslant y\}
$$

$$
= P\left\{X\leqslant {\frac{y - 8}{2}}\right\} = F_{X}\left(\frac{y - 8}{2}\right).
$$

将  $F_{Y}(y)$  关于  $y$  求导数,得  $Y = 2X + 8$  的概率密度为

$$
\begin{array}{r l} & {f_{Y}(y) = f_{X}\Big(\frac{y - 8}{2}\Big)\Big(\frac{y - 8}{2}\Big)^{\prime}}\\ & {\qquad = \left\{\frac{1}{8}\times \frac{y - 8}{2}\times \frac{1}{2},\quad 0< \frac{y - 8}{2} < 4,\right.}\\ & {\qquad \left.\right.}\\ & {\qquad = \left\{\frac{y - 8}{32},\quad 8< y< 16,\right.}\\ & {\qquad \left.\right.}\\ & {\qquad \left.\right.} \end{array}
$$

例3设随机变量  $X$  具有概率密度  $f_{X}(x), - \infty < x< \infty$  ,求  $Y = X^{2}$  的概率密度.

解分别记  $X,Y$  的分布函数为  $F_{X}(x),F_{Y}(y)$  .先来求  $Y$  的分布函数

$F_{Y}(y)$ . 由于  $Y = X^{2} \geqslant 0$ , 故当  $y \leqslant 0$  时  $F_{Y}(y) = 0$ . 当  $y > 0$  时有

$$
\begin{array}{r l} & {F_{Y}(y) = P\{Y\leqslant y\} = P\{X^{2}\leqslant y\}}\\ & {\qquad = P\{-\sqrt{y}\leqslant X\leqslant \sqrt{y}\}}\\ & {\qquad = F_{X}(\sqrt{y}) - F_{X}(-\sqrt{y}).} \end{array}
$$

将  $F_{Y}(y)$  关于  $y$  求导数, 即得  $Y$  的概率密度为

$$
f_{Y}(y) = \left\{ \begin{array}{ll}\frac{1}{2\sqrt{y}} \left[ f_{X}(\sqrt{y}) + f_{X}(-\sqrt{y}) \right], & y > 0, \\ 0, & y \leqslant 0. \end{array} \right. \tag{5.1}
$$

例如, 设  $X \sim N(0,1)$ , 其概率密度为

$$
\phi (x) = \frac{1}{\sqrt{2\pi}} \mathrm{e}^{-x^{2} / 2}, \quad -\infty < x < \infty .
$$

由(5.1)式得  $Y = X^{2}$  的概率密度为

$$
f_{Y}(y) = \left\{ \begin{array}{ll} \frac{1}{\sqrt{2\pi}} y^{-1 / 2} \mathrm{e}^{-y / 2}, & y > 0, \\ 0, & y \leqslant 0. \end{array} \right.
$$

此时称  $Y$  服从自由度为1的  $\chi^{2}$  分布.

上述两个例子解法的关键一步是在"  $Y \leqslant y^{\prime \prime}$  中, 即在"  $g(X) \leqslant y^{\prime \prime}$  中解出  $X$ , 从而得到一个与"  $g(X) \leqslant y^{\prime \prime}$  等价的  $X$  的不等式, 并以后者代替"  $g(X) \leqslant y^{\prime \prime}$ . 例如, 在例2中以"  $X \leqslant \frac{y - 8}{2}$  "代替"  $2X + 8 \leqslant y^{\prime \prime}$ ; 在例3中, 当  $y > 0$  时以"  $- \sqrt{y} \leqslant X \leqslant \sqrt{y}$  "代替"  $X^{2} \leqslant y^{\prime \prime}$ . 一般来说, 可以用这样的方法  $①$  求连续型随机变量的函数的分布函数或概率密度. 下面我们仅对  $Y = g(X)$ , 其中  $g(\cdot)$  是严格单调函数的情况, 写出一般的结果.

定理设随机变量  $X$  具有概率密度  $f_{X}(x), - \infty < x < \infty$ , 又设函数  $g(x)$  处处可导且恒有  $g^{\prime}(x) > 0$  (或恒有  $g^{\prime}(x) < 0$ ), 则  $Y = g(X)$  是连续型随机变量, 其概率密度为

$$
f_{Y}(y) = \left\{ \begin{array}{ll} f_{X} \left[ h(y) \right] \mid h^{\prime}(y) \mid , & \alpha < y < \beta , \\ 0, & \text{其他}, \end{array} \right. \tag{5.2}
$$

其中  $\alpha = \min \{g(- \infty), g(\infty) \} , \beta = \max \{g(- \infty), g(\infty) \} , h(y)$  是  $g(x)$  的反函数.

我们只证  $g^{\prime}(x) > 0$  的情况. 此时  $g(x)$  在  $(- \infty , \infty)$  内严格单调增加, 它的

反函数  $h(y)$  存在,且在  $(\alpha ,\beta)$  内严格单调增加、可导.分别记  $X,Y$  的分布函数为 $F_{X}(x),F_{Y}(y)$  .现在先来求  $Y$  的分布函数  $F_{Y}(y)$

因为  $Y = g(X)$  在  $(\alpha ,\beta)$  内取值,故当  $y\leqslant \alpha$  时,  $F_{Y}(y) = P\{Y\leqslant y\} = 0$  ;当  $y\geq \beta$  时,  $F_{Y}(y) = P\{Y\leqslant y\} = 1$

当  $\alpha {<}y{<}\beta$  时,

$$
\begin{array}{r}{F_{Y}(y) = P\{Y\leqslant y\} = P\{g(X)\leqslant y\}}\\ {= P\{X\leqslant h(y)\} = F_{X}[h(y)].} \end{array}
$$

将  $F_{Y}(y)$  关于  $y$  求导数,即得  $Y$  的概率密度

$$
f_{Y}(y) = \left\{ \begin{array}{l l}{f_{X}[h(y)]h^{\prime}(y),} & {\alpha {<}y{<}\beta ,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right. \tag{5.3}
$$

对于  $g^{\prime}(x){<}0$  的情况可以同样地证明,此时有

$$
f_{Y}(y) = \left\{ \begin{array}{l l}{f_{X}[h(y)][-h^{\prime}(y)],} & {\alpha {<}y{<}\beta ,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right. \tag{5.4}
$$

合并(5.3)与(5.4)两式,(5.2)式得证. 口

若  $f(x)$  在有限区间  $[a,b]$  以外等于零,则只需假设在  $[a,b]$  上恒有  $g^{\prime}(x) > 0$  (或恒有  $g^{\prime}(x){<}0)$  ,此时

$$
\alpha = \min \{g(a),g(b)\} ,\quad \beta = \max \{g(a),g(b)\} .
$$

例4设随机变量  $X\sim N(\mu ,\sigma^{2})$  .试证明  $X$  的线性函数  $Y = a X + b$ $(a\neq 0)$  也服从正态分布.

证  $X$  的概率密度为

$$
f_{X}(x) = \frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x - \mu)^{2}}{2\sigma^{2}}}, - \infty {<}x{<}\infty .
$$

现在  $y = g(x) = a x + b$  ,由这一式子解得

由(5.2)式得  $Y = a X + b$  的概率密度为

$$
f_{Y}(y) = \frac{1}{|a|} f_{X}\Big(\frac{y - b}{a}\Big),\quad -\infty {<}y{<}\infty ,
$$

即

$$
f_{Y}(y) = \frac{1}{|a|}\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(\frac{y - b}{a} - \mu)^{2}}{2\sigma^{2}}} = \frac{1}{|a|\sigma\sqrt{2\pi}}\mathrm{e}^{-\frac{[y - (b + a\mu)^{2}}{2(a\sigma)^{2}}},\quad -\infty {<}y{<}\infty .
$$

即有  $Y = a X + b\sim N(a\mu +b,(a\sigma)^{2})$

特别,在上例中取  $a = \frac{1}{\sigma},b = - \frac{\mu}{\sigma}$  得

$$
Y = \frac{X - \mu}{\sigma} \sim N(0,1).
$$

这就是上一节引理的结果.  $\square$

例5设电压  $V = A\sin \theta$ ,其中  $A$  是一个已知的正常数,相角  $\Theta$  是一个随机变量,且有  $\Theta \sim U\left(- \frac{\pi}{2},\frac{\pi}{2}\right)$ ,试求电压  $V$  的概率密度.

解现在  $v = g(\theta) = A\sin \theta$  在  $\left(- \frac{\pi}{2},\frac{\pi}{2}\right)$  上恒有  $g^{\prime}(\theta) = A\cos \theta >0$ ,且有反函数

$$
\theta = h(v) = \arcsin {\frac{v}{A}},\quad h^{\prime}(v) = \frac{1}{\sqrt{A^{2} - v^{2}}},
$$

又,  $\Theta$  的概率密度为

$$
f(\theta) = \left\{ \begin{array}{ll}\frac{1}{\pi}, & -\frac{\pi}{2} < \theta < \frac{\pi}{2}, \\ 0, & \text{其他.} \end{array} \right.
$$

由(5.2)式得  $V = A\sin \theta$  的概率密度为

$$
\psi (v) = \left\{ \begin{array}{ll}\frac{1}{\pi} \cdot \frac{1}{\sqrt{A^{2} - v^{2}}}, & -A < v < A, \\ 0, & \text{其他.} \end{array} \right.
$$

若在上题中  $\Theta \sim U(0,\pi)$ ,因为此时  $v = g(\theta) = A\sin \theta$  在  $(0,\pi)$  内不是单调函数,上述定理失效,应仍按例3的方法来做.请读者自行求出其结果.

小结

随机变量  $X = X(e)$  是定义在样本空间  $S = \{e\}$  上的实值单值函数.也就是说,它是随机试验结果的函数.它的取值随试验的结果而定,是不能预先确定的,它的取值有一定的概率.随机变量的引入,使概率论的研究由个别随机事件扩大为随机变量所表征的随机现象的研究.今后,我们主要研究随机变量和它的分布.

一个随机变量,如果它所有可能的值是有限个或可列无限个,这种随机变量称为离散型随机变量,不是这种情况则称为非离散型的.不论是离散型的或非离散型的随机变量  $X$ ,都可以借助分布函数

$$
F(x) = P\{X \leqslant x\} , \quad -\infty < x < \infty
$$

来描述.若已知随机变量  $X$  的分布函数,则能知道  $X$  落在任一区间  $[x_{1},x_{2}]$  上的概率

$$
P\{x_{1}< X\leqslant x_{2}\} = F(x_{2}) - F(x_{1}),\quad x_{1}< x_{2}.
$$

这样,分布函数就能完整地描述随机变量取值的统计规律性.

对于离散型随机变量,我们需要掌握的是它可能取哪些值,以及它以怎样的概率取这些值,这就是离散型随机变量取值的统计规律性.因而,对于离散型随机变量,用分布律

$$
P\{X = x_{k}\} = p_{k},\quad k = 1,2,\dots
$$

或写成

$$
\frac{X\mid x_{1}\quad x_{2}\quad\cdots\quad x_{k}\quad\cdots}{p_{k}\mid p_{1}\quad p_{2}\quad\cdots\quad p_{k}\quad\cdots}
$$

这里  $\sum_{k = 1}^{\infty}p_{k} = 1$  来描述它的取值的统计规律性较为直观和简洁,分布律与分布函数有以下的关系

$$
F(x) = P\{X\leqslant x\} = \sum_{x_{k}\leqslant x}P\{X = x_{k}\} ,
$$

它们是一一对应的.

设随机变量  $X$  的分布函数为  $F(x)$ ,如果存在非负可积函数  $f(x)$ ,使得对于任意  $x$ ,有

$$
F(x) = \int_{-\infty}^{x}f(x)\mathrm{d}x,
$$

则称  $X$  是连续型随机变量,其中  $f(x)\geqslant 0$  称为  $X$  的概率密度.

给定  $X$  的概率密度  $f(x)$  就能确定  $F(x)$ ,由于  $f(x)$  位于积分号之内,故改变  $f(x)$  在个别点上的函数值并不改变  $F(x)$  的值.因此,改变  $f(x)$  在个别点上的值,是无关紧要的.

连续型随机变量  $X$  的分布函数是连续的,连续型随机变量取任一指定实数值  $a$  的概率为0,即  $P\{X = a\} = 0$ 。离散型随机变量是不具备这两点性质的.

我们将随机变量分成:

读者不要误以为,一个随机变量,如果它不是离散型的那一定是连续型的,但本书只讨论两类重要的随机变量:离散型和连续型随机变量.

读者应掌握分布函数、分布律、概率密度的性质,本章引入了几种重要的随机变量的分布:(0- 1)分布、二项分布、泊松分布、指数分布、均匀分布和正态分布,读者必须熟知这几种随机变量的分布律或概率密度.

随机变量  $X$  的函数  $Y = g(X)$  也是一个随机变量,要掌握如何由已知的  $X$  的分布( $X$  的分布律或概率密度)去求得  $Y = g(X)$  的分布( $Y$  的分布律或概率密度).

# 重要术语及主题

随机变量分布函数离散型随机变量及其分布律连续型随机变量及其概率密度伯努利试验(0- 1)分布  $n$  重伯努利试验二项分布泊松分布指数分布均匀分布正态分布随机变量函数的分布

# 习题

1. 考虑为期一年的一张保险单,若投保人在投保后一年内因意外死亡,则公司赔付20万元;若投保人因其他原因死亡,则公司赔付5万元;若投保人在投保期末生存,则公司无

须付给任何费用. 若投保人在一年内因意外死亡的概率为 0.0002, 因其他原因死亡的概率为 0.0010, 求公司赔付金额的分布律.

2. (1) 一袋中装有 5 只球, 编号为 1, 2, 3, 4, 5. 在袋中同时取 3 只, 以  $X$  表示取出的 3 只球中的最大号码, 写出随机变量  $X$  的分布律.

(2) 将一颗骰子抛掷两次, 以  $X$  表示两次中得到的小的点数, 试求  $X$  的分布律.

3. 设在 15 只同类型的零件中有 2 只是次品, 在其中取 3 次, 每次任取 1 只, 作不放回抽样. 以  $X$  表示取出的次品的只数.

(1) 求  $X$  的分布律.

(2) 画出分布律的图形.

4. 进行重复独立试验, 设每次试验成功的概率为  $p$ , 失败的概率为  $q = 1 - p$ $(0 < p < 1)$ .

(1) 将试验进行到出现一次成功为止, 以  $X$  表示所需的试验次数, 求  $X$  的分布律. (此时称  $X$  服从以  $p$  为参数的几何分布.)

(2) 将试验进行到出现  $r$  次成功为止, 以  $Y$  表示所需的试验次数, 求  $Y$  的分布律. (此时称  $Y$  服从以  $r, p$  为参数的帕斯卡分布或负二项分布.)

(3) 一篮球运动员的投篮命中率为  $45\%$ . 以  $X$  表示他首次投中时累计已投篮的次数, 写出  $X$  的分布律, 并计算  $X$  取偶数的概率.

5. 一房间有 3 扇同样大小的窗子, 其中只有一扇是打开的. 有一只鸟自开着的窗子飞入了房间, 它只能从开着的窗子飞出去. 鸟在房间里飞来飞去, 试图飞出房间. 假定鸟是没有记忆的, 它飞向各扇窗子是随机的.

(1) 以  $X$  表示鸟为了飞出房间试飞的次数, 求  $X$  的分布律.

(2) 户主声称, 他养的一只鸟是有记忆的, 它飞向任一窗子的尝试不多于一次. 以  $Y$  表示这只聪明的鸟为了飞出房间试飞的次数. 如户主所说是确实的, 试求  $Y$  的分布律.

(3) 求试飞次数  $X$  小于  $Y$  的概率和试飞次数  $Y$  小于  $X$  的概率.

6. 一大楼装有 5 台同类型的供水设备. 设各台设备是否被使用相互独立. 调查表明在任一时刻  $t$  每台设备被使用的概率为 0.1, 问在同一时刻,

(1) 恰有 2 台设备被使用的概率是多少?

(2) 至少有 3 台设备被使用的概率是多少?

(3) 至多有 3 台设备被使用的概率是多少?

(4) 至少有 1 台设备被使用的概率是多少?

7. 设事件  $A$  在每次试验中发生的概率为 0.3. 当  $A$  发生不少于 3 次时, 指示灯发出信号.

(1) 进行了 5 次重复独立试验, 求指示灯发出信号的概率.

(2) 进行了 7 次重复独立试验, 求指示灯发出信号的概率.

8. 甲、乙两人投篮, 投中的概率分别为 0.6, 0.7. 今各投 3 次. 求

(1) 两人投中次数相等的概率.

(2) 甲比乙投中次数多的概率.

9. 有一大批产品, 其验收方案如下, 先作第一次检验: 从中任取 10 件, 经检验无次品时

接受这批产品, 次品数大于 2 时拒收; 否则作第二次检验, 其做法是从中再任取 5 件, 仅当 5 件中无次品时接受这批产品. 若产品的次品率为  $10\%$ , 求

(1) 这批产品经第一次检验就能接受的概率.

(2) 需作第二次检验的概率.

(3) 这批产品按第二次检验的标准被接受的概率.

(4) 这批产品在第一次检验未能作决定且第二次检验时被通过的概率.

(5) 这批产品被接受的概率.

10. 有甲、乙两种味道和颜色都极为相似的名酒各 4 杯. 如果从中挑 4 杯, 能将甲种酒全部挑出来, 算是试验成功一次.

(1) 某人随机地去挑, 问他试验成功一次的概率是多少?

(2) 某人声称他通过品尝能区分两种酒. 他连续试验 10 次, 成功 3 次. 试推断他是猜对的, 还是他确有区分的能力 (设各次试验是相互独立的).

11. 尽管在几何教科书中已经讲过仅用圆规和直尺三等分一个任意角是不可能的, 但每一年总是有一些"发明者"撰写关于仅用圆规和直尺将角三等分的文章. 设某地区每年撰写此类文章的篇数  $X$  服从参数为 6 的泊松分布. 求明年没有此类文章的概率.

12. 一电话总机每分钟收到呼唤的次数服从参数为 4 的泊松分布. 求

(1) 某一分钟恰有 8 次呼唤的概率.

(2) 某一分钟的呼唤次数大于 3 的概率.

13. 某一公安局在长度为  $t$  的时间间隔内收到的紧急呼救的次数  $X$  服从参数为  $t / 2$  的泊松分布, 而与时间间隔的起点无关 (时间以 h 计). 求

(1) 某一天中午 12 时至下午 3 时未收到紧急呼救的概率.

(2) 某一天中午 12 时至下午 5 时至少收到 1 次紧急呼救的概率.

14. 某人家中在时间间隔  $t$  (以 h 计) 内接到电话的次数  $X$  服从参数为  $2t$  的泊松分布.

(1) 若他外出计划用时  $10 \mathrm{~min}$ , 问其间电话铃响一次的概率是多少?

(2) 若他希望外出时没有电话的概率至少为 0.5, 问他外出应控制的最长时间是多少?

15. 保险公司 在一天内承保了 5000 张相同年龄、为期一年的寿险保单, 每人一份. 在合同有效期内若投保人死亡, 则公司需赔付 3 万元. 设在一年内, 该年龄段的死亡率为 0.0015, 且各投保人是否死亡相互独立. 求该公司对于这批投保人的赔付总额不超过 30 万元的概率 (利用泊松定理计算).

16. 有一繁忙的汽车站, 每天有大量汽车通过, 设一辆汽车在一天的某段时间内出事故的概率为 0.0001. 在某天的该时间段内有 1000 辆汽车通过. 问出事故的车辆数不小于 2 的概率是多少? (利用泊松定理计算.)

17. (1) 设  $X$  服从  $(0 - 1)$  分布, 其分布律为  $P\{X = k\} = p^{k}(1 - p)^{1 - k}, k = 0,1$ , 求  $X$  的分布函数, 并作出其图形.

(2) 求第 2 题 (1) 中的随机变量的分布函数.

18. 在区间  $[0,a]$  上任意投掷一个质点, 以  $X$  表示这个质点的坐标. 设这个质点落在  $[0,a]$  中任意小区间内的概率与这个小区间的长度成正比例. 试求  $X$  的分布函数.

19. 以  $X$  表示某商店从早晨开始营业起直到第一个顾客到达的等待时间(以 min 计),  $X$  的分布函数是

$$
F_{X}(x)={\left\{\begin{array}{l l}{1-\mathrm{e}^{-0.4x},}&{x>0,}\\ {0,}&{x\leqslant0.}\end{array}\right.}
$$

求下述概率:

(1)  $P\{$  至多  $3\mathrm{min}\}$

(2)  $P\{$  至少  $4\mathrm{min}\}$

(3)  $P\{3\mathrm{min}$  至  $4\mathrm{min}$  之间  $\}$

(4)  $P\{$  至多  $3\mathrm{min}$  或至少  $4\mathrm{min}\}$

(5)  $P\{$  恰好  $2.5\mathrm{min}\}$

20. 设随机变量  $X$  的分布函数为

$$
F_{X}(x)={\left\{\begin{array}{l l}{0,}&{x< 1,}\\ {\ln x,}&{1\leqslant x< \mathbf{e},}\\ {1,}&{x\geqslant\mathbf{e}.}\end{array}\right.}
$$

(1)求  $P\{X{<}2\} ,P\{0{<}X\leqslant 3\} ,P\{2{<}X{<}5 / 2\}$

(2)求概率密度  $f_{X}(x)$

21. 设随机变量  $X$  的概率密度为

(1)  $f(x) = \left\{ \begin{array}{l l}{2(1 - 1 / x^{2}),} & {1\leqslant x\leqslant 2,}\\ {0,} & {\mathrm{~}\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.$

(2)  $f(x) = \left\{ \begin{array}{l l}{x,} & {0\leqslant x< 1,}\\ {2 - x,} & {1\leqslant x< 2,}\\ {0,} & {\mathrm{~}\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.$

求  $X$  的分布函数  $F(x)$  ,并画出(2)中的  $f(x)$  及  $F(x)$  的图形.

22. (1)分子运动速度的绝对值  $X$  服从麦克斯韦(Maxwell)分布,其概率密度为

$$
f(x)={\left\{\begin{array}{l l}{A x^{2}\mathrm{e}^{-x^{2}/b},}&{x>0,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}\end{array}\right.}
$$

其中  $b = m / (2k T),k$  为玻耳兹曼(Boltzmann)常数,  $T$  为绝对温度,  $m$  是分子的质量,试确定常数  $A$

(2)某人研究了英格兰在1875—1951年间,在矿山发生导致不少于10人死亡的事故的频繁程度,得知相继两次事故之间的时间  $T$  (以日计)服从指数分布,其概率密度为

$$
f_{T}(t) = \left\{ \begin{array}{l l}{\frac{1}{241}\mathrm{e}^{-t / 241},} & {t > 0,}\\ {0,} & {\mathrm{~}\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.
$$

求分布函数  $F_{T}(t)$  ,并求概率  $P\{50{<}T{<}100\}$

23. 某种型号器件的寿命  $X$  (以  $\mathrm{h}$  计)具有概率密度

$$
f(x) = \left\{ \begin{array}{l l}{\frac{1000}{x^{2}},} & {x > 1000,}\\ {0,} & {\mathrm{~}\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.
$$

现有一大批此种器件(设各器件损坏与否相互独立),任取5只,问其中至少有2只寿命大于 $1500\mathrm{~h~}$  的概率是多少?

24. 设顾客在某银行的窗口等待服务的时间  $X$  (以min计)服从指数分布,其概率密度为

$$
f_{X}(x) = \left\{ \begin{array}{l l}{\frac{1}{5}\mathrm{e}^{-x / 5},} & {x > 0,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.
$$

某顾客在窗口等待服务,若超过  $10\mathrm{min}$  ,他就离开.他一个月要到银行5次.以  $Y$  表示一个月内他未等到服务而离开窗口的次数.写出  $Y$  的分布律,并求  $P\{Y\geqslant 1\}$

25. 设  $K$  在(0,5)内服从均匀分布,求  $x$  的方程

$$
4x^{2} + 4K x + K + 2 = 0
$$

有实根的概率.

26. 设  $X\sim N(3,2^{2})$

(1)求  $P\{2< X\leqslant 5\} ,P\{-4< X\leqslant 10\} ,P\{|X| > 2\} ,P\{X > 3\} .$

(2)确定  $c$  ,使得  $P\{X > c\} = P\{X\leqslant c\}$

(3)设  $d$  满足  $P\{X > d\} \geqslant 0.9$  ,问  $d$  至多为多少?

27. 某地区18岁的女青年的血压(收缩压,以  $\mathrm{mmHg}$  计,  $1\mathrm{mmHg} = 133.3224\mathrm{Pa})$  服从 $N(110,12^{2})$  分布.在该地区任选一18岁的女青年,测量她的血压  $X$

(1)求  $P\{X\leqslant 105\} ,P\{100< X\leqslant 120\}$

(2)确定最小的  $x$  ,使  $P\{X > x\} \leqslant 0.05$

28. 由某机器生产的螺栓的长度(以  $\mathrm{cm}$  计)服从参数  $\mu = 10.05,\sigma = 0.06$  的正态分布.规定长度在范围  $10.05\pm 0.12$  内为合格品,求一螺栓为不合格品的概率.

29. 一工厂生产的某种元件的寿命  $X$  (以h计)服从参数为  $\mu = 160,\sigma (\sigma >0)$  的正态分布.若要求  $P\{120< X\leqslant 200\} \geqslant 0.80$  ,允许  $\sigma$  最大为多少?

30. 设在一电路中,电阻两端的电压(以  $\mathrm{v}$  计)服从  $N(120,2^{2})$  分布,今独立测量了5次,试确定有2次测定值落在区间[118,122]之外的概率.

31. 某人上班,自家里去办公楼要经过一交通指示灯,这一指示灯有  $80\%$  时间亮红灯,此时他在指示灯旁等待直至绿灯亮.等待时间在区间[0,30](以s计)上服从均匀分布.以  $X$  表示他的等待时间,求  $X$  的分布函数  $F(x)$  .画出  $F(x)$  的图形,并问  $X$  是否为连续型随机变量,是否为离散型的?(要说明理由.)

32. 设  $f(x),g(x)$  都是概率密度函数,求证

$$
h(x) = \alpha f(x) + (1 - \alpha)g(x),\quad 0\leqslant \alpha \leqslant 1
$$

也是一个概率密度函数.

33. 设随机变量  $X$  的分布律为

$$
\frac{X}{\begin{array}{c}{{\begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c}}\\ {{\begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c}}\\ {{\begin{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c}}\end{array}}}\end{array}}}\end{array}
$$

求  $Y = X^{2}$  的分布律.

34. 设随机变量  $X$  在区间(0,1)内服从均匀分布.

(1)求  $Y = \mathrm{e}^{X}$  的概率密度.

(2)求  $Y = -2\ln X$  的概率密度.

35. 设随机变量  $X\sim N(0,1)$

(1)求  $Y = \mathrm{e}^{X}$  的概率密度.

(2)求  $Y = 2X^{2} + 1$  的概率密度.

(3)求  $Y = \mid X\mid$  的概率密度.

36. (1)设随机变量  $X$  的概率密度为  $f(x), - \infty < x< \infty$  求  $Y = X^{3}$  的概率密度.

(2)设随机变量  $X$  的概率密度为

$$
f(x)={\binom{\mathrm{e}^{-x}}{0}},\quad x>0,
$$

求  $Y = X^{2}$  的概率密度.

37. 设随机变量  $X$  的概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{2x}{\pi^{2}}, & 0< x< \pi , \\ 0, & \text{其他.} \end{array} \right.
$$

求  $Y = \sin X$  的概率密度.

38. 设电流  $I$  是一个随机变量,它均匀分布在  $9\sim 11$  A之间.若此电流通过2Ω的电阻,在其上消耗的功率  $W = 2I^{2}$  .求  $W$  的概率密度.

39. 某物体的温度  $T(\mathrm{~\mathbb{Z}~}^{\circ}\mathrm{~\mathbb{F}~}$  计)是随机变量,且有  $T\sim N(98.6,2)$  ,已知  $\Theta = \frac{5}{9} (T - 32)$  试求  $\Theta$  (以  $^\circ \mathrm{C}$  计)的概率密度.

# 第三章 多维随机变量及其分布

# $\S 1$  二维随机变量

以上我们只限于讨论一个随机变量的情况,但在实际问题中,对于某些随机试验的结果需要同时用两个或两个以上的随机变量来描述。例如,为了研究某一地区学龄前儿童的发育情况,对这一地区的儿童进行抽查。对于每个儿童都能观察到他的身高  $H$  和体重  $W$ 。在这里,样本空间  $S = \{e\} = \{$  某地区的全部学龄前儿童  $\}$ ,而  $H(e)$  和  $W(e)$  是定义在  $S$  上的两个随机变量。又如炮弹弹着点的位置需要由它的横坐标和纵坐标来确定,而横坐标和纵坐标是定义在同一个样本空间的两个随机变量。

一般,设  $E$  是一个随机试验,它的样本空间是  $S = \{e\}$ ,设  $X = X(e)$  和  $Y = Y(e)$  是定义在  $S$  上的随机变量,由它们构成的一个向量  $(X,Y)$ ,叫做二维随机向量或二维随机变量(如图3- 1)。第二章讨论的随机变量也叫一维随机变量。

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-1

二维随机变量  $(X,Y)$  的性质不仅与  $X$  及  $Y$  有关,而且还依赖于这两个随机变量的相互关系。因此,逐个地来研究  $X$  或  $Y$  的性质是不够的,还需将  $(X,Y)$  作为一个整体来进行研究。

和一维的情况类似,我们也借助"分布函数"来研究二维随机变量。

定义 设  $(X,Y)$  是二维随机变量,对于任意实数  $x,y$ ,二元函数:

$$
F(x,y) = P\{(X\leqslant x)\cap (Y\leqslant y)\} \stackrel {\mathrm{i}\mathbb{E}\mathbb{E}}{\longrightarrow} P\{X\leqslant x,Y\leqslant y\}
$$

称为二维随机变量  $(X,Y)$  的分布函数,或称为随机变量  $X$  和  $Y$  的联合分布函数。

如果将二维随机变量  $(X,Y)$  看成平面上随机点的坐标,那么,分布函数  $F(x,y)$  在  $(x,y)$  处的函数值就是随机点  $(X,Y)$  落在如图3- 2所示的,以点  $(x,y)$  为顶点而位于该点左下方的无穷矩形域内的概率。

依照上述解释,借助于图3- 3容易算出随机点  $(X,Y)$  落在矩形域  $\{(x,y)\mid x_{1}< x\leqslant x_{2},y_{1}< y\leqslant y_{2}\}$  的概率为

$$
\begin{array}{r l} & {P\{x_{1}< X\leqslant x_{2},y_{1}< Y\leqslant y_{2}\}}\\ & {\quad = F(x_{2},y_{2}) - F(x_{2},y_{1}) + F(x_{1},y_{1}) - F(x_{1},y_{2}).} \end{array} \tag{1.1}
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-2

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-3

分布函数  $F(x,y)$  具有以下的基本性质:

$1^{\circ} F(x,y)$  是变量  $x$  和  $y$  的不减函数,即对于任意固定的  $y$ ,当  $x_{2} > x_{1}$  时  $F(x_{2},y) \geqslant F(x_{1},y)$ ;对于任意固定的  $x$ ,当  $y_{2} > y_{1}$  时  $F(x,y_{2}) \geqslant F(x,y_{1})$

$2^{\circ} 0 \leqslant F(x,y) \leqslant 1$ ,且

对于任意固定的  $x,F(- \infty ,y) = 0$

对于任意固定的  $x,F(x, - \infty) = 0$

$$
F(-\infty , - \infty) = 0,F(\infty ,\infty) = 1.
$$

上面四个式子可以从几何上加以说明.例如,在图3一2中将无穷矩形的右面边界向左无限平移(即  $x\rightarrow - \infty$  ),则"随机点  $(X,Y)$  落在这个矩形内"这一事件趋于不可能事件,故其概率趋于0,即有  $F(- \infty ,y) = 0$  ;又如当  $x\rightarrow \infty ,y\rightarrow \infty$  时图3一2中的无穷矩形扩展到全平面,随机点  $(X,Y)$  落在其中这一事件趋于必然事件,故其概率趋于1,即  $F(\infty ,\infty) = 1$

$3^{\circ} F(x + 0,y) = F(x,y),F(x,y + 0) = F(x,y)$ ,即  $F(x,y)$  关于  $x$  右连续,关于  $y$  也右连续.

$4^{\circ}$  对于任意  $(x_{1},y_{1}),(x_{2},y_{2}),x_{1}< x_{2},y_{1}< y_{2}$ ,下述不等式成立:

$$
F(x_{2},y_{2}) - F(x_{2},y_{1}) + F(x_{1},y_{1}) - F(x_{1},y_{2}) \geqslant 0.
$$

这一性质由(1.1)式及概率的非负性即可得,

如果二维随机变量  $(X,Y)$  全部可能取到的值是有限对或可列无限多对,则称  $(X,Y)$  是二维离散型随机变量.

设二维离散型随机变量  $(X,Y)$  所有可能取的值为  $(x_{i},y_{j}),i,j = 1,2,\dots$ ,记  $P\{X = x_{i},Y = y_{j}\} = p_{ij},i,j = 1,2,\dots$ ,则由概率的定义有

$$
p_{ij} \geqslant 0, \quad \sum_{i = 1}^{\infty} \sum_{j = 1}^{\infty} p_{ij} = 1.
$$

我们称  $P\{X = x_{i},Y = y_{j}\} = p_{ij},i,j = 1,2,\dots$  为二维离散型随机变量  $(X,Y)$  的分布律,或称为随机变量  $X$  和  $Y$  的联合分布律.

我们也能用表格来表示  $X$  和  $Y$  的联合分布律,如下表所示  $①$

<table><tr><td>X
Y</td><td>x1</td><td>x2</td><td>...</td><td>xi</td><td>...</td></tr><tr><td>y1</td><td>p11</td><td>p21</td><td>...</td><td>p11</td><td>...</td></tr><tr><td>y2</td><td>p12</td><td>p22</td><td>...</td><td>p12</td><td>...</td></tr><tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td></td></tr><tr><td>yj</td><td>p1j</td><td>p2j</td><td>...</td><td>pij</td><td>...</td></tr><tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td></td></tr></table>

例1设随机变量  $X$  在1,2,3,4四个整数中等可能地取一个值,另一个随机变量  $Y$  在  $1\sim X$  中等可能地取一整数值.试求  $(X,Y)$  的分布律.

解由乘法公式容易求得  $(X,Y)$  的分布律.易知  $\{X = i,Y = j\}$  的取值情况是:  $i = 1,2,3,4,j$  取不大于  $i$  的正整数,且

$$
P\{X = i,Y = j\} = P\{Y = j\mid X = i\} P\{X = i\} = \frac{1}{i}\cdot \frac{1}{4},\quad i = 1,2,3,4,j\leqslant i.
$$

于是  $(X,Y)$  的分布律为

<table><tr><td>X
Y</td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>1</td><td>1/4</td><td>1/8</td><td>1/12</td><td>1/16</td></tr><tr><td>2</td><td>0</td><td>1/8</td><td>1/12</td><td>1/16</td></tr><tr><td>3</td><td>0</td><td>0</td><td>1/12</td><td>1/16</td></tr><tr><td>4</td><td>0</td><td>0</td><td>0</td><td>1/16</td></tr></table>

将  $(X,Y)$  看成一个随机点的坐标,由图3一2知道离散型随机变量  $X$  和  $Y$  的联合分布函数为

$$
F(x,y) = \sum_{x_{i}\leqslant x} \sum_{y_{j}\leqslant y} p_{ij}, \tag{1.2}
$$

其中和式是对一切满足  $x_{i}\leqslant x,y_{j}\leqslant y$  的  $i,j$  来求和的.

与一维随机变量相似,对于二维随机变量  $(X,Y)$  的分布函数  $F(x,y)$ ,如果存在非负可积函数  $f(x,y)$  使对于任意  $x,y$  有

$$
F(x,y) = \int_{-\infty}^{y}\int_{-\infty}^{x}f(u,v)\mathrm{d}u\mathrm{d}v,
$$

则称  $(X,Y)$  是二维连续型随机变量,函数  $f(x,y)$  称为二维连续型随机变量  $(X,Y)$  的概率密度,或称为随机变量  $X$  和  $Y$  的联合概率密度.

按定义,概率密度  $f(x,y)$  具有以下性质:

$1^{\circ}f(x,y)\geq 0.$

$$
2^{\circ}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}f(x,y)\mathrm{d}x\mathrm{d}y = F(\infty ,\infty) = 1.
$$

$3^{\circ}$  设  $G$  是  $xOy$  平面上的区域,点  $(X,Y)$  落在  $G$  内的概率为

$$
P\{(X,Y)\in G\} = \iint_{G}f(x,y)\mathrm{d}x\mathrm{d}y. \tag{1.3}
$$

$4^{\circ}$  若  $f(x,y)$  在点  $(x,y)$  连续,则有

$$
\frac{\partial^{2}F(x,y)}{\partial x\partial y} = f(x,y).
$$

由性质  $4^{\circ}$ ,在  $f(x,y)$  的连续点处有

$$
\lim_{\Delta x\to 0^{+}}\frac{P\{x< X\leqslant x + \Delta x,y< Y\leqslant y + \Delta y\}}{\Delta x\Delta y}
$$

$\frac{\mathrm{~\texttt~{~H~(1. 1)~}~}}{\Delta x\to 0^{+}}\lim_{\Delta x\to 0^{+}}\frac{1}{\Delta x\Delta y}\big[F(x + \Delta x,y + \Delta y) - F(x + \Delta x,y) - F(x,y + \Delta y) + F(x,y)\big]$

$$
= \frac{\partial^{2}F(x,y)}{\partial x\partial y} = f(x,y).
$$

这表示若  $f(x,y)$  在点  $(x,y)$  处连续,则当  $\Delta x,\Delta y$  很小时

$$
P\{x< X\leqslant x + \Delta x,y< Y\leqslant y + \Delta y\} \approx f(x,y)\Delta x\Delta y,
$$

也就是点  $(X,Y)$  落在小矩形  $(x,x + \Delta x]\times (y,y + \Delta y]$  内的概率近似地等于  $f(x,y)\Delta x\Delta y$

在几何上  $z = f(x,y)$  表示空间的一个曲面.由性质  $2^{\circ}$  知,介于它和  $xOy$  平面的空间区域的体积为1. 由性质  $3^{\circ},P\{(X,Y)\in G\}$  的值等于以  $G$  为底,以曲面  $z = f(x,y)$  为顶面的柱体体积.

例2设二维随机变量  $(X,Y)$  具有概率密度

$$
f(x,y) = \left\{ \begin{array}{ll}2\mathrm{e}^{-(2x + y)}, & x > 0,y > 0, \\ 0, & \text{其他}. \end{array} \right.
$$

(1)求分布函数  $F(x,y)$  .(2)求概率  $P\{Y\leqslant X\}$

解 (1)  $F(x,y) = \int_{- \infty}^{y}\int_{- \infty}^{x}f(x,y)\mathrm{d}x\mathrm{d}y$

$$
= \left\{ \begin{array}{ll}\int_{0}^{y}\int_{0}^{x}2\mathrm{e}^{-(2x + y)}\mathrm{d}x\mathrm{d}y, & x > 0, y > 0, \\ 0, & \text{其他.} \end{array} \right.
$$

即有  $F(x, y) = \left\{ \begin{array}{ll}(1 - \mathrm{e}^{- 2x})(1 - \mathrm{e}^{- y}), & x > 0, y > 0, \\ 0, & \text{其他.} \end{array} \right.$

(2)将  $(X, Y)$  看作平面上随机点的坐标. 即有

$$
\{Y \leqslant X\} = \{(X, Y) \in G\} ,
$$

其中  $G$  为  $xOy$  平面上直线  $y = x$  及其下方的部分,如图3一4. 于是

$$
\begin{array}{l}{{P\{Y\leqslant X\}=P\{(X,Y)\in G\}=\iint_{G}f(x,y)\mathrm{d}x\mathrm{d}y}}\\ {{\qquad=\int_{0}^{\infty}\int_{y}^{\infty}2\mathrm{e}^{-(2x+y)}\mathrm{d}x\mathrm{d}y=\frac{1}{3}.}}\end{array}
$$

以上关于二维随机变量的讨论,不难推广到  $n$  ( $n > 2$ ) 维随机变量的情况. 一般,设  $E$  是一个随机试验,它的样本空间是  $S = \{e\}$ ,设  $X_{1} = X_{1}(e)$ ,  $X_{2} = X_{2}(e), \dots , X_{n} = X_{n}(e)$  是定义在  $S$  上的随机

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-4

变量,由它们构成的一个  $n$  维向量  $(X_{1}, X_{2}, \dots , X_{n})$  称为  $n$  维随机向量或  $n$  维随机变量.

对于任意  $n$  个实数  $x_{1}, x_{2}, \dots , x_{n}, n$  元函数

$$
F(x_{1}, x_{2}, \dots , x_{n}) = P\{X_{1} \leqslant x_{1}, X_{2} \leqslant x_{2}, \dots , X_{n} \leqslant x_{n}\}
$$

称为  $n$  维随机变量  $(X_{1}, X_{2}, \dots , X_{n})$  的分布函数或随机变量  $X_{1}, X_{2}, \dots , X_{n}$  的联合分布函数. 它具有类似于二维随机变量的分布函数的性质.

# $\S 2$  边缘分布

二维随机变量  $(X, Y)$  作为一个整体,具有分布函数  $F(x, y)$ . 而  $X$  和  $Y$  都是随机变量,各自也有分布函数,将它们分别记为  $F_{X}(x), F_{Y}(y)$ ,依次称为二维随机变量  $(X, Y)$  关于  $X$  和关于  $Y$  的边缘分布函数. 边缘分布函数可以由  $(X, Y)$  的分布函数  $F(x, y)$  所确定,事实上,

$$
F_{X}(x) = P\{X \leqslant x\} = P\{X \leqslant x, Y < \infty \} = F(x, \infty),
$$

即  $F_{X}(x) = F(x, \infty)$ . (2.1)

就是说,只要在函数  $F(x, y)$  中令  $y \to \infty$  就能得到  $F_{X}(x)$ . 同理

$$
F_{Y}(y) = F(\infty , y). \tag{2.2}
$$

对于离散型随机变量,由(1.2),(2.1)式可得

$$
F_{X}(x) = F(x,\infty) = \sum_{x_{i}\leqslant x}\sum_{j = 1}^{\infty}p_{i j}.
$$

与第二章(3.2)式比较,知道  $X$  的分布律为

$$
P\{X = x_{i}\} = \sum_{j = 1}^{\infty}p_{i j},\quad i = 1,2,\dots .
$$

同样,  $Y$  的分布律为

$$
P\{Y = y_{j}\} = \sum_{i = 1}^{\infty}p_{i j},\quad j = 1,2,\dots ,
$$

记  $p_{i\cdot} = \sum_{j = 1}^{\infty}p_{i j} = P\{X = x_{i}\} ,\quad i = 1,2,\dots ,$

$$
p_{\cdot j} = \sum_{i = 1}^{\infty}p_{i j} = P\{Y = y_{j}\} ,\quad j = 1,2,\dots ,
$$

分别称  $\boldsymbol{\mathscr{p}}_{i}$  .  $(i = 1,2,\dots)$  和  $\boldsymbol{\mathscr{p}}_{\cdot j}(j = 1,2,\dots)$  为  $(X,Y)$  关于  $X$  和关于  $Y$  的边缘分布律(注意,记号  $\boldsymbol{\mathscr{p}}_{i}$  .中的"·"表示  $\boldsymbol{\mathscr{p}}_{i}$  .是由  $\boldsymbol{\mathscr{p}}_{i j}$  关于  $j$  求和后得到的;同样,  $\boldsymbol{\mathscr{p}}_{\cdot j}$  是由  $\boldsymbol{\mathscr{p}}_{i j}$  关于  $i$  求和后得到的).

对于连续型随机变量  $(X,Y)$  ,设它的概率密度为  $f(x,y)$  ,由于

$$
F_{X}(x) = F(x,\infty) = \int_{-\infty}^{x}\left[\int_{-\infty}^{\infty}f(x,y)\mathrm{d}y\right]\mathrm{d}x,
$$

由第二章(4.1)式知道,  $X$  是一个连续型随机变量,且其概率密度为

$$
f_{X}(x) = \int_{-\infty}^{\infty}f(x,y)\mathrm{d}y. \tag{2.3}
$$

同样,  $Y$  也是一个连续型随机变量,其概率密度为

$$
f_{Y}(y) = \int_{-\infty}^{\infty}f(x,y)\mathrm{d}x. \tag{2.4}
$$

分别称  $f_{X}(x),f_{Y}(y)$  为  $(X,Y)$  关于  $X$  和关于  $Y$  的边缘概率密度.

例1一整数  $N$  等可能地在  $1,2,3,\dots ,10$  十个值中取一个值.设  $D =$ $D(N)$  是能整除  $N$  的正整数的个数,  $F = F(N)$  是能整除  $N$  的素数的个数(注意1不是素数).试写出  $D$  和  $F$  的联合分布律,并求边缘分布律.

解先将试验的样本空间及  $D,F$  取值的情况列出如下:

<table><tr><td>样本点</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td></tr><tr><td>D</td><td>1</td><td>2</td><td>2</td><td>3</td><td>2</td><td>4</td><td>2</td><td>4</td><td>3</td><td>4</td></tr><tr><td>F</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>1</td><td>2</td></tr></table>

$D$  所有可能取的值为  $1,2,3,4;F$  所有可能取的值为0,1,2. 容易得到  $(D,F)$  取 $(i,j),i = 1,2,3,4,j = 0,1,2$  的概率,例如

$$
P\{D = 1,F = 0\} = \frac{1}{10},\quad P\{D = 2,F = 1\} = \frac{4}{10},
$$

可得  $D$  和  $F$  的联合分布律及边缘分布律如下表所示:

<table><tr><td>D
F</td><td>1</td><td>2</td><td>3</td><td>4</td><td>P{F=i}</td></tr><tr><td>0</td><td>1/10</td><td>0</td><td>0</td><td>0</td><td>1/10</td></tr><tr><td>1</td><td>0</td><td>4/10</td><td>2/10</td><td>1/10</td><td>7/10</td></tr><tr><td>2</td><td>0</td><td>0</td><td>0</td><td>2/10</td><td>2/10</td></tr><tr><td>P{D=i}</td><td>1/10</td><td>4/10</td><td>2/10</td><td>3/10</td><td>1</td></tr></table>

即有边缘分布律

$$
\begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c} & \begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c} & \frac{D}{\frac{1}{10}} & \frac{2}{\frac{4}{10}} & \frac{3}{\frac{2}{10}} & \frac{4}{\frac{3}{10}} & \frac{F}{\frac{1}{10}} & \frac{0}{\frac{1}{10}} & \frac{1}{\frac{2}{10}} & \frac{2}{\frac{2}{10}} & \frac{1}{\frac{1}{10}} & \frac{1}{\frac{1}{10}} & \frac{1}{\frac{1}{10}} & \frac{1}{\frac{1}{10}} & \frac{1}{\frac{1}{10}} & \frac{1}{\frac{1}{10}} & \frac{1}{\frac{1}{10}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\left(1 - \frac{1}{2}\right)} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{\frac{1}{2}}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \left(1 - \frac{1}{2}\right) & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac {1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{1}{\frac{1}{2}} & \frac{ \end{array}
$$

我们常常将边缘分布律写在联合分布律表格的边缘上,如上表所示.这就是"边缘分布律"这个名词的来源.

例2设随机变量  $X$  和  $Y$  具有联合概率密度(图3- 5)

$$
f(x,y)={\left\{\begin{array}{l l}{0,}&{x^{2}\leqslant y\leqslant x,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}\end{array}\right.}
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-5

求边缘概率密度  $f_{X}(x),f_{Y}(y)$

解

$$
f_{X}(x) = \int_{-\infty}^{\infty}f(x,y)\mathrm{d}y = \left\{ \begin{array}{l l}{\int_{x^{2}}^{x}6\mathrm{d}y = 6(x - x^{2}),} & {0\leqslant x\leqslant 1,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.
$$

$$
f_{Y}(y) = \int_{-\infty}^{\infty}f(x,y)\mathrm{d}x = \left\{ \begin{array}{l l}{\int_{y}^{\sqrt{y}}6\mathrm{d}x = 6(\sqrt{y} -y),} & {0\leqslant y\leqslant 1,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.
$$

例3 设二维随机变量  $(X,Y)$  的概率密度为

$$
\begin{array}{c}{{f(x,y)=\frac{1}{2\pi\sigma_{1}\sigma_{2}\sqrt{1-\rho^{2}}}\mathrm{exp}\left\{\frac{-1}{2(1-\rho^{2})}\bigg[\frac{(x-\mu_{1})^{2}}{\sigma_{1}^{2}}\right.}}\\ {{\left.-2\rho\frac{(x-\mu_{1})(y-\mu_{2})}{\sigma_{1}\sigma_{2}}+\frac{(y-\mu_{2})^{2}}{\sigma_{2}^{2}}\bigg]\right\},}}\end{array}
$$

其中  $\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}, \rho$  都是常数,且  $\sigma_{1} > 0, \sigma_{2} > 0, - 1< \rho < 1$ . 我们称  $(X,Y)$  为服从参数为  $\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}, \rho$  的二维正态分布(这五个参数的意义将在下一章说明),记为  $(X,Y) \sim N(\mu_{1}, \mu_{2}, \sigma_{1}^{2}, \sigma_{2}^{2}, \rho)$ . 试求二维正态随机变量的边缘概率密度.

解  $f_{X}(x) = \int_{- \infty}^{\infty} f(x, y) \mathrm{d}y$ , 由于

$$
\begin{array}{r l} & {\frac{(y - \mu_{2})^{2}}{\sigma_{2}^{2}} -2\rho \frac{(x - \mu_{1})(y - \mu_{2})}{\sigma_{1}\sigma_{2}}}\\ & {\qquad = \Big(\frac{y - \mu_{2}}{\sigma_{2}} -\rho \frac{x - \mu_{1}}{\sigma_{1}}\Big)^{2} - \rho^{2}\frac{(x - \mu_{1})^{2}}{\sigma_{1}^{2}},} \end{array}
$$

于是

$$
f_{X}(x) = \frac{1}{2\pi\sigma_{1} \sigma_{2} \sqrt{1 - \rho^{2}}} \mathrm{e}^{-\frac{(x - \mu_{1})^{2}}{2\sigma_{1}^{2}}} \int_{-\infty}^{\infty} \mathrm{e}^{-\frac{1}{2(1 - \rho^{2})} \left(\frac{y - \mu_{2}}{\sigma_{2}} - \rho^{2} \sigma_{1}^{2}\right)^{2}} \mathrm{d}y.
$$

令

$$
t = \frac{1}{\sqrt{1 - \rho^{2}}} \left(\frac{y - \mu_{2}}{\sigma_{2}} - \rho \frac{x - \mu_{1}}{\sigma_{1}}\right),
$$

则有

$$
f_{X}(x) = \frac{1}{2\pi \sigma_{1}} \mathrm{e}^{-\frac{(x - \mu_{1})^{2}}{2\sigma_{1}^{2}}} \int_{-\infty}^{\infty} \mathrm{e}^{-t^{2} / 2} \mathrm{d}t,
$$

即  $f_{X}(x) = \frac{1}{\sqrt{2\pi} \sigma_{1}} \mathrm{e}^{- \frac{(x - \mu_{1})^{2}}{2\sigma_{1}^{2}}}, \quad - \infty < x < \infty .$

同理

$$
f_{Y}(y) = \frac{1}{\sqrt{2\pi} \sigma_{2}} \mathrm{e}^{-\frac{(y - \mu_{2})^{2}}{2\sigma_{2}^{2}}}, \quad -\infty < y < \infty .
$$

我们看到二维正态分布的两个边缘分布都是一维正态分布,并且都不依赖于参数  $\rho$ ,亦即对于给定的  $\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}$ ,不同的  $\rho$  对应不同的二维正态分布,它们的边缘分布却都是一样的. 这一事实表明,单由关于  $X$  和关于  $Y$  的边缘分布,一般来说是不能确定随机变量  $X$  和  $Y$  的联合分布的.

# $\S 3$  条件分布

我们由条件概率很自然地引出条件概率分布的概念,

设  $(X,Y)$  是二维离散型随机变量,其分布律为

$$
P\{X = x_{i},Y = y_{j}\} = p_{ij},\quad i,j = 1,2,\dots .
$$

$(X,Y)$  关于  $X$  和关于  $Y$  的边缘分布律分别为

$$
P\{X = x_{i}\} = p_{i\cdot} = \sum_{j = 1}^{\infty}p_{ij},\quad i = 1,2,\dots ,
$$

$$
P\{Y = y_{j}\} = p_{\cdot j} = \sum_{i = 1}^{\infty}p_{ij},\quad j = 1,2,\dots .
$$

设  $\boldsymbol{\mathscr{p}}_{\cdot j} > 0$  ,我们来考虑在事件  $\{Y = y_{j}\}$  已发生的条件下事件  $\{X = x_{i}\}$  发生的概率,也就是来求事件

$$
\{X = x_{i}|Y = y_{j}\} ,\quad i = 1,2,\dots
$$

的概率.由条件概率公式,可得

$$
P\{X = x_{i}|Y = y_{j}\} = \frac{P\{X = x_{i},Y = y_{j}\}}{P\{Y = y_{j}\}} = \frac{p_{ij}}{p_{\cdot j}},\quad i = 1,2,\dots .
$$

易知上述条件概率具有分布律的性质:

$$
1^{\circ}P\{X = x_{i}|Y = y_{j}\} \geqslant 0.
$$

$$
2^{\circ}\sum_{i = 1}^{\infty}P\{X = x_{i}\mid Y = y_{j}\} = \sum_{i = 1}^{\infty}\frac{p_{ij}}{p_{\cdot j}} = \frac{1}{p_{\cdot j}}\sum_{i = 1}^{\infty}p_{ij} = \frac{p_{\cdot j}}{p_{\cdot j}} = 1.
$$

于是我们引入以下的定义,

定义设  $(X,Y)$  是二维离散型随机变量,对于固定的  $j$  ,若  $P\{Y = y_{j}\} >0$  则称

$$
P\{X = x_{i}|Y = y_{j}\} = \frac{P\{X = x_{i},Y = y_{j}\}}{P\{Y = y_{j}\}} = \frac{p_{ij}}{p_{\cdot j}},\quad i = 1,2,\dots \tag{3.1}
$$

为在  $Y = y_{j}$  条件下随机变量  $X$  的条件分布律.

同样,对于固定的  $i$  ,若  $P\{X = x_{i}\} >0$  ,则称

$$
P\{Y = y_{j}|X = x_{i}\} = \frac{P\{X = x_{i},Y = y_{j}\}}{P\{X = x_{i}\}} = \frac{p_{ij}}{p_{i}},\quad j = 1,2,\dots \tag{3.2}
$$

为在  $X = x_{i}$  条件下随机变量  $Y$  的条件分布律.

例1在一汽车工厂中,一辆汽车有两道工序是由机器人完成的.其一是紧固3只螺栓,其二是焊接2处焊点.以  $X$  表示由机器人紧固的螺栓中紧固得不良的数目,以  $Y$  表示由机器人焊接的不良焊点的数目.据积累的资料知  $(X$ $Y)$  具有分布律:

<table><tr><td>X
Y</td><td>0</td><td>1</td><td>2</td><td>3</td><td>P{Y=j}</td></tr><tr><td>0</td><td>0.840</td><td>0.030</td><td>0.020</td><td>0.010</td><td>0.900</td></tr><tr><td>1</td><td>0.060</td><td>0.010</td><td>0.008</td><td>0.002</td><td>0.080</td></tr><tr><td>2</td><td>0.010</td><td>0.005</td><td>0.004</td><td>0.001</td><td>0.020</td></tr><tr><td>P{X=i}</td><td>0.910</td><td>0.045</td><td>0.032</td><td>0.013</td><td>1.000</td></tr></table>

(1)求在  $X = 1$  的条件下,  $Y$  的条件分布律.(2)求在  $Y = 0$  的条件下,  $X$  的条件分布律.

解 边缘分布律已经求出列在上表中.

(1)在  $X = 1$  的条件下,  $Y$  的条件分布律为

$$
P\{Y = 0 \mid X = 1\} = \frac{P\{X = 1,Y = 0\}}{P\{X = 1\}} = \frac{0.030}{0.045},
$$

$$
P\{Y = 1 \mid X = 1\} = \frac{P\{X = 1,Y = 1\}}{P\{X = 1\}} = \frac{0.010}{0.045},
$$

$$
P\{Y = 2 \mid X = 1\} = \frac{P\{X = 1,Y = 2\}}{P\{X = 1\}} = \frac{0.005}{0.045},
$$

或写成

<table><tr><td>Y=k</td><td>0</td><td>1</td><td>2</td></tr><tr><td>P{Y=k|X=1}</td><td>6/9</td><td>2/9</td><td>1/9</td></tr></table>

(2)同样可得在  $Y = 0$  的条件下  $X$  的条件分布律为

<table><tr><td>X=k</td><td>0</td><td>1</td><td>2</td><td>3</td></tr><tr><td>P{X=k|Y=0}</td><td>84/90</td><td>3/90</td><td>2/90</td><td>1/90</td></tr></table>

例2一射手进行射击,击中目标的概率为  $p$ $(0< p< 1)$  ,射击直至击中目标两次为止.设以  $X$  表示首次击中目标所进行的射击次数,以  $Y$  表示总共进行的射击次数,试求  $X$  和  $Y$  的联合分布律及条件分布律.

解 按题意  $Y = n$  就表示在第  $n$  次射击时击中目标,且在第1次,第2次,…,第  $n - 1$  次射击中恰有一次击中目标.已知各次射击是相互独立的,于是

不管  $m$ $(m{<}n)$  是多少,概率  $P\{X = m,Y = n\}$  都应等于

$$
\begin{array}{r}{\boldsymbol {\mathbf{\mathit{p}}}\cdot \boldsymbol {\mathbf{\mathit{p}}}\cdot \underbrace{\boldsymbol{\mathbf{\mathit{q}}}\cdot\boldsymbol{\mathbf{\mathit{q}}}\cdot\cdots\cdot\boldsymbol{\mathbf{\mathit{q}}} = \boldsymbol{\mathbf{\mathit{p}}}^{2}\boldsymbol{\mathbf{\mathit{q}}}^{n - 2}}_{n - 2\uparrow}} \end{array}
$$

即得  $X$  和  $Y$  的联合分布律为

$$
P\{X = m,Y = n\} = p^{2}q^{n - 2},\quad n = 2,3,\dots ;m = 1,2,\dots ,n - 1.
$$

又  $P\{X = m\} = \sum_{n = m + 1}^{\infty}P\{X = m,Y = n\} = \sum_{n = m + 1}^{\infty}p^{2}q^{n - 2}$

$$
= p^{2}\sum_{n = m + 1}^{\infty}q^{n - 2} = \frac{p^{2}q^{m - 1}}{1 - q} = p q^{m - 1},\quad m = 1,2,\dots ,
$$

$$
\begin{array}{l}{{P\{Y=n\}=\sum_{m=1}^{n-1}P\{X=m,Y=n\}}}\\ {{=\sum_{m=1}^{n-1}p^{2}q^{n-2}=(n-1)p^{2}q^{n-2},\quad n=2,3,\cdots.}}\end{array}
$$

于是由(3.1),(3.2)式得到所求的条件分布律为

当  $n = 2,3,\dots$  时,

$$
P\{X = m|Y = n\} = \frac{p^{2}q^{n - 2}}{(n - 1)p^{2}q^{n - 2}} = \frac{1}{n - 1},\quad m = 1,2,\dots ,n - 1;
$$

当  $m = 1,2,\dots$  时,

$$
P\{Y = n|X = m\} = \frac{p^{2}q^{n - 2}}{p q^{m - 1}} = p q^{n - m - 1},\quad n = m + 1,m + 2,\dots .
$$

例如,  $P\{X = m|Y = 3\} = \frac{1}{2},\quad m = 1,2;$

$$
P\{Y = n|X = 3\} = p q^{n - 4},\quad n = 4,5,\dots .
$$

现设  $(X,Y)$  是二维连续型随机变量,这时由于对任意  $x,y$  有  $P\{X = x\} = 0$ $P\{Y = y\} = 0$  ,因此就不能直接用条件概率公式引入"条件分布函数"了.

设  $(X,Y)$  的概率密度为  $f(x,y),(X,Y)$  关于  $Y$  的边缘概率密度为  $f_{Y}(y)$  给定  $y$  ,对于任意固定的  $\epsilon >0$  ,对于任意  $x$  ,考虑条件概率

$$
P\{X\leqslant x\mid y< Y\leqslant y + \epsilon \} ,
$$

设  $P\{y{<}Y\leqslant y + \epsilon \} >0$  ,则有

$$
\begin{array}{r l} & {P\{X\leqslant x\mid y< Y\leqslant y + \epsilon \} = \frac{P\{X\leqslant x,y< Y\leqslant y + \epsilon\}}{P\{y< Y\leqslant y + \epsilon\}}}\\ & {\qquad = \frac{\int_{-\infty}^{x}\left[\int_{y}^{y + \epsilon}f(x,y)\mathrm{d}y\right]\mathrm{d}x}{\int_{y}^{y + \epsilon}f_{Y}(y)\mathrm{d}y}.} \end{array}
$$

在某些条件下,当  $\epsilon$  很小时,上式右端分子、分母分别近似于  $\epsilon \int_{- \infty}^{x}f(x,y)\mathrm{d}x$  和  $\epsilon f_{Y}(y)$ ,于是当  $\epsilon$  很小时,有

$$
P\{X\leqslant x\mid y< Y\leqslant y + \epsilon \} \approx \frac{\epsilon\int_{-\infty}^{x}f(x,y)\mathrm{d}x}{\epsilon f_{Y}(y)} = \int_{-\infty}^{x}\frac{f(x,y)}{f_{Y}(y)}\mathrm{d}x. \tag{3.3}
$$

与一维随机变量概率密度的定义式第二章(4.1)式比较,我们给出以下的定义:

定义设二维随机变量  $(X,Y)$  的概率密度为  $f(x,y),(X,Y)$  关于  $Y$  的边缘概率密度为  $f_{Y}(y)$  .若对于固定的  $y,f_{Y}(y) > 0$  ,则称  $\frac{f(x,y)}{f_{Y}(y)}$  为在  $Y = y$  的条件下  $X$  的条件概率密度,记为  $①$

$$
f_{X|Y}(x\mid y) = \frac{f(x,y)}{f_{Y}(y)}. \tag{3.4}
$$

称  $\int_{- \infty}^{x}f_{X|Y}(x\mid y)\mathrm{d}x = \int_{- \infty}^{x}\frac{f(x,y)}{f_{Y}(y)}\mathrm{d}x$  为在  $Y = y$  的条件下  $X$  的条件分布函数,记为  $P\{X\leqslant x\mid Y = y\}$  或  $F_{X|Y}(x\mid y)$ ,即

$$
F_{X|Y}(x\mid y) = P\{X\leqslant x\mid Y = y\} = \int_{-\infty}^{x}\frac{f(x,y)}{f_{Y}(y)}\mathrm{d}x. \tag{3.5}
$$

类似地,可以定义  $f_{Y|X}(y\mid x) = \frac{f(x,y)}{f_{X}(x)}$  和  $F_{Y|X}(y\mid x) = \int_{- \infty}^{y}\frac{f(x,y)}{f_{X}(x)}\mathrm{d}y$ .

由(3.3)式知道,当  $\epsilon$  很小时,有

$$
P\{X\leqslant x\mid y< Y\leqslant y + \epsilon \} \approx \int_{-\infty}^{x}f_{X|Y}(x\mid y)\mathrm{d}x = F_{X|Y}(x\mid y),
$$

上式说明了条件密度和条件分布函数的含义,

例3设  $G$  是平面上的有界区域,其面积为  $A$  .若二维随机变量  $(X,Y)$  具有概率密度

$$
f(x,y) = \left\{ \begin{array}{ll}\frac{1}{A}, & (x,y)\in G, \\ 0, & \text{其他}, \end{array} \right.
$$

则称  $(X,Y)$  在  $G$  上服从均匀分布.现设二维随机变量  $(X,Y)$  在圆域  $x^{2} + y^{2}\leqslant 1$  上服从均匀分布,求条件概率密度  $f_{X|Y}(x\mid y)$ .

解由假设,随机变量  $(X,Y)$  具有概率密度

$①$  条件概率密度满足条件:  $f_{X|Y}(x\mid y) = \frac{f(x,y)}{f_{Y}(y)}\geqslant 0$ ;

$$
\int_{-\infty}^{\infty}f_{X|Y}(x\mid y)\mathrm{d}x = \int_{-\infty}^{\infty}\frac{f(x,y)}{f_{Y}(y)}\mathrm{d}x = \frac{1}{f_{Y}(y)}\int_{-\infty}^{\infty}f(x,y)\mathrm{d}x = 1.
$$

$$
f(x,y) = \left\{ \begin{array}{ll}\frac{1}{\pi}, & x^{2} + y^{2} \leqslant 1, \\ 0, & \text{其他}, \end{array} \right.
$$

且有边缘概率密度

$$
\begin{array}{l}{{f_{Y}(y)=\int_{-\infty}^{\infty}f(x,y)\mathrm{d}x}}\\ {{\qquad=\left\{\begin{array}{l l}{{\frac{1}{\pi}\int_{-\sqrt{1-y^{2}}}^{\sqrt{1-y^{2}}}\mathrm{d}x=\frac{2}{\pi}\sqrt{1-y^{2}},}}\\ {{0,}}\end{array}\right.}}\end{array}
$$

于是当  $- 1 < y < 1$  时有

$$
\begin{array}{r l} & {f_{X|Y}(x|y) = \frac{\frac{1}{\pi}}{\frac{2}{\pi}\sqrt{1 - y^{2}}} = \frac{1}{2\sqrt{1 - y^{2}}}, - \sqrt{1 - y^{2}}\leqslant x\leqslant \sqrt{1 - y^{2}},}\\ & {\qquad \quad \mathrm{~i~o~},\qquad \quad \mathrm{~i~t~h~e~.}} \end{array}
$$

当  $y = 0$  和  $y = \frac{1}{2}$  时  $f_{X|Y}(x|y)$  的图形分别如图 3- 6, 图 3- 7 所示.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-6

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-7

例4设数  $X$  在区间(0,1)上随机地取值,当观察到  $X = x$  (  $0 < x < 1$  )时,数  $Y$  在区间  $(x,1)$  上随机地取值. 求  $Y$  的概率密度  $f_{Y}(y)$

解按题意  $X$  具有概率密度

$$
f_{X}(x) = \left\{ \begin{array}{ll}1, & 0 < x < 1, \\ 0, & \text{其他}. \end{array} \right.
$$

对于任意给定的值  $x$  (  $0 < x < 1$  ),在  $X = x$  的条件下  $Y$  的条件概率密度为

$$
f_{Y|X}(y|x) = \left\{ \begin{array}{ll} \frac{1}{1 - x}, & x < y < 1, \\ 0, & \text{其他}. \end{array} \right.
$$

由(3.4)式得  $X$  和  $Y$  的联合概率密度为

$$
f(x,y) = f_{Y|X}(y|x)f_{X}(x) = \left\{ \begin{array}{ll}\frac{1}{1 - x}, & 0< x< y< 1, \\ 0, & \text{其他.} \end{array} \right.
$$

于是得关于  $Y$  的边缘概率密度为

$$
\begin{array}{l}{f_{Y}(y) = \int_{-\infty}^{\infty}f(x,y)\mathrm{d}x}\\ {= \left\{ \begin{array}{l l}{\int_{0}^{y}\frac{1}{1 - x}\mathrm{d}x = -\ln (1 - y),} & {0< y< 1,}\\ {0,} & {\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}} \end{array} \right.} \end{array}
$$

# §4 相互独立的随机变量

本节我们将利用两个事件相互独立的概念引出两个随机变量相互独立的概念,这是一个十分重要的概念.

定义设  $F(x,y)$  及  $F_{X}(x),F_{Y}(y)$  分别是二维随机变量  $(X,Y)$  的分布函数及边缘分布函数.若对于所有  $x,y$  有

$$
P\{X\leqslant x,Y\leqslant y\} = P\{X\leqslant x\} P\{Y\leqslant y\} , \tag{4.1}
$$

即  $F(x,y) = F_{X}(x)F_{Y}(y),$  (4.2)

则称随机变量  $X$  和  $Y$  是相互独立的,

设  $(X,Y)$  是连续型随机变量,  $f(x,y),f_{X}(x),f_{Y}(y)$  分别为  $(X,Y)$  的概率密度和边缘概率密度,则  $X$  和  $Y$  相互独立的条件(4.2)式等价于:等式

$$
f(x,y) = f_{X}(x)f_{Y}(y) \tag{4.3}
$$

在平面上几乎处处  $①$  成立,

当  $(X,Y)$  是离散型随机变量时,  $X$  和  $Y$  相互独立的条件(4.2)式等价于:对于  $(X,Y)$  的所有可能取的值  $(x_{i},y_{j})$  有

$$
P\{X = x_{i},Y = y_{j}\} = P\{X = x_{i}\} P\{Y = y_{j}\} . \tag{4.4}
$$

在实际中使用(4.3)式或(4.4)式要比使用(4.2)式方便.

例如  $\S 1$  例2中的随机变量  $X$  和  $Y$  ,由于

$$
f_{X}(x)={\left\{\begin{array}{l l}{2\mathrm{e}^{-2x},}&{x>0,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}\end{array}\right.}{\left\{\begin{array}{l l}{\mathrm{e}^{-y},}&{y>0,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}\end{array}\right.}
$$

故有  $f(x,y) = f_{X}(x)f_{Y}(y)$  ,因而  $X,Y$  是相互独立的.

又如,若  $X,Y$  具有联合分布律

<table><tr><td>X
Y</td><td>0</td><td>1</td><td>P{Y=j}</td></tr><tr><td>1</td><td>1/6</td><td>2/6</td><td>1/2</td></tr><tr><td>2</td><td>1/6</td><td>2/6</td><td>1/2</td></tr><tr><td>P{X=i}</td><td>1/3</td><td>2/3</td><td>1</td></tr></table>

则有

$$
P\{X = 0,Y = 2\} = 1 / 6 = P\{X = 0\} P\{Y = 2\} ,
$$

$$
P\{X = 1,Y = 1\} = 2 / 6 = P\{X = 1\} P\{Y = 1\} ,
$$

$$
P\{X = 1,Y = 2\} = 2 / 6 = P\{X = 1\} P\{Y = 2\} ,
$$

因而  $X,Y$  是相互独立的.

再如  $\S 2$  例1中的随机变量  $F$  和  $D$  ,由于  $P\{D = 1,F = 0\} = 1 / 10\neq P\{D = 1\} \times P\{F = 0\}$  ,因而  $F$  和  $D$  不是相互独立的.

下面考察二维正态随机变量  $(X,Y)$  .它的概率密度为

$$
\begin{array}{r l} & {f(x,y) = \frac{1}{2\pi\sigma_{1}\sigma_{2}\sqrt{1 - \rho^{2}}}\mathrm{exp}\bigg\{\frac{-1}{2(1 - \rho^{2})}\bigg[\frac{(x - \mu_{1})^{2}}{\sigma_{1}^{2}}}\\ & {\qquad -2\rho \frac{(x - \mu_{1})(y - \mu_{2})}{\sigma_{1}\sigma_{2}} +\frac{(y - \mu_{2})^{2}}{\sigma_{2}^{2}}\bigg]\bigg\} .} \end{array}
$$

由  $\S 2$  中例3知道,其边缘概率密度  $f_{X}(x),f_{Y}(y)$  的乘积为

$$
f_{X}(x)f_{Y}(y) = \frac{1}{2\pi\sigma_{1}\sigma_{2}}\mathrm{exp}\bigg\{-\frac{1}{2}\bigg[\frac{(x - \mu_{1})^{2}}{\sigma_{1}^{2}} +\frac{(y - \mu_{2})^{2}}{\sigma_{2}^{2}}\bigg]\bigg\} .
$$

因此,如果  $\rho = 0$  ,则对于所有  $x,y$  有  $f(x,y) = f_{X}(x)f_{Y}(y)$  ,即  $X$  和  $Y$  相互独立.反之,如果  $X$  和  $Y$  相互独立,由于  $f(x,y),f_{X}(x),f_{Y}(y)$  都是连续函数,故对于所有的  $x,y$  有  $f(x,y) = f_{X}(x)f_{Y}(y)$  .特别,令  $x = \mu_{1},y = \mu_{2}$  ,自这一等式得到

$$
\frac{1}{2\pi\sigma_{1}\sigma_{2}\sqrt{1 - \rho^{2}}} = \frac{1}{2\pi\sigma_{1}\sigma_{2}},
$$

从而  $\rho = 0$  .综上所述,得到以下的结论:

对于二维正态随机变量  $(X,Y),X$  和  $Y$  相互独立的充要条件是参数  $\rho = 0$

例一负责人到达办公室的时间均匀分布在  $8\sim 12$  时,他的秘书到达办公室的时间均匀分布在  $7\sim 9$  时,设他们两人到达的时间相互独立,求他们到达办公室的时间相差不超过  $5\mathrm{min}(1 / 12\mathrm{h})$  的概率.

解设  $X$  和  $Y$  分别是负责人和他的秘书到达办公室的时间,由假设  $X$  和  $Y$  的概率密度分别为

$$
f_{X}(x) = \left\{ \begin{array}{l l}{\frac{1}{4},} & {8< x< 12,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H},} \end{array} \right.f_{Y}(y) = \left\{ \begin{array}{l l}{\frac{1}{2},} & {7< y< 9,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H},} \end{array} \right.
$$

因为  $X, Y$  相互独立, 故  $(X, Y)$  的概率密度为

$$
f(x, y) = f_{X}(x) f_{Y}(y) = \left\{ \begin{array}{ll} \frac{1}{8}, & 8 < x < 12, 7 < y < 9, \\ 0, & \text {其他.} \end{array} \right.
$$

按题意需要求概率  $P\{|X - Y| \leqslant 1 / 12\}$ . 画出区域:  $|x - y| \leqslant 1 / 12$ , 以及长方形  $[8 < x < 12; 7 < y < 9]$ , 它们的公共部分是四边形  $BCC^{\prime}B^{\prime}$ , 记为  $G$  (如图 3- 8). 显然仅当  $(X, Y)$  取值于  $G$  内, 他们两人到达的时间相差才不超过  $1 / 12 \mathrm{~h}$ . 因此, 所求的概率为

$$
P\left\{\left| X - Y \right| \leqslant \frac{1}{12} \right\} = \iint_{G} f(x, y) \mathrm{d}x \mathrm{~d}y
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-8

而  $G$  的面积  $=$  三角形ABC的面积一三角形  $A B^{\prime}C^{\prime}$  的面积

$$
= \frac{1}{2}\left(\frac{13}{12}\right)^{2} - \frac{1}{2}\left(\frac{11}{12}\right)^{2} = \frac{1}{6}.
$$

于是  $P\left\{\left| X - Y \right| \leqslant \frac{1}{12} \right\} = \frac{1}{48}.$

即负责人和他的秘书到达办公室的时间相差不超过  $5 \mathrm{~min}$  的概率为  $1 / 48$ .

以上所述关于二维随机变量的一些概念, 容易推广到  $n$  维随机变量的情况.

上面说过,  $n$  维随机变量  $(X_{1}, X_{2}, \dots , X_{n})$  的分布函数定义为

$$
F(x_{1}, x_{2}, \dots , x_{n}) = P\left\{X_{1} \leqslant x_{1}, X_{2} \leqslant x_{2}, \dots , X_{n} \leqslant x_{n} \right\} ,
$$

其中  $x_{1}, x_{2}, \dots , x_{n}$  为任意实数.

若存在非负可积函数  $f(x_{1}, x_{2}, \dots , x_{n})$ , 使对于任意实数  $x_{1}, x_{2}, \dots , x_{n}$  有

$$
F(x_{1}, x_{2}, \dots , x_{n}) = \int_{-\infty}^{x_{n}} \int_{-\infty}^{x_{n - 1}} \dots \int_{-\infty}^{x_{1}} f(x_{1}, x_{2}, \dots , x_{n}) \mathrm{d}x_{1} \mathrm{~d}x_{2} \dots \mathrm{d}x_{n},
$$

则称  $f(x_{1}, x_{2}, \dots , x_{n})$  为  $(X_{1}, X_{2}, \dots , X_{n})$  的概率密度函数.

设  $(X_{1}, X_{2}, \dots , X_{n})$  的分布函数  $F(x_{1}, x_{2}, \dots , x_{n})$  为已知, 则  $(X_{1}, X_{2}, \dots , X_{n})$  的  $k$ $(1 \leqslant k < n)$  维边缘分布函数就随之确定. 例如  $(X_{1}, X_{2}, \dots , X_{n})$  关于  $X_{1}$  、关于  $(X_{1}, X_{2})$  的边缘分布函数分别为

$$
F_{X_{1}}(x_{1}) = F(x_{1}, \infty , \infty , \dots , \infty),
$$

$$
F_{X_{1},X_{2}}(x_{1},x_{2}) = F(x_{1},x_{2},\infty ,\infty ,\dots ,\infty).
$$

又若  $f(x_{1},x_{2},\dots ,x_{n})$  是  $(X_{1},X_{2},\dots ,X_{n})$  的概率密度,则  $(X_{1},X_{2},\dots ,X_{n})$  关于  $X_{1}$  、关于  $(X_{1},X_{2})$  的边缘概率密度分别为

$$
f_{X_{1}}(x_{1}) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\dots \int_{-\infty}^{\infty}f(x_{1},x_{2},\dots ,x_{n})\mathrm{d}x_{2}\mathrm{d}x_{3}\dots \mathrm{d}x_{n},
$$

$$
f_{X_{1},X_{2}}(x_{1},x_{2}) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\dots \int_{-\infty}^{\infty}f(x_{1},x_{2},\dots ,x_{n})\mathrm{d}x_{3}\mathrm{d}x_{4}\dots \mathrm{d}x_{n}.
$$

若对于所有的  $x_{1},x_{2},\dots ,x_{n}$  有

$$
F(x_{1},x_{2},\dots ,x_{n}) = F_{X_{1}}(x_{1})F_{X_{2}}(x_{2})\dots F_{X_{n}}(x_{n}),
$$

则称  $X_{1},X_{2},\dots ,X_{n}$  是相互独立的.

若对于所有的  $x_{1},x_{2},\dots ,x_{m};y_{1},y_{2},\dots ,y_{n}$  有

$F(x_{1},x_{2},\dots ,x_{m},y_{1},y_{2},\dots ,y_{n}) = F_{1}(x_{1},x_{2},\dots ,x_{m})F_{2}(y_{1},y_{2},\dots ,y_{n}),$  其中  $F_{1},F_{2},F$  依次为随机变量  $(X_{1},X_{2},\dots ,X_{m}),(Y_{1},Y_{2},\dots ,Y_{n})$  和  $(X_{1},X_{2},\dots ,$ $X_{m},Y_{1},Y_{2},\dots ,Y_{n})$  的分布函数,则称随机变量  $(X_{1},X_{2},\dots ,X_{m})$  和  $(Y_{1},Y_{2},\dots ,Y_{n})$  是相互独立的.

我们有以下的定理,它在数理统计中是很有用的,

定理设  $(X_{1},X_{2},\dots ,X_{m})$  和  $(Y_{1},Y_{2},\dots ,Y_{n})$  相互独立,则  $X_{i}(i = 1,2,\dots ,$ $m)$  和  $Y_{j}(j = 1,2,\dots ,n)$  相互独立.又若  $h,g$  是连续函数,则  $h(X_{1},X_{2},\dots ,X_{m})$  和  $g(Y_{1},Y_{2},\dots ,Y_{n})$  相互独立.

(证明略.)

# §5 两个随机变量的函数的分布

上一章 §5 中已经讨论过一个随机变量的函数的分布,本节讨论两个随机变量的函数的分布.我们只就下面几个具体的函数来讨论.

(一)  $Z = X + Y$  的分布

设  $(X,Y)$  是二维连续型随机变量,它具有概率密度  $f(x,y)$  .则  $Z = X + Y$  仍为连续型随机变量,其概率密度为

$$
f_{X + Y}(z) = \int_{-\infty}^{\infty}f(z - y,y)\mathrm{d}y, \tag{5.1}
$$

或  $f_{X + Y}(z) = \int_{- \infty}^{\infty}f(x,z - x)\mathrm{d}x.$  (5.2)

又若  $X$  和  $Y$  相互独立,设  $(X,Y)$  关于  $X,Y$  的边缘概率密度分别为  $f_{X}(x)$ $f_{Y}(y)$  ,则(5.1),(5.2)式分别化为

$$
f_{X + Y}(z) = \int_{-\infty}^{\infty}f_{X}(z - y)f_{Y}(y)\mathrm{d}y \tag{5.3}
$$

和

$$
f_{X + Y}(z) = \int_{-\infty}^{\infty}f_{X}(x)f_{Y}(z - x)\mathrm{d}x. \tag{5.4}
$$

这两个公式称为  $f_{X}$  和  $f_{Y}$  的卷积公式,记为  $f_{X}*f_{Y}$ ,即

$$
f_{X}*f_{Y} = \int_{-\infty}^{\infty}f_{X}(z - y)f_{Y}(y)\mathrm{d}y = \int_{-\infty}^{\infty}f_{X}(x)f_{Y}(z - x)\mathrm{d}x.
$$

证先来求  $Z = X + Y$  的分布函数  $F_{z}(z)$ ,即有

$$
F_{Z}(x) = P\{Z\leqslant z\} = \iint_{x + y\leqslant z}f(x,y)\mathrm{d}x\mathrm{d}y,
$$

这里积分区域  $G;x + y\leqslant z$  是直线  $x + y = z$  及其左下方的半平面(如图3一9).将二重积分化成累次积分,得

$$
F_{Z}(z) = \int_{-\infty}^{\infty}\left[\int_{-\infty}^{z - y}f(x,y)\mathrm{d}x\right]\mathrm{d}y.
$$

固定  $z$  和  $y$  对积分  $\int_{- \infty}^{z - y}f(x,y)\mathrm{d}x$  作变量变换,令  $x = u - y$ ,得

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-9

$$
\int_{-\infty}^{z - y}f(x,y)\mathrm{d}x = \int_{-\infty}^{z}f(u - y,y)\mathrm{d}u.
$$

于是

$$
F_{Z}(z) = \int_{-\infty}^{\infty}\left[\int_{-\infty}^{z}f(u - y,y)\mathrm{d}u\right]\mathrm{d}y = \int_{-\infty}^{z}\left[\int_{-\infty}^{\infty}f(u - y,y)\mathrm{d}y\right]\mathrm{d}u.
$$

由概率密度的定义即得(5.1)式.类似可证得(5.2)式.

例1设  $X$  和  $Y$  是两个相互独立的随机变量.它们都服从  $N(0,1)$  分布,其概率密度为

$$
\begin{array}{r l} & {f_{X}(x) = \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-x^{2} / 2},\quad -\infty < x< \infty ,}\\ & {f_{Y}(y) = \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-y^{2} / 2},\quad -\infty < y< \infty .} \end{array}
$$

求  $Z = X + Y$  的概率密度.

解由(5.4)式

$$
\begin{array}{l}{{f_{Z}(z)=\int_{-\infty}^{\infty}f_{X}(x)f_{Y}(z-x)\mathrm{d}x}}\\ {{\quad=\frac{1}{2\pi}\int_{-\infty}^{\infty}\mathrm{e}^{-\frac{x^{2}}{2}}\bullet\mathrm{e}^{-\frac{(z-x)^{2}}{2}}\mathrm{d}x=\frac{1}{2\pi}\mathrm{e}^{-\frac{x^{2}}{4}}\int_{-\infty}^{\infty}\mathrm{e}^{-\left(x-\frac{x}{2}\right)^{2}}\mathrm{d}x,}}\end{array}
$$

令  $t = x - \frac{z}{2}$ ,得

$$
f_{Z}(z) = \frac{1}{2\pi}\mathrm{e}^{-\frac{z^{2}}{4}}\int_{-\infty}^{\infty}\mathrm{e}^{-t^{2}}\mathrm{d}t = \frac{1}{2\pi}\mathrm{e}^{-\frac{z^{2}}{4}}\sqrt{\pi} = \frac{1}{2\sqrt{\pi}}\mathrm{e}^{-\frac{z^{2}}{4}}.
$$

即  $Z$  服从  $N(0,2)$  分布.

一般,设  $X,Y$  相互独立且  $X\sim N(\mu_{1},\sigma_{1}^{2}),Y\sim N(\mu_{2},\sigma_{2}^{2})$  .由(5.4)式经过计算知  $Z = X + Y$  仍然服从正态分布,且有  $Z\sim N(\mu_{1} + \mu_{2},\sigma_{1}^{2} + \sigma_{2}^{2})$  .这个结论还能推广到  $n$  个独立正态随机变量之和的情况.即若  $X_{i}\sim N(\mu_{i},\sigma_{i}^{2}) (i = 1,2,\dots ,n)$  ,且它们相互独立,则它们的和  $Z = X_{1} + X_{2} + \dots +X_{n}$  仍然服从正态分布,且有 $Z\sim N(\mu_{1} + \mu_{2} + \dots +\mu_{n},\sigma_{1}^{2} + \sigma_{2}^{2} + \dots +\sigma_{n}^{2}).$

更一般地,可以证明有限个相互独立的正态随机变量的线性组合仍然服从正态分布.  $\square$

例2在一简单电路中,两电阻  $R_{1}$  和  $R_{2}$  串联连接,设  $R_{1},R_{2}$  相互独立,它们的概率密度均为

$$
f(x) = \left\{{\frac{10 - x}{50}},\quad 0\leqslant x\leqslant 10,\right.
$$

求总电阻  $R = R_{1} + R_{2}$  的概率密度.

解由(5.4)式,  $R$  的概率密度为

$$
f_{R}(z) = \int_{-\infty}^{\infty}f(x)f(z - x)\mathrm{d}x.
$$

易知仅当

$$
\left\{ \begin{array}{l l}{0< x< 10,}\\ {0< z - x< 10,} \end{array} \right.\mathbb{H}\left\{ \begin{array}{l l}{0< x< 10,}\\ {z - 10< x< z} \end{array} \right.
$$

时上述积分的被积函数不等于零.参考图3一10,即得

$$
f_{R}(z) = \left\{ \begin{array}{l l}{\int_{0}^{z}f(x)f(z - x)\mathrm{d}x,} & {0\leqslant z< 10,}\\ {\int_{z - 10}^{10}f(x)f(z - x)\mathrm{d}x,} & {10\leqslant z\leqslant 20,}\\ {0,} & {\mathrm{~}\mathbb{H}\mathbb{H}.} \end{array} \right.
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-10

将  $f(x)$  的表达式代入上式得

$$
f_{R}(z) = \left\{ \begin{array}{l l}{\frac{1}{15 000} (600z - 60z^{2} + z^{3}),} & {0\leqslant z< 10,}\\ {\frac{1}{15 000} (20 - z)^{3},} & {10\leqslant z< 20,}\\ {0,} & {\mathbb{H}\mathbb{H}.} \end{array} \right.
$$

例3设随机变量  $X,Y$  相互独立,且分别服从参数为  $\alpha ,\theta ;\beta ,\theta$  的  $\boldsymbol{\cal T}$  分布(分别记成  $X\sim \Gamma (\alpha ,\theta),Y\sim \Gamma (\beta ,\theta)).X,Y$  的概率密度分别为

$$
f_{X}(x) = \left\{ \begin{array}{l l}{\frac{1}{\theta^{\alpha}\Gamma(\alpha)} x^{\alpha -1}\mathrm{e}^{-x / \theta},} & {x > 0,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H},} \end{array} \right.\alpha >0,\theta >0.
$$

$$
f_{Y}(y) = \left\{ \begin{array}{l l}{\frac{1}{\theta^{\beta}\Gamma(\beta)} y^{\beta -1}\mathrm{e}^{-y / \theta},} & {y > 0,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H},} \end{array} \right.\beta >0,\theta >0.
$$

试证明  $Z = X + Y$  服从参数为  $\alpha +\beta ,\theta$  的  $\boldsymbol{\cal T}$  分布,即  $X + Y\sim \Gamma (\alpha +\beta ,\theta)$

证由(5.4)式  $Z = X + Y$  的概率密度为

$$
f_{Z}(z) = \int_{-\infty}^{\infty}f_{X}(x)f_{Y}(z - x)\mathrm{d}x.
$$

易知仅当

$$
\left\{ \begin{array}{l l}{x > 0,}\\ {z - x > 0,} \end{array} \right.\quad \mathcal{H}\mathbb{H}\quad \left\{ \begin{array}{l l}{x > 0,}\\ {x< z} \end{array} \right.
$$

时上述积分的被积函数不等于零,于是(参见图3一11)知当  $z = 0$  时  $f_{Z}(z) = 0$  ,而当  $z > 0$  时有

$$
\begin{array}{r l} & {f_{Z}(z) = \int_{0}^{z}\frac{1}{\theta^{\alpha}\Gamma(\alpha)} x^{\alpha -z / \theta}\frac{1}{\theta^{\beta}\Gamma(\beta)} (z - x)^{\beta -1}\mathrm{e}^{-(z - x) / \alpha}\mathrm{d}x}\\ & {\qquad = \frac{\mathrm{e}^{-z / \theta}}{\theta^{\alpha + \beta}\Gamma(\alpha)\Gamma(\beta)}\int_{0}^{z}x^{\alpha -1}(z - x)^{\beta -1}\mathrm{d}x(\Leftrightarrow x = z t)}\\ & {\qquad = \frac{z^{\alpha + \beta - 1}\mathrm{e}^{-z / \theta}}{\theta^{\alpha + \beta}\Gamma(\alpha)\Gamma(\beta)}\int_{0}^{1}t^{\alpha -1}(1 - t)^{\beta -1}\mathrm{d}t}\\ & {\qquad \frac{\mathrm{i}\mathbb{E}\mathbb{E}}{\mathrm{~\alpha~}} A z^{\alpha +\beta -1}\mathrm{e}^{-z / \theta},} \end{array}
$$

其中  $A = \frac{1}{\theta^{\alpha + \beta}\Gamma(\alpha)\Gamma(\beta)}\int_{0}^{1}t^{\alpha - 1}(1 - t)^{\beta - 1}\mathrm{d}t.$  (5.5)①

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-11

现在来计算  $A$  .由概率密度的性质得到

$$
\begin{array}{l}{{1=\int_{-\infty}^{\infty}f_{Z}(z)\mathrm{d}z=\int_{0}^{\infty}A z^{\alpha+\beta-1}\mathrm{e}^{-z/\theta}\mathrm{d}z}}\\ {{=A\theta^{\alpha+\beta}\int_{0}^{\infty}(z/\theta)^{\alpha+\beta-1}\mathrm{e}^{-z/\theta}\mathrm{d}(z/\theta)=A\theta^{\alpha+\beta}\Gamma(\alpha+\beta),}}\end{array}
$$

$①$  (5.5)式中的积分

$$
\int_{0}^{1}t^{\alpha -1}(1 - t)^{\beta -1}\mathrm{d}t\overset {\mathrm{i}\mathbb{E}\mathbb{E}}{=}\mathrm{B}(\alpha ,\beta),\qquad \alpha ,\beta >0,
$$

称为Beta函数.由(5.5),(5.6)式知Beta函数与  $\Gamma$  函数有如下关系:

$$
\mathrm{B}(\alpha ,\beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}.
$$

即有

$$
A = \frac{1}{\theta^{\alpha + \beta}\Gamma(\alpha + \beta)}. \tag{5.6}
$$

于是

$$
f_{Y}(z) = \left\{ \begin{array}{ll}\frac{1}{\theta^{\alpha + \beta}\Gamma(\alpha + \beta)} z^{\alpha +\beta -1}\mathrm{e}^{-z / \theta}, & z > 0, \\ 0, & \text{其他}. \end{array} \right.
$$

即  $X + Y \sim \Gamma (\alpha + \beta , \theta)$ .

上述结论还能推广到  $n$  个相互独立的  $\boldsymbol{\Gamma}$  分布变量之和的情况.即若  $X_{1},X_{2},\dots ,$ $X_{n}$  相互独立,且  $X_{i}$  服从参数为  $\alpha_{i},\beta (i = 1,2,\dots ,n)$  的  $\boldsymbol{\Gamma}$  分布,则  $\sum_{i = 1}^{n}X_{i}$  服从参数为  $\sum_{i = 1}^{n}\alpha_{i},\beta$  的  $\boldsymbol{\Gamma}$  分布.这一性质称为  $\boldsymbol{\Gamma}$  分布的可加性.

(二)  $Z = \frac{Y}{X}$  的分布、  $Z = X Y$  的分布

设  $(X, Y)$  是二维连续型随机变量, 它具有概率密度  $f(x, y)$ , 则  $Z = \frac{Y}{X}$ ,  $Z = X Y$  仍为连续型随机变量, 其概率密度分别为

$$
f_{Y / X}(z) = \int_{-\infty}^{\infty} |x| f(x, x z) \mathrm{d} x, \tag{5.7}
$$

$$
f_{X Y}(z) = \int_{-\infty}^{\infty} \frac{1}{|x|} f\left(x, \frac{z}{x}\right) \mathrm{d} x. \tag{5.8}
$$

又若  $X$  和  $Y$  相互独立. 设  $(X, Y)$  关于  $X, Y$  的边缘概率密度分别为  $f_{X}(x)$ ,  $f_{Y}(y)$ , 则 (5.7) 式化为

$$
f_{Y / X}(z) = \int_{-\infty}^{\infty} |x| f_{X}(x) f_{Y}(x z) \mathrm{d} x. \tag{5.9}
$$

而 (5.8) 式化为

$$
f_{X Y}(z) = \int_{-\infty}^{\infty} \frac{1}{|x|} f_{X}(x) f_{Y}\left(\frac{z}{x}\right) \mathrm{d} x. \tag{5.10}
$$

证  $Z = Y / X$  的分布函数为 (如图 3- 12)

$$
\begin{array}{r l} & {F_{Y / X}(z) = P\{Y / X\leqslant z\} = \underset {G_{1}\cup G_{2}}{\iint}f(x,y)\mathrm{d}x\mathrm{d}y}\\ & {\qquad = \underset {y / x\leqslant z,x< 0}{\iint}f(x,y)\mathrm{d}y\mathrm{d}x + \underset {y / x\leqslant z,x > 0}{\iint}f(x,y)\mathrm{d}y\mathrm{d}x}\\ & {\qquad = \underset {-\infty}{\iint}\underset {z x}{\iint}f(x,y)\mathrm{d}y\biggr ]\mathrm{d}x + \underset {0}{\iint}\biggl [\underset {-\infty}{\iint}f(x,y)\mathrm{d}y\biggr ]\mathrm{d}x}\\ & {\qquad \overset {\underset{\mathrm{~\scriptstyle~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~\mathscr{~}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}} =}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}})}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}})).}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}).}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-12

$$
\begin{array}{r l} & {= \int_{-\infty}^{0}\left[\int_{-\infty}^{z}(-x)f(x,x u)\mathrm{d}u\right]\mathrm{d}x + \int_{0}^{\infty}\left[\int_{-\infty}^{z}x f(x,x u)\mathrm{d}u\right]\mathrm{d}x}\\ & {= \int_{-\infty}^{\infty}\left[\int_{-\infty}^{z}\mid x\mid f(x,x u)\mathrm{d}u\right]\mathrm{d}x}\\ & {= \int_{-\infty}^{z}\left[\int_{-\infty}^{\infty}\mid x\mid f(x,x u)\mathrm{d}x\right]\mathrm{d}u,} \end{array}
$$

由概率密度的定义即得(5.7)式.

类似地,可求出  $f_{XY}(z)$  的概率密度为(5.8)式.

例4 某公司提供一种地震保险,保险费  $Y$  的概率密度为

$$
f(y) = \left\{ \begin{array}{ll}\frac{y}{25} \mathrm{e}^{-y / 5}, & y > 0, \\ 0, & \text{其他.} \end{array} \right.
$$

保险赔付  $X$  的概率密度为

$$
g(x) = \left\{ \begin{array}{ll}\frac{1}{5} \mathrm{e}^{-x / 5}, & x > 0, \\ 0, & \text{其他.} \end{array} \right.
$$

设  $X$  与  $Y$  相互独立,求  $Z = Y / X$  的概率密度.

解 由(5.9)式知,当  $z< 0$  时,  $f_{Z}(z) = 0$  ;当  $z > 0$  时,  $Z$  的概率密度为

$$
\begin{array}{l}{{f_{Z}(z)=\int_{0}^{\infty}x\cdot\frac{1}{5}\mathrm{e}^{-x/5}\cdot\frac{2z}{25}\mathrm{e}^{-x/5}\mathrm{d}x=\frac{z}{125}\int_{0}^{\infty}x^{2}\mathrm{e}^{-x/5}\mathrm{d}x}}\\ {{=\frac{z}{125}\frac{\Gamma(3)}{\left[(1+z)/5\right]^{3}}=\frac{2z}{(1+z)^{3}}.}}\end{array}
$$

(三)  $M = \max \{X,Y\}$  及  $N = \min \{X,Y\}$  的分布

设  $X,Y$  是两个相互独立的随机变量,它们的分布函数分别为  $F_{X}(x)$  和

$F_{Y}(y)$ . 现在来求  $M = \max \{X, Y\}$  及  $N = \min \{X, Y\}$  的分布函数.

由于  $M = \max \{X, Y\}$  不大于  $z$  等价于  $X$  和  $Y$  都不大于  $z$ , 故有

$$
P\{M \leqslant z\} = P\{X \leqslant z, Y \leqslant z\} .
$$

又由于  $X$  和  $Y$  相互独立, 得到  $M = \max \{X, Y\}$  的分布函数为

$$
F_{\max}(z) = P\{M \leqslant z\} = P\{X \leqslant z, Y \leqslant z\} = P\{X \leqslant z\} P\{Y \leqslant z\} .
$$

即有  $F_{\max}(z) = F_{X}(z) F_{Y}(z)$ . (5.11)

类似地, 可得  $N = \min \{X, Y\}$  的分布函数为

$$
\begin{array}{r l} & {F_{\min}(z) = P\{N\leqslant z\} = 1 - P\{N > z\}}\\ & {\qquad = 1 - P\{X > z,Y > z\} = 1 - P\{X > z\} P\{Y > z\} .} \end{array}
$$

即  $F_{\min}(z) = 1 - [1 - F_{X}(z)][1 - F_{Y}(z)]$ . (5.12)

以上结果容易推广到  $n$  个相互独立的随机变量的情况. 设  $X_{1}, X_{2}, \dots , X_{n}$  是  $n$  个相互独立的随机变量. 它们的分布函数分别为  $F_{X_{i}}(x_{i}) (i = 1,2, \dots , n)$ , 则  $M = \max \{X_{1}, X_{2}, \dots , X_{n}\}$  及  $N = \min \{X_{1}, X_{2}, \dots , X_{n}\}$  的分布函数分别为

$$
F_{\max}(z) = F_{X_{1}}(z) F_{X_{2}}(z) \dots F_{X_{n}}(z), \tag{5.13}
$$

$$
F_{\min}(z) = 1 - [1 - F_{X_{1}}(z)][1 - F_{X_{2}}(z)] \dots [1 - F_{X_{n}}(z)]\]特别, 当 \( X_{1}, X_{2}, \dots , X_{n} \) 相互独立且具有相同分布函数 \( F(x) \) 时有 \tag{5.14}
$$

特别,当  $X_{1},X_{2},\dots ,X_{n}$  相互独立且具有相同分布函数  $F(x)$  时有

$$
F_{\max}(z) = [F(z)]^{n}, \tag{5.15}
$$

$$
F_{\min}(z) = 1 - [1 - F(z)]^{n}. \tag{5.16}
$$

例5 设系统  $L$  由两个相互独立的子系统  $L_{1}, L_{2}$  连接而成, 连接的方式分别为 (i) 串联, (ii) 并联, (iii) 备用 (当系统  $L_{1}$  损坏时, 系统  $L_{2}$  开始工作), 如图 3- 13 所示. 设  $L_{1}, L_{2}$  的寿命分别为  $X, Y$ , 已知它们的概率密度分别为

$$
f_{X}(x)={\left\{\begin{array}{l l}{\alpha\mathrm{e}^{-\alpha},}&{x>0,}\\ {0,}&{x\leqslant0,}\end{array}\right.} \tag{5.17}
$$

$$
f_{Y}(y)={\left\{\begin{array}{l l}{\beta\mathrm{e}^{-\beta y},}&{y>0,}\\ {0,}&{y\leqslant0,}\end{array}\right.} \tag{5.18}
$$

其中  $\alpha >0, \beta >0$  且  $\alpha \neq \beta$ . 试分别就以上三种连接方式写出  $L$  的寿命  $Z$  的概率密度.

解 (i) 串联的情况.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_2.pdf-a278370c-6594-4f43-a5bd-2bff106b477d_dc1caa2fbbac7e79baeb034cca4d04f523f1a1ed55e74917e129eed232d6a732.jpg)  
图3-13

由于当  $L_{1},L_{2}$  中有一个损坏时,系统  $L$  就停止工作,所以这时  $L$  的寿命为

$$
Z = \min \{X,Y\} .
$$

由(5.17),(5.18)式  $X,Y$  的分布函数分别为

$$
F_{X}(x) = \left\{ \begin{array}{l l}{1 - \mathrm{e}^{-\alpha x},} & {x > 0,}\\ {0,} & {x\leqslant 0,} \end{array} \right.\quad F_{Y}(y) = \left\{ \begin{array}{l l}{1 - \mathrm{e}^{-\beta x},} & {y > 0,}\\ {0,} & {y\leqslant 0.} \end{array} \right.
$$

由(5.12)式得  $Z = \min \{X,Y\}$  的分布函数为

$$
F_{\min}(z) = \left\{ \begin{array}{l l}{1 - \mathrm{e}^{-(\alpha +\beta)z},} & {z > 0,}\\ {0,} & {z\leqslant 0.} \end{array} \right.
$$

于是  $Z = \min \{X,Y\}$  的概率密度为

$$
f_{\min}(z) = \left\{ \begin{array}{l l}{(\alpha +\beta)\mathrm{e}^{-(\alpha +\beta)z},} & {z > 0,}\\ {0,} & {z\leqslant 0.} \end{array} \right.
$$

(ii)并联的情况.

由于当且仅当  $L_{1},L_{2}$  都损坏时,系统  $L$  才停止工作,所以这时  $L$  的寿命  $z$  为

$$
Z = \max \{X,Y\} .
$$

按(5.11)式得  $Z = \max \{X,Y\}$  的分布函数为

$$
F_{\max}(z) = F_{X}(z)F_{Y}(z) = \left\{ \begin{array}{l l}{(1 - \mathrm{e}^{-\alpha z})(1 - \mathrm{e}^{-\beta z}),} & {z > 0,}\\ {0,} & {z\leqslant 0.} \end{array} \right.
$$

于是  $Z = \max \{X,Y\}$  的概率密度为

$$
f_{\max}(z) = \left\{ \begin{array}{l l}{\alpha \mathrm{e}^{-\alpha z} + \beta \mathrm{e}^{-\beta z} - (\alpha +\beta)\mathrm{e}^{-(\alpha +\beta)z},} & {z > 0,}\\ {0,} & {z\leqslant 0.} \end{array} \right.
$$

(iii)备用的情况.

由于这时当系统  $L_{1}$  损坏时系统  $L_{2}$  才开始工作,因此整个系统  $L$  的寿命  $z$  是  $L_{1},L_{2}$  两者寿命之和,即

$$
Z = X + Y.
$$

按(5.3)式,当  $z > 0$  时  $Z = X + Y$  的概率密度为

$$
\begin{array}{r l r} & {} & {f(z) = \int_{-\infty}^{\infty}f_{X}(z - y)f_{Y}(y)\mathrm{d}y = \int_{0}^{z}\alpha \mathrm{e}^{-\alpha (z - y)}\beta \mathrm{e}^{-\beta y}\mathrm{d}y}\\ & {} & {= \alpha \beta \mathrm{e}^{-\alpha z}\int_{0}^{z}\mathrm{e}^{-(\beta -\alpha)y}\mathrm{d}y = \frac{\alpha\beta}{\beta - \alpha} (\mathrm{e}^{-\alpha z} - \mathrm{e}^{-\beta z}).} \end{array}
$$

当  $z\leqslant 0$  时,  $f(z) = 0$  ,于是  $Z = X + Y$  的概率密度为

$$
f(z) = \left\{ \begin{array}{l l}{\frac{\alpha\beta}{\beta - \alpha} (\mathrm{e}^{-\alpha z} - \mathrm{e}^{-\beta z}),} & {z > 0,}\\ {0,} & {z\leqslant 0.} \end{array} \right.
$$

# 小结

将一维随机变量的概念加以扩充, 就得到多维随机变量. 我们着重讨论了二维随机变量. 和一维随机变量一样, 我们定义二维随机变量  $(X,Y)$  的分布函数

$$
F(x,y) = P\{X\leqslant x,Y\leqslant y\} , -\infty < x< \infty , -\infty < y< \infty .
$$

对于离散型随机变量  $(X,Y)$  定义了分布律

$$
P\{X = x,Y = y_{j}\} = \phi_{j}, i = 1,2,\dots ,j = 1,2,\dots \Big(\phi_{j}\geqslant 0,\sum_{i = 1}^{\infty}\sum_{j = 1}^{\infty}\phi_{j} = 1\Big).
$$

对于连续型随机变量  $(X,Y)$  定义了概率密度  $f(x,y) (f(x,y)\geqslant 0)$ , 且有

$$
F(x,y) = \int_{-\infty}^{y}\int_{-\infty}^{x}f(x,y)\mathrm{d}x\mathrm{d}y,
$$

二维随机变量的分布律与概率密度的性质与一维的类似. 特别, 对于二维连续型随机变量, 有公式

$$
P\{(X,Y)\in G\} = \iint_{G}f(x,y)\mathrm{d}x\mathrm{d}y,
$$

其中,  $G$  是平面上的某区域 (它是一维连续型随机变量的公式  $P\{a< X\leqslant b\} = \int_{a}^{b}f(x)\mathrm{d}x$  的扩充). 这一公式常用来求随机变量的不等式成立的概率, 例如

$$
P\{Y\leqslant X\} = P\{(X,Y)\in G\} = \iint_{G}f(x,y)\mathrm{d}x\mathrm{d}y,
$$

其中,  $G$  为半平面  $y\leqslant x$

在研究二维随机变量  $(X,Y)$  时, 除了讨论上述与一维随机变量类似的内容外, 还要讨论以下的新内容: 边缘分布、条件分布、随机变量的独立性等.

注意到, 对于  $(X,Y)$  而言, 由  $(X,Y)$  的分布可以确定关于  $X$  关于  $Y$  的边缘分布. 反之, 由关于  $X$  和关于  $Y$  的边缘分布一般是不能确定  $(X,Y)$  的分布的. 只有当  $X,Y$  相互独立时, 由两边缘分布能确定  $(X,Y)$  的分布.

随机变量的独立性是随机事件独立性的扩充. 我们也常利用问题的实际意义去判断两个随机变量的独立性. 例如, 若  $X,Y$  分别表示两个工厂生产的显像管的寿命, 我们可以认为  $X,Y$  是相互独立的.

我们还讨论了  $Z = X + Y,Z = Y / X,Z = XY,M = \max \{X,Y\} ,N = \min \{X,Y\}$  的分布的求法 (设  $(X,Y)$  的分布已知).

本章在进行各种问题的计算时, 要用到二重积分或用到二元函数固定其中一个变量对另一个变量的积分. 此时千万要搞清楚积分变量的变化范围. 题目做错, 往往是由于在进行积分运算时, 将有关的积分区间或积分区域搞错了. 在做题时, 画出有关函数的定义域的图形, 对于正确确定积分上下限肯定是有帮助的. 另外, 所求得的边缘概率密度、条件概率密度或  $Z = X + Y$  的概率密度等, 往往是分段函数, 正确写出分段函数的表达式当然是必需的.

# 重要术语及主题

二维随机变量  $(X,Y)$ $(X,Y)$  的分布函数 离散型随机变量  $(X,Y)$  的分布律 连续型

随机变量  $(X,Y)$  的概率密度离散型随机变量  $(X,Y)$  的边缘分布律连续型随机变量  $(X,$  Y)的边缘概率密度条件分布函数条件分布律条件概率密度两个随机变量  $X,Y$  的独立性  $Z = X + Y,Z = Y / X,Z = X Y$  的概率密度  $M = \max \{X,Y\}$ $N = \min \{X,Y\}$  的概率密度

# 习题

1. 在一箱子中装有 12 只开关, 其中 2 只是次品, 在其中取两次, 每次任取一只, 考虑两种试验: (1) 放回抽样; (2) 不放回抽样. 我们定义随机变量  $X, Y$  如下:

$X = \left\{ \begin{array}{ll}0, & \text { 若第一次取出的是正品,} \\ 1, & \text { 若第一次取出的是次品;} \end{array} \right.$

$Y = \left\{ \begin{array}{ll}0, & \text { 若第二次取出的是正品,} \\ 1, & \text { 若第二次取出的是次品.} \end{array} \right.$

试分别就 (1)、(2) 两种情况, 写出  $X$  和  $Y$  的联合分布律.

2. (1) 盒子里装有 3 只黑球、2 只红球、2 只白球, 在其中任取 4 只球. 以  $X$  表示取到黑球的只数, 以  $Y$  表示取到红球的只数. 求  $X$  和  $Y$  的联合分布律.

(2) 在 (1) 中求  $P\{X > Y\} , P\{Y = 2X\} , P\{X + Y = 3\} , P\{X< 3 - Y\}$ .

3. 设随机变量  $(X,Y)$  的概率密度为

$$
f(x,y) = \left\{ \begin{array}{ll}k(6 - x - y), & 0< x< 2, 2< y< 4, \\ 0, & \text { 其他.} \end{array} \right.
$$

(1) 确定常数  $k$ .

(2) 求  $P\{X< 1, Y< 3\}$ .

(3) 求  $P\{X< 1.5\}$ .

(4) 求  $P\{X + Y\leqslant 4\}$ .

4. 设  $X, Y$  都是非负的连续型随机变量, 它们相互独立.

(1) 证明  $P\{X< Y\} = \int_{0}^{\infty} F_{X}(x) f_{Y}(x) \mathrm{d}x$ ,

其中  $F_{X}(x)$  是  $X$  的分布函数,  $f_{Y}(y)$  是  $Y$  的概率密度.

(2) 设  $X, Y$  相互独立, 其概率密度分别为

$$
f_{X}(x) = \left\{ \begin{array}{ll} \lambda_{1} \mathrm{e}^{-\lambda_{1} x}, & x > 0, \\ 0, & \text { 其他,} \end{array} \right. \quad f_{Y}(y) = \left\{ \begin{array}{ll} \lambda_{2} \mathrm{e}^{-\lambda_{2} y}, & y > 0, \\ 0, & \text { 其他,} \end{array} \right.
$$

求  $P\{X< Y\}$ .

5. 设随机变量  $(X,Y)$  具有分布函数

$$
F(x,y) = \left\{ \begin{array}{ll} 1 - \mathrm{e}^{-x} - \mathrm{e}^{-y} + \mathrm{e}^{-x - y}, & x > 0, y > 0, \\ 0, & \text { 其他.} \end{array} \right.
$$

求边缘分布函数.

6. 将一枚硬币掷 3 次, 以  $X$  表示前 2 次中出现  $H$  的次数, 以  $Y$  表示 3 次中出现  $H$  的次数. 求  $X, Y$  的联合分布律以及  $(X, Y)$  的边缘分布律.

7. 设二维随机变量  $(X,Y)$  的概率密度为

$$
f(x,y)={\left\{\begin{array}{l l}{4.8y(2-x),}&{0\leqslant x\leqslant1,0\leqslant y\leqslant x,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}}\end{array}\right.}
$$

求边缘概率密度.

8. 设二维随机变量  $(X,Y)$  的概率密度为

$$
f(x,y)={\left\{\begin{array}{l l}{\mathrm{e}^{-y},}&{0< x< y,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm~}}\end{array}\right.}
$$

求边缘概率密度.

9. 设二维随机变量  $(X,Y)$  的概率密度为

$$
f(x,y)={{\begin{array}{l l}{c x^{2}y,}&{x^{2}\leqslant y\leqslant1,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{\quad}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{
$$

(1)确定常数  $\bar{c}$

(2)求边缘概率密度.

10. 将某医药公司8月份和9月份收到的青霉素针剂的订货单数分别记为  $X$  和  $Y$ . 据以往积累的资料知  $X$  和  $Y$  的联合分布律为

<table><tr><td>X</td><td>51</td><td>52</td><td>53</td><td>54</td><td>55</td></tr><tr><td>Y</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>51</td><td>0.06</td><td>0.05</td><td>0.05</td><td>0.01</td><td>0.01</td></tr><tr><td>52</td><td>0.07</td><td>0.05</td><td>0.01</td><td>0.01</td><td>0.01</td></tr><tr><td>53</td><td>0.05</td><td>0.10</td><td>0.10</td><td>0.05</td><td>0.05</td></tr><tr><td>54</td><td>0.05</td><td>0.02</td><td>0.01</td><td>0.01</td><td>0.03</td></tr><tr><td>55</td><td>0.05</td><td>0.06</td><td>0.05</td><td>0.01</td><td>0.03</td></tr></table>

(1)求边缘分布律.

(2)求条件分布律.

(3)特别,写出当  $X = 20$  时,  $Y$  的条件分布律.

12. 求  $\S 1$  例1中的条件分布律:  $P\left\{Y = k \mid X = i\right\}$

13. 在第9题中: (1)求条件概率密度  $f_{X \mid Y}(x \mid y)$ , 特别, 写出当  $Y = \frac{1}{2}$  时  $X$  的条件概率密度.

(1)求边缘分布律.

(2)求条件分布律.

(3)特别,写出当  $X = 20$  时,  $Y$  的条件分布律.

12. 求  $\S 1$  例1中的条件分布律:  $P\left\{Y = k \mid X = i\right\}$

13. 在第9题中:

(1)求条件概率密度  $f_{X \mid Y}(x \mid y)$ , 特别, 写出当  $Y = \frac{1}{2}$  时  $X$  的条件概率密度.

(2)求条件概率密度  $f_{Y \mid X}(y \mid x)$ , 特别, 分别写出当  $X = \frac{1}{3}, X = \frac{1}{2}$  时  $Y$  的条件概率密度.

(3)求条件概率

$$
P\left\{Y \geqslant \frac{1}{4} \mid X = \frac{1}{2}\right\} , \quad P\left\{Y \geqslant \frac{3}{4} \mid X = \frac{1}{2}\right\} .
$$

14. 设随机变量  $(X,Y)$  的概率密度为

$$
f(x,y)={\left\{\begin{array}{l l}{1,}&{|y|< x,0< x< 1,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}\end{array}\right.}
$$

求条件概率密度  $f_{Y|X}(y|x), f_{X|Y}(x|y)$

15. 设随机变量  $X \sim U(0,1)$ ,当给定  $X = x$  时,随机变量  $Y$  的条件概率密度为

$$
f_{Y|X}(y|x) = \left\{ \begin{array}{ll}x, & 0 < y < \frac{1}{x}, \\ 0, & \text{其他}. \end{array} \right.
$$

(1)求  $X$  和  $Y$  的联合概率密度  $f(x,y)$

(2)求边缘概率密度  $f_{Y}(y)$ ,并画出它的图形,

(3)求  $P\{X > Y\}$

16. (1)问第1题中的随机变量  $X$  和  $Y$  是否相互独立?

(2)问第14题中的随机变量  $X$  和  $Y$  是否相互独立(需说明理由)?

17. (1)设随机变量  $(X,Y)$  具有分布函数

$$
F(x,y)={{\begin{array}{l l}{(1-\mathrm{e}^{-\alpha x})y,}&{x\geqslant0,0\leqslant y\leqslant1,}\\ {1-\mathrm{e}^{-\alpha x},}&{x\geqslant0,y>1,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{{\begin{array}{l l}{1-\mathrm{e}^{-\alpha x})y,}&{x\geqslant0,0\leqslant y\leqslant1,}\\ {1-\mathrm{e}^{-\alpha x},}&{x\geqslant0,y>1,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}\leqslant1,}\end{array}}\end{array}}}
$$

证明  $X,Y$  相互独立.

(2)设随机变量  $(X,Y)$  具有分布律

问  $X,Y$  是否相互独立?

18. 设  $X$  和  $Y$  是两个相互独立的随机变量,  $X$  在区间(0,1)上服从均匀分布,  $Y$  的概率密度为

$$
f_{Y}(y) = \left\{ \begin{array}{ll}\frac{1}{2} \mathrm{e}^{-y / 2}, & y > 0, \\ 0, & y \leqslant 0. \end{array} \right.
$$

(1)求  $X$  和  $Y$  的联合概率密度,

(2)设含有  $a$  的二次方程为  $a^{2} + 2Xa + Y = 0$ ,试求  $a$  有实根的概率.

19. 进行打靶,设弹着点  $A(X,Y)$  的坐标  $X$  和  $Y$  相互独立,且都服从  $N(0,1)$  分布,规定

点  $A$  落在区域  $D_{1} = \{(x,y) \mid x^{2} + y^{2} \leqslant 1\}$  得2分;

点  $A$  落在  $D_{2} = \{(x,y) \mid 1 < x^{2} + y^{2} \leqslant 4\}$  得1分;

点  $A$  落在  $D_{3} = \{(x,y) \mid x^{2} + y^{2} > 4\}$  得0分.

以  $Z$  记打靶的得分.写出  $X,Y$  的联合概率密度,并求  $Z$  的分布律.

20. 设  $X$  和  $Y$  是相互独立的随机变量,其概率密度分别为

$$
f_{X}(x) = \left\{ \begin{array}{ll}\lambda \mathrm{e}^{-\lambda x}, & x > 0, \\ 0, & x \leqslant 0, \end{array} \right. \quad f_{Y}(y) = \left\{ \begin{array}{ll}\mu \mathrm{e}^{-\mu y}, & y > 0, \\ 0, & y \leqslant 0, \end{array} \right.
$$

其中  $\lambda >0, \mu >0$  是常数. 引入随机变量

$$
Z = \left\{ \begin{array}{ll}1, & \text{当} X \leqslant Y, \\ 0, & \text{当} X > Y. \end{array} \right.
$$

(1) 求条件概率密度  $f_{X|Y}(x|y)$ .

(2) 求  $Z$  的分布律和分布函数.

21. 设随机变量  $(X,Y)$  的概率密度为

$$
f(x,y)={\left\{\begin{array}{l l}{x+y,}&{0< x< 1,0< y< 1,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}\end{array}\right.}
$$

分别求(1)  $Z = X + Y$ , (2)  $Z = XY$  的概率密度.

22. 设  $X$  和  $Y$  是两个相互独立的随机变量, 其概率密度分别为

$$
f_{X}(x)={{\begin{array}{l l}{1,}&{0\leqslant x\leqslant1,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{{\begin{array}{l l}{\mathrm{e}^{-y},}&{y>0,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm~}}\end{array}}
$$

求随机变量  $Z = X + Y$  的概率密度.

23. 某种商品一周的需求量是一个随机变量, 其概率密度为

$$
f(t) = \left\{ \begin{array}{ll}t\mathrm{e}^{-t}, & t > 0, \\ 0, & t \leqslant 0. \end{array} \right.
$$

设各周的需求量是相互独立的. 求(1)两周, (2)三周的需求量的概率密度.

24. 设随机变量  $(X,Y)$  的概率密度为

$$
f(x,y)={\left\{\begin{array}{l l}{\frac{1}{2}(x+y)\mathrm{e}^{-(x+y)},}&{x>0,y>0,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}}\end{array}\right.}
$$

(1) 问  $X$  和  $Y$  是否相互独立?

(2) 求  $Z = X + Y$  的概率密度.

25. 设随机变量  $X,Y$  相互独立, 且具有相同的分布, 它们的概率密度均为

$$
f(x)={\left\{\begin{array}{l l}{\mathrm{e}^{1-x},}&{x>1,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\right.}}
$$

求  $Z = X + Y$  的概率密度.

26. 设随机变量  $X,Y$  相互独立, 它们的概率密度均为

$$
f(x)={\left\{\begin{array}{l l}{\mathrm{e}^{-x},}&{x>0,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}\end{array}\right.}
\]  

其他.
$$

求  $Z = Y / X$  的概率密度.

27. 设随机变量  $X,Y$  相互独立, 它们都在区间(0,1)上服从均匀分布.  $A$  是以  $X,Y$  为边长的矩形的面积, 求  $A$  的概率密度.

28. 设  $X,Y$  是相互独立的随机变量, 它们都服从正态分布  $N(0,\sigma^{2})$ . 试验证随机变量  $Z = \sqrt{X^{2} + Y^{2}}$  的概率密度为

$$
f_{Z}(z) = \left\{ \begin{array}{ll}\frac{z}{\sigma^{2}}\mathrm{e}^{-z^{2} / (2\sigma^{2})}, & z > 0, \\ 0, & \text{其他.} \end{array} \right.
$$

我们称  $Z$  服从参数为  $\sigma (\sigma >0)$  的瑞利(Rayleigh)分布.

29. 设随机变量  $(X,Y)$  的概率密度为

$$
f(x,y) = \left\{ \begin{array}{ll}b e^{-(x + y)}, & 0< x< 1,0< y< \infty , \\ 0, & \text{其他}. \end{array} \right.
$$

(1)试确定常数  $b$

(2)求边缘概率密度  $f_{X}(x),f_{Y}(y)$

(3)求函数  $U = \max \{X,Y\}$  的分布函数.

30. 设某种型号的电子元件的寿命(以  $\mathrm{h}$  计)近似地服从正态分布  $N(160,20^{2})$ ,随机地选取4只,求其中没有一只寿命小于180的概率.

31. 对某种电子装置的输出测量了5次,得到结果为  $X_{1},X_{2},X_{3},X_{4},X_{5}$ . 设它们是相互独立的随机变量且都服从参数  $\sigma = 2$  的瑞利分布.

(1)求  $Z = \max \{X_{1},X_{2},X_{3},X_{4},X_{5}\}$  的分布函数.

(2)求  $P\{Z > 4\}$

32. 设随机变量  $X,Y$  相互独立,且服从同一分布,试证明

$$
P\{a< \min \{X,Y\} \leqslant b\} = (P\{X > a\})^{2} - (P\{X > b\})^{2} \quad (a \leqslant b).
$$

33. 设  $X,Y$  是相互独立的随机变量,其分布律分别为

$$
P\{X = k\} = p(k), \quad k = 0,1,2,\dots ,
$$

$$
P\{Y = r\} = q(r), \quad r = 0,1,2,\dots .
$$

证明随机变量  $Z = X + Y$  的分布律为

$$
P\{Z = i\} = \sum_{k = 0}^{i}p(k)q(i - k), \quad i = 0,1,2,\dots .
$$

34. 设  $X,Y$  是相互独立的随机变量,  $X\sim \pi (\lambda_{1}),Y\sim \pi (\lambda_{2})$ . 证明  $Z = X + Y\sim \pi (\lambda_{1} + \lambda_{2})$

35. 设  $X,Y$  是相互独立的随机变量,  $X\sim b(n_{1},p),Y\sim b(n_{2},p)$ . 证明

$$
Z = X + Y\sim b(n_{1} + n_{2},p).
$$

36. 设随机变量  $(X,Y)$  的分布律为

<table><tr><td>X
Y</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td>0</td><td>0.00</td><td>0.01</td><td>0.03</td><td>0.05</td><td>0.07</td><td>0.09</td></tr><tr><td>1</td><td>0.01</td><td>0.02</td><td>0.04</td><td>0.05</td><td>0.06</td><td>0.08</td></tr><tr><td>2</td><td>0.01</td><td>0.03</td><td>0.05</td><td>0.05</td><td>0.05</td><td>0.06</td></tr><tr><td>3</td><td>0.01</td><td>0.02</td><td>0.04</td><td>0.06</td><td>0.06</td><td>0.05</td></tr></table>

(1)求  $P\{X = 2\mid Y = 2\} ,P\{Y = 3\mid X = 0\} .$

(2)求  $V = \max \{X,Y\}$  的分布律.

(3)求  $U = \min \{X,Y\}$  的分布律.

(4)求  $W = X + Y$  的分布律.

# 第四章 随机变量的数字特征

上一章介绍了随机变量的分布函数、概率密度和分布律,它们都能完整地描述随机变量,但在某些实际或理论问题中,人们感兴趣于某些能描述随机变量某一种特征的常数。例如,一篮球队上场比赛的运动员的身高是一个随机变量,人们常关心上场运动员的平均身高。一个城市一户家庭拥有汽车的辆数是一个随机变量,在考察城市的交通情况时,人们关心户均拥有汽车的辆数。评价棉花的质量时,既需要注意纤维的平均长度,又需要注意纤维长度与平均长度的偏离程度,平均长度较大,偏离程度较小,质量就较好。这种由随机变量的分布所确定的,能刻画随机变量某一方面的特征的常数统称为数字特征,它在理论和实际应用中都很重要。本章将介绍几个重要的数字特征:数学期望、方差、相关系数和矩。

# $\S 1$  数学期望

先看一个例子。一射手进行打靶练习,规定射入区域  $e_{2}$  (图4一1)得2分;射入区域  $e_{1}$  得1分;脱靶,即射入区域  $e_{0}$ ,得0分。射手一次射击所得分数  $X$  是一个随机变量。设  $X$  的分布律为

$$
P\{X = k\} = p_{k},\quad k = 0,1,2.
$$

现在射击  $N$  次,其中得0分的有  $a_{0}$  次,得1分的有  $a_{1}$  次,得2分的有  $a_{2}$  次,  $a_{0} + a_{1} + a_{2} = N$ 。他射击  $N$  次得分的总和为  $a_{0} \times 0 + a_{1} \times 1 + a_{2} \times 2$ 。于是平均一次射击的得分数为

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_3.pdf-8b019cbe-e56b-4db0-aa4a-872484615581_86f06b0126c340fd8071513db28c218f845cdec67f56e84a36112bbacbf868cd.jpg)  
图4-1

$$
\frac{a_{0} \times 0 + a_{1} \times 1 + a_{2} \times 2}{N} = \sum_{k = 0}^{2} k \frac{a_{k}}{N}.
$$

这里,  $a_{k} / N$  是事件  $\{X = k\}$  的频率。在第五章将会讲到,当  $N$  很大时,  $a_{k} / N$  在一定意义下接近于事件  $\{X = k\}$  的概率  $p_{k}$ 。就是说,在试验次数很大时,随机变量  $X$  的观察值的算术平均  $\sum_{k = 0}^{2} k \frac{a_{k}}{N}$  在一定意义下接近于  $\sum_{k = 0}^{2} k p_{k}$ 。我们称  $\sum_{k = 0}^{2} k p_{k}$  为随机变量  $X$  的数学期望或均值。一般,有以下的定义。

定义 设离散型随机变量  $X$  的分布律为

$$
P\{X = x_{k}\} = p_{k},\quad k = 1,2,\dots .
$$

若级数

$$
\sum_{k = 1}^{\infty}x_{k}p_{k}
$$

绝对收敛,则称级数  $\sum_{k = 1}^{\infty}x_{k}p_{k}$  的和为随机变量  $X$  的数学期望,记为  $E(X)$ . 即

$$
E(X) = \sum_{k = 1}^{\infty}x_{k}p_{k}. \tag{1.1}
$$

设连续型随机变量  $X$  的概率密度为  $f(x)$ ,若积分

$$
\int_{-\infty}^{\infty}x f(x)\mathrm{d}x
$$

绝对收敛,则称积分  $\int_{- \infty}^{\infty}x f(x)\mathrm{d}x$  的值为随机变量  $X$  的数学期望,记为  $E(X)$ . 即

$$
E(X) = \int_{-\infty}^{\infty}x f(x)\mathrm{d}x. \tag{1.2}
$$

数学期望简称期望,又称为均值,

数学期望  $E(X)$  完全由随机变量  $X$  的概率分布所确定. 若  $X$  服从某一分布,也称  $E(X)$  是这一分布的数学期望.

例1 某医院当新生儿诞生时,医生要根据婴儿的皮肤颜色、肌肉弹性、反应的敏感性、心脏的搏动等方面的情况进行评分,新生儿的得分  $X$  是一个随机变量. 据以往的资料表明  $X$  的分布律为

<table><tr><td>X</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td></tr><tr><td>pk</td><td>0.002</td><td>0.001</td><td>0.002</td><td>0.005</td><td>0.02</td><td>0.04</td><td>0.18</td><td>0.37</td><td>0.25</td><td>0.12</td><td>0.01</td></tr></table>

试求  $X$  的数学期望  $E(X)$

解  $E(X) = 0\times 0.002 + 1\times 0.001 + 2\times 0.002 + 3\times 0.005 + 4\times 0.02$

$$
+5\times 0.04 + 6\times 0.18 + 7\times 0.37 + 8\times 0.25 + 9\times 0.12 + 10\times 0.01
$$

$= 7.15$  (分).

这意味着,若考察医院出生的很多新生儿,例如1000个,则一个新生儿的平均得分约为7.15分,1000个新生儿共得分约7150分.

例2 有两个相互独立工作的电子装置,它们的寿命(以h计)  $X_{k}(k = 1,2)$  服从同一指数分布,其概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{\theta}\mathrm{e}^{-x / \theta}, & x > 0, \\ 0, & x\leqslant 0, \end{array} \right.\theta >0.
$$

若将这两个电子装置串联连接组成整机,求整机寿命(以h计)  $N$  的数学期望.

解  $X_{k}(k = 1,2)$  的分布函数为

$$
F(x) = \left\{ \begin{array}{ll}1 - \mathrm{e}^{-x / \theta}, & x > 0, \\ 0, & x \leqslant 0. \end{array} \right.
$$

由第三章 §5 的 (5.12) 式,  $N = \min \{X_{1}, X_{2}\}$  的分布函数为

$$
F_{\min}(x) = 1 - [1 - F(x)]^{2} = \left\{ \begin{array}{ll}1 - \mathrm{e}^{-2x / \theta}, & x > 0, \\ 0, & x \leqslant 0, \end{array} \right.
$$

因而  $N$  的概率密度为

$$
f_{\min}(x) = \left\{ \begin{array}{ll} \frac{2}{\theta} \mathrm{e}^{-2x / \theta}, & x > 0, \\ 0, & x \leqslant 0. \end{array} \right.
$$

于是  $N$  的数学期望为

$$
E(N) = \int_{-\infty}^{\infty} x f_{\min}(x) \mathrm{d}x = \int_{0}^{\infty} \frac{2x}{\theta} \mathrm{e}^{-2x / \theta} \mathrm{d}x = \frac{\theta}{2}.
$$

例3 按规定,某车站每天  $8:00 \sim 9:00, 9:00 \sim 10:00$  都恰有一辆客车到站,但到站的时刻是随机的,且两者到站的时间相互独立. 其规律为

<table><tr><td rowspan="2">到站时刻</td><td>8:10</td><td>8:30</td><td>8:50</td></tr><tr><td>9:10</td><td>9:30</td><td>9:50</td></tr><tr><td>概率</td><td>1/6</td><td>3/6</td><td>2/6</td></tr></table>

一旅客8:20到车站,求他候车时间的数学期望,

解 设旅客的候车时间为  $X$  (以  $\min$  计).  $X$  的分布律为

<table><tr><td>X</td><td>10</td><td>30</td><td>50</td><td>70</td><td>90</td></tr><tr><td>p k</td><td>3/6</td><td>2/6</td><td>1/6 × 1/6</td><td>1/6 × 3/6</td><td>1/6 × 2/6</td></tr></table>

在上表中,例如

$$
P\{X = 70\} = P(AB) = P(A)P(B) = \frac{1}{6} \times \frac{3}{6},
$$

其中  $A$  为事件"第一班车在8:10到站",  $B$  为"第二班车在9:30到站". 候车时间的数学期望为

$$
E(X) = 10 \times \frac{3}{6} + 30 \times \frac{2}{6} + 50 \times \frac{1}{36} + 70 \times \frac{3}{36} + 90 \times \frac{2}{36} = 27.22.
$$

例4 某商店对某种家用电器的销售采用先使用后付款的方式. 记使用寿命为  $X$  (以年计),规定:

$X \leqslant 1$ , 一台付款 1500 元;

$1 < X \leqslant 2$ , 一台付款 2000 元;

$2 < X \leqslant 3$ , 一台付款 2500 元;

$X > 3$ , 一台付款 3000 元.

设寿命  $X$  服从指数分布, 概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{10} \mathrm{e}^{-x / 10}, & x > 0, \\ 0, & x \leqslant 0. \end{array} \right.
$$

试求该商店一台这种家用电器收费  $Y$  的数学期望,

解 先求出寿命  $X$  落在各个时间区间的概率. 即有

$$
P\{X \leqslant 1\} = \int_{0}^{1} \frac{1}{10} \mathrm{e}^{-x / 10} \mathrm{d}x = 1 - \mathrm{e}^{-0.1} = 0.0952,
$$

$$
P\{1 < X \leqslant 2\} = \int_{1}^{2} \frac{1}{10} \mathrm{e}^{-x / 10} \mathrm{d}x = \mathrm{e}^{-0.1} - \mathrm{e}^{-0.2} = 0.0861,
$$

$$
P\{2 < X \leqslant 3\} = \int_{2}^{3} \frac{1}{10} \mathrm{e}^{-x / 10} \mathrm{d}x = \mathrm{e}^{-0.2} - \mathrm{e}^{-0.3} = 0.0779,
$$

$$
P\{X > 3\} = \int_{3}^{\infty} \frac{1}{10} \mathrm{e}^{-x / 10} \mathrm{d}x = \mathrm{e}^{-0.3} = 0.7408.
$$

一台家用电器收费  $Y$  (以元计)的分布律为

<table><tr><td>Y</td><td>1 500</td><td>2 000</td><td>2 500</td><td>3 000</td></tr><tr><td>pk</td><td>0.095 2</td><td>0.086 1</td><td>0.077 9</td><td>0.740 8</td></tr></table>

得  $E(Y) = 2732.15$ , 即平均一台收费 2732.15 元.

例5 在一个人数很多的团体中普查某种疾病, 为此要抽验  $N$  个人的血, 可以用两种方法进行. (i) 将每个人的血分别去验, 这就需验  $N$  次. (ii) 按  $k$  个人一组进行分组, 把从  $k$  个人抽来的血混合在一起进行检验. 如果这混合血液呈阴性反应, 就说明  $k$  个人的血都呈阴性反应, 这样, 这  $k$  个人的血就只需验一次; 若呈阳性, 则再对这  $k$  个人的血液分别进行化验, 这样,  $k$  个人的血总共要化验  $k + 1$  次. 假设每个人化验呈阳性的概率为  $p$ , 且这些人的试验反应是相互独立的. 试说明当  $p$  较小时, 选取适当的  $k$ , 按第二种方法可以减少化验的次数. 并说明  $k$  取什么值时最适宜.

解 各人的血呈阴性反应的概率为  $q = 1 - p$ . 因而  $k$  个人的混合血呈阴性反应的概率为  $q^{k}$ ,  $k$  个人的混合血呈阳性反应的概率为  $1 - q^{k}$ .

设以  $k$  个人为一组时, 组内每人化验的次数为  $X$ , 则  $X$  是一个随机变量, 其分布律为

$$
\frac{X}{\frac{p_{k}}{p_{k}}}\left|\frac{1}{k}\frac{k + 1}{k}\right.
$$

$X$  的数学期望为

$$
E(X) = \frac{1}{k} q^{k} + \left(1 + \frac{1}{k}\right)(1 - q^{k}) = 1 - q^{k} + \frac{1}{k}.
$$

$N$  个人平均需化验的次数为

$$
N\left(1 - q^{k} + \frac{1}{k}\right).
$$

由此可知,只要选择  $k$  使

$$
1 - q^{k} + \frac{1}{k} < 1,
$$

则  $N$  个人平均需化验的次数  $< N$  当  $\boldsymbol{\mathscr{p}}$  固定时,我们选取  $k$  使得

$$
L = 1 - q^{k} + \frac{1}{k}
$$

小于1且取到最小值,这时就能得到最好的分组方法,

例如,  $\scriptstyle{p = 0,1}$  ,则  $q = 0,9$  ,当  $k = 4$  时,  $L = 1 - q^{k} + \frac{1}{k}$  取到最小值.此时得到最好的分组方法.若  $N = 1000$  ,此时以  $k = 4$  分组,则按第二种方法平均只需化验

这样平均来说,约可以减少  $40\%$  的工作量,

例6设随机变量  $X\sim \pi (\lambda)$  ,求  $E(X)$

解  $X$  的分布律为

$$
P\{X = k\} = \frac{\lambda^{k}\mathrm{e}^{-\lambda}}{k!},\quad k = 0,1,2,\dots ,\quad \lambda >0.
$$

$X$  的数学期望为

$$
E(X) = \sum_{k = 0}^{\infty}k\frac{\lambda^{k}\mathrm{e}^{-\lambda}}{k!} = \lambda \mathrm{e}^{-\lambda}\sum_{k = 1}^{\infty}\frac{\lambda^{k - 1}}{(k - 1)!} = \lambda \mathrm{e}^{-\lambda}\bullet \mathrm{e}^{\lambda} = \lambda ,
$$

即  $E(X) = \lambda$

例7设随机变量  $X\sim U(a,b)$  ,求  $E(X)$

解  $X$  的概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{b - a}, & a< x< b \\ 0, & \text{其他.} \end{array} \right.
$$

$X$  的数学期望为

$$
E(X) = \int_{-\infty}^{\infty}x f(x)\mathrm{d}x = \int_{a}^{b}{\frac{x}{b - a}}\mathrm{d}x = \frac{a + b}{2}.
$$

即数学期望位于区间  $(a,b)$  的中点.

我们经常需要求随机变量的函数的数学期望,例如飞机机翼受到压力  $W =$ $k V^{2}$  (  $V$  是风速,  $k > 0$  是常数)的作用,需要求  $W$  的数学期望,这里  $W$  是随机变量  $V$  的函数.这时,可以通过下面的定理来求  $W$  的数学期望.

定理设  $Y$  是随机变量  $X$  的函数:  $Y = g(X)$  (  $g$  是连续函数).

(i)如果  $X$  是离散型随机变量,它的分布律为  $P\{X = x_{k}\} = p_{k},k = 1,2,\dots$  ,若 $\sum_{k = 1}^{\infty}g(x_{k})p_{k}$  绝对收敛,则有

$$
E(Y) = E\big[g(X)\big] = \sum_{k = 1}^{\infty}g(x_{k})p_{k}. \tag{1.3}
$$

(ii)如果  $X$  是连续型随机变量,它的概率密度为  $f(x)$  ,若  $\int_{- \infty}^{\infty}g(x)f(x)\mathrm{d}x$  绝对收敛,则有

$$
E(Y) = E\big[g(X)\big] = \int_{-\infty}^{\infty}g(x)f(x)\mathrm{d}x. \tag{1.4}
$$

定理的重要意义在于当我们求  $E(Y)$  时,不必算出  $Y$  的分布律或概率密度,而只需利用  $X$  的分布律或概率密度就可以了,定理的证明超出了本书的范围.我们只对下述特殊情况加以证明.

证设  $X$  是连续型随机变量,且  $y = g(x)$  满足第二章  $\S 5$  中定理的条件.

由第二章  $\S 5$  中的(5.2)式知道随机变量  $Y = g(X)$  的概率密度为

$$
f_{Y}(y) = \left\{ \begin{array}{l l}{f_{X}\big[h(y)\big]\big|h^{\prime}(y)\big|,} & {\alpha {<}y{<}\beta ,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H},} \end{array} \right.
$$

于是

$$
E(Y) = \int_{-\infty}^{\infty}y f_{Y}(y)\mathrm{d}y = \int_{a}^{\beta}y f_{X}[h(y)]\mid h^{\prime}(y)\mid \mathrm{d}y.
$$

当  $h^{\prime}(y)$  恒  $>0$  时

$$
E(Y) = \int_{a}^{\beta}y f_{X}[h(y)]h^{\prime}(y)\mathrm{d}y = \int_{-\infty}^{\infty}g(x)f(x)\mathrm{d}x.
$$

当  $h^{\prime}(y)$  恒  $< 0$  时

$$
\begin{array}{l}{{ E(Y)=-\int_{\alpha}^{\beta}y f_{X}[h(y)]h^{\prime}(y)\mathrm{d}y}}\\ {{\quad=-\int_{\infty}^{-\infty}g(x)f(x)\mathrm{d}x=\int_{-\infty}^{\infty}g(x)f(x)\mathrm{d}x.}}\end{array}
$$

综合上两式,(1.4)式得证.

上述定理还可以推广到两个或两个以上随机变量的函数的情况。

例如,设  $Z$  是随机变量  $X, Y$  的函数  $Z = g(X, Y)$  ( $g$  是连续函数),那么, $Z$  是一个一维随机变量。若二维随机变量  $(X, Y)$  的概率密度为  $f(x, y)$ ,则有

$$
E(Z) = E\big[g(X,Y)\big] = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}g(x,y)f(x,y)\mathrm{d}x\mathrm{d}y, \tag{1.5}
$$

这里设上式右边的积分绝对收敛。又若  $(X, Y)$  为离散型随机变量,其分布律为  $P\{X = x_i, Y = y_j\} = p_{ij}, i, j = 1,2, \dots$ ,则有

$$
E(Z) = E\big[g(X,Y)\big] = \sum_{j = 1}^{\infty}\sum_{i = 1}^{\infty}g(x_{i},y_{j})\phi_{i j}, \tag{1.6}
$$

这里设上式右边的级数绝对收敛。

例8 设风速  $V$  在  $(0, a)$  上服从均匀分布,即具有概率密度

$$
f(v) = \left\{ \begin{array}{ll}\frac{1}{a}, & 0 < v < a, \\ 0, & \text{其他}. \end{array} \right.
$$

又设飞机机翼受到的正压力  $W$  是  $V$  的函数: $W = kV^2 (k > 0$ ,常数),求  $W$  的数学期望。

解 由(1.4)式有

$$
E(W) = \int_{-\infty}^{\infty} k v^2 f(v) \mathrm{d}v = \int_{0}^{a} k v^2 \frac{1}{a} \mathrm{d}v = \frac{1}{3} k a^2.
$$

例9 设随机变量  $(X, Y)$  的概率密度

$$
f(x,y) = \left\{{\frac{3}{2x^{3}y^{2}}},\quad {\frac{1}{x}}{<}y{<}x,x{>}1,\right.
$$

求数学期望  $E(Y), E\left(\frac{1}{X Y}\right)$ 。

解 由(1.5)式得

$$
\begin{array}{l}{{ E(Y)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}y f(x,y)\mathrm{d}y\mathrm{d}x=\int_{1}^{\infty}\int_{\frac{1}{x}}^{x}\frac{3}{2x^{3}y^{3}}\mathrm{d}y\mathrm{d}x}}\\ {{\quad=\frac{3}{2}\int_{1}^{\infty}\frac{1}{x^{3}}\biggl[\ln y\biggr]_{\frac{1}{x}}^{x}\mathrm{d}x=3\int_{1}^{\infty}\frac{\ln x}{x^{3}}\mathrm{d}x}}\\ {{\quad=\biggl[-\frac{3}{2}\frac{\ln x}{x^{2}}\biggr]_{1}^{\infty}+\frac{3}{2}\int_{1}^{\infty}\frac{1}{x^{3}}\mathrm{d}x=\frac{3}{4}.}}\end{array}
$$

$$
E\left(\frac{1}{X Y}\right) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \frac{1}{x y} f(x, y) \mathrm{d} y \mathrm{d} x = \int_{1}^{\infty} \mathrm{d} x \int_{\frac{1}{x}}^{x} \frac{3}{2 x^4 y^3} \mathrm{d} y = \frac{3}{5}.
$$

例10 某公司计划开发一种新产品市场,并试图确定该产品的产量。他们估计出售一件产品可获利  $m$  元,而积压一件产品将导致  $n$  元的损失。再者,他们预测销售量  $Y$  (件)服从指数分布,其概率密度为

$$
f_{Y}(y) = \left\{ \begin{array}{ll}\frac{1}{\theta} \mathrm{e}^{-y / \theta}, & y > 0, \\ 0, & y \leqslant 0. \end{array} \right.
$$

问若要获得利润的数学期望最大,应生产多少件产品  $(m, n, \theta$  均为已知)?

解 设生产  $x$  件,则获利  $Q$  是  $x$  的函数

$$
Q = Q(x) = \left\{ \begin{array}{ll}m Y - n(x - Y), & Y < x, \\ m x, & Y \geqslant x. \end{array} \right.
$$

$Q$  是随机变量,它是  $Y$  的函数,其数学期望为

$$
\begin{array}{l}{{ E(Q)=\int_{0}^{\infty}Q f_{Y}(y)\mathrm{d}y=\int_{0}^{x}[m y-n(x-y)]\frac{1}{\theta}\mathrm{e}^{-y/\theta}\mathrm{d}y+\int_{x}^{\infty}m x\frac{1}{\theta}\mathrm{e}^{-y/\theta}\mathrm{d}y}}\\ {{\quad=(m+n)\theta-(m+n)\theta\mathrm{e}^{-x/\theta}-n x.}}\end{array}
$$

令  $\frac{\mathrm{d}}{\mathrm{d}x} E(Q) = (m + n) \mathrm{e}^{- x / \theta} - n = 0,$

得  $x = - \theta \ln \frac{n}{m + n}.$

而  $\frac{\mathrm{d}^{2}}{\mathrm{d}x^{2}} E(Q) = \frac{-(m + n)}{\theta} \mathrm{e}^{- x / \theta} < 0,$

故知当  $x = - \theta \ln \frac{n}{m + n}$  时  $E(Q)$  取极大值,且可知这也是最大值.

例如,若

$$
f_{Y}(y) = \left\{ \begin{array}{ll}\frac{1}{10000} \mathrm{e}^{-\frac{y}{10000}}, & y > 0, \\ 0, & y \leqslant 0, \end{array} \right.
$$

且有  $m = 500$  元,  $n = 2000$  元,则

$$
x = -10000 \ln \frac{2000}{500 + 2000} = 2231.4.
$$

取  $x = 2231$  件.

例11 设甲与其他三人参与一个项目的竞拍,价格以千美元计,价格高者获胜.若甲中标,他就将此项目以10千美元转让给他人.可认为其他三人的竞拍价是相互独立的,且都在7千~11千美元之间均匀分布.问甲应如何报价才能使获益的数学期望最大(若甲中标,则必须将此项目以他自己的报价买下).

解 设  $X_{1}, X_{2}, X_{3}$  是其他三人的报价,按题意  $X_{1}, X_{2}, X_{3}$  相互独立,且在区间(7,11)上服从均匀分布.其分布函数为

$$
F(u) = \left\{ \begin{array}{ll}0, & u < 7, \\ \frac{u - 7}{4}, & 7 \leqslant u < 11, \\ 1, & u \geqslant 11. \end{array} \right.
$$

以  $Y$  记三人的最高出价, 即  $Y = \max \{X_{1}, X_{2}, X_{3}\} . Y$  的分布函数为

$$
F_{Y}(u) = \left\{ \begin{array}{ll}0, & u< 7, \\ \left(\frac{u - 7}{4}\right)^{3}, & 7 \leqslant u< 11, \\ 1, & u \geqslant 11. \end{array} \right.
$$

若甲的报价为  $x$  ,按题意  $7 \leqslant x \leqslant 10$  ,知甲能赢得这一项目的概率为

$$
p = P\{Y \leqslant x\} = F_{Y}(x) = \left(\frac{x - 7}{4}\right)^{3} \quad (7 \leqslant x \leqslant 10).
$$

以  $G(X)$  记甲的赚钱数,  $G(X)$  是一个随机变量,它的分布律为

$$
\frac{G(X)}{\left(\frac{x - 7}{4}\right)^{3}} \quad 1 - \left(\frac{x - 7}{4}\right)^{3}
$$

于是甲的赚钱数的数学期望为

$$
E[G(X)] = \left(\frac{x - 7}{4}\right)^{3} (10 - x).
$$

令  $\frac{\mathrm{d}}{\mathrm{d}x} E[G(X)] = \frac{1}{4^{3}}\left[(x - 7)^{2}(37 - 4x)\right] = 0,$

得  $x = 37 / 4, \quad x = 7$  (舍去).

又知  $\left.\frac{\mathrm{d}^{2}}{\mathrm{d}x^{2}} E[G(X)]\right|_{x = 37 / 4} < 0.$

故知当甲的报价为  $x = 37 / 4$  千美元时,他的赚钱数的数学期望达到极大值,还可知这也是最大值.

现在来证明数学期望的几个重要性质  $①$  (以下设所遇到的随机变量的数学期望存在).

$1^{\circ}$  设  $c$  是常数,则有  $E(C) = C$

$2^{\circ}$  设  $X$  是一个随机变量,  $c$  是常数,则有

$$
E(C X) = C E(X).
$$

$3^{\circ}$  设  $X, Y$  是两个随机变量,则有

$$
E(X + Y) = E(X) + E(Y).
$$

这一性质可以推广到任意有限个随机变量之和的情况,

$4^{\circ}$  设  $X, Y$  是相互独立的随机变量,则有

$$
E(X Y) = E(X)E(Y).
$$

这一性质可以推广到任意有限个相互独立的随机变量之积的情况.

证  $1^{\circ},2^{\circ}$  由读者自己证明.我们来证  $3^{\circ}$  和  $4^{\circ}$

设二维随机变量  $(X,Y)$  的概率密度为  $f(x,y)$  .其边缘概率密度为  $f_{X}(x)$ $f_{Y}(y)$  .由(1.5)式

$$
\begin{array}{l}{{ E(X+Y)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(x+y)f(x,y)\mathrm{d}x\mathrm{d}y}}\\ {{\qquad=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}x f(x,y)\mathrm{d}x\mathrm{d}y+\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}y f(x,y)\mathrm{d}x\mathrm{d}y}}\\ {{\qquad=E(X)+E(Y).}}\end{array}
$$

$3^{\circ}$  得证.

又若  $X$  和  $\mathbf{Y}$  相互独立,

$$
\begin{array}{l}{{ E(X Y)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}x y f(x,y)\mathrm{d}x\mathrm{d}y=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}x y f_{X}(x)f_{Y}(y)\mathrm{d}x\mathrm{d}y}}\\ {{\qquad=\left[\int_{-\infty}^{\infty}x f_{X}(x)\mathrm{d}x\right]\left[\int_{-\infty}^{\infty}y f_{Y}(y)\mathrm{d}y\right]=E(X)E(Y).}}\end{array}
$$

$4^{\circ}$  得证.

例12一民航送客车载有20位旅客自机场开出,旅客有10个车站可以下车.如到达一个车站没有旅客下车就不停车.以  $X$  表示停车的次数,求 $E(X)$  (设每位旅客在各个车站下车是等可能的,并设各位旅客是否下车相互独立).

解引入随机变量

易知  $X = X_{1} + X_{2} + \dots +X_{10}.$

现在来求  $E(X)$

按题意,任一旅客在第  $i$  站不下车的概率为  $\frac{9}{10}$  ,因此20位旅客都不在第  $i$  站下车的概率为  $\left(\frac{9}{10}\right)^{20}$  ,在第  $i$  站有人下车的概率为  $1 - \left(\frac{9}{10}\right)^{20}$  ,也就是

$$
P\{X_{i} = 0\} = \left(\frac{9}{10}\right)^{20},\quad P\{X_{i} = 1\} = 1 - \left(\frac{9}{10}\right)^{20},\quad i = 1,2,\dots ,10.
$$

由此

$$
E(X_{i}) = 1 - \left(\frac{9}{10}\right)^{20},\quad i = 1,2,\dots ,10.
$$

进而  $E(X) = E(X_{1} + X_{2} + \dots +X_{10}) = E(X_{1}) + E(X_{2}) + \dots +E(X_{10})$

$$
= 10\left[1 - \left(\frac{9}{10}\right)^{20}\right] = 8.784(\text{次}).
$$

本题是将  $X$  分解成数个随机变量之和,然后利用随机变量和的数学期望等于随机变量数学期望之和来求数学期望的,这种处理方法具有一定的普遍意义.

例13设一电路中电流  $I$  (以A计)与电阻  $R$  (以  $\Omega$  计)是两个相互独立的随机变量,其概率密度分别为

$$
g(i)={\left\{\begin{array}{l l}{2i,}&{0\leqslant i\leqslant1,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}\end{array}\right.}
$$

试求电压  $V = I R$  的均值.

$$
\begin{array}{l}{{ E(V)=E(I R)=E(I)E(R)=\left[\int_{-\infty}^{\infty}i g\left(i\right)\mathrm{d}i\right]\left[\int_{-\infty}^{\infty}r h\left(r\right)\mathrm{d}r\right]}}\\ {{=\left(\int_{0}^{1}2i^{2}\mathrm{d}i\right)\left(\int_{0}^{3}\frac{r^{3}}{9}\mathrm{d}r\right)=\frac{3}{2}(\mathrm{V}).}}\end{array}
$$

# $\S 2$  方差

先从例子说起.例如,有一批灯泡,知其平均寿命是  $E(X) = 1000 \mathrm{h}$ .仅由这一指标我们还不能判定这批灯泡的质量好坏.事实上,有可能其中绝大部分灯泡的寿命都在  $950 \sim 1050 \mathrm{h}$ ;也有可能其中约有一半是高质量的,它们的寿命大约有  $1300 \mathrm{h}$ ,另一半却是质量很差的,其寿命大约只有  $700 \mathrm{h}$ .为评定这批灯泡质量的好坏,还需进一步考察灯泡寿命  $X$  与其均值  $E(X) = 1000 \mathrm{h}$  的偏离程度.若偏离程度较小,则表示质量比较稳定.从这个意义上来说,我们认为质量较好.前面也曾提到在检验棉花的质量时,既要注意纤维的平均长度,还要注意纤维长度与平均长度的偏离程度.由此可见,研究随机变量与其均值的偏离程度是十分必要的.那么,用怎样的量去度量这个偏离程度呢?容易看到

$$
E\big[\big|X - E(X)\big|\big]
$$

能度量随机变量与其均值  $E(X)$  的偏离程度.但由于上式带有绝对值,运算不方便,为运算方便起见,通常用量

$$
E\{[X - E(X)]^{2}\}
$$

来度量随机变量  $X$  与其均值  $E(X)$  的偏离程度.

定义设  $X$  是随机变量,若  $E\{[X - E(X)]^{2}\}$  存在,则称它为  $X$  的方差,记为  $D(X)$  或  $\operatorname {Var}(X)$ ,即

$$
D(X) = \operatorname {Var}(X) = E\{[X - E(X)]^{2}\} . \tag{2.1}
$$

在应用上还引入量  $\sqrt{D(X)}$ , 记为  $\sigma (X)$ , 称为标准差或均方差.

按定义, 随机变量  $X$  的方差表达了  $X$  的取值与其数学期望的偏离程度. 若  $D(X)$  较小, 则意味着  $X$  的取值在  $E(X)$  的附近比较集中, 反之, 若  $D(X)$  较大, 则表示  $X$  的取值较分散. 因此,  $D(X)$  是刻画  $X$  取值分散程度的一个量, 它是衡量  $X$  取值分散程度的一个尺度.

由定义知, 方差实际上就是随机变量  $X$  的函数  $g(X) = [X - E(X)]^{2}$  的数学期望. 于是对于离散型随机变量, 按(1.3)式有

$$
D(X) = \sum_{k = 1}^{\infty}[x_{k} - E(X)]^{2}p_{k}, \tag{2.2}
$$

其中  $P\{X = x_{k}\} = p_{k}, k = 1,2, \dots$  是  $X$  的分布律.

对于连续型随机变量, 按(1.4)式有

$$
D(X) = \int_{-\infty}^{\infty}[x - E(X)]^{2}f(x)\mathrm{d}x, \tag{2.3}
$$

其中  $f(x)$  是  $X$  的概率密度.

随机变量  $X$  的方差可按下列公式计算:

$$
D(X) = E(X^{2}) - [E(X)]^{2}. \tag{2.4}
$$

证 由数学期望的性质  $1^{\prime}, 2^{\prime}, 3^{\prime}$  得

$$
\begin{array}{r l} & {D(X) = E\{[X - E(X)]^{2}\} = E\{X^{2} - 2X E(X) + [E(X)]^{2}\}}\\ & {\qquad = E(X^{2}) - 2E(X)E(X) + [E(X)]^{2}}\\ & {\qquad = E(X^{2}) - [E(X)]^{2}.} \end{array}
$$

例1 设随机变量  $X$  具有数学期望  $E(X) = \mu$ , 方差  $D(X) = \sigma^{2} \neq 0$ . 记

$$
X^{*} = \frac{X - \mu}{\sigma},
$$

则

$$
\begin{array}{c}{{E(X^{*})=\frac{1}{\sigma}E(X-\mu)=\frac{1}{\sigma}[E(X)-\mu]=0,}}\\ {{}}\\ {{D(X^{*})=E(X^{*2})-[E(X^{*})]^{2}=E\left[\left(\frac{X-\mu}{\sigma}\right)^{2}\right]}}\\ {{}}\\ {{=\frac{1}{\sigma^{2}}E[(X-\mu)^{2}]=\frac{\sigma^{2}}{\sigma^{2}}=1.}}\end{array}
$$

即  $X^{*} = \frac{X - \mu}{\sigma}$  的数学期望为 0, 方差为  $1. X^{*}$  称为  $X$  的标准化变量.

例2 设随机变量  $X$  具有  $(0 - 1)$  分布, 其分布律为

$$
P\{X = 0\} = 1 - p, \quad P\{X = 1\} = p.
$$

求  $D(X)$

$$
\begin{array}{c}{{E(X)=0\times(1-p)+1\times p=p,}}\\ {{E(X^{2})=0^{2}\times(1-p)+1^{2}\times p=p.}}\end{array}
$$

由(2.4)式

$$
D(X) = E(X^{2}) - [E(X)]^{2} = p - p^{2} = p(1 - p).
$$

例3 设随机变量  $X \sim \pi (\lambda)$ ,求  $D(X)$

解 随机变量  $X$  的分布律为

$$
P\{X = k\} = \frac{\lambda^{k} \mathrm{e}^{-\lambda}}{k!}, \quad k = 0, 1, 2, \dots , \quad \lambda > 0.
$$

上节例6已算得  $E(X) = \lambda$ ,而

$$
\begin{array}{l}{{ E(X^{2})=E\big[X(X-1)+X\big]=E\big[X(X-1)\big]+E(X)}}\\ {{=\sum_{k=0}^{\infty}k(k-1)\frac{\lambda^{k}\mathrm{e}^{-\lambda}}{k!}+\lambda=\lambda^{2}\mathrm{e}^{-\lambda}\sum_{k=2}^{\infty}\frac{\lambda^{k-2}}{(k-2)!}+\lambda}}\\ {{=\lambda^{2}\mathrm{e}^{-\lambda}\mathrm{e}^{\lambda}+\lambda=\lambda^{2}+\lambda,}}\end{array}
$$

所以方差

$$
D(X) = E(X^{2}) - [E(X)]^{2} = \lambda .
$$

由此可知,泊松分布的数学期望与方差相等,都等于参数  $\lambda$ 。因为泊松分布只含一个参数  $\lambda$ ,只要知道它的数学期望或方差就能完全确定它的分布了。

例4 设随机变量  $X \sim U(a, b)$ ,求  $D(X)$

解  $X$  的概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{b - a}, & a < x < b, \\ 0, & \text{其他}. \end{array} \right.
$$

上节例7已算得  $E(X) = \frac{a + b}{2}$ 。方差为

$$
\begin{array}{l}{{ D(X)=E(X^{2})-[E(X)]^{2}}}\\ {{\quad=\int_{a}^{b}x^{2}\frac{1}{b-a}\mathrm{d}x-\left(\frac{a+b}{2}\right)^{2}=\frac{(b-a)^{2}}{12}.}}\end{array}
$$

例5 设随机变量  $X$  服从指数分布,其概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{\theta} \mathrm{e}^{-x / \theta}, & x > 0, \\ 0, & x \leqslant 0, \end{array} \right.
$$

其中  $\theta > 0$ ,求  $E(X), D(X)$

$$
\begin{array}{l}{{ E(X)=\int_{-\infty}^{\infty}x f(x)\mathrm{d}x=\int_{0}^{\infty}x\frac{1}{\theta}\mathrm{e}^{-x/\theta}\mathrm{d}x}}\\ {{\quad=-x\mathrm{e}^{-x/\theta}\bigg|_{0}^{\infty}+\int_{0}^{\infty}\mathrm{e}^{-x/\theta}\mathrm{d}x=\theta,}}\end{array}
$$

$$
\begin{array}{l}{{ E(X^{2})=\int_{-\infty}^{\infty}x^{2}f(x)\mathrm{d}x=\int_{0}^{\infty}x^{2}\frac{1}{\theta}\mathrm{e}^{-x/\theta}\mathrm{d}x}}\\ {{=-x^{2}\mathrm{e}^{-x/\theta}\bigg|_{0}^{\infty}+\int_{0}^{\infty}2x\mathrm{e}^{-x/\theta}\mathrm{d}x=2\theta^{2},}}\end{array}
$$

于是  $D(X) = E(X^{2}) - [E(X)]^{2} = 2\theta^{2} - \theta^{2} = \theta^{2}.$

即有  $E(X) = \theta , \quad D(X) = \theta^{2}.$

现在来证明方差的几个重要性质(以下设所遇到的随机变量其方差存在).

$1^{\circ}$  设  $c$  是常数,则  $D(C) = 0$

$2^{\circ}$  设  $X$  是随机变量,  $c$  是常数,则有

$$
D(C X) = C^{2}D(X), \quad D(X + C) = D(X).
$$

$3^{\circ}$  设  $X, Y$  是两个随机变量,则有

$$
D(X + Y) = D(X) + D(Y) + 2E\{[X - E(X)][Y - E(Y)]\} . \tag{2.5}
$$

特别,若  $X, Y$  相互独立,则有

$$
D(X + Y) = D(X) + D(Y). \tag{2.6}
$$

这一性质可以推广到任意有限多个相互独立的随机变量之和的情况,

$4^{\circ} D(X) = 0$  的充要条件是  $X$  以概率1取常数  $E(X)$ ,即

$$
P\{X = E(X)\} = 1.
$$

证  $1^{\circ} D(C) = E\{[C - E(C)]^{2}\} = 0$

$2^{\circ} D(C X) = E\{[C X - E(C X)]^{2}\} = C^{2}E\{[X - E(X)]^{2}\} = C^{2}D(X).$

$$
D(X + C) = E\{[X + C - E(X + C)]^{2}\} = E\{[X - E(X)]^{2}\} = D(X).
$$

$3^{\circ} D(X + Y) = E\{[(X + Y) - E(X + Y)]^{2}\}$

$$
= E\{[(X - E(X)) + (Y - E(Y))]^{2}\}
$$

$$
= E\{[X - E(X)]^{2}\} +E\{[Y - E(Y)]^{2}\}
$$

$$
+2E\{[X - E(X)][Y - E(Y)]\}
$$

$$
= D(X) + D(Y) + 2E\{[X - E(X)][Y - E(Y)]\} .
$$

上式右端第三项:

$$
\begin{array}{r l} & {2E\left\{\left[X - E(X)\right]\left[Y - E(Y)\right]\right\}}\\ & {\quad = 2E\left[X Y - X E(Y) - Y E(X) + E(X)E(Y)\right]}\\ & {\quad = 2\left[E(X Y) - E(X)E(Y) - E(Y)E(X) + E(X)E(Y)\right]}\\ & {\quad = 2\left[E(X Y) - E(X)E(Y)\right].} \end{array}
$$

若  $X, Y$  相互独立,由数学期望的性质  $4^{\circ}$  知道上式右端为0,于是

$$
D(X + Y) = D(X) + D(Y).
$$

$4^{\circ}$  充分性.设  $P\{X = E(X)\} = 1$ ,则有  $P\{X^{2} = [E(X)]^{2}\} = 1$ ,于是

$$
D(X) = E(X^{2}) - [E(X)]^{2} = 0.
$$

必要性的证明写在切比雪夫不等式证明的后面.

例6 设随机变量  $X \sim b(n, p)$ , 求  $E(X), D(X)$ .

解 由二项分布的定义知, 随机变量  $X$  是  $n$  重伯努利试验中事件  $A$  发生的次数, 且在每次试验中  $A$  发生的概率为  $p$ . 引入随机变量

易知

$$
X = X_{1} + X_{2} + \dots + X_{n}. \tag{2.7}
$$

由于  $X_{k}$  只依赖于第  $k$  次试验, 而各次试验相互独立, 于是  $X_{1}, X_{2}, \dots , X_{n}$  相互独立, 又知  $X_{k}, k = 1, 2, \dots , n$  服从同一  $(0 - 1)$  分布

$$
\frac{X_{k}}{\frac{p_{k}}{p_{k}}}\left| \begin{array}{ll}0 & 1 \\ 1 - p & p \end{array} \right|
$$

(2.7) 式表明以  $n, p$  为参数的二项分布变量, 可分解成为  $n$  个相互独立且都服从以  $p$  为参数的  $(0 - 1)$  分布的随机变量之和.

由例2知  $E(X_{k}) = p, D(X_{k}) = p(1 - p), k = 1, 2, \dots , n$ . 故知

$$
E(X) = E\Big(\sum_{k = 1}^{n} X_{k}\Big) = \sum_{k = 1}^{n} E(X_{k}) = n p.
$$

又由于  $X_{1}, X_{2}, \dots , X_{n}$  相互独立, 得

$$
D(X) = D\Big(\sum_{k = 1}^{n} X_{k}\Big) = \sum_{k = 1}^{n} D(X_{k}) = n p(1 - p).
$$

即

$$
E(X) = n p, \quad D(X) = n p(1 - p).
$$

例7 设随机变量  $X \sim N(\mu , \sigma^{2})$ , 求  $E(X), D(X)$ .

解 先求标准正态变量

$$
Z = \frac{X - \mu}{\sigma}
$$

的数学期望和方差.  $Z$  的概率密度为

$$
\phi (t) = \frac{1}{\sqrt{2\pi}} \mathrm{e}^{-t^{2} / 2},
$$

于是

$$
E(Z) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} t \mathrm{e}^{-t^{2} / 2} \mathrm{d}t = \frac{-1}{\sqrt{2\pi}} \mathrm{e}^{-t^{2} / 2} \bigg|_{-\infty}^{\infty} = 0,
$$

$$
\begin{array}{l}{{D(Z)=E(Z^{2})=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}t^{2}\mathrm{e}^{-t^{2}/2}\mathrm{d}t}}\\ {{=\frac{-1}{\sqrt{2\pi}}t\mathrm{e}^{-t^{2}/2}\bigg|_{-\infty}^{\infty}+\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}\mathrm{e}^{-t^{2}/2}\mathrm{d}t=1.}}\end{array}
$$

因  $X = \mu + \sigma Z$ , 即得

$$
E(X) = E(\mu + \sigma Z) = \mu ,
$$

$$
D(X) = D(\mu + \sigma Z) = D(\sigma Z) = \sigma^{2} D(Z) = \sigma^{2}.
$$

这就是说, 正态分布的概率密度中的两个参数  $\mu$  和  $\sigma$  分别就是该分布的数学期望和均方差, 因而正态分布完全可由它的数学期望和方差所确定.

再者, 由上一章 §5 中例 1 知道, 若  $X_{i} \sim N(\mu_{i}, \sigma_{i}^{2}), i = 1,2, \dots , n$ , 且它们相互独立, 则它们的线性组合:  $C_{1} X_{1} + C_{2} X_{2} + \dots + C_{n} X_{n}$ $(C_{1}, C_{2}, \dots , C_{n}$  是不全为 0 的常数) 仍然服从正态分布, 于是由数学期望和方差的性质知道

$$
C_{1} X_{1} + C_{2} X_{2} + \dots + C_{n} X_{n} \sim N\left(\sum_{i = 1}^{n} C_{i} \mu_{i}, \sum_{i = 1}^{n} C_{i}^{2} \sigma_{i}^{2}\right) \tag{2.8}
$$

这一重要结果.

例如, 若  $X \sim N(1,3), Y \sim N(2,4)$  且  $X, Y$  相互独立, 则  $Z = 2 X - 3 Y$  也服从正态分布, 而  $E(Z) = 2 \times 1 - 3 \times 2 = - 4, D(Z) = D(2 X - 3 Y) = 4 D(X) + 9 D(Y) = 48$ . 故有  $Z \sim N(- 4,48)$ .

例8设活塞的直径(以cm计)  $X\sim N(22.40,0.03^{2})$  ,气缸的直径  $Y\sim$ $N(22.50,0.04^{2}),X,Y$  相互独立.任取一只活塞,任取一只气缸,求活塞能装人气缸的概率.

解 按题意需求  $P\{X < Y\} = P\{X - Y < 0\}$ . 由于

$$
X - Y \sim N(-0.10, 0.0025),
$$

故有

$$
\begin{array}{r l} & {P\{X{<}Y\} = P\{X - Y{<}0\}}\\ & {\qquad = P\Big\{\frac{(X - Y) - (-0.10)}{\sqrt{0.0025}}{<}\frac{0 - (-0.10)}{\sqrt{0.0025}}\Big\}}\\ & {\qquad = \Phi \Big(\frac{0.10}{0.05}\Big) = \Phi (2) = 0.9772.} \end{array}
$$

下面介绍一个重要的不等式.

定理 设随机变量  $X$  具有数学期望  $E(X) = \mu$ , 方差  $D(X) = \sigma^{2}$ , 则对于任意正数  $\epsilon$ , 不等式

$$
P\{|X - \mu | \geqslant \epsilon \} \leqslant \frac{\sigma^{2}}{\epsilon^{2}} \tag{2.9}
$$

成立.

这一不等式称为切比雪夫 (Chebyshev) 不等式.

证 我们只就连续型随机变量的情况来证明. 设  $X$  的概率密度为  $f(x)$ , 则有 (如图 4- 2)

$$
\begin{array}{l}{P\{\mid X - \mu \mid \geqslant \epsilon \} = \int_{|x - \mu |\geqslant \epsilon}f(x)\mathrm{d}x}\\ {\leqslant \int_{|x - \mu |\geqslant \epsilon}\frac{\mid x - \mu\mid^{2}}{\epsilon^{2}} f(x)\mathrm{d}x}\\ {\leqslant \frac{1}{\epsilon^{2}}\int_{-\infty}^{\infty}(x - \mu)^{2}f(x)\mathrm{d}x = \frac{\sigma^{2}}{\epsilon^{2}}.} \end{array}
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_3.pdf-8b019cbe-e56b-4db0-aa4a-872484615581_86f06b0126c340fd8071513db28c218f845cdec67f56e84a36112bbacbf868cd.jpg)  
图4-2

切比雪夫不等式也可以写成如下的形式:

$$
P\{|X - \mu |< \epsilon \} \geqslant 1 - \frac{\sigma^{2}}{\epsilon^{2}}. \tag{2.10}
$$

切比雪夫不等式给出了在随机变量的分布未知,而只知道  $E(X)$  和  $D(X)$  的情况下估计概率  $P\{|X - E(X)|< \epsilon \}$  的界限。例如在(2.10)式中分别取  $\epsilon = 3\sqrt{D(X)}$ ,  $4\sqrt{D(X)}$  得到

$$
P\{|X - E(X)|< 3\sqrt{D(X)}\} \geqslant 0.8889,
$$

$$
P\{|X - E(X)|< 4\sqrt{D(X)} \geqslant 0.9375.
$$

这个估计是比较粗糙的  $①$ ,如果已经知道随机变量的分布,那么所需求的概率可以确切地计算出来,也就没有必要利用这一不等式来作估计了。

方差性质  $4^{\circ}$  必要性的证明:

设  $D(X) = 0$ ,要证  $P\{X = E(X)\} = 1$

证用反证法。假设  $P\{X = E(X)\} < 1$ ,则对于某一个数  $\epsilon >0$ ,有  $P\{|X - E(X)| \geqslant \epsilon \} >0$ 。但由切比雪夫不等式,对于任意  $\epsilon >0$ ,由(2.9)式因  $\sigma^{2} = 0$ ,有

$$
P\{|X - E(X)| \geqslant \epsilon \} = 0,
$$

矛盾,于是  $P\{X = E(X)\} = 1$ 。

在书末附表1中列出了多种常用的随机变量的数学期望和方差,供读者查用。

# $\S 3$  协方差及相关系数

对于二维随机变量  $(X,Y)$ , 我们除了讨论  $X$  与  $Y$  的数学期望和方差以外, 还需讨论描述  $X$  与  $Y$  之间相互关系的数字特征. 本节讨论有关这方面的数字特征.

在本章  $\S 2$  方差性质  $3^{\circ}$  的证明中, 我们已经看到, 如果两个随机变量  $X$  和  $Y$  是相互独立的, 则

$$
E\{[X - E(X)][Y - E(Y)]\} = 0.
$$

这意味着当  $E\{[X - E(X)][Y - E(Y)]\} \neq 0$  时,  $X$  与  $Y$  不相互独立, 而是存在着一定的关系的.

定义量  $E\{[X - E(X)][Y - E(Y)]\}$  称为随机变量  $X$  与  $Y$  的协方差. 记为  $\operatorname {Cov}(X,Y)$ , 即

$$
\operatorname {Cov}(X,Y) = E\{[X - E(X)][Y - E(Y)]\} .
$$

而  $\rho_{XY} = \frac{\operatorname{Cov}(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}$

称为随机变量  $X$  与  $Y$  的相关系数.

由定义, 即知

$$
\operatorname {Cov}(X,Y) = \operatorname {Cov}(Y,X), \quad \operatorname {Cov}(X,X) = D(X).
$$

由上述定义及(2.5)式知道, 对于任意两个随机变量  $X$  和  $Y$ , 下列等式成立:

$$
D(X + Y) = D(X) + D(Y) + 2\operatorname {Cov}(X,Y). \tag{3.1}
$$

将  $\operatorname {Cov}(X,Y)$  的定义式展开, 易得

$$
\operatorname {Cov}(X,Y) = E(XY) - E(X)E(Y). \tag{3.2}
$$

我们常常利用这一式子计算协方差,

协方差具有下述性质:

$1^{\circ} \operatorname {Cov}(aX,bY) = ab\operatorname {Cov}(X,Y), a,b$  是常数.

$2^{\circ} \operatorname {Cov}(X_{1} + X_{2},Y) = \operatorname {Cov}(X_{1},Y) + \operatorname {Cov}(X_{2},Y).$

(证明由读者自己来完成.)

下面我们来推导  $\rho_{XY}$  的两条重要性质, 并说明  $\rho_{XY}$  的含义.

考虑以  $X$  的线性函数  $a + bX$  来近似表示  $Y$ . 我们以均方误差

$$
\begin{array}{l}e = E\{[Y - (a + bX)]^{2}\} \\ = E(Y^{2}) + b^{2}E(X^{2}) + a^{2} - 2bE(XY) + 2abE(X) - 2aE(Y) \end{array} \tag{3.3}
$$

来衡量以  $a + bX$  近似表达  $Y$  的好坏程度.  $e$  的值越小表示  $a + bX$  与  $Y$  的近似程

度越好.这样,我们就取  $a,b$  使  $e$  取到最小.下面就来求最佳近似式  $a + b X$  中的 $a,b.$  为此,将  $e$  分别关于  $a,b$  求偏导数,并令它们等于零.得

$$
\left\{ \begin{array}{l l}{\frac{\partial e}{\partial a} = 2a + 2b E(X) - 2E(Y) = 0,}\\ {\frac{\partial e}{\partial b} = 2b E(X^{2}) - 2E(X Y) + 2a E(X) = 0,} \end{array} \right.
$$

解得  $b_{0} = \frac{\operatorname{Cov}(X,Y)}{D(X)}$ ,

$$
a_{0} = E(Y) - b_{0}E(X) = E(Y) - E(X)\frac{\operatorname{Cov}(X,Y)}{D(X)}.
$$

将  $a_{0},b_{0}$  代入(3.3)式得

$$
\min_{a,b}E\{[Y - (a + b X)]^{2}\} = E\{[Y - (a_{0} + b_{0}X)]^{2}\} = (1 - \rho_{X Y}^{2})D(Y)①. \tag{3.4}
$$

由(3.4)式容易得到下述定理:

定理  $1^{\circ} |\rho_{X Y}|\leqslant 1.$

$2^{\circ} |\rho_{X Y}| = 1$  的充要条件是,存在常数  $a,b$  使

$$
P\{Y = a + b X\} = 1.
$$

证  $1^{\circ}$  由(3.4)式与  $E\{[Y - (a_{0} + b_{0}X)]^{2}\}$  及  $D(Y)$  的非负性,知  $1 - \rho_{X Y}^{2}\geqslant 0$  亦即  $|\rho_{X Y}|\leqslant 1$

$2^{\circ}$  若  $|\rho_{X Y}| = 1$  ,由(3.4)式得

$$
E\{[Y - (a_{0} + b_{0}X)]^{2}\} = 0.
$$

从而  $0 = E\{[Y - (a_{0} + b_{0}X)]^{2}\} = D[Y - (a_{0} + b_{0}X)] + \{E[Y - (a_{0} + b_{0}X)]\}^{2},$

故有  $D[Y - (a_{0} + b_{0}X)] = 0,$

$$
E[Y - (a_{0} + b_{0}X)] = 0.
$$

又由方差的性质  $4^{\circ}$  知

反之,若存在常数  $a^{*},b^{*}$  使

于是

即得

$P\{Y - (a^{*} + b^{*}X)\} = 1$  ,即  $P\{Y - (a^{*} + b^{*}X) = 0\} = 1$

$$
P\{[Y - (a^{*} + b^{*}X)]^{2} = 0\} = 1.
$$

$$
E\{[Y - (a^{*} + b^{*}X)]^{2}\} = 0.
$$

故有

$$
0 = E\{[Y - (a^{*} + b^{*}X)]^{2}\} \geqslant \min_{a,b}E\{[Y - (a + bX)]^{2}\}
$$

$$
= E\{[Y - (a_{0} + b_{0}X)]^{2}\} = (1 - \rho_{XY}^{2})D(Y).
$$

即得  $\mid \rho_{X Y}\mid = 1.$

由(3.4)式知,均方误差  $e$  是  $\mid \rho_{X Y}\mid$  的严格单调减少函数,这样  $\rho_{X Y}$  的含义就很明显了.当  $\mid \rho_{X Y}\mid$  较大时  $e$  较小,表明  $X,Y$  (就线性关系来说)联系较紧密.特别当 $\mid \rho_{X Y}\mid = 1$  时,由定理中的  $2^{\circ},X,Y$  之间以概率1存在着线性关系.于是  $\rho_{X Y}$  是一个可以用来表征  $X,Y$  之间线性关系紧密程度的量.当  $\mid \rho_{X Y}\mid$  较大时,我们通常说 $X,Y$  线性相关的程度较好;当  $\mid \rho_{X Y}\mid$  较小时,我们说,  $X,Y$  线性相关的程度较差.

当  $\rho_{X Y} = 0$  时,称  $X$  和  $Y$  不相关.

假设随机变量  $X,Y$  的相关系数  $\rho_{X Y}$  存在.当  $X$  和  $Y$  相互独立时,由数学期望的性质  $4^{\circ}$  及(3.2)式知  $\operatorname {Cov}(X,Y) = 0$  ,从而  $\rho_{X Y} = 0$  ,即  $X,Y$  不相关.反之,若 $X,Y$  不相关,  $X$  和  $Y$  却不一定相互独立(见例1).上述情况,从"不相关"和"相互独立"的含义来看是明显的.这是因为不相关只是就线性关系来说的,而相互独立是就一般关系而言的.

不过,从例2可以看到,当  $(X,Y)$  服从二维正态分布时,  $X$  和  $Y$  不相关与  $X$  和  $Y$  相互独立是等价的.

例1设  $(X,Y)$  的分布律为

<table><tr><td>X
Y</td><td>-2</td><td>-1</td><td>1</td><td>2</td><td>P{Y=j}</td></tr><tr><td>1</td><td>0</td><td>1/4</td><td>1/4</td><td>0</td><td>1/2</td></tr><tr><td>4</td><td>1/4</td><td>0</td><td>0</td><td>1/4</td><td>1/2</td></tr><tr><td>P{X=i}</td><td>1/4</td><td>1/4</td><td>1/4</td><td>1/4</td><td>1</td></tr></table>

易知  $E(X) = 0,E(Y) = 5 / 2,E(X Y) = 0$  ,于是  $\rho_{X Y} = 0,X,Y$  不相关.这表示  $X,Y$  不存在线性关系.但,  $P\{X = - 2,Y = 1\} = 0\neq P\{X = - 2\} P\{Y = 1\}$  ,知  $X,Y$  不是相互独立的.事实上,  $X$  和  $Y$  具有关系:  $Y = X^{2},Y$  的值完全可由  $X$  的值所确定. 口

例2设  $(X,Y)$  服从二维正态分布,它的概率密度为

$$
f(x,y) = \frac{1}{2\pi\sigma_{1}\sigma_{2}\sqrt{1 - \rho^{2}}}\exp \left\{\frac{-1}{2(1 - \rho^{2})}\left[\frac{(x - \mu_{1})^{2}}{\sigma_{1}^{2}}\right.\right.
$$

$$
-2\rho \frac{(x - \mu_{1})(y - \mu_{2})}{\sigma_{1}\sigma_{2}} +\frac{(y - \mu_{2})^{2}}{\sigma_{2}^{2}}\Biggr \} ,
$$

我们来求  $X$  和  $Y$  的相关系数.

在第三章  $\S 2$  例3中已经知道  $(X,Y)$  的边缘概率密度为

$$
f_{X}(x) = \frac{1}{\sqrt{2\pi}\sigma_{1}}\mathrm{e}^{-\frac{(x - \mu_{1})^{2}}{2\sigma_{1}^{2}}},\quad -\infty < x< \infty ,
$$

$$
f_{Y}(y) = \frac{1}{\sqrt{2\pi}\sigma_{2}}\mathrm{e}^{-\frac{(y - \mu_{2})^{2}}{2\sigma_{2}^{2}}},\quad -\infty < y< \infty .
$$

故知  $E(X) = \mu_{1},E(Y) = \mu_{2},D(X) = \sigma_{1}^{2},D(Y) = \sigma_{2}^{2}$  .而

$$
\begin{array}{l}{\operatorname {Cov}(X,Y) = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(x - \mu_{1})(y - \mu_{2})f(x,y)\mathrm{d}x\mathrm{d}y}\\ {= \frac{1}{2\pi\sigma_{1}\sigma_{2}\sqrt{1 - \rho^{2}}}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(x - \mu_{1})(y - \mu_{2})}\\ {\qquad \times \exp \Biggl \{\frac{-1}{2(1 - \rho^{2})}\Bigl (\frac{y - \mu_{2}}{\sigma_{2}} -\rho \frac{x - \mu_{1}}{\sigma_{1}}\Bigr)^{2} - \frac{(x - \mu_{1})^{2}}{2\sigma_{1}^{2}}\Biggr \} \mathrm{d}y\mathrm{d}x.} \end{array}
$$

令  $t = \frac{1}{\sqrt{1 - \rho^{2}}}\Bigl (\frac{y - \mu_{2}}{\sigma_{2}} - \rho \frac{x - \mu_{1}}{\sigma_{1}}\Bigr),u = \frac{x - \mu_{1}}{\sigma_{1}}$  ,则有

$$
\begin{array}{r l} & {\mathrm{Cov}(X,Y) = \frac{1}{2\pi}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(\sigma_{1}\sigma_{2}\sqrt{1 - \rho^{2}} t u + \rho \sigma_{1}\sigma_{2}u^{2})\mathrm{e}^{-(u^{2} + t^{2}) / 2}\mathrm{d}t\mathrm{d}u}\\ & {\qquad = \frac{\rho\sigma_{1}\sigma_{2}}{2\pi}\Big(\int_{-\infty}^{\infty}u^{2}\mathrm{e}^{-\frac{u^{2}}{2}}\mathrm{d}u\Big)\Big(\int_{-\infty}^{\infty}\mathrm{e}^{-\frac{t^{2}}{2}}\mathrm{d}t\Big)}\\ & {\qquad +\frac{\sigma_{1}\sigma_{2}\sqrt{1 - \rho^{2}}}{2\pi}\Big(\int_{-\infty}^{\infty}u\mathrm{e}^{-\frac{u^{2}}{2}}\mathrm{d}u\Big)\Big(\int_{-\infty}^{\infty}t\mathrm{e}^{-\frac{t^{2}}{2}}\mathrm{d}t\Big)}\\ & {\qquad = \frac{\rho\sigma_{1}\sigma_{2}}{2\pi}\sqrt{2\pi}\cdot \sqrt{2\pi},} \end{array}
$$

即有  $\operatorname {Cov}(X,Y) = \rho \sigma_{1}\sigma_{2}.$

于是  $\rho_{X Y} = \frac{\operatorname{Cov}(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}} = \rho .$

这就是说,二维正态随机变量  $(X,Y)$  的概率密度中的参数  $\rho$  就是  $X$  和  $Y$  的相关系数,因而二维正态随机变量的分布完全可由  $X,Y$  各自的数学期望、方差以及它们的相关系数所确定.

在第三章  $\S 4$  中已经讲过,若  $(X,Y)$  服从二维正态分布,那么  $X$  和  $Y$  相互独立的充要条件为  $\rho = 0$  .现在知道  $\rho = \rho_{X Y}$  ,故知对于二维正态随机变量  $(X,Y)$  来说,  $X$  和  $Y$  不相关与  $X$  和  $Y$  相互独立是等价的.

# $\S 4$  矩、协方差矩阵

本节先介绍随机变量的另外几个数字特征.设  $(X,Y)$  是二维随机变量.

定义 设  $X$  和  $Y$  是随机变量,若

$$
E(X^{k}),\quad k = 1,2,\dots
$$

存在,称它为  $X$  的  $k$  阶原点矩,简称  $k$  阶矩.

若  $E\{[X - E(X)]^{k}\} ,\quad k = 2,3,\dots$

存在,称它为  $X$  的  $k$  阶中心矩.

若  $E(X^{k}Y^{l}),\quad k,l = 1,2,\dots$

存在,称它为  $X$  和  $Y$  的  $k + l$  阶混合矩.

若  $E\{[X - E(X)]^{k}[Y - E(Y)]^{l}\} ,\quad k,l = 1,2,\dots$

存在,称它为  $X$  和  $Y$  的  $k + l$  阶混合中心矩.

显然,  $X$  的数学期望  $E(X)$  是  $X$  的一阶原点矩,方差  $D(X)$  是  $X$  的二阶中心矩,协方差  $\operatorname {Cov}(X,Y)$  是  $X$  和  $Y$  的二阶混合中心矩.

下面介绍  $n$  维随机变量的协方差矩阵.先从二维随机变量讲起,

二维随机变量  $(X_{1},X_{2})$  有四个二阶中心矩(设它们都存在),分别记为

$$
\begin{array}{r l} & {c_{11} = E\{[X_{1} - E(X_{1})]^{2}\} ,}\\ & {c_{11} = E\{[X_{1} - E(X_{1})][X_{2} - E(X_{2})]\} ,}\\ & {c_{21} = E\{[X_{2} - E(X_{2})][X_{1} - E(X_{1})]\} ,}\\ & {c_{21} = E\{[X_{2} - E(X_{2})]^{2}\} .} \end{array}
$$

将它们排成矩阵的形式

$$
\binom{c_{11}}{c_{21}}\binom{c_{12}}{c_{22}}.
$$

这个矩阵称为随机变量  $(X_{1},X_{2})$  的协方差矩阵.

设  $n$  维随机变量  $(X_{1},X_{2},\dots ,X_{n})$  的二阶混合中心矩

$c_{i j} = \operatorname {Cov}(X_{i},X_{j}) = E\{[X_{i} - E(X_{i})][X_{j} - E(X_{j})]\} ,\quad i,j = 1,2,\dots ,n$  都存在,则称矩阵

$$
\begin{array}{r}{C = \left( \begin{array}{c c c c}{c_{11}} & {c_{12}} & \dots & {c_{1n}}\\ {c_{21}} & {c_{22}} & \dots & {c_{2n}}\\ \vdots & \vdots & & \vdots \\ {c_{n1}} & {c_{n2}} & \dots & {c_{m}} \end{array} \right)} \end{array}
$$

为  $n$  维随机变量  $(X_{1},X_{2},\dots ,X_{n})$  的协方差矩阵.由于  $c_{i j} = c_{j i}$ $(i\neq j;i,j = 1$ $2,\dots ,n)$  ,因而上述矩阵是一个对称矩阵.

一般,  $n$  维随机变量的分布是不知道的, 或者是太复杂, 以致在数学上不易处理, 因此在实际应用中协方差矩阵就显得重要了.

本节的最后, 介绍  $n$  维正态随机变量的概率密度. 我们先将二维正态随机变量的概率密度改写成另一种形式, 以便将它推广到  $n$  维随机变量的场合中去. 二维正态随机变量  $(X_{1}, X_{2})$  的概率密度为

$$
\begin{array}{r l} & {f(x_{1},x_{2}) = \frac{1}{2\pi\rho_{1}\sigma_{2}\sqrt{1 - \rho^{2}}}\mathrm{exp}\Big\{\frac{-1}{2(1 - \rho^{2})}\Big[\frac{(x_{1} - \mu_{1})^{2}}{\sigma_{1}^{2}}}\\ & {\qquad -2\rho \frac{(x_{1} - \mu_{1})(x_{2} - \mu_{2})}{\sigma_{1}\sigma_{2}} +\frac{(x_{2} - \mu_{2})^{2}}{\sigma_{2}^{2}}\Big]\Big\} .} \end{array}
$$

现在将上式中花括号内的式子写成矩阵形式, 为此引入下面的列矩阵

$$
\begin{array}{r}{\pmb {X} = \binom{x_{1}}{x_{2}},\pmb {\mu} = \binom{\mu_{1}}{\mu_{2}}.} \end{array}
$$

$(X_{1}, X_{2})$  的协方差矩阵为

$$
\begin{array}{r}{C=\left(\begin{array}{c c}{c_{11}}&{c_{12}}\\ {c_{21}}&{c_{22}}\end{array}\right)=\left(\begin{array}{c c}{\sigma_{1}^{2}}&{\rho\sigma_{1}\sigma_{2}}\\ {\rho\sigma_{1}\sigma_{2}}&{\sigma_{2}^{2}}\end{array}\right),}\end{array}
$$

它的行列式  $\operatorname *{det} \mathbf{C} = \sigma_{1}^{2} \sigma_{2}^{2}(1 - \rho^{2}), \mathbf{C}$  的逆矩阵为

$$
\begin{array}{r}{C^{-1} = \frac{1}{\operatorname*{det}C}\left[ \begin{array}{c c}{\sigma_{2}^{2}} & {-\rho \sigma_{1}\sigma_{2}}\\ {-\rho \sigma_{1}\sigma_{2}} & {\sigma_{1}^{2}} \end{array} \right].} \end{array}
$$

经过计算可知 (这里矩阵  $(X - \mu)^{\mathrm{T}}$  是  $X - \mu$  的转置矩阵)

$$
\begin{array}{r l} & {\left(X - \pmb {\mu}\right)^{\mathrm{T}}\pmb{C}^{-1}\left(X - \pmb {\mu}\right)}\\ & {\quad = \frac{1}{\operatorname*{det}\pmb{C}} (x_{1} - \mu_{1}\quad x_{2} - \mu_{2})\left[ \begin{array}{c c}{\sigma_{2}^{2}} & {-\rho \sigma_{1}\sigma_{2}}\\ {-\rho \sigma_{1}\sigma_{2}} & {\sigma_{1}^{2}} \end{array} \right]\left( \begin{array}{c}{x_{1} - \mu_{1}}\\ {x_{2} - \mu_{2}} \end{array} \right)}\\ & {\quad = \frac{1}{1 - \rho^{2}}\left[ \begin{array}{c c}{(x_{1} - \mu_{1})^{2}}\\ {\sigma_{1}^{2}} \end{array} -2\rho \frac{(x_{1} - \mu_{1})(x_{2} - \mu_{2})}{\sigma_{1}\sigma_{2}} +\frac{(x_{2} - \mu_{2})^{2}}{\sigma_{2}^{2}}\right].} \end{array}
$$

于是  $(X_{1}, X_{2})$  的概率密度可写成

$$
f(x_{1}, x_{2}) = \frac{1}{(2\pi)^{2 / 2}(\operatorname*{det} \mathbf{C})^{1 / 2}} \exp \left\{-\frac{1}{2} (\mathbf{X} - \pmb{\mu})^{\mathrm{T}} \mathbf{C}^{-1}(\mathbf{X} - \pmb {\mu})\right\} .
$$

上式容易推广到  $n$  维正态随机变量  $(X_{1}, X_{2}, \dots , X_{n})$  的情况.

引入列矩阵

$$
\begin{array}{r}{X = [ \begin{array}{c}{x_{1}}\\ {x_{2}}\\ \vdots \\ {x_{n}} \end{array} ]\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots}\\ {\vdots} \end{array} ].} \end{array}
$$

$n$  维正态随机变量  $(X_{1}, X_{2}, \dots , X_{n})$  的概率密度定义为

$$
f(x_{1},x_{2},\dots ,x_{n}) = \frac{1}{(2\pi)^{n / 2}(\operatorname*{det}C)^{1 / 2}}\exp \left\{-\frac{1}{2} (X - \mu)^{\mathrm{T}}C^{-1}(X - \mu)\right\} ,
$$

其中  $c$  是  $(X_{1},X_{2},\dots ,X_{n})$  的协方差矩阵.

$n$  维正态随机变量具有以下四条重要性质(证略):

$1^{\circ}n$  维正态随机变量  $(X_{1},X_{2},\dots ,X_{n})$  的每一个分量  $X_{i},i = 1,2,\dots ,n$  都是正态随机变量;反之,若  $X_{1},X_{2},\dots ,X_{n}$  都是正态随机变量,且相互独立,则  $(X_{1}$ $X_{2},\dots ,X_{n})$  是  $n$  维正态随机变量.

$2^{\circ}n$  维随机变量  $(X_{1},X_{2},\dots ,X_{n})$  服从  $n$  维正态分布的充要条件是  $X_{1}$ $X_{2},\dots ,X_{n}$  的任意的线性组合

$$
l_{1}X_{1} + l_{2}X_{2} + \dots +l_{n}X_{n}
$$

服从一维正态分布(其中  $l_{1},l_{2},\dots ,l_{n}$  不全为零).

$3^{\circ}$  若  $(X_{1},X_{2},\dots ,X_{n})$  服从  $n$  维正态分布,设  $Y_{1},Y_{2},\dots ,Y_{k}$  是  $X_{j}(j = 1$ $2,\dots ,n)$  的线性函数,则  $(Y_{1},Y_{2},\dots ,Y_{k})$  也服从多维正态分布.

这一性质称为正态变量的线性变换不变性,

$4^{\circ}$  设  $(X_{1},X_{2},\dots ,X_{n})$  服从  $n$  维正态分布,则"  $X_{1},X_{2},\dots ,X_{n}$  相互独立"与 $^{\ast}X_{1},X_{2},\dots ,X_{n}$  两两不相关"是等价的.

$n$  维正态分布在随机过程和数理统计中常会遇到.

小结

随机变量的数字特征是由随机变量的分布确定的,能描述随机变量某一个方面的特征的常数.最重要的数字特征是数学期望和方差.数学期望  $E(X)$  描述随机变量  $X$  取值的平均大小,方差  $D(X) = E\{[X - E(X)]^{2}\}$  描述随机变量  $X$  与它自己的数学期望  $E(X)$  的偏离程度.数学期望和方差在应用和理论上都非常重要.

要掌握随机变量的函数  $Y = g(X)$  的数学期望  $E(Y) = E\big[g(X)\big]$  的计算公式(1.3)和(1.4).这两个公式的意义在于当我们求  $E(Y)$  时,不必先求出  $Y = g(X)$  的分布律或概率密度,而只需利用  $X$  的分布律或概率密度就可以了,这样做的好处是明显的.

要掌握数学期望和方差的性质,提请读者注意的是:

(1)当  $X_{1},X_{2}$  独立或  $X_{1},X_{2}$  不相关时,才有  $E(X_{1}X_{2}) = E(X_{1})E(X_{2})$

(2)设  $c$  为常数,则有  $D(C X) = C^{2}D(X)$  ,右边的系数是  $C^{2}$  ,不是  $c$

(3)  $D(X_{1} + X_{2}) = D(X_{1}) + D(X_{2}) + 2\mathrm{Cov}(X_{1},X_{2})$  ,当  $X_{1},X_{2}$  独立或  $X_{1},X_{2}$  不相关时才有

$$
D(X_{1} + X_{2}) = D(X_{1}) + D(X_{2}).
$$

例如,若  $X_{1},X_{2}$  独立,则有  $D(2X_{1} - 3X_{2}) = 4D(X_{1}) + 9D(X_{2})$

相关系数  $\rho_{X Y}$  有时也称为线性相关系数,它是一个可以用来描述随机变量  $(X,Y)$  的两个分

量  $X,Y$  之间的线性关系紧密程度的数字特征.当  $\vert \rho_{X Y}$  较小时  $X,Y$  的线性相关的程度较差;当 $\rho_{X Y} = 0$  时称  $X,Y$  不相关.不相关是指  $X,Y$  之间不存在线性关系,  $X,Y$  不相关,它们还可能存在除线性关系之外的关系(参见  $\S 3$  例1).又由于  $X,Y$  相互独立是指  $X,Y$  的一般关系而言的,因此有以下的结论:  $X,Y$  相互独立则  $X,Y$  一定不相关;反之,若  $X,Y$  不相关则  $X,Y$  不一定相互独立.

特别,对于二维正态随机变量  $(X,Y),X$  和  $Y$  不相关与  $X$  和  $Y$  相互独立是等价的.而二元正态随机变量的相关系数  $\rho_{X Y}$  就是参数  $\rho$ . 于是,用  $\rho = 0$  "是否成立来检验  $X,Y$  是否相互独立是很方便的.

切比雪夫不等式给出了在随机变量  $X$  的分布未知,只知道  $E(X)$  和  $D(X)$  的情况下,对事件  $\{|X - E(X)|< \epsilon \}$  概率的下限的估计.

# 重要术语及主题

数学期望随机变量函数的数学期望数学期望的性质方差标准差方差的性质标准化的随机变量协方差相关系数相关系数的性质  $X,Y$  不相关切比雪夫不等式几种重要分布的数学期望和方差矩协方差矩阵

# 习题

1. (1)在下列句子中随机地取一个单词,以  $X$  表示取到的单词所包含的字母个数,写出  $X$  的分布律并求  $E(X)$

"THE GIRL PUT ON HER BEAUTIFUL RED HAT".

(2)在上述句子的30个字母中随机地取一个字母,以  $Y$  表示取到的字母所在单词所包含的字母数,写出  $Y$  的分布律并求  $E(Y)$

(3)一人掷骰子,如得6点则掷第2次,此时得分为  $6+$  第二次得到的点数;否则得分为他第一次掷得的点数,且不能再掷,求得分  $X$  的分布律及  $E(X)$

2. 某产品的次品率为0.1,检验员每天检验4次.每次随机地取10件产品进行检验,如发现其中的次品数多于1,就去调整设备.以  $X$  表示一天中调整设备的次数,试求  $E(X)$  .(设诸产品是否为次品是相互独立的.)

3. 有3只球、4个盒子,盒子的编号为1,2,3,4.将球逐个独立地,随机地放入4个盒子中去.以  $X$  表示其中至少有一只球的盒子的最小号码(例如  $X = 3$  表示第1号、第2号盒子是空的,第3号盒子至少有一只球),试求  $E(X)$

4. (1)设随机变量  $X$  的分布律为  $P\left\{X = (-1)^{j + 1}\frac{3^{j}}{j}\right\} = \frac{2}{3^{j}},j = 1,2,\dots ,$  说明  $X$  的数学期望不存在.

(2)一盒中装有一只黑球、一只白球,作摸球游戏,规则如下:一次从盒中随机摸一只球,若摸到白球,则游戏结束;若摸到黑球,放回再放入一只黑球,然后再从盒中随机地摸一只球.试说明要游戏结束的摸球次数  $X$  的数学期望不存在.

5. 设在某一规定的时间间隔里,某电气设备用于最大负荷的时间  $X$  (以 min 计)是一个随机变量,其概率密度为

$$
f(x) = \left\{ \begin{array}{l l}{\frac{1}{1500^{2}} x,} & {0\leqslant x\leqslant 1500,}\\ {\frac{-1}{1500^{2}} (x - 3000),} & {1500< x\leqslant 3000,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.
$$

求  $E(X)$

6. (1)设随机变量  $X$  的分布律为

$$
\frac{\left| \begin{array}{c c c c}{{X}} & {{-2}} & {{0}} & {{2}}\\ {{p_{k}}} & {{0.4}} & {{0.3}} & {{0.3}} \end{array} \right|}{}
$$

求  $E(X),E(X^{2}),E(3X^{2} + 5)$

(2)设  $X\sim \pi (\lambda)$  ,求  $E[1 / (X + 1)]$

7. (1)设随机变量  $X$  的概率密度为

$$
f(x) = \left\{ \begin{array}{l l}{\mathrm{e}^{-x},} & {x > 0,}\\ {0,} & {x\leqslant 0.} \end{array} \right.
$$

求  $(\mathrm{i})Y = 2X$  ,(ii)  $Y = \mathrm{e}^{- 2X}$  的数学期望.

(2)设随机变量  $X_{1},X_{2},\dots ,X_{n}$  相互独立,且都服从(0,1)上的均匀分布.(i)求  $U =$ $\max \{X_{1},X_{2},\dots ,X_{n}\}$  的数学期望,(ii)求  $V = \min \{X_{1},X_{2},\dots ,X_{n}\}$  的数学期望.

8. 设随机变量  $(X,Y)$  的分布律为

<table><tr><td>X
Y</td><td>1</td><td>2</td><td>3</td></tr><tr><td>-1</td><td>0.2</td><td>0.1</td><td>0.0</td></tr><tr><td>0</td><td>0.1</td><td>0.0</td><td>0.3</td></tr><tr><td>1</td><td>0.1</td><td>0.1</td><td>0.1</td></tr></table>

(1)求  $E(X),E(Y)$

(2)设  $Z = Y / X$  ,求  $E(Z)$

(3)设  $Z = (X - Y)^{2}$  ,求  $E(Z)$

9. (1)设随机变量  $(X,Y)$  的概率密度为

$$
f(x,y) = \left\{ \begin{array}{l l}{12y^{2},} & {0\leqslant y\leqslant x\leqslant 1,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.
$$

求  $E(X),E(Y),E(X Y),E(X^{2} + Y^{2})$

(2)设随机变量  $X,Y$  的联合概率密度为

$$
f(x,y) = \left\{ \begin{array}{l l}{\frac{1}{y}\mathrm{e}^{-(y + x / y)},} & {x > 0,y > 0,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.
$$

求  $E(X),E(Y),E(X Y)$

10. (1)设随机变量  $X\sim N(0,1),Y\sim N(0,1)$  且  $X,Y$  相互独立.求  $E[X^{2} / (X^{2} + Y^{2})]$

(2)一飞机进行空投物资作业,设目标点为原点  $O(0,0)$ ,物资着陆点为  $(X,Y), X,Y$  相互独立,且设  $X \sim N(0,\sigma^{2}), Y \sim N(0,\sigma^{2})$ ,求原点到点  $(X,Y)$  间距离的数学期望.

11. 一工厂生产的某种设备的寿命  $X$  (以年计)服从指数分布,概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{4} \mathrm{e}^{-x / 4}, & x > 0, \\ 0, & x \leqslant 0. \end{array} \right.
$$

工厂规定,出售的设备若在售出一年之内损坏可予以调换。若工厂售出一台设备赢利100元,调换一台设备厂方需花费300元。试求厂方出售一台设备净赢利的数学期望.

12. 某车间生产的圆盘直径在区间  $(a,b)$  上服从均匀分布,试求圆盘面积的数学期望.

13. 设电压(以  $V$  计)  $X \sim N(0,9)$ 。将电压施加于一检波器,其输出电压为  $Y = 5X^{2}$ ,求输出电压  $Y$  的均值.

14. 设随机变量  $X_{1}, X_{2}$  的概率密度分别为

$$
f_{1}(x) = \left\{ \begin{array}{ll}2 \mathrm{e}^{-2x}, & x > 0, \\ 0, & x \leqslant 0, \end{array} \right. \quad f_{2}(x) = \left\{ \begin{array}{ll}4 \mathrm{e}^{-4x}, & x > 0, \\ 0, & x \leqslant 0. \end{array} \right.
$$

(1)求  $E(X_{1} + X_{2}), E(2X_{1} - 3X_{2}^{2})$

(2)又设  $X_{1}, X_{2}$  相互独立,求  $E(X_{1}X_{2})$

15. 将  $n$  只球  $(1 \sim n$  号)随机地放进  $n$  个盒子  $(1 \sim n$  号)中去,一个盒子装一只球。若一只球装入与球同号的盒子中,则称为一个配对。记  $X$  为总的配对数,求  $E(X)$

16. 若有  $n$  把看上去样子相同的钥匙,其中只有一把能打开门上的锁,用它们去试开门上的锁。设取到每只钥匙是等可能的。若每把钥匙试开一次后除去,试用下面两种方法求试开次数  $X$  的数学期望.

(1)写出  $X$  的分布律.

(2)不写出  $X$  的分布律.

17. 设  $X$  为随机变量,  $C$  是常数,证明  $D(X) < E[(X - C)^{2}]$ ,对于  $C \neq E(X)$ 。(由于  $D(X) = E\{[X - E(X)]^{2}\}$ ,上式表明  $E[(X - C)^{2}]$  当  $C = E(X)$  时取到最小值.)

18. 设随机变量  $X$  服从瑞利分布,其概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{x}{\sigma^{2}} \mathrm{e}^{-x^{2} / (2\sigma^{2})}, & x > 0, \\ 0, & x \leqslant 0, \end{array} \right.
$$

其中  $\sigma > 0$  是常数。求  $E(X), D(X)$

19. 设随机变量  $X$  服从  $\boldsymbol{\Gamma}$  分布,其概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{\beta^{\alpha} \Gamma(\alpha)} x^{\alpha^{-1}} \mathrm{e}^{-x / \beta}, & x > 0, \\ 0, & x \leqslant 0, \end{array} \right.
$$

其中  $\alpha > 0, \beta > 0$  是常数。求  $E(X), D(X)$

20. 设随机变量  $X$  服从几何分布,其分布律为

$$
P\{X = k\} = p(1 - p)^{k - 1}, \quad k = 1, 2, \dots ,
$$

其中  $0 < p < 1$  是常数。求  $E(X), D(X)$

21. 设长方形的长(以  $\mathrm{m}$  计)  $X\sim U(0,2)$ ,已知长方形的周长(以  $\mathrm{m}$  计)为20. 求长方形面积  $A$  的数学期望和方差.

22. (1)设随机变量  $X_{1},X_{2},X_{3},X_{4}$  相互独立,且有  $E(X_{i}) = i,D(X_{i}) = 5 - i,i = 1,2,3,4.$  设  $Y = 2X_{1} - X_{2} + 3X_{3} - \frac{1}{2} X_{4}$  求  $E(Y),D(Y)$

(2)设随机变量  $X,Y$  相互独立,且  $X\sim N(720,30^{2}),Y\sim N(640,25^{2})$  ,求  $Z_{1} = 2X + Y$ $Z_{2} = X - Y$  的分布,并求概率  $P\{X > Y\} ,P\{X + Y > 1400\}$

23. 五家商店联营,它们每两周售出的某种农产品的数量(以  $\mathrm{kg}$  计)分别为  $X_{1},X_{2},X_{3}$ $X_{4},X_{5}$  .已知  $X_{1}\sim N(200,225),X_{2}\sim N(240,240),X_{3}\sim N(180,225),X_{4}\sim N(260,265),$ $X_{5}\sim N(320,270),X_{1},X_{2},X_{3},X_{4},X_{5}$  相互独立.

(1)求五家商店两周的总销售量的均值和方差,

(2)商店每隔两周进货一次,为了使新的供货到达前商店不会脱销的概率大于0.99,问商店的仓库应至少储存多少千克该产品?

24. 卡车装运水泥,设每袋水泥质量  $X$  (以  $\mathrm{kg}$  计)服从  $N(50,2.5^{2})$  ,问至多装多少袋水泥使总质量超过2000的概率不大于0.05?

25. 设随机变量  $X,Y$  相互独立,且都服从(0,1)上的均匀分布.

(1)求  $E(X Y),E(X / Y),E[\ln (X Y)],E(|Y - X|).$

(2)以  $X,Y$  为边长作一长方形,以  $A,C$  分别表示长方形的面积和周长,求  $A$  和  $c$  的相关系数.

26. (1)设随机变量  $X_{1},X_{2},X_{3}$  相互独立,且有  $X_{1}\sim b(4,1 / 2),X_{2}\sim b(6,1 / 3),X_{3}\sim$ $b(6,1 / 3)$  ,求  $P\{X_{1} = 2,X_{2} = 2,X_{3} = 5\} ,E(X_{1}X_{2}X_{3}),E(X_{1} - X_{2}),E(X_{1} - 2X_{2}).$

(2)设  $X,Y$  是随机变量,且有  $E(X) = 3,E(Y) = 1,D(X) = 4,D(Y) = 9$  ,令  $Z = 5X - Y + 15$  分别在下列3种情况下求  $E(Z)$  和  $D(Z)$

(i)  $X,Y$  相互独立,(ii)  $X,Y$  不相关,(iii)  $X$  与  $Y$  的相关系数为0.25.

27. 下列各对随机变量  $X$  和  $Y$  ,问哪几对是相互独立的?哪几对是不相关的?

(1)  $X\sim U(0,1),Y = X^{2}$

(2)  $X\sim U(-1,1),Y = X^{2}.$

(3)  $X = \cos V,Y = \sin V,V\sim U(0,2\pi).$

若  $(X,Y)$  的概率密度为  $f(x,y)$

(4)  $f(x,y) = \left\{{ \begin{array}{l l}{x + y,} & {0< x< 1,0< y< 1,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} }\right.$

(5)  $f(x,y) = \left\{{ \begin{array}{l l}{2y,} & {0< x< 1,0< y< 1,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} }\right.$

28. 设二维随机变量  $(X,Y)$  的概率密度为

$$
f(x,y) = \left\{{ \begin{array}{l l}{\frac{1}{\pi},} & {x^{2} + y^{2}\leqslant 1,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} }\right.
$$

试验证  $X$  和  $Y$  是不相关的,但  $X$  和  $Y$  不是相互独立的.

29. 设随机变量  $(X,Y)$  的分布律为

<table><tr><td>X</td><td rowspan="2">-1</td><td rowspan="2">0</td><td rowspan="2">1</td></tr><tr><td>Y</td></tr><tr><td>-1</td><td>1/8</td><td>1/8</td><td>1/8</td></tr><tr><td>0</td><td>1/8</td><td>0</td><td>1/8</td></tr><tr><td>1</td><td>1/8</td><td>1/8</td><td>1/8</td></tr></table>

验证  $X$  和  $Y$  是不相关的,但  $X$  和  $Y$  不是相互独立的.

30. 设  $A$  和  $B$  是试验  $E$  的两个事件,且  $P(A) > 0, P(B) > 0$ ,并定义随机变量  $X, Y$  如下:

证明若  $\rho_{XY} = 0$ ,则  $X$  和  $Y$  必定相互独立.

31. 设随机变量  $(X,Y)$  具有概率密度

$$
f(x,y)={\left\{\begin{array}{l l}{1,}&{|\ y|< x,0< x< 1,}\\ {0,}&{{\mathrm{if}}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}}\\ {0,}&{{\mathrm{if}}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{if}\ \mathrm{.}}\end{array}\right.}
$$

求  $E(X), E(Y), \operatorname {Cov}(X,Y)$

32. 设随机变量  $(X,Y)$  具有概率密度

$$
f(x,y) = \left\{ \begin{array}{ll}\frac{1}{8} (x + y), & 0 \leqslant x \leqslant 2, 0 \leqslant y \leqslant 2, \\ 0, & \text{其他.} \end{array} \right.
$$

求  $E(X), E(Y), \operatorname {Cov}(X,Y), \rho_{XY}, D(X + Y)$

33. 设随机变量  $X\sim N(\mu ,\sigma^{2}),Y\sim N(\mu ,\sigma^{2})$  ,且设  $X,Y$  相互独立,试求  $Z_{1} = \alpha X + \beta Y$  和 $Z_{2} = \alpha X - \beta Y$  的相关系数(其中  $\alpha ,\beta$  是不为零的常数).

34. (1)设随机变量  $W = (a X + 3 Y)^{2}, E(X) = E(Y) = 0, D(X) = 4, D(Y) = 16, \rho_{XY} = -0.5.$  求常数  $a$  使  $E(W)$  为最小,并求  $E(W)$  的最小值.

(2)设随机变量  $(X,Y)$  服从二维正态分布,且有  $D(X) = \sigma_{X}^{2}, D(Y) = \sigma_{Y}^{2}$ . 证明当  $a^{2} = \sigma_{X}^{2} / \sigma_{Y}^{2}$  时,随机变量  $W = X - a Y$  与  $V = X + a Y$  相互独立.

35. 设随机变量  $(X,Y)$  服从二维正态分布,且  $X\sim N(0,3), Y\sim N(0,4)$ ,相关系数  $\rho_{XY} = -1 / 4$ ,试写出  $X$  和  $Y$  的联合概率密度.

36. 已知正常男性或人血液中,每一毫升所含白细胞数的均值是7300,均方差是700.利用切比雪夫不等式估计每毫升含白细胞数在  $5200 \sim 9400$  的概率  $p$ .

37. 对于两个随机变量  $V, W$ ,若  $E(V^{2}), E(W^{2})$  存在,证明

$$
[E(VW)]^{2} \leqslant E(V^{2}) E(W^{2}), \tag{A}
$$

这一不等式称为柯西一施瓦茨(Cauchy- Schwarz)不等式.

提示:考虑实变量  $t$  的函数

$$
q(t) = E\big[(V + t W)^{2}\big] = E(V^{2}) + 2t E(V W) + t^{2} E(W^{2}).
$$

38. 分位数(分位点).

定义 设连续型随机变量  $X$  的分布函数为  $F(x)$ , 概率密度函数为  $f(x)$ .

$1^{\circ}$  对于任意正数  $\alpha (0< \alpha < 1)$ , 称满足条件

$$
P\{X \leqslant x_{\underline{\alpha}}\} = F(x_{\underline{\alpha}}) = \int_{-\infty}^{x_{\underline{\alpha}}} f(x) \mathrm{d}x = \alpha
$$

的数  $x_{\underline{\alpha}}$  为此分布的  $\alpha$  分位数或下  $\alpha$  分位数.

$2^{\circ}$  对于任意正数  $\alpha (0< \alpha < 1)$ , 称满足条件

$$
P\{X > x_{\underline{\alpha}}\} = 1 - F(x_{\underline{\alpha}}) = \int_{x_{\underline{\alpha}}}^{\infty} f(x) \mathrm{d}x = \alpha
$$

的数  $x_{\alpha}$  为此分布的上  $\alpha$  分位数.

特别, 当  $\alpha = 0.5$  时,

$$
P(x_{0.5}) = F(x_{0.5}) = \int_{0.5}^{\infty} f(x) \mathrm{d}x = 0.5,
$$

$x_{0.5}$  称为此分布的中位数.

下  $\alpha$  分位数  $x_{\underline{\alpha}}$  将概率密度曲线下的面积分为两部分, 左侧的面积恰为  $\alpha$  (见题 38 图(1)). 上  $\alpha$  分位数  $x_{\alpha}$  也将概率密度曲线下的面积分为两部分, 右侧的面积恰为  $\alpha$  (见题 38 图(2)).

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_3.pdf-8b019cbe-e56b-4db0-aa4a-872484615581_86f06b0126c340fd8071513db28c218f845cdec67f56e84a36112bbacbf868cd.jpg)  
(1)

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_3.pdf-8b019cbe-e56b-4db0-aa4a-872484615581_86f06b0126c340fd8071513db28c218f845cdec67f56e84a36112bbacbf868cd.jpg)  
(2) 题38图

下  $\alpha$  分位数与上  $\alpha$  分位数有以下的关系:

$$
x_{\alpha} = x_{1 - \alpha}, \quad x_{\underline{\alpha}} = x_{1 - \alpha}.
$$

类似地, 可定义离散型随机变量  $X$  的分位数.

定义 对于任意正数  $\alpha (0< \alpha < 1)$ , 称满足条件

的数  $x_{\underline{\alpha}}$  为此分布的  $\alpha$  分位数或下  $\alpha$  分位数.

(1) 设  $X$  的概率密度为

$$
f(x)={\left\{\begin{array}{l l}{2\mathrm{e}^{-2x},}&{x\geqslant0,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}}\end{array}\right.}
$$

试求  $X$  的中位数  $M$

(2) 设  $X$  服从柯西分布, 其概率密度为

$$
f(x) = \frac{b}{\pi[(x - a)^{2} + b^{2}]}, \quad b > 0.
$$

试求  $X$  的中位数  $M$

# 第五章 大数定律及中心极限定理

极限定理是概率论的基本理论,在理论研究和应用中起着重要的作用,其中最重要的是称为"大数定律"与"中心极限定理"的一些定理.大数定律是叙述随机变量序列的前一些项的算术平均值在某种条件下收敛到这些项的均值的算术平均值;中心极限定理则是确定在什么条件下,大量随机变量之和的分布逼近于正态分布.本章介绍几个大数定律和中心极限定理.

# $\S 1$  大数定律

第一章曾讲过,大量试验证实,随机事件  $A$  的频率  $f_{n}(A)$  当重复试验的次数  $n$  增大时总呈现出稳定性,稳定在某一个常数的附近.频率的稳定性是概率定义的客观基础.本节我们将对频率的稳定性作出理论的说明.

弱大数定律(辛钦大数定律)设  $X_{1},X_{2}$  ,…是相互独立  $①$  ,服从同一分布的随机变量序列,且具有数学期望  $E(X_{k}) = \mu (k = 1,2,\dots)$  .作前  $n$  个变量的算术平均  ${\frac{1}{n}}\sum_{k=1}^{n}X_{k}$  ,则对于任意  $\epsilon >0$  ,有

$$
\lim_{n\to \infty}P\Bigg\{\Bigg|\frac{1}{n}\sum_{k = 1}^{n}X_{k} - \mu \Bigg|< \epsilon \Bigg\} = 1. \tag{1.1}
$$

证我们只在随机变量的方差  $D(X_{k}) = \sigma^{2}(k = 1,2,\dots)$  存在这一条件下证明上述结果.因为

$$
E\Big(\frac{1}{n}\sum_{k = 1}^{n}X_{k}\Big) = \frac{1}{n}\sum_{k = 1}^{n}E(X_{k}) = \frac{1}{n} n\mu = \mu ,
$$

又由独立性得

$$
D\Big(\frac{1}{n}\sum_{k = 1}^{n}X_{k}\Big) = \frac{1}{n^{2}}\sum_{k = 1}^{n}D(X_{k}) = \frac{1}{n^{2}} n\sigma^{2} = \frac{\sigma^{2}}{n},
$$

由切比雪夫不等式(见第四章(2.9)式)得

$$
1\geqslant P\Bigg\{\Bigg|\frac{1}{n}\sum_{k = 1}^{n}X_{k} - \mu \Bigg|< \epsilon \Bigg\} \geqslant 1 - \frac{\sigma^{2} / n}{\epsilon^{2}}.
$$

在上式中令  $n \rightarrow \infty$ , 即得

$$
\lim_{n \to \infty} P\left\{\left| \frac{1}{n} \sum_{k = 1}^{n} X_{k} - \mu \right| < \epsilon \right\} = 1.
$$

$\left\{\left| \frac{1}{n} \sum_{k = 1}^{n} X_{k} - \mu \right| < \epsilon \right\}$  是一个随机事件. 等式(1.1)表明, 当  $n \rightarrow \infty$  时这个事件的概率趋于1. 即对于任意正数  $\epsilon$ , 当  $n$  充分大时, 不等式  $\left| \frac{1}{n} \sum_{k = 1}^{n} X_{k} - \mu \right| < \epsilon$  成立的概率很大. 通俗地说, 辛钦大数定律是说, 对于独立同分布且具有均值  $\mu$  的随机变量  $X_{1}, X_{2}, \dots , X_{n}$ , 当  $n$  很大时它们的算术平均  $\frac{1}{n} \sum_{k = 1}^{n} X_{k}$  很可能接近于  $\mu$ .

设  $Y_{1}, Y_{2}, \dots , Y_{n}, \dots$  是一个随机变量序列,  $a$  是一个常数. 若对于任意正数  $\epsilon$ , 有

$$
\lim_{n \rightarrow \infty} P\left\{\left| Y_{n} - a \right| < \epsilon \right\} = 1,
$$

则称序列  $Y_{1}, Y_{2}, \dots , Y_{n}, \dots$  依概率收敛于  $a$ , 记为

$$
Y_{n} \xrightarrow{P} a.
$$

依概率收敛的序列有以下的性质,

设  $X_{n} \xrightarrow{P} a, Y_{n} \xrightarrow{P} b$ , 又设函数  $g(x, y)$  在点  $(a, b)$  连续, 则

这样, 辛钦大数定律又可叙述为:

弱大数定律(辛钦大数定律)设随机变量  $X_{1}, X_{2}, \dots , X_{n}, \dots$  相互独立, 服从同一分布且具有数学期望  $E(X_{k}) = \mu (k = 1, 2, \dots)$ , 则序列  $\overline{X} = \frac{1}{n} \sum_{k = 1}^{n} X_{k}$  依概率收敛于  $\mu$ , 即  $\overline{X} \xrightarrow{P} \mu$ .

下面介绍辛钦大数定律的一个重要推论,

伯努利大数定律设  $f_{A}$  是  $n$  次独立重复试验中事件  $A$  发生的次数,  $p$  是事件  $A$  在每次试验中发生的概率, 则对于任意  $\epsilon > 0$ , 有

$$
\lim_{n \rightarrow \infty} P\left\{\left| \frac{f_{A}}{n} - p \right| < \epsilon \right\} = 1 \tag{1.2}
$$

或

$$
\lim_{n \rightarrow \infty} P\left\{\left| \frac{f_{A}}{n} - p \right| \geqslant \epsilon \right\} = 0. \tag{1.2}
$$

证因为  $f_{A} \sim b(n, p)$ , 由第四章 §2 例6, 有

$$
f_{A} = X_{1} + X_{2} + \dots + X_{n},
$$

其中,  $X_{1}, X_{2}, \dots , X_{n}$  相互独立, 且都服从以  $p$  为参数的  $(0 - 1)$  分布, 因而  $E(X_{k}) = p (k = 1, 2, \dots , n)$ , 由(1.1)式即得

$$
\lim_{n\to \infty}P\left\{\left|\frac{1}{n}\sum_{k = 1}^{n}X_{k} - p\right|< \epsilon \right\} = 1,
$$

即  $\lim_{n\to \infty}P\left\{\left|\frac{f_{A}}{n} - p\right|\geqslant \epsilon \right\} = 0.$

伯努利大数定律的结果表明,对于任意  $\epsilon >0$  ,只要重复独立试验的次数  $n$  充分大,事件  $\left\{\left|\frac{f_{A}}{n} - p\right|\geqslant \epsilon \right\}$  是一个小概率事件,由实际推断原理知(见第一章 $\S 4)$  ,这一事件实际上几乎是不发生的,即在  $n$  充分大时事件  $\left\{\left|\frac{f_{A}}{n} - p\right|< \epsilon \right\}$  实际上几乎是必定要发生的,亦即对于给定的任意小的正数  $\epsilon$  ,在  $n$  充分大时,事件"频率  $\frac{f_{A}}{n}$  与概率  $\boldsymbol{\mathscr{p}}$  的偏差小于  $\epsilon$  "实际上几乎是必定要发生的.这就是我们所说的频率稳定性的真正含义.由实际推断原理,在实际应用中,当试验次数很大时,便可以用事件的频率来代替事件的概率.

# $\S 2$  中心极限定理

在客观实际中有许多随机变量,它们是由大量的相互独立的随机因素的综合影响所形成的.而其中每一个别因素在总的影响中所起的作用都是微小的.这种随机变量往往近似地服从正态分布.这种现象就是中心极限定理的客观背景.本节只介绍三个常用的中心极限定理.

定理1(独立同分布的中心极限定理)设随机变量  $X_{1},X_{2},\dots ,X_{n},\dots$  相互独立,服从同一分布,且具有数学期望和方差:  $E(X_{k}) = \mu ,D(X_{k}) = \sigma^{2} > 0$  (  $k = 1$  , $2,\dots)$  ,则随机变量之和  $\sum_{k = 1}^{n}X_{k}$  的标准化变量

$$
Y_{n} = \frac{\sum_{k = 1}^{n}X_{k} - E\Big(\sum_{k = 1}^{n}X_{k}\Big)}{\sqrt{D\Big(\sum_{k = 1}^{n}X_{k}\Big)}} = \frac{\sum_{k = 1}^{n}X_{k} - n\mu}{\sqrt{n}\sigma}
$$

的分布函数  $F_{n}(x)$  对于任意  $x$  满足

$$
\begin{array}{r}{\lim_{n\to \infty}F_{n}(x) = \lim_{n\to \infty}P\Bigg\{\frac{\sum_{k = 1}^{n}X_{k} - n\mu}{\sqrt{n}\sigma}\leqslant x\Bigg\}}\\ {= \int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t2 / 2}\mathrm{d}t = \Phi (x).} \end{array} \tag{2.1}
$$

证明略.

这就是说,均值为  $\mu$ ,方差为  $\sigma^{2} > 0$  的独立同分布的随机变量  $X_{1}, X_{2}, \dots , X_{n}$  之和  $\sum_{k = 1}^{n} X_{k}$  的标准化变量,当  $n$  充分大时,有

$$
\frac{\sum_{k = 1}^{n} X_{k} - n \mu}{\sqrt{n} \sigma} \xrightarrow{\text{近似地}} N(0,1). \tag{2.2}
$$

在一般情况下,很难求出  $n$  个随机变量之和  $\sum_{k = 1}^{n} X_{k}$  的分布函数,(2.2)式表明,当  $n$  充分大时,可以通过  $\Phi (x)$  给出其近似的分布。这样,就可以利用正态分布对  $\sum_{k = 1}^{n} X_{k}$  作理论分析或作实际计算,其好处是明显的。

将(2.2)式左端改写成  $\frac{\frac{1}{n} \sum_{k = 1}^{n} X_{k} - \mu}{\sigma / \sqrt{n}} = \frac{\overline{X} - \mu}{\sigma / \sqrt{n}}$ ,这样,上述结果可写成:当  $n$  充分大时,

$$
\frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \xrightarrow{\text{近似地}} N(0,1) \quad \text{或} \quad \overline{X} \xrightarrow{\text{近似地}} N(\mu , \sigma^{2} / n). \tag{2.3}
$$

这是独立同分布的中心极限定理结果的另一个形式.这就是说,均值为  $\mu$  ,方差为  $\sigma^{2} > 0$  的独立同分布的随机变量  $X_{1},X_{2},\dots ,X_{n}$  的算术平均  ${\overline{{X}}}={\frac{1}{n}}\sum_{k=1}^{n}X_{k}$  当  $n$  充分大时近似地服从均值为  $\mu$  ,方差为  $\sigma^{2} / n$  的正态分布.这一结果是数理统计中大样本统计推断的基础.

定理2(李雅普诺夫(Lyapunov)定理)设随机变量  $X_{1}, X_{2}, \dots , X_{n}$ ,相互独立,它们具有数学期望和方差

记  $B_{n}^{2} = \sum_{k = 1}^{n} \sigma_{k}^{2}$ .

若存在正数  $\delta$ ,使得当  $n \to \infty$  时,

$$
\frac{1}{B_{n}^{2 + \delta}} \sum_{k = 1}^{n} E\{|X_{k} - \mu_{k}|^{2 + \delta}\} \to 0,
$$

则随机变量之和  $\sum_{k = 1}^{n} X_{k}$  的标准化变量

$$
Z_{n} = \frac{\sum_{k = 1}^{n}X_{k} - E\Big(\sum_{k = 1}^{n}X_{k}\Big)}{\sqrt{D\Big(\sum_{k = 1}^{n}X_{k}\Big)}} = \frac{\sum_{k = 1}^{n}X_{k} - \sum_{k = 1}^{n}\mu_{k}}{B_{n}}
$$

的分布函数  $F_{n}(x)$  对于任意  $x$ ,满足

$$
\begin{array}{l}{\lim_{n\to \infty}F_{n}(x) = \lim_{n\to \infty}P\Bigg\{\frac{\sum_{k = 1}^{n}X_{k} - \sum_{k = 1}^{n}\mu_{k}}{B_{n}}\leqslant x\Bigg\}}\\ {= \int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2} / 2}\mathrm{d}t = \Phi (x).} \end{array} \tag{2.4}
$$

证明略.

定理2表明,在定理的条件下,随机变量

$$
Z_{n} = \frac{\sum_{k = 1}^{n}X_{k} - \sum_{k = 1}^{n}\mu_{k}}{B_{n}}
$$

当  $n$  很大时,近似地服从正态分布  $N(0,1)$ . 由此,当  $n$  很大时,  $\sum_{k = 1}^{n}X_{k} = B_{n}Z_{n} + \sum_{k = 1}^{n}\mu_{k}$  近似地服从正态分布  $N\Big(\sum_{k = 1}^{n}\mu_{k},B_{n}^{2}\Big)$ . 这就是说,无论各个随机变量  $X_{k}(k = 1,2,\dots)$  服从什么分布,只要满足定理的条件,那么它们的和  $\sum_{k = 1}^{n}X_{k}$  当  $n$  很大时,就近似地服从正态分布. 这就是正态随机变量在概率论中占有重要地位的一个基本原因. 在很多问题中,所考虑的随机变量可以表示成很多个独立的随机变量之和. 例如,在任一指定时刻,一个城市的耗电量是大量用户耗电量的总和;一个物理实验的测量误差是由许多观察不到的、可加的微小误差所合成的,它们往往近似地服从正态分布.

下面介绍另一个中心极限定理,它是定理1的特殊情况,

定理3(棣莫弗一拉普拉斯(DeMoivre- Laplace)定理)设随机变量  $\eta_{n}(n = 1,2,\dots)$  服从参数为  $n,p$ $(0< p< 1)$  的二项分布,则对于任意  $x$ ,有

$$
\lim_{n\to \infty}P\left\{\frac{\eta_{n} - n\phi}{\sqrt{n\phi(1 - \phi)}}\leqslant x\right\} = \int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2} / 2}\mathrm{d}t = \Phi (x). \tag{2.5}
$$

证由第四章  $\S 2$  例6知可以将  $\eta_{n}$  分解成为  $n$  个相互独立、服从同一  $(0 - 1)$  分布的诸随机变量  $X_{1},X_{2},\dots ,X_{n}$  之和,即有

$$
\eta_{n} = \sum_{k = 1}^{n}X_{k},
$$

其中  $X_{k}(k = 1,2,\dots ,n)$  的分布律为

$$
P\{X_{k} = i\} = p^{i}(1 - p)^{1 - i},\quad i = 0,1.
$$

由于  $E(X_{k}) = p,D(X_{k}) = p(1 - p)(k = 1,2,\dots ,n)$ ,由定理1得

$$
\begin{array}{r l r} & {} & {\underset {n\to \infty}{\lim}P\left\{\frac{\eta_{n} - n\phi}{\sqrt{n\phi(1 - \phi)}}\leqslant x\right\} = \underset {n\to \infty}{\lim}P\left\{\frac{\sum_{k = 1}^{n}X_{k} - n\phi}{\sqrt{n\phi(1 - \phi)}}\leqslant x\right\}}\\ & {} & {= \int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2} / 2}\mathrm{d}t = \Phi (x).} \end{array}
$$

这个定理表明,正态分布是二项分布的极限分布。当  $n$  充分大时,我们可以利用(2.5)式来计算二项分布的概率。下面举几个关于中心极限定理应用的例子。

例1 一加法器同时收到20个噪声电压  $V_{k}(k = 1,2,\dots ,20)$ ,设它们是相互独立的随机变量,且都在区间(0,10)上服从均匀分布。记  $V = \sum_{k = 1}^{20}V_{k}$ ,求  $P\{V > 105\}$  的近似值。

解 易知  $E(V_{k}) = 5,D(V_{k}) = 100 / 12(k = 1,2,\dots ,20)$ 。由定理1,随机变量

$$
Z = \frac{\sum_{k = 1}^{20}V_{k} - 20\times5}{\sqrt{100 / 12}\sqrt{20}} = \frac{V - 20\times5}{\sqrt{100 / 12}\sqrt{20}}
$$

近似服从正态分布  $N(0,1)$ ,于是

$$
P\{V > 105\} = P\left\{\frac{V - 20\times5}{(10 / \sqrt{12})\sqrt{20}} >\frac{105 - 20\times5}{(10 / \sqrt{12})\sqrt{20}}\right\}
$$

$$
= P\left\{\frac{V - 100}{(10 / \sqrt{12})\sqrt{20}} >0.387\right\}
$$

$$
= 1 - P\left\{\frac{V - 100}{(10 / \sqrt{12})\sqrt{20}}\leqslant 0.387\right\}
$$

$$
\approx 1 - \int_{-\infty}^{0.387}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2} / 2}\mathrm{d}t = 1 - \Phi (0.387) = 0.348.
$$

即有  $P\{V > 105\} \approx 0.348.$

例2 一船舶在某海区航行,已知每遭受一次波浪的冲击,纵摇角大于  $3^{\circ}$  的概率为  $p = 1 / 3$ ,若船舶遭受了90000次波浪冲击,问其中有  $29500\sim 30500$  次纵摇角度大于  $3^{\circ}$  的概率是多少?

解 我们将船舶每遭受一次波浪冲击看作一次试验,并假定各次试验是独

立的. 在 90000 次波浪冲击中纵摇角度大于  $3^{\circ}$  的次数记为  $X$ , 则  $X$  是一个随机变量, 且有  $X \sim b(90000,1 / 3)$ . 其分布律为

$$
P\{X = k\} = \left( \begin{array}{c}90000 \\ k \end{array} \right)\left(\frac{1}{3}\right)^{k}\left(\frac{2}{3}\right)^{90000 - k}, \quad k = 0,1, \dots , 90000.
$$

所求的概率为

$$
P\{29500 \leqslant X \leqslant 30500\} = \sum_{k = 29500}^{30500}\left(\frac{90000}{k}\right)\left(\frac{1}{3}\right)^{k}\left(\frac{2}{3}\right)^{90000 - k},
$$

要直接计算是麻烦的, 我们利用棣莫弗一拉普拉斯定理来求它的近似值. 即有

$$
P\{29500 \leqslant X \leqslant 30500\}
$$

$$
= P\left\{\frac{29500 - n p}{\sqrt{n p(1 - p)}} \leqslant \frac{X - n p}{\sqrt{n p(1 - p)}} \leqslant \frac{30500 - n p}{\sqrt{n p(1 - p)}}\right\}
$$

$$
\approx \int_{\frac{29500 - n p}{\sqrt{n p(1 - p)}}}^{\frac{30500 - n p}{\sqrt{n p(1 - p)}}}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2} / 2}\mathrm{d}t = \Phi \left(\frac{30500 - n p}{\sqrt{n p(1 - p)}}\right) - \Phi \left(\frac{29500 - n p}{\sqrt{n p(1 - p)}}\right),
$$

其中  $n = 90000, p = 1 / 3$ . 即有

$$
P\{29500 \leqslant X \leqslant 30500\} \approx \Phi \left(\frac{5\sqrt{2}}{2}\right) - \Phi \left(-\frac{5\sqrt{2}}{2}\right) = 0.9995.
$$

例3 对于一个学生而言, 来参加家长会的家长人数是一个随机变量, 设一个学生无家长、有 1 名家长、有 2 名家长来参加会议的概率分别为 0.05、0.8、0.15. 若学校共有 400 名学生, 设各学生参加会议的家长人数相互独立, 且服从同一分布.

(1) 求参加会议的家长人数  $X$  超过 450 的概率.

(2) 求有 1 名家长来参加会议的学生人数不多于 340 的概率.

解 (1) 以  $X_{k}(k = 1,2, \dots , 400)$  记第  $k$  个学生来参加会议的家长人数, 则  $X_{k}$  的分布律为

$$
\frac{X_{k}}{p_{k}} \quad \begin{array}{cccc}0 & 1 & 2 \\ 0.05 & 0.8 & 0.15 \end{array}
$$

易知  $E(X_{k}) = 1.1, D(X_{k}) = 0.19, k = 1,2, \dots , 400$ . 而  $X = \sum_{k = 1}^{400} X_{k}$ . 由定理 1, 随机变量

$$
\frac{\sum_{k = 1}^{400} X_{k} - 400 \times 1.1}{\sqrt{400} \sqrt{0.19}} = \frac{X - 400 \times 1.1}{\sqrt{400} \sqrt{0.19}}
$$

近似服从正态分布  $N(0,1)$ , 于是

$$
P\{X > 450\} = P\left\{\frac{X - 400\times1.1}{\sqrt{400}\sqrt{0.19}} >\frac{450 - 400\times1.1}{\sqrt{400}\sqrt{0.19}}\right\}
$$

$$
= 1 - P\left\{\frac{X - 400\times1.1}{\sqrt{400}\sqrt{0.19}}\leqslant 1.147\right\}
$$

$$
\approx 1 - \Phi (1.147) = 0.1251.
$$

(2)以  $Y$  记有1名家长参加会议的学生人数,则  $Y\sim b(400,0.8)$ ,由定理3,

$$
P\{Y\leqslant 340\} = P\left\{\frac{Y - 400\times0.8}{\sqrt{400\times0.8\times0.2}}\leqslant \frac{340 - 400\times0.8}{\sqrt{400\times0.8\times0.2}}\right\}
$$

$$
= P\left\{\frac{Y - 400\times0.8}{\sqrt{400\times0.8\times0.2}}\leqslant 2.5\right\} \approx \Phi (2.5) = 0.9938.
$$

小结

人们在长期实践中认识到频率具有稳定性,即当试验次数不断增大时,频率稳定在一个数的附近,这一事实显示了可以用一个数来表征事件发生的可能性的大小,这使人们认识到概率是客观存在的,进而由频率的性质的启发和抽象给出了概率的定义,因而频率的稳定性是概率定义的客观基础,伯努利大数定律则以严密的数学形式论证了频率的稳定性.

中心极限定理表明,在相当一般的条件下,当独立随机变量的个数不断增加时,其和的分布趋于正态分布,这一事实阐明了正态分布的重要性,也揭示了为什么在实际应用中会经常遇到正态分布,也就是揭示了产生正态分布变量的源泉,另一方面,它提供了独立同分布随机变量之和  $\sum_{k = 1}^{n}X_{k}$  (其中  $X_{k}$  的方差存在)的近似分布,只要和式中加项的个数充分大,就可以不必考虑和式中的随机变量服从什么分布,都能用正态分布来近似,这在应用上是有效和重要的.

中心极限定理的内容包含极限,因而称它为极限定理是很自然的,又由于它在统计中的重要性,称它为中心极限定理,这是波利亚(Pólya)在1920年取的名字.

# 重要术语及主题

依概率收敛伯努利大数定律辛钦大数定律独立同分布的中心极限定理李雅普诺夫中心极限定理棣莫弗一拉普拉斯中心极限定理

# 习题

1. 据以往经验,某种电器元件的寿命服从均值为  $100\mathrm{~h~}$  的指数分布,现随机地取16只,设它们的寿命是相互独立的.求这16只元件的寿命的总和大于  $1920\mathrm{~h~}$  的概率.

2. (1)一保险公司有10000个汽车投保人,每个投保人索赔金额的数学期望为280美元,标准差为800美元,求索赔总金额超过2700000美元的概率.

(2)一公司有50张签约保险单,各张保险单的索赔金额  $X_{i},i = 1,2,\dots ,50$  (以千美元计)

服从韦布尔(Weibull)分布,均值  $E(X_{i}) = 5$ ,方差  $D(X_{i}) = 6$ ,求50张保险单索赔的合计金额大于300的概率(设各保险单索赔金额是相互独立的).

3. 计算器在进行加法时,将每个加数舍入最靠近它的整数,设所有舍入误差相互独立且在  $(-0.5,0.5)$  上服从均匀分布.

(1)将1500个数相加,问误差总和的绝对值超过15的概率是多少?

(2)最多可有几个数相加使得误差总和的绝对值小于10的概率不小于0.90?

4. 设各零件的质量都是随机变量,它们相互独立,且服从相同的分布,其数学期望为  $0.5 \mathrm{~kg}$ ,均方差为  $0.1 \mathrm{~kg}$ ,问5000个零件的总质量超过  $2510 \mathrm{~kg}$  的概率是多少?

5. 有一批建筑房屋用的木柱,其中  $80\%$  的长度不小于  $3 \mathrm{~m}$ ,现从这批木柱中随机地取100根,求其中至少有30根短于  $3 \mathrm{~m}$  的概率.

6. 一工人修理一台机器需两个阶段,第一阶段所需时间(以h计)服从均值为0.2的指数分布,第二阶段所需时间服从均值为0.3的指数分布,且与第一阶段独立.现有20台机器需要修理,求他在  $8 \mathrm{~h}$  内完成的概率.

7. 一食品店有三种蛋糕出售,由于售出哪一种蛋糕是随机的,因而售出一只蛋糕的价格是一个随机变量,它取1元、1.2元、1.5元各个值的概率分别为0.3,0.2,0.5.若售出300只蛋糕.

(1)求收入至少400元的概率.

(2)求售出价格为1.2元的蛋糕多于60只的概率.

8. 一复杂的系统由100个相互独立起作用的部件所组成,在整个运行期间每个部件损坏的概率为0.1.为了使整个系统起作用,至少必须有85个部件正常工作,求整个系统起作用的概率.

9. 已知在某十字路口,一周事故发生数的数学期望为2.2,标准差为1.4.

(1)以  $\overline{X}$  表示一年(以52周计)此十字路口事故发生数的算术平均,试用中心极限定理求  $\overline{X}$  的近似分布,并求  $P\{\overline{X} < 2\}$

(2)求一年事故发生数小于100的概率.

10. 某种小汽车氧化氮的排放量的数学期望为  $0.9 \mathrm{~g} / \mathrm{km}$ ,标准差为  $1.9 \mathrm{~g} / \mathrm{km}$ ,某汽车公司有这种小汽车100辆,以  $\overline{X}$  表示这些车辆氧化氮排放量的算术平均,问当  $L$  为何值时  $\overline{X} > L$  的概率不超过0.01?

11. 随机地选取两组学生,每组80人,分别在两个实验室里测量某种化合物的  $\mathrm{pH}$ .各人测量的结果是随机变量;它们相互独立,服从同一分布,数学期望为5,方差为0.3,以  $\overline{X}, \overline{Y}$  分别表示第一组和第二组所得结果的算术平均.

(1)求  $P\{4.9< \overline{X} < 5.1\}$

(2)求  $P\{-0.1< \overline{X} -\overline{Y} < 0.1\}$

12. 一公寓有200户住户,一户住户拥有汽车辆数  $X$  的分布律为

<table><tr><td>X</td><td>0</td><td>1</td><td>2</td></tr><tr><td>pK</td><td>0.1</td><td>0.6</td><td>0.3</td></tr></table>

问需要多少车位,才能使每辆汽车都具有一个车位的概率至少为0.95?

13. 某种电子器件的寿命(以h计)具有数学期望  $\mu$  (未知),方差  $\sigma^{2} = 400$ 。为了估计  $\mu$ ,随机地取  $n$  只这种器件,在时刻  $t = 0$  投入测试(测试是相互独立的)直到失效,测得其寿命为  $X_{1}, X_{2}, \dots , X_{n}$ ,以  $\overline{X} = \frac{1}{n} \sum_{\mu = 1}^{n} X_{i}$  作为  $\mu$  的估计,为使  $P\{| \overline{X} - \mu | < 1 \} \geqslant 0.95$ ,问  $n$  至少为多少?

14. 某药厂断言,该厂生产的某种药品对于医治一种疑难血液病的治愈率为0.8,医院任意抽查100个服用此药品的患者,若其中多于75人治愈,就接受此断言,否则就拒绝此断言。

(1)若实际上此药品对这种疾病的治愈率为0.8,问接受这一断言的概率是多少?

(2)若实际上此药品对这种疾病的治愈率为0.7,问接受这一断言的概率是多少?

# 第六章 样本及抽样分布

前面五章我们讲述了概率论的基本内容,随后的四章将讲述数理统计。数理统计是具有广泛应用的一个数学分支,它以概率论为理论基础,根据试验或观察得到的数据,来研究随机现象,对研究对象的客观规律性作出种种合理的估计和判断。

数理统计的内容包括:如何收集、整理数据资料;如何对所得的数据资料进行分析、研究,从而对所研究的对象的性质、特点作出推断。后者就是我们所说的统计推断问题。本书只讲述统计推断的基本内容。

在概率论中,我们所研究的随机变量,它的分布都是假设已知的,在这一前提下去研究它的性质、特点和规律性,例如求出它的数字特征,讨论随机变量函数的分布,介绍常用的各种分布等。在数理统计中,我们研究的随机变量,它的分布是未知的,或者是不完全知道的,人们是通过对所研究的随机变量进行重复独立的观察,得到许多观察值,对这些数据进行分析,从而对所研究的随机变量的分布作出种种推断的。

本章我们介绍总体、随机样本及统计量等基本概念,并着重介绍几个常用统计量及抽样分布。

# §1 随机样本

我们知道,随机试验的结果很多是可以用数来表示的,另有一些试验的结果虽是定性的,但总可以将它数量化。例如,检验某个学校学生的血型这一试验,其可能结果有O型、A型、B型、AB型4种,是定性的。如果分别以1,2,3,4依次记这4种血型,那么试验的结果就能用数来表示了。

在数理统计中,我们往往研究有关对象的某一项数量指标(例如研究某种型号灯泡的寿命这一数量指标)。为此,考虑与这一数量指标相联系的随机试验,对这一数量指标进行试验或观察。我们将试验的全部可能的观察值称为总体,这些值不一定都不相同,数目上也不一定是有限的,每一个可能观察值称为个体。总体中所包含的个体的个数称为总体的容量。容量为有限的称为有限总体,容量为无限的称为无限总体。

例如在考察某大学一年级男生的身高这一试验中,若一年级男生共2000人,每个男生的身高是一个可能观察值,所形成的总体中共含2000个可

能观察值, 是一个有限总体. 又如考察某一湖泊中某种鱼的含汞量, 所得总体也是有限总体. 观察并记录某一地点每天 (包括以往、现在和将来) 的最高气温, 或者测量一湖泊任一地点的深度, 所得总体是无限总体. 有些有限总体的容量很大, 我们可以认为它是一个无限总体. 例如, 考察全国正在使用的某种型号灯泡的寿命所形成的总体, 由于可能观察值的个数很多, 就可以认为是无限总体.

总体中的每一个个体是随机试验的一个观察值, 因此它是某一随机变量  $X$  的值, 这样, 一个总体对应于一个随机变量  $X$ . 我们对总体的研究就是对一个随机变量  $X$  的研究,  $X$  的分布函数和数字特征就称为总体的分布函数和数字特征. 今后将不区分总体与相应的随机变量, 笼统称为总体  $X$ .

例如, 我们检验自生产线出来的零件是次品还是正品, 以 0 表示产品为正品, 以 1 表示产品为次品. 设出现次品的概率为  $p$  (常数), 那么总体是由一些"1"和一些"0"所组成, 这一总体对应于一个具有参数为  $p$  的  $(0 - 1)$  分布:

$$
P\{X = x\} = p^{x}(1 - p)^{1 - x}, \quad x = 0, 1
$$

的随机变量. 我们就将它说成是  $(0 - 1)$  分布总体. 意指总体中的观察值是  $(0 - 1)$  分布随机变量的值. 又如上述灯泡寿命这一总体是指数分布总体, 意指总体中的观察值是指数分布随机变量的值.

在实际中, 总体的分布一般是未知的, 或只知道它具有某种形式而其中包含着未知参数. 在数理统计中, 人们都是通过从总体中抽取一部分个体, 根据获得的数据来对总体分布作出推断的. 被抽出的部分个体叫做总体的一个样本.

所谓从总体抽取一个个体, 就是对总体  $X$  进行一次观察并记录其结果. 我们在相同的条件下对总体  $X$  进行  $n$  次重复的、独立的观察. 将  $n$  次观察结果按试验的次序记为  $X_{1}, X_{2}, \dots , X_{n}$ . 由于  $X_{1}, X_{2}, \dots , X_{n}$  是对随机变量  $X$  观察的结果, 且各次观察是在相同的条件下独立进行的, 所以有理由认为  $X_{1}, X_{2}, \dots , X_{n}$  是相互独立的, 且都是与  $X$  具有相同分布的随机变量. 这样得到的  $X_{1}, X_{2}, \dots , X_{n}$  称为来自总体  $X$  的一个简单随机样本,  $n$  称为这个样本的容量. 以后如无特别说明, 所提到的样本都是指简单随机样本.

当  $n$  次观察一经完成, 我们就得到一组实数  $x_{1}, x_{2}, \dots , x_{n}$ , 它们依次是随机变量  $X_{1}, X_{2}, \dots , X_{n}$  的观察值, 称为样本值.

对于有限总体, 采用放回抽样就能得到简单随机样本, 但放回抽样使用起来不方便, 当个体的总数  $N$  比要得到的样本的容量  $n$  大得多时, 在实际中可将不放回抽样近似地当作放回抽样来处理.

至于无限总体, 因抽取一个个体不影响它的分布, 所以总是用不放回抽样. 例如, 在生产过程中, 每隔一定时间抽取一个个体, 抽取  $n$  个就得到一个简单随机样本, 实验室中的记录, 水文、气象等观察资料都是样本. 试制新产品得到的样

品的质量指标, 也常被认为是样本.

综合上述, 我们给出以下的定义.

定义设  $X$  是具有分布函数  $F$  的随机变量,若  $X_{1},X_{2},\dots ,X_{n}$  是具有同一分布函数  $F$  的、相互独立的随机变量,则称  $X_{1},X_{2},\dots ,X_{n}$  为从分布函数  $F$  (或总体  $F$  、或总体  $X$  )得到的容量为  $n$  的简单随机样本,简称样本,它们的观察值 $x_{1},x_{2},\dots ,x_{n}$  称为样本值,又称为  $X$  的  $n$  个独立的观察值.

也可以将样本看成是一个随机向量,写成  $(X_{1},X_{2},\dots ,X_{n})$  ,此时样本值相应地写成  $(x_{1},x_{2},\dots ,x_{n})$  .若  $(x_{1},x_{2},\dots ,x_{n})$  与  $(y_{1},y_{2},\dots ,y_{n})$  都是相应于样本 $(X_{1},X_{2},\dots ,X_{n})$  的样本值,一般来说它们是不相同的.

由定义得:若  $X_{1},X_{2},\dots ,X_{n}$  为  $F$  的一个样本,则  $X_{1},X_{2},\dots ,X_{n}$  相互独立,且它们的分布函数都是  $F$  ,所以  $(X_{1},X_{2},\dots ,X_{n})$  的分布函数为

$$
F^{*}\left(x_{1},x_{2},\dots ,x_{n}\right) = \prod_{i = 1}^{n}F(x_{i}).
$$

又若  $X$  具有概率密度  $f$  ,则  $(X_{1},X_{2},\dots ,X_{n})$  的概率密度为

$$
f^{*}\left(x_{1},x_{2},\dots ,x_{n}\right) = \prod_{i = 1}^{n}f(x_{i}).
$$

# $\S 2$  直方图和箱线图

为了研究总体分布的性质,人们通过试验得到许多观察值,一般来说这些数据是杂乱无章的.为了利用它们进行统计分析,将这些数据加以整理,还常借助于表格或图形对它们加以描述.本节将通过例子对连续型随机变量  $X$  引人"频率直方图",接着介绍数据的"箱线图".它们使人们对总体  $X$  的分布有一个粗略的了解.

# (一)直方图

例1下面列出了84个伊特鲁里亚人(Etruscans)男子的头颅的最大宽度(以  $\mathrm{mm}$  计),现在来画这些数据的"频率直方图".

141 148 132 138 154 142 150 146 155 158

150 140 147 148 144 150 149 145 149 158

143 141 144 144 126 140 144 142 141 140

145 135 147 146 141 136 140 146 142 137

148 154 137 139 143 140 131 143 141 149

148 135 148 152 143 144 141 143 147 146

150 132 142 142 143 153 149 146 149 138

142 149 142 137 134 144 146 147 140 142

140 137 152 145

解 这些数据杂乱无章, 先要将它们进行整理. 这些数据的最小值、最大值分别为 126、158, 即所有数据落在区间[126,158]上, 现取区间[124.5,159.5], 它能覆盖区间[126,158]. 将区间[124.5,159.5]等分为7个小区间  $\mathcal{O}$ , 小区间的长度记为  $\Delta , \Delta = (159.5 - 124.5) / 7 = 5$ .  $\Delta$  称为组距. 小区间的端点称为组限. 数出落在每个小区间内的数据的频数  $f_{i}$ , 算出频率  $f_{i} / n$ $(n = 84, i = 1,2, \dots , 7)$  如下表:

<table><tr><td>组 限</td><td>频数fi</td><td>频率fi/n</td><td>累积频率</td></tr><tr><td>124.5～129.5</td><td>1</td><td>0.011 9</td><td>0.011 9</td></tr><tr><td>129.5～134.5</td><td>4</td><td>0.047 6</td><td>0.059 5</td></tr><tr><td>134.5～139.5</td><td>10</td><td>0.119 1</td><td>0.178 6</td></tr><tr><td>139.5～144.5</td><td>33</td><td>0.392 9</td><td>0.571 5</td></tr><tr><td>144.5～149.5</td><td>24</td><td>0.285 7</td><td>0.857 2</td></tr><tr><td>149.5～154.5</td><td>9</td><td>0.107 1</td><td>0.964 3</td></tr><tr><td>154.5～159.5</td><td>3</td><td>0.035 7</td><td>1</td></tr></table>

现在自左至右依次在各个小区间上作以  $\frac{f_{i}}{n} /\Delta$  为高的小矩形. 如图6- 1所示, 这样的图形叫频率直方图. 显然这种小矩形的面积就等于数据落在该小区间的频率  $f_{i} / n$ . 由于当  $n$  很大时, 频率接近于概率, 因而一般来说, 每个小区间上的小矩形面积接近于概率密度曲线之下该小区间之上的曲边梯形的面积. 于是, 一般来说, 直方图的外廓曲线接近于总体  $X$  的概率密度曲线. 从本例的直方图看 (图6- 1), 它有一个峰, 中间高, 两头低, 比较对称. 看起来样本很像来自某一正态总体  $X$  (在第八章中将进一步讨论). 从直方图上还可以估计  $X$  落在某一区间的概率, 例如从图上看到有  $51.2\%$  的人最大头颅宽度落在区间(134.5,144.5)之内, 最大头颅宽度小于129.5的仅占  $1.19\%$ , 等等.  $\square$

# (二) 箱线图

先介绍样本分位数.

定义 设有容量为  $n$  的样本观察值  $x_{1}, x_{2}, \dots , x_{n}$ , 样本  $p$  分位数  $(0< p< 1)$  记为  $x_{p}$ , 它具有以下的性质: (1) 至少有  $np$  个观察值小于或等于  $x_{p}$ . (2) 至少有  $n(1 - p)$  个观察值大于或等于  $x_{p}$ .

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_3.pdf-8b019cbe-e56b-4db0-aa4a-872484615581_86f06b0126c340fd8071513db28c218f845cdec67f56e84a36112bbacbf868cd.jpg)  
图6-1

样本  $\boldsymbol{\mathscr{p}}$  分位数可按以下法则求得.将  $x_{1},x_{2},\dots ,x_{n}$  按自小到大的次序排列成  $x_{(1)}\leqslant x_{(2)}\leqslant \dots \leqslant x_{(n)}$

$1^{\circ}$  若  $n p$  不是整数,则只有一个数据满足定义中的两点要求,这一数据位于大于  $n p$  的最小整数处,即为位于  $[n p] + 1$  处的数.例如,  $n = 12,p = 0.9,n p =$ $10.8,n(1 - p) = 1.2$  ,则  $x_{\phi}$  的位置应满足至少有10.8个数据  $\leqslant x_{\phi}(x_{\phi}$  应位于第11或大于第11处);且至少有1.2个数据  $\geqslant x_{\phi}(x_{\phi}$  应位于第11或小于第11处),故  $x_{\phi}$  应位于第11处.

$2^{\circ}$  若  $n p$  是整数.例如在  $n = 20,p = 0.95$  时,  $x_{\phi}$  的位置应满足至少有19个数据  $\leqslant x_{\phi}(x_{\phi}$  应位于第19或大于第19处)且至少有1个数据  $\geqslant x_{\phi}(x_{\phi}$  应位于第20或小于第20处),故第19或第20的数据均符合要求,就取这两个数的平均值作为  $x_{\phi}$

综上,

$$
x_{\phi} = \left\{ \begin{array}{l l}{x_{([n p] + 1)},}\\ {\frac{1}{2} [x_{(n p)} + x_{(n p + 1)}],} \end{array} \right.
$$

特别,当  $\scriptstyle{p = 0,5}$  时,0.5分位数  $x_{0,5}$  也记为  $Q_{2}$  或  $M$  ,称为样本中位数,即有

$$
x_{0,5} = \left\{ \begin{array}{l l}{x_{\left[\frac{n}{2}\right] + 1},}\\ {\frac{1}{2}\left[x_{\left(\frac{n}{2}\right)} + x_{\left(\frac{n}{2} +1\right)}\right],} \end{array} \right.
$$

易知,当  $n$  是奇数时中位数  $x_{0,5}$  就是  $x_{(1)}\leqslant x_{(2)}\leqslant \dots \leqslant x_{(n)}$  这一数组中最中间的一个数;而当  $n$  是偶数时中位数  $x_{0,5}$  就是  $x_{(1)}\leqslant x_{(2)}\leqslant \dots \leqslant x_{(n)}$  这一数组中最中间两个数的平均值.

0.25分位数  $x_{0,25}$  称为第一四分位数,又记为  $Q_{1}$ ;0.75分位数  $x_{0,75}$  称为第三四分位数,又记为  $Q_{3},x_{0,25},x_{0,5},x_{0,75}$  在统计中是很有用的.

例2设有一组容量为18的样本值如下(已经过排序):

求样本分位数:  $x_{0,2}, x_{0,25}, x_{0,5}$ .

解因为  $n p = 18\times 0.2 = 3.6$ $x_{0,2}$  位于第  $[3.6] + 1 = 4$  处,即有 $x_{0,2} = x_{(4)} = 140$

因为  $n p = 18\times 0.25 = 4.5, x_{0,25}$  位于第  $[4.5] + 1 = 5$  处,即有  $x_{0,25} = 145$

因为  $n p = 18\times 0.5 = 9, x_{0,5}$  是这组数中间两个数的平均值,即有

$$
x_{0,5} = \frac{1}{2} (157 + 162) = 159.5.
$$

下面介绍箱线图.

数据集的箱线图是由箱子和直线组成的图形,它是基于以下5个数的图形概括:最小值Min,第一四分位数  $Q_{1}$ ,中位数  $M$ ,第三四分位数  $Q_{3}$  和最大值Max.它的作法如下:

(1)画一水平数轴,在轴上标上  $\mathrm{Min}, Q_{1}, M, Q_{3}, \mathrm{Max}$ . 在数轴上方画一个上、下侧平行于数轴的矩形箱子,箱子的左右两侧分别位于  $Q_{1}, Q_{3}$  的上方. 在  $M$  点的上方画一条垂直线段. 线段位于箱子内部.

(2)自箱子左侧引一条水平线直至最小值Min,在同一水平高度自箱子右侧引一条水平线直至最大值.这样就将箱线图作好了,如图6一2所示.箱线图也可以沿垂直数轴来作.自箱线图可以形象地看出数据集的以下重要性质.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图6-2

$①$  中心位置:中位数所在的位置就是数据集的中心.

$②$  散布程度:全部数据都落在  $[ \mathrm{Min}, \mathrm{Max} ]$  之内,在区间  $[ \mathrm{Min}, Q_{1} ], [ Q_{1}, M ], [ M, Q_{3} ], [ Q_{3}, \mathrm{Max} ]$  上的数据个数各约占1/4. 区间较短时,表示落在该区间的点较集中,反之较为分散.

(3)关于对称性:若中位数位于箱子的中间位置,则数据分布较为对称.又若Min离  $M$  的距离较Max离  $M$  的距离大,则表示数据分布向左倾斜,反之表示数据向右倾斜,且能看出分布尾部的长短.

例3以下是8个患者的血压(收缩压,以  $\mathrm{mmHg}$  计)数据(已经过排序),试作出箱线图.

$$
102\quad 110\quad 117\quad 118\quad 122\quad 123\quad 132\quad 150
$$

解因  $n p = 8\times 0.25 = 2$ ,故  $x_{0,25} = Q_{1} = \frac{1}{2} (110 + 117) = 113.5$

因  $n p = 8\times 0.5 = 4$ ,故  $x_{0,5} = Q_{2} = \frac{1}{2} (118 + 122) = 120$

因  $n p = 8 \times 0.75 = 6$ , 故  $x_{0.75} = Q_{3} = \frac{1}{2} (123 + 132) = 127.5$ .

$\mathrm{Min} = 102, \mathrm{Max} = 150$ , 作出箱线图如图 6- 3 所示.

例4 下面分别给出了25个男子和25个女子的肺活量(以L计.数据已经排过序):

女子组 2.7 2.8 2.9 3.1 3.1 3.1 3.2 3.4 3.4

3.4 3.4 3.4 3.5 3.5 3.5 3.6 3.7 3.7

3.7 3.8 3.8 4.0 4.1 4.2 4.2

男子组 4.1 4.1 4.3 4.3 4.5 4.6 4.7 4.8 4.8

5.1 5.3 5.3 5.3 5.4 5.4 5.5 5.6 5.7

5.8 5.8 6.0 6.1 6.3 6.7 6.7

试分别画出这两组数据的箱线图,

解 女子组  $\mathrm{Min} = 2.7, \mathrm{Max} = 4.2, M = 3.5$ .

因  $n p = 25 \times 0.25 = 6.25, Q_{1} = 3.2$ .

因  $n p = 25 \times 0.75 = 18.75, Q_{3} = 3.7$ .

男子组  $\mathrm{Min} = 4.1, \mathrm{Max} = 6.7, M = 5.3$ .

因  $n p = 25 \times 0.25 = 6.25, Q_{1} = 4.7$ .

因  $n p = 25 \times 0.75 = 18.75, Q_{3} = 5.8$ .

作出箱线图如图6- 4所示.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图6-3

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图6-4

箱线图特别适用于比较两个或两个以上数据集的性质, 为此, 我们将几个数据集的箱线图画在同一个数轴上. 例如在例4中可以明显地看到男子的肺活量要比女子大, 男子的肺活量较女子的肺活量更为分散.

若在数据集中某一个观察值不寻常地大于或小于该数集中的其他数据, 则称之为疑似异常值. 疑似异常值的存在, 会对随后的计算结果产生不适当的影响. 检查疑似异常值并加以适当的处理是十分重要的. 箱线图只要稍加修改, 就能用来检测数据集是否存在疑似异常值.

第一四分位数Q与第三四分位数Q之间的距离;Q- Q,=IQR,称为

四分位数间距. 若数据小于  $Q_{1} - 1.5IQR$  或大于  $Q_{3} + 1.5IQR$ , 就认为它是疑似异常值. 我们将上述箱线图的作法(1), (2), (3)作如下的改变:

$(1^{\prime})$  同(1).

$(2^{\prime})$  计算  $IQR = Q_{3} - Q_{1}$ , 若一个数据小于  $Q_{1} - 1.5IQR$  或大于  $Q_{3} + 1.5IQR$ , 则认为它是一个疑似异常值. 画出疑似异常值, 并以  $^{\circ}$  表示.

$(3^{\prime})$  自箱子左侧引一水平线段直至数据集中除去疑似异常值后的最小值, 又自箱子右侧引一水平线直至数据集中除去疑似异常值后的最大值.

按  $(1^{\prime}),(2^{\prime}),(3^{\prime})$  作出的图形称为修正箱线图.

例5 下面给出了某医院21个患者的住院时间(以天计), 试画出修正箱线图(数据已经过排序).

$$
\begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c} & 1 & 2 & 3 & 3 & 4 & 4 & 5 & 6 & 6 & 7 & 7 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 & 9 \end{array}
$$

解  $\mathrm{Min} = 1, \mathrm{Max} = 55, M = 7$

因  $21 \times 0.25 = 5.25$ , 得  $Q_{1} = 4$

又  $21 \times 0.75 = 15.75$ , 得  $Q_{3} = 12$

故  $IQR = Q_{3} - Q_{1} = 8$

$$
Q_{3} + 1.5IQR = 12 + 1.5 \times 8 = 24, \quad Q_{1} - 1.5IQR = 4 - 12 = -8.
$$

观察值  $55 > 24$ , 故55是疑似异常值, 且仅此一个疑似异常值. 作出修正箱线图如图6- 5所示. 可见数据分布不对称, 而向右倾斜, 在中位数的右边较为分散.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图6-5

数据集中, 疑似异常值的产生源于: (1) 数据的测量、记录或输入计算机时的错误. (2) 数据来自不同的总体. (3) 数据是正确的, 但它只体现小概率事件. 当检测出疑似异常值时, 人们需对疑似异常值出现的原因加以分析. 如果是由于测量或记录的错误, 或某些其他明显的原因造成的, 那么将这些疑似异常值从数据集中丢弃就可以了. 然而当出现的原因无法解释时, 要作出丢弃或保留这些值的决策无疑是困难的, 此时我们在对数据集作分析时尽量选用稳健的方法, 使得疑似异常值对我们的结论的影响较小. 例如我们采用中位数来描述数据集的中心趋势, 而不使用数据集的平均值, 因为后者受疑似异常值的影响较大.

# $\S 3$  抽样分布

样本是进行统计推断的依据。在应用时,往往不是直接使用样本本身,而是针对不同的问题构造样本的适当函数,利用这些样本的函数进行统计推断。

定义设  $X_{1},X_{2},\dots ,X_{n}$  是来自总体  $X$  的一个样本,  $g(X_{1},X_{2},\dots ,X_{n})$  是  $X_{1}$ $X_{2},\dots ,X_{n}$  的函数,若  $g$  中不含未知参数,则称  $g(X_{1},X_{2},\dots ,X_{n})$  是一统计量.

因为  $X_{1},X_{2},\dots ,X_{n}$  都是随机变量,而统计量  $g(X_{1},X_{2},\dots ,X_{n})$  是随机变量的函数,因此统计量是一个随机变量.设  $x_{1},x_{2},\dots ,x_{n}$  是相应于样本  $X_{1},X_{2},\dots ,X_{n}$  的样本值,则称  $g(x_{1},x_{2},\dots ,x_{n})$  是  $g(X_{1},X_{2},\dots ,X_{n})$  的观察值.

下面列出几个常用的统计量.设  $X_{1},X_{2},\dots ,X_{n}$  是来自总体  $X$  的一个样本, $x_{1},x_{2},\dots ,x_{n}$  是这一样本的观察值.定义

样本均值

$$
\overline{{X}} = \frac{1}{n}\sum_{i = 1}^{n}X_{i};
$$

样本方差

$$
S^{2} = \frac{1}{n - 1}\sum_{i = 1}^{n}(X_{i} - \overline{{X}})^{2} = \frac{1}{n - 1}\Big(\sum_{i = 1}^{n}X_{i}^{2} - n\overline{{X}}^{2}\Big);
$$

样本标准差

$$
S = \sqrt{S^{2}} = \sqrt{\frac{1}{n - 1}\sum_{i = 1}^{n}(X_{i} - \overline{{X}})^{2}};
$$

样本  $k$  阶(原点)矩

$$
A_{k} = \frac{1}{n}\sum_{i = 1}^{n}X_{i}^{k}, k = 1,2,\dots ;
$$

样本  $k$  阶中心矩

$$
B_{k} = \frac{1}{n}\sum_{i = 1}^{n}(X_{i} - \overline{{X}})^{k}, k = 2,3,\dots .
$$

它们的观察值分别为

$$
\bar{x} = \frac{1}{n}\sum_{i = 1}^{n}x_{i};
$$

$$
s^{2} = \frac{1}{n - 1}\sum_{i = 1}^{n}(x_{i} - \bar{x})^{2} = \frac{1}{n - 1}\Big(\sum_{i = 1}^{n}x_{i}^{2} - n\bar{x}^{2}\Big);
$$

$$
s = \sqrt{\frac{1}{n - 1}\sum_{i = 1}^{n}(x_{i} - \bar{x})^{2}};
$$

$$
a_{k} = \frac{1}{n}\sum_{i = 1}^{n}x_{i}^{k},\quad k = 1,2,\dots;
$$

$$
b_{k} = \frac{1}{n}\sum_{i = 1}^{n}(x_{i} - \bar{x})^{k},\quad k = 2,3,\dots .
$$

这些观察值仍分别称为样本均值、样本方差、样本标准差、样本  $k$  阶(原点)矩以及样本  $k$  阶中心矩.

我们指出,若总体  $X$  的  $k$  阶矩  $E(X^{k})\stackrel {\mathrm{~i~a~r~}}{\longrightarrow}\mu_{k}$  存在,则当  $n\to \infty$  时,  $A_{k}\stackrel {P}{\longrightarrow}$ $\mu_{k},k = 1,2,\dots$  .这是因为  $X_{1},X_{2},\dots ,X_{n}$  独立且与  $X$  同分布,所以  $X_{1}^{k},X_{2}^{k},\dots ,X_{n}^{k}$  独立且与  $X^{k}$  同分布.故有

$$
E(X_{1}^{k}) = E(X_{2}^{k}) = \dots = E(X_{n}^{k}) = \mu_{k}.
$$

从而由第五章的辛钦大数定律知

$$
A_{k} = \frac{1}{n}\sum_{i = 1}^{n}X_{i}^{k}\stackrel {P}{\longrightarrow}\mu_{k},\quad k = 1,2,\dots .
$$

进而由第五章中关于依概率收敛的序列的性质知道

$$
g(A_{1},A_{2},\dots ,A_{k})\stackrel {P}{\longrightarrow}g(\mu_{1},\mu_{2},\dots ,\mu_{k}),
$$

其中  $g$  为连续函数.这就是下一章所要介绍的矩估计法的理论根据,

我们还要介绍一个与总体分布函数  $F(x)$  相应的统计量——经验分布函数.

定义设  $x_{1},x_{2}\dots ,x_{n}$  是来自分布函数为  $F(x)$  的总体  $X$  的样本观察值.  $X$  的经验分布函数,记为  $F_{n}(x)$  ,定义为样本观察值  $x_{1},x_{2},\dots ,x_{n}$  中小于或等于指定值  $x$  所占的比率,即

$$
F_{n}(x) = \frac{\#(x_{i}\leqslant x)}{n},\quad -\infty < x< \infty .
$$

其中#  $(x_{i}\leqslant x)$  表示  $x_{1},x_{2},\dots ,x_{n}$  中小于或等于  $x$  的个数.

按定义,当给定样本观察值  $x_{1},x_{2},\dots ,x_{n}$  时,  $F_{n}(x)$  是自变量  $x$  的函数,它具有分布函数的三个条件:  $①F_{n}(x)$  是  $x$  的不减函数.  $②0\leqslant F_{n}(x)\leqslant 1$  ,且  $F(- \infty) =$ $0,F(\infty) = 1.$ $③F(x)$  是一个右连续函数.由此知  $F_{n}(x)$  是一个分布函数.当  $x_{1}$  , $x_{2},\dots ,x_{n}$  各不相同时,  $F_{n}(x)$  是以等概率  $1 / n$  取  $x_{1},x_{2},\dots ,x_{n}$  的离散型随机变量的分布函数  $①$

一般地,设  $x_{1},x_{2},\dots ,x_{n}$  是总体  $X$  的一个容量为  $n$  的样本观察值,先将  $x_{1}$  , $x_{2},\dots ,x_{n}$  按自小到大的次序排序,并重新编号为

$$
x_{(1)} \leqslant x_{(2)} \leqslant \dots \leqslant x_{(n)},
$$

则经验分布函数  $F_{n}(x)$  可写成

$$
F_{n}(x) = \left\{ \begin{array}{ll}0, & x < x_{(1)}, \\ k / n, & x_{(k)} \leqslant x < x_{(k + 1)}, \\ 1, & x \geqslant x_{(n)}. \end{array} \right. \quad k = 1, 2, \dots , n - 1,
$$

例如,设总体  $X$  有样本观察值  $x_{(1)} =$ $- 1, x_{(2)} = 1, x_{(3)} = 2$ , 得经验分布函数为 (如图6- 6):

$$
F_{3}(x) = \left\{ \begin{array}{ll}0, & x < -1, \\ 1 / 3, & -1 \leqslant x < 1, \\ 2 / 3, & 1 \leqslant x < 2, \\ 1, & x \geqslant 2. \end{array} \right.
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图6-6

另一方面,当给定  $x$  时,  $F_{n}(x)$  是样本  $X_{1}, X_{2}, \dots , X_{n}$  的函数,因此,它是一个统计量.格里汶科(Glivenko)在1933年给出了以下的定理.

定理1(格里汶科定理)设  $X_{1}, X_{2}, \dots , X_{n}$  是来自以  $F(x)$  为分布函数的总体  $X$  的样本,  $F(x)$  是经验分布函数,则有

$$
F\Big\{\lim_{n\to \infty}\sup_{-\infty < x< \infty}\big|F_{n}(x) - F(x)\big| = 0\Big\} = 1.
$$

(证明略.)

定理1的含义是  $F_{n}(x)$  在整个实轴上以概率1均匀收敛于  $F(x)$ . 于是当样本容量  $n$  充分大时,  $F_{n}(x)$  能够良好地逼近总体分布函数  $F(x)$ . 这是在概率统计学中以样本推断总体的依据.

# $(-)\chi^{2}$  分布

设  $X_{1}, X_{2}, \dots , X_{n}$  是来自总体  $N(0,1)$  的样本,则称统计量

$$
\chi^{2} = X_{1}^{2} + X_{2}^{2} + \dots + X_{n}^{2} \tag{3.1}
$$

服从自由度为  $n$  的  $\chi^{2}$  分布,记为  $\chi^{2} \sim \chi^{2}(n)$

此处,自由度是指(3.1)式右端包含的独立变量的个数.

$\chi^{2}(n)$  分布的概率密度为

$$
f(y) = \left\{ \begin{array}{ll} \frac{1}{2^{n / 2} \Gamma(n / 2)} y^{n / 2 - 1} \mathrm{e}^{-y / 2}, & y > 0, \\ 0, & \text{其他}. \end{array} \right. \tag{3.2}
$$

$f(y)$  的图形如图6- 7所示.

现在来推求(3.2)式.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图6-7

首先由第二章  $\S 5$  例3及第三章  $\S 5$  例3知  $\chi^{2}$  (1)分布即为  $\Gamma \Big(\frac{1}{2},2\Big)$  分布.现  $X_{i}\sim N(0,1)$  ,由定义  $X_{i}^{2}\sim \chi^{2}\left(1\right)$  ,即  $X_{i}^{2}\sim \Gamma \Big(\frac{1}{2},2\Big),i = 1,2,\dots ,n.$  再由  $X_{1}$ $X_{2},\dots ,X_{n}$  的独立性知  $X_{1}^{2},X_{2}^{2},\dots ,X_{n}^{2}$  相互独立,从而由  $\boldsymbol{\cal T}$  分布的可加性(见第三章  $\S 5$  例3)知

$$
\chi^{2} = \sum_{i = 1}^{n}X_{i}^{2}\sim \Gamma \Big(\frac{n}{2},2\Big), \tag{3.3}
$$

即得  $\chi^{2}(n)$  分布的概率密度如(3.2)式所示.

根据  $\boldsymbol{\cal T}$  分布的可加性易得  $\chi^{2}$  分布的可加性如下:

$\chi^{2}$  分布的可加性设  $\chi_{1}^{2}\sim \chi^{2}\left(n_{1}\right),\chi_{2}^{2}\sim \chi^{2}\left(n_{2}\right)$  ,并且  $\chi_{1}^{2},\chi_{2}^{2}$  相互独立,则有

$$
\chi_{1}^{2} + \chi_{2}^{2}\sim \chi^{2}\left(n_{1} + n_{2}\right). \tag{3.4}
$$

$\chi^{2}$  分布的数学期望和方差若  $\chi^{2}\sim \chi^{2}(n)$  ,则有

$$
E(\chi^{2}) = n,\quad D(\chi^{2}) = 2n. \tag{3.5}
$$

事实上,因  $X_{i}\sim N(0,1)$  ,故

$$
E(X_{i}^{2}) = D(X_{i}) = 1,
$$

$$
D(X_{i}^{2}) = E(X_{i}^{4}) - [E(X_{i}^{2})]^{2} = 3 - 1 = 2,\quad i = 1,2,\dots ,n.
$$

于是  $E(\chi^{2}) = E\Big(\sum_{i = 1}^{n}X_{i}^{2}\Big) = \sum_{i = 1}^{n}E(X_{i}^{2}) = n,$

$$
D(\chi^{2}) = D\Big(\sum_{i = 1}^{n}X_{i}^{2}\Big) = \sum_{i = 1}^{n}D(X_{i}^{2}) = 2n.
$$

$\chi^{2}$  分布的上分位数对于给定的正数  $\alpha ,0{<}\alpha {<}1$  ,满足条件(参见120页)

$$
P\{\chi^{2} > \chi_{\alpha}^{2}(n)\} = \int_{\chi_{\alpha}^{2}(n)}^{\infty}f(y)\mathrm{d}y = \alpha , \tag{3.6}
$$

的  $\chi_{\alpha}^{2}(n)$  就是  $\chi^{2}(n)$  分布的上  $\alpha$  分位数,如图6一8所示.对于不同的  $\alpha ,n$  ,上  $\alpha$  分

位数的值已制成表格, 可以查用 (参见附表 5). 例如对于  $\alpha = 0.1, n = 25$ , 查得  $\chi_{0.1}^{2}(25) = 34.382$ . 但该表只详列到  $n = 40$  为止, 费希尔 (R. A. Fisher) 曾证明, 当  $n$  充分大时, 近似地有

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图6-8

$$
\chi_{\alpha}^{2}(n) \approx \frac{1}{2} (z_{\alpha} + \sqrt{2n - 1})^{2}, \tag{3.7}
$$

其中  $z_{\alpha}$  是标准正态分布的上  $\alpha$  分位数. 利用 (3.7) 式可以求得当  $n > 40$  时  $\chi^{2}(n)$  分布的上  $\alpha$  分位数的近似值.

例如, 由 (3.7) 式可得  $\chi_{0.05}^{2}(50) \approx \frac{1}{2} (1.645 + \sqrt{99})^{2} = 67.221$  (由更详细的表得  $\chi_{0.05}^{2}(50) = 67.505$ ).

# (二)  $t$  分布

设  $X \sim N(0,1), Y \sim \chi^{2}(n)$ , 且  $X, Y$  相互独立, 则称随机变量

$$
t = \frac{X}{\sqrt{Y / n}} \tag{3.8}
$$

服从自由度为  $n$  的  $t$  分布. 记为  $t \sim t(n)$

$t$  分布又称学生氏 (Student) 分布.  $t(n)$  分布的概率密度函数为

$$
h(t) = \frac{\Gamma[(n + 1) / 2]}{\sqrt{\pi n} \Gamma(n / 2)} \left(1 + \frac{t^{2}}{n}\right)^{-(n + 1) / 2}, \quad -\infty < t < \infty \tag{3.9}
$$

(证略). 图 6- 9 中画出了  $h(t)$  的图形.  $h(t)$  的图形关于  $t = 0$  对称, 当  $n$  充分大时其图形类似于标准正态变量概率密度的图形. 事实上, 利用  $\Gamma$  函数的性质可得

$$
\lim_{n \to \infty} h(t) = \frac{1}{\sqrt{2\pi}} \mathrm{e}^{-t^{2} / 2}, \tag{3.10}
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图6-9

故当  $n$  足够大时  $t$  分布近似于  $N(0,1)$  分布. 但对于较小的  $n, t$  分布与  $N(0,1)$  分布相差较大(见附表2与附表4).

$t$  分布的上分位数 对于给定的  $\alpha , 0< \alpha < 1$ , 满足条件

$$
P\{t > t_{\alpha}(n)\} = \int_{t_{\alpha}(n)}^{\infty}h(t)\mathrm{d}t = \alpha \tag{3.11}
$$

的  $t_{\alpha}(n)$  就是  $t(n)$  分布的上  $\alpha$  分位数(如图6一10).

由  $t(n)$  分布的上  $\alpha$  分位数的定义及  $h(t)$  图形的对称性知

$$
t_{1 - \alpha}(n) = -t_{\alpha}(n). \tag{3.12}
$$

$t$  分布的上  $\alpha$  分位数可自附表4查得. 当  $n > 45$  时, 对于常用的  $\alpha$  的值, 就用正态近似

$$
t_{\alpha}(n) \approx z_{\alpha}. \tag{3.13}
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图6-10

# (三)  $F$  分布

设  $U \sim \chi^{2}(n_{1}), V \sim \chi^{2}(n_{2})$ , 且  $U, V$  相互独立, 则称随机变量

$$
F = \frac{U / n_{1}}{V / n_{2}} \tag{3.14}
$$

服从自由度为  $(n_{1}, n_{2})$  的  $F$  分布, 记为  $F \sim F(n_{1}, n_{2})$

$F(n_{1}, n_{2})$  分布的概率密度为

$$
\psi (y) = \left\{ \begin{array}{l l}{\frac{\Gamma\left[(n_{1} + n_{2}) / 2\right](n_{1} / n_{2})^{n_{1} / 2}y^{(n_{1} / 2) - 1}}{\Gamma(n_{1} / 2)\Gamma(n_{2} / 2)[1 + (n_{1}y / n_{2})]^{(n_{1} + n_{2}) / 2}},} & {y > 0,}\\ {0,} & {\mathrm{~if~}y > 0.} \end{array} \right. \tag{3.15}
$$

其他

(证略). 图6- 11中画出了  $\psi (y)$  的图形.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图6-11

由定义可知, 若  $F \sim F(n_{1}, n_{2})$ , 则

$$
\frac{1}{F} \sim F(n_{2}, n_{1}). \tag{3.16}
$$

$F$  分布的上分位数 对于给定的  $\alpha , 0 < \alpha < 1$ , 满足条件

$$
P\{F > F_{\alpha}(n_{1}, n_{2})\} = \int_{F_{\alpha}(n_{1}, n_{2})}^{\infty} \psi (y) \mathrm{d}y = \alpha \tag{3.17}
$$

的  $F_{\alpha}(n_{1}, n_{2})$  就是  $F(n_{1}, n_{2})$  分布的上  $\alpha$  分位数 (图 6- 12).  $F$  分布的上  $\alpha$  分位数有表可查 (见附表 6).

类似地有  $\chi^{2}$  分布,  $t$  分布,  $F$  分布的下分位数.

$F$  分布的上  $\alpha$  分位数有如下的重要性质  $①$

$$
F_{1 - \alpha}(n_{1}, n_{2}) = \frac{1}{F_{\alpha}(n_{2}, n_{1})}.
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图6-12

(3.18)式常用来求  $F$  分布表中未列出的常用的上  $\alpha$  分位数. 例如,

$$
F_{0.95}(12, 9) = \frac{1}{F_{0.05}(9, 12)} = \frac{1}{2.80} = 0.357.
$$

# (四) 正态总体的样本均值与样本方差的分布

设总体  $X$  (不管服从什么分布, 只要均值和方差存在) 的均值为  $\mu$ , 方差为  $\sigma^{2}$ ,  $X_{1}, X_{2}, \dots , X_{n}$  是来自  $X$  的一个样本,  $\overline{X}, S^{2}$  分别是样本均值和样本方差, 则有

$$
E(\overline{X}) = \mu , \quad D(\overline{X}) = \sigma^{2} / n. \tag{3.19}
$$

而  $E(S^{2}) = E\left[\frac{1}{n - 1}\Big(\sum_{i = 1}^{n}X_{i}^{2} - n\overline{{X}}^{2}\Big)\right] = \frac{1}{n - 1}\Big[\sum_{i = 1}^{n}E(X_{i}^{2}) - n E(\overline{{X}}^{2})\Big]$

$①$  (3.18)式的证明如下:若  $F\sim F(n_{1},n_{2})$  ,按定义

$$
\begin{array}{r l} & {1 = \alpha = P\{F > F_{1 - \alpha}(n_{1},n_{2})\} = P\Big\{\frac{1}{F} < \frac{1}{F_{1 - \alpha}(n_{1},n_{2})}\Big\}}\\ & {\quad = 1 - P\Big\{\frac{1}{F}\geqslant \frac{1}{F_{1 - \alpha}(n_{1},n_{2})}\Big\} = 1 - P\Big\{\frac{1}{F} >\frac{1}{F_{1 - \alpha}(n_{1},n_{2})}\Big\} ,} \end{array}
$$

于是  $P\left\{\frac{1}{F} > \frac{1}{F_{1 - \alpha}(n_{1}, n_{2})}\right\} = \alpha .$  (1)

再由  $\frac{1}{F} \sim F(n_{2}, n_{1})$  知  $P\left\{\frac{1}{F} > F_{\alpha}(n_{2}, n_{1})\right\} = \alpha .$  (2)

比较(1), (2)两式得

$$
= \frac{1}{n - 1}\left[\sum_{i = 1}^{n}(\sigma^{2} + \mu^{2}) - n(\sigma^{2} / n + \mu^{2})\right] = \sigma^{2},
$$

即  $E(S^{2}) = \sigma^{2}$ . (3.20)

进而,设总体  $X\sim N(\mu ,\sigma^{2})$ ,由第四章 §2 的 (2.8) 式知  $\overline{X} = \frac{1}{n}\sum_{i = 1}^{n}X_{i}$  也服从正态分布,于是得到以下的定理:

定理2 设  $X_{1},X_{2},\dots ,X_{n}$  是来自正态总体  $N(\mu ,\sigma^{2})$  的样本,  $\overline{X}$  是样本均值,则有

$$
\overline{X}\sim N(\mu ,\sigma^{2} / n).
$$

对于正态总体  $N(\mu ,\sigma^{2})$  的样本均值  $\overline{X}$  和样本方差  $S^{2}$ ,有以下两个重要定理.

定理3 设  $X_{1},X_{2},\dots ,X_{n}$  是来自总体  $N(\mu ,\sigma^{2})$  的样本,  $\overline{X},S^{2}$  分别是样本均值和样本方差,则有

$$
1^{\circ}\frac{(n - 1)S^{2}}{\sigma^{2}}\sim \chi^{2}(n - 1). \tag{3.21}
$$

$2^{\circ}\overline{X}$  与  $S^{2}$  相互独立.

定理3的证明见本章末二维码.

定理4 设  $X_{1},X_{2},\dots ,X_{n}$  是来自总体  $N(\mu ,\sigma^{2})$  的样本,  $\overline{X},S^{2}$  分别是样本均值和样本方差,则有

$$
\frac{\overline{X} - \mu}{S / \sqrt{n}}\sim t(n - 1). \tag{3.22}
$$

证 由定理2、定理3,

$$
\frac{\overline{X} - \mu}{\sigma / \sqrt{n}}\sim N(0,1),\quad \frac{(n - 1)S^{2}}{\sigma^{2}}\sim \chi^{2}(n - 1),
$$

且两者独立.由  $t$  分布的定义知

$$
\frac{\overline{X} - \mu}{\sigma / \sqrt{n}}\sqrt{\frac{(n - 1)S^{2}}{\sigma^{2}(n - 1)}}\sim t(n - 1).
$$

化简上式左边,即得 (3.22) 式.

对于两个正态总体的样本均值和样本方差有以下的定理.

定理5 设  $X_{1},X_{2},\dots ,X_{n_{1}}$  与  $Y_{1},Y_{2},\dots ,Y_{n_{2}}$  分别是来自正态总体  $N(\mu_{1},\sigma_{1}^{2})$  和  $N(\mu_{2},\sigma_{2}^{2})$  的样本,且这两个样本相互独立. 设  $\overline{X} = \frac{1}{n_{1}}\sum_{i = 1}^{n_{1}}X_{i},\overline{Y} = \frac{1}{n_{2}}\sum_{i = 1}^{n_{2}}Y_{i}$  分别

是这两个样本的样本均值;  $S_{1}^{2} = \frac{1}{n_{1} - 1}\sum_{i = 1}^{n_{1}}(X_{i} - \overline{{X}})^{2},S_{2}^{2} = \frac{1}{n_{2} - 1}\sum_{i = 1}^{n_{2}}(Y_{i} - \overline{{Y}})^{2}$  分别是这两个样本的样本方差,则有

$$
1^{\circ}\frac{S_{1}^{2} / S_{2}^{2}}{\sigma_{1}^{2} / \sigma_{2}^{2}}{\sim} F(n_{1} - 1,n_{2} - 1).
$$

$2^{\circ}$  当  $\sigma_{1}^{2} = \sigma_{2}^{2} = \sigma^{2}$  时,

$$
\frac{(\overline{{X}} - \overline{{Y}}) - (\mu_{1} - \mu_{2})}{S_{w}\sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}}{\sim} t(n_{1} + n_{2} - 2),
$$

其中  $S_{w}^{2} = \frac{(n_{1} - 1)S_{1}^{2} + (n_{2} - 1)S_{2}^{2}}{n_{1} + n_{2} - 2},\quad S_{w} = \sqrt{S_{w}^{2}}.$

证  $1^{\circ}$  由定理3,

$$
\frac{(n_{1} - 1)S_{1}^{2}}{\sigma_{1}^{2}}{\sim}\chi^{2}(n_{1} - 1),\quad \frac{(n_{2} - 1)S_{2}^{2}}{\sigma_{2}^{2}}{\sim}\chi^{2}(n_{2} - 1).
$$

由假设  $S_{1}^{2},S_{2}^{2}$  相互独立,则由  $F$  分布的定义知

$$
\frac{(n_{1} - 1)S_{1}^{2}}{(n_{1} - 1)\sigma_{1}^{2}}\frac{(n_{2} - 1)S_{2}^{2}}{(n_{2} - 1)\sigma_{2}^{2}}{\sim} F(n_{1} - 1,n_{2} - 1),
$$

即  $\frac{S_{1}^{2} / S_{2}^{2}}{\sigma_{1}^{2} / \sigma_{2}^{2}}{\sim} F(n_{1} - 1,n_{2} - 1).$

$2^{\circ}$  易知  $\overline{{X}} - \overline{{Y}} \sim N\left(\mu_{1} - \mu_{2},\frac{\sigma^{2}}{n_{1}} +\frac{\sigma^{2}}{n_{2}}\right)$  即有

$$
U = \frac{(\overline{{X}} - \overline{{Y}}) - (\mu_{1} - \mu_{2})}{\sigma\sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}}{\sim} N(0,1).
$$

又由给定条件知

$$
\frac{(n_{1} - 1)S_{1}^{2}}{\sigma^{2}}{\sim}\chi^{2}(n_{1} - 1),\quad \frac{(n_{2} - 1)S_{2}^{2}}{\sigma^{2}}{\sim}\chi^{2}(n_{2} - 1),
$$

且它们相互独立,故由  $\chi^{2}$  分布的可加性知

$$
V = \frac{(n_{1} - 1)S_{1}^{2}}{\sigma^{2}} +\frac{(n_{2} - 1)S_{2}^{2}}{\sigma^{2}}{\sim}\chi^{2}(n_{1} + n_{2} - 2).
$$

由本章末所附"  $\S 3$  定理3的证明及其推广"的  $2^{\circ}$  知  $U$  与  $V$  相互独立.从而按  $t$  分布的定义知

$$
\frac{U}{\sqrt{V / (n_{1} + n_{2} - 2)}} = \frac{(\overline{{X}} - \overline{{Y}}) - (\mu_{1} - \mu_{2})}{S_{w}\sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}}{\sim} t(n_{1} + n_{2} - 2).
$$

本节所介绍的几个分布以及后四个定理,在下面各章中都起着重要的作用.应注意,它们都是在总体为正态总体这一基本假定下得到的.

# 小结

在数理统计中往往研究有关对象的某一项数量指标,对这一数量指标进行试验或观察,将试验的全部可能的观察值称为总体,每个观察值称为个体,总体中的每一个个体是某一随机变量  $X$  的值,因此一个总体对应一个随机变量  $X$  。我们将不区分总体与相应的随机变量  $X$  ,笼统称为总体  $X$  。随机变量  $X$  服从什么分布,就称总体服从什么分布,在实际中遇到的总体往往是有限总体,它对应一个离散型随机变量,当总体中包含的个体的个数很大时,在理论上可以认为它是一个无限总体,我们说某种型号的灯泡寿命总体服从指数分布,是指无限总体而言的,又如我们说某一年龄段的男性儿童的身高服从正态分布,也是指无限总体而言的。无限总体是人们对具体事物的抽象,无限总体的分布的形式较为简明,便于在数学上进行处理,使用方便。

在相同的条件下,对总体  $X$  进行  $n$  次重复的、独立的观察,得到  $n$  个结果  $X_{1}, X_{2}, \dots , X_{n}$ ,称随机变量  $X_{1}, X_{2}, \dots , X_{n}$  为来自总体  $X$  的简单随机样本,它具有两条性质:

$1^{\circ} X_{1}, X_{2}, \dots , X_{n}$  都与总体具有相同的分布。

$2^{\circ} X_{1}, X_{2}, \dots , X_{n}$  相互独立。

我们就是利用来自样本的信息推断总体,得到有关总体分布的种种结论的。

样本  $X_{1}, X_{2}, \dots , X_{n}$  的函数  $g(X_{1}, X_{2}, \dots , X_{n})$ ,若不包含未知参数,则称为统计量。统计量是一个随机变量,它是完全由样本所确定的。统计量是进行统计推断的工具,样本均值

$$
\overline{X} = \frac{1}{n} \sum_{k = 1}^{n} X_{k}
$$

和样本方差

$$
S^{2} = \frac{1}{n - 1} \sum_{k = 1}^{n} (X_{k} - \overline{X})^{2}
$$

是两个最重要的统计量,统计量的分布称为抽样分布。下面是三个来自正态分布的抽样分布:

这三个分布称为统计学的三大分布,它们在数理统计中有着广泛的应用。对于这三个分布,要求读者掌握它们的定义和概率密度函数图形的轮廓,还会使用分位数表写出分位数。

关于样本均值  $\overline{X}$  、样本方差  $S^{2}$ ,有以下的结果。

1. 设  $X_{1}, X_{2}, \dots , X_{n}$  是来自总体  $X$  (不管服从什么分布,只要它的均值和方差存在)的样本,且有  $E(X) = \mu , D(X) = \sigma^{2}$ ,则有

$$
E(X) = \mu , \quad D(X) = \sigma^{2} / n.
$$

2. 设总体  $X \sim N(\mu , \sigma^{2}), X_{1}, X_{2}, \dots , X_{n}$  是来自  $X$  的样本,则有

$1^{\circ} \overline{X} \sim N(\mu , \sigma^{2} / n)$

$$
2^{\circ} \frac{(n - 1) S^{2}}{\sigma^{2}} \sim \chi^{2}(n - 1).
$$

$3^{\circ} \overline{X}$  与  $S^{2}$  相互独立。

$$
4^{\circ} \frac{\overline{X} - \mu}{S / \sqrt{n}} \sim t(n - 1).
$$

3. 对于两个正态总体  $X \sim N(\mu_{1}, \sigma_{1}^{2})$ ,  $Y \sim N(\mu_{2}, \sigma_{2}^{2})$ , 有 §3 定理 5 的重要结果.

# 重要术语及主题

总体 简单随机样本 统计量

$\chi^{2}$  分布、  $t$  分布、  $F$  分布的定义及它们的概率密度函数图形轮廓

上  $\alpha$  分位数  $F_{1 - \alpha}(n_{1}, n_{2}) = \frac{1}{F_{\alpha}(n_{2}, n_{1})}$

小结中关于样本均值、样本方差的重要结果

# 习题

1. 在总体  $N(52,6,3^{2})$  中随机抽取一容量为 36 的样本, 求样本均值  $\overline{X}$  落在 50.8 到 53.8 之间的概率.

2. 在总体  $N(12,4)$  中随机抽一容量为 5 的样本  $X_{1}, X_{2}, X_{3}, X_{4}, X_{5}$ .

(1) 求样本均值与总体均值之差的绝对值大于 1 的概率.

(2) 求概率  $P\{\max \{X_{1}, X_{2}, X_{3}, X_{4}, X_{5}\} >15\} , P\{\min \{X_{1}, X_{2}, X_{3}, X_{4}, X_{5}\} < 10\}$ .

3. 求总体  $N(20,3)$  的容量分别为 10, 15 的两独立样本均值差的绝对值大于 0.3 的概率.

4. (1) 设样本  $X_{1}, X_{2}, \dots , X_{6}$  来自总体  $N(0,1), Y = (X_{1} + X_{2} + X_{3})^{2} + (X_{4} + X_{5} + X_{6})^{2}$ , 试确定常数  $C$  使  $CY$  服从  $\chi^{2}$  分布.

(2) 设样本  $X_{1}, X_{2}, \dots , X_{5}$  来自总体  $N(0,1), Y = \frac{C(X_{1} + X_{2})}{(X_{3}^{2} + X_{4}^{2} + X_{6}^{2})^{1 / 2}}$ , 试确定常数  $C$  使  $Y$  服从  $t$  分布.

(3) 已知总体  $X \sim t(n)$ , 求证  $X^{2} \sim F(1, n)$ .

5. (1) 已知某种能力测试的得分服从正态分布  $N(\mu , \sigma^{2})$ , 随机取 10 个人参与这一测试. 求他们得分的联合概率密度, 并求这 10 个人得分的平均值小于  $\mu$  的概率.

(2) 在 
(1) 中设  $\mu = 62, \sigma^{2} = 25$ , 若得分超过 70 就能得奖, 求至少有一人得奖的概率.

6. 设总体  $X \sim b(1, p), X_{1}, X_{2}, \dots , X_{n}$  是来自  $X$  的样本.

(1) 求  $(X_{1}, X_{2}, \dots , X_{n})$  的分布律.

(2) 求  $\sum_{i = 1}^{n} X_{i}$  的分布律.

(3) 求  $E(\overline{X}), D(\overline{X}), E(S^{2})$ .

7. 设总体  $X\sim \chi^{2}\left(n\right),X_{1},X_{2},\dots ,X_{10}$  是来自  $X$  的样本,求  $E(\overline{{X}}),D(\overline{{X}}),E(S^{2})$

8. 设总体  $X \sim N(\mu , \sigma^{2}), X_{1}, X_{2}, \dots , X_{10}$  是来自  $X$  的样本.

(1) 写出  $X_{1}, X_{2}, \dots , X_{10}$  的联合概率密度.

(2) 写出  $\overline{X}$  的概率密度.

9. 设在总体  $N(\mu , \sigma^{2})$  中抽得一容量为 16 的样本, 这里  $\mu , \sigma^{2}$  均未知.

(1) 求  $P\{S^{2} / \sigma^{2} \leqslant 2.041\}$ , 其中  $S^{2}$  为样本方差.

(2) 求  $D(S^{2})$ .

10. 下面列出了 30 个美国 NBA 球员的体重(以磅计,1 磅  $= 0.454 \mathrm{~kg}$ )数据. 这些数据是从美国 NBA 球队 1990-1991 年赛季的花名册中抽样得到的.

$$
\begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c} & 225 & 232 & 232 & 245 & 235 & 245 & 270 & 225 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 24 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 240 & 24 \end{array}
$$

(1)画出这些数据的频率直方图(提示:最大和最小观察值分别为271和185,区间[184.5,271.5]包含所有数据,将整个区间分为5等份,为计算方便,将区间调整为(179.5,279.5).

(2)作出这些数据的箱线图.

11. 截尾均值 设数据集包含  $n$  个数据,将这些数据自小到大排序为

$$
x_{(1)} \leqslant x_{(2)} \leqslant \dots \leqslant x_{(n)},
$$

删去  $100 \alpha \%$  个数值小的数,同时删去  $100 \alpha \%$  个数值大的数,将留下的数据取算术平均,记为  $\bar{x}_{\alpha}$ ,即

$$
\bar{x}_{\alpha} = \frac{x_{([n \alpha ] + 1)} + \cdots + x_{(n - [n \alpha ])}}{n - 2[n \alpha]}
$$

其中  $[n \alpha ]$  是小于或等于  $n \alpha$  的最大整数(一般取  $\alpha$  为  $0.1 \sim 0.2$ ).  $\bar{x}_{\alpha}$  称为  $100 \alpha \%$  截尾均值.例如对于第 10 题中的 30 个数据,取  $\alpha = 0.1$ ,则有  $[n \alpha ] = [30 \times 0.1] = 3$ ,得  $100 \times 0.1 \%$  截尾均值为

$$
\bar{x}_{\alpha} = \frac{200 + 200 + \cdots + 245 + 245}{30 - 6} = 225.4167.
$$

若数据来自某一总体的样本,则  $\bar{x}_{\alpha}$  是一个统计量.  $\bar{x}_{\alpha}$  不受样本的极端值的影响. 截尾均值在实际应用问题中是常会用到的.

试求第 10 题的 30 个数据的  $\alpha = 0.2$  的截尾均值.

# 第七章 参数估计

统计推断的基本问题可以分为两大类, 一类是估计问题, 另一类是假设检验问题. 本章讨论总体参数的点估计和区间估计.

# $\S 1$  点估计

设总体  $X$  的分布函数的形式已知, 但它的一个或多个参数未知, 借助于总体  $X$  的一个样本来估计总体未知参数的值的问题称为参数的点估计问题.

例1在某炸药制造厂, 一天中发生着火现象的次数  $X$  是一个随机变量, 假设它服从以  $\lambda >0$  为参数的泊松分布, 参数  $\lambda$  为未知. 现有以下的样本值, 试估计参数  $\lambda$ .

<table><tr><td>着火次数k</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>≥7</td><td></td></tr><tr><td>发生k次着火的天数nk</td><td>75</td><td>90</td><td>54</td><td>22</td><td>6</td><td>2</td><td>1</td><td>0</td><td>∑=250</td></tr></table>

解由于  $X\sim \pi (\lambda)$ , 故有  $\lambda = E(X)$ . 我们自然想到用样本均值来估计总体的均值  $E(X)$ . 现由已知数据计算得到

$\bar{x} = \frac{\sum_{k = 0}^{6}k n_{k}}{\sum_{k = 0}^{6}n_{k}} = \frac{1}{250} (0\times 75 + 1\times 90 + 2\times 54 + 3\times 22 + 4\times 6 + 5\times 2 + 6\times 1) = 1.22,$

即  $E(X) = \lambda$  的估计为1.22.

点估计问题的一般提法如下: 设总体  $X$  的分布函数  $F(x; \theta) \mathbb{O}$  的形式为已知,  $\theta$  是待估参数.  $X_{1}, X_{2}, \dots , X_{n}$  是  $X$  的一个样本,  $x_{1}, x_{2}, \dots , x_{n}$  是相应的一个样本值. 点估计问题就是要构造一个适当的统计量  $\hat{\theta} (X_{1}, X_{2}, \dots , X_{n})$ , 用它的观察值  $\hat{\theta} (x_{1}, x_{2}, \dots , x_{n})$  作为未知参数  $\theta$  的近似值. 我们称  $\hat{\theta} (X_{1}, X_{2}, \dots , X_{n})$  为  $\theta$  的估

计量,称  $\hat{\theta} (x_{1},x_{2},\dots ,x_{n})$  为  $\theta$  的估计值.在不致混淆的情况下统称估计量和估计值为估计,并都简记为  $\hat{\theta}$ . 由于估计量是样本的函数.因此对于不同的样本值, $\theta$  的估计值一般是不相同的.

例如在例1中,我们用样本均值来估计总体均值.即有估计量

$$
\widehat{\lambda} = E(\widehat{X}) = \frac{1}{n}\sum_{k = 1}^{n}X_{k},\quad n = 250,
$$

估计值  $\widehat{\lambda} = E(\widehat{X}) = \frac{1}{n}\sum_{k = 1}^{n}x_{k} = 1.22.$

下面介绍两种常用的构造估计量的方法:矩估计法和最大似然估计法.

# (一)矩估计法

设  $X$  为连续型随机变量,其概率密度为  $f(x;\theta_{1},\theta_{2},\dots ,\theta_{k})$  ,或  $X$  为离散型随机变量,其分布律为  $P\{X = x\} = p(x;\theta_{1},\theta_{2},\dots ,\theta_{k})$  ,其中  $\theta_{1},\theta_{2},\dots ,\theta_{k}$  为待估参数,  $X_{1},X_{2},\dots ,X_{n}$  是来自  $X$  的样本.假设总体  $X$  的前  $k$  阶矩

或

$$
\begin{array}{l}{{\mu_{l}=E(X^{l})=\int_{-\infty}^{\infty}x^{l}f(x;\theta_{1},\theta_{2},\cdots,\theta_{k})\mathrm{d}x\quad(X\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}}}}\\ {{\mu_{l}=E(X^{l})=\sum_{x\in R_{X}}x^{l}p(x;\theta_{1},\theta_{2},\cdots,\theta_{k})\quad(X\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathbb{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathcal{H}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~,~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm~{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\mathrm{~}\)
$$

(其中  $R_{X}$  是  $X$  可能取值的范围)存在,  $l = 1,2,\dots ,k$  .一般来说,它们是  $\theta_{1}$  , $\theta_{2},\dots ,\theta_{k}$  的函数.基于样本矩

$$
A_{l} = \frac{1}{n}\sum_{i = 1}^{n}X_{i}^{l}
$$

依概率收敛于相应的总体矩  $\mu_{l}(l = 1,2,\dots ,k)$  ,样本矩的连续函数依概率收敛于相应的总体矩的连续函数(见第六章  $\S 3$  ),我们就用样本矩作为相应的总体矩的估计量,而以样本矩的连续函数作为相应的总体矩的连续函数的估计量.这种估计方法称为矩估计法.矩估计法的具体做法如下:设

$$
\left\{ \begin{array}{l}\mu_{1} = \mu_{1}(\theta_{1},\theta_{2},\dots ,\theta_{k}), \\ \mu_{2} = \mu_{2}(\theta_{1},\theta_{2},\dots ,\theta_{k}), \\ \qquad \dots \dots \dots \dots \dots \\ \mu_{k} = \mu_{k}(\theta_{1},\theta_{2},\dots ,\theta_{k}). \end{array} \right.
$$

这是一个包含  $k$  个未知参数  $\theta_{1},\theta_{2},\dots ,\theta_{k}$  的联立方程组.一般来说,可以从中解出  $\theta_{1},\theta_{2},\dots ,\theta_{k}$  ,得到

$$
\left\{ \begin{array}{l}\theta_{1} = \theta_{1}(\mu_{1},\mu_{2},\dots ,\mu_{k}), \\ \theta_{2} = \theta_{2}(\mu_{1},\mu_{2},\dots ,\mu_{k}), \\ \qquad \dots \dots \dots \dots \dots \\ \theta_{k} = \theta_{k}(\mu_{1},\mu_{2},\dots ,\mu_{k}). \end{array} \right.
$$

以  $A_{i}$  分别代替上式中的  $\mu_{i}, i = 1,2,\dots ,k$ , 就以

$$
\hat{\theta}_{i} = \theta_{i}(A_{1},A_{2},\dots ,A_{k}), \quad i = 1,2,\dots ,k
$$

分别作为  $\theta_{i}, i = 1,2,\dots ,k$  的估计量, 这种估计量称为矩估计量. 矩估计量的观察值称为矩估计值.

例2 设总体  $X$  在  $[a,b]$  上服从均匀分布,  $a,b$  未知.  $X_{1},X_{2},\dots ,X_{n}$  是来自  $X$  的样本, 试求  $a,b$  的矩估计量.

解  $\mu_{1} = E(X) = (a + b) / 2$

$$
\mu_{2} = E(X^{2}) = D(X) + [E(X)]^{2} = (b - a)^{2} / 12 + (a + b)^{2} / 4.
$$

即

$$
\left\{ \begin{array}{l}a + b = 2\mu_{1}, \\ b - a = \sqrt{12(\mu_{2} - \mu_{1}^{2})}. \end{array} \right.
$$

解这一方程组得

$$
a = \mu_{1} - \sqrt{3(\mu_{2} - \mu_{1}^{2})}, \quad b = \mu_{1} + \sqrt{3(\mu_{2} - \mu_{1}^{2})}.
$$

分别以  $A_{1},A_{2}$  代替  $\mu_{1},\mu_{2}$ , 得到  $a,b$  的矩估计量分别为 (注意到  $\frac{1}{n}\sum_{i = 1}^{n}X_{i}^{2} - \overline{X}^{2} = \frac{1}{n}\sum_{i = 1}^{n}(X_{i} - \overline{X})^{2}$ )

$$
\hat{a} = A_{1} - \sqrt{3(A_{2} - A_{1}^{2})} = \overline{X} -\sqrt{\frac{3}{n}\sum_{i = 1}^{n}(X_{i} - \overline{X})^{2}},
$$

$$
\hat{b} = A_{1} + \sqrt{3(A_{2} - A_{1}^{2})} = \overline{X} +\sqrt{\frac{3}{n}\sum_{i = 1}^{n}(X_{i} - \overline{X})^{2}}.
$$

例3 设总体  $X$  的均值  $\mu$  及方差  $\sigma^{2}$  都存在, 且有  $\sigma^{2} > 0$ . 但  $\mu ,\sigma^{2}$  均为未知. 又设  $X_{1},X_{2},\dots ,X_{n}$  是来自  $X$  的样本. 试求  $\mu ,\sigma^{2}$  的矩估计量.

解

$$
\left\{ \begin{array}{l}\mu_{1} = E(X) = \mu , \\ \mu_{2} = E(X^{2}) = D(X) + [E(X)]^{2} = \sigma^{2} + \mu^{2}. \end{array} \right.
$$

解得

$$
\left\{ \begin{array}{l}\mu = \mu_{1}, \\ \sigma^{2} = \mu_{2} - \mu_{1}^{2}. \end{array} \right.
$$

分别以  $A_{1},A_{2}$  代替  $\mu_{1},\mu_{2}$ , 得  $\mu$  和  $\sigma^{2}$  的矩估计量分别为

$$
\hat{\mu} = A_{1} = \overline{X},
$$

$$
\hat{\sigma}^{2} = A_{2} - \hat{A}_{1}^{2} = \frac{1}{n}\sum_{i = 1}^{n}X_{i}^{2} - \overline{{X}}^{2} = \frac{1}{n}\sum_{i = 1}^{n}(X_{i} - \overline{{X}})^{2}.
$$

所得结果表明,总体均值与方差的矩估计量的表达式不因不同的总体分布而异.

例如,  $X\sim N(\mu ,\sigma^{2}),\mu ,\sigma^{2}$  未知,即得  $\mu ,\sigma^{2}$  的矩估计量为

$$
\hat{\mu} = \overline{{X}},\quad \hat{\sigma}^{2} = \frac{1}{n}\sum_{i = 1}^{n}(X_{i} - \overline{{X}})^{2}.
$$

# (二) 最大似然估计法

若总体  $X$  属离散型,其分布律  $P\{X = x\} = p(x;\theta),\theta \in \Theta$  的形式为已知,  $\theta$  为待估参数,  $\Theta$  是  $\theta$  可能取值的范围.设  $X_{1},X_{2},\dots ,X_{n}$  是来自  $X$  的样本,则  $X_{1}$ $X_{2},\dots ,X_{n}$  的联合分布律为

$$
\prod_{i = 1}^{n}p(x_{i};\theta).
$$

又设  $x_{1},x_{2},\dots ,x_{n}$  是相应于样本  $X_{1},X_{2},\dots ,X_{n}$  的一个样本值.易知样本  $X_{1}$ $X_{2},\dots ,X_{n}$  取到观察值  $x_{1},x_{2},\dots ,x_{n}$  的概率,亦即事件  $\{X_{1} = x_{1},X_{2} = x_{2},\dots ,$ $X_{n} = x_{n}\}$  发生的概率为

$$
L(\theta) = L(x_{1},x_{2},\dots ,x_{n};\theta) = \prod_{i = 1}^{n}p(x_{i};\theta),\quad \theta \in \Theta . \tag{1.1}
$$

这一概率随  $\theta$  的取值而变化,它是  $\theta$  的函数,  $L(\theta)$  称为样本的似然函数(注意,这里  $x_{1},x_{2},\dots ,x_{n}$  是已知的样本值,它们都是常数).

关于最大似然估计法,我们有以下的直观想法:现在已经取到样本值  $x_{1}$ $x_{2},\dots ,x_{n}$  了,这表明取到这一样本值的概率  $L(\theta)$  比较大,我们当然不会考虑那些不能使样本  $x_{1},x_{2},\dots ,x_{n}$  出现的  $\theta \in \Theta$  作为  $\theta$  的估计,再者,如果已知当  $\theta =$ $\theta_{0}\in \Theta$  时使  $L(\theta)$  取很大的值,而  $\Theta$  中其他  $\theta$  的值使  $L(\theta)$  取很小的值,我们自然认为取  $\theta_{0}$  作为未知参数  $\theta$  的估计值,较为合理,由费希尔引进的最大似然估计法,就是固定样本观察值  $x_{1},x_{2},\dots ,x_{n}$  ,在  $\theta$  取值的可能范围  $\Theta$  内挑选使似然函数  $L(x_{1}$ $x_{2},\dots ,x_{n};\theta)$  达到最大的参数值  $\hat{\theta}$  ,作为参数  $\theta$  的估计值.即取  $\hat{\theta}$  使

$$
L(x_{1},x_{2},\dots ,x_{n};\theta) = \max_{\theta \in \Theta}L(x_{1},x_{2},\dots ,x_{n};\theta). \tag{1.2}
$$

这样得到的  $\hat{\theta}$  与样本值  $x_{1},x_{2},\dots ,x_{n}$  有关,常记为  $\hat{\theta} (x_{1},x_{2},\dots ,x_{n})$  ,称为参数  $\theta$  的最大似然估计值,而相应的统计量  $\hat{\theta} (X_{1},X_{2},\dots ,X_{n})$  称为参数  $\theta$  的最大似然估计量.

若总体  $X$  属连续型,其概率密度  $f(x;\theta),\theta \in \Theta$  的形式已知,  $\theta$  为待估参数,  $\Theta$  是  $\theta$  可能取值的范围.设  $X_{1},X_{2},\dots ,X_{n}$  是来自  $X$  的样本,则  $X_{1},X_{2},\dots ,X_{n}$  的联合

概率密度为

$$
\prod_{i = 1}^{n}f(x_{i};\theta).
$$

设  $x_{1},x_{2},\dots ,x_{n}$  是相应于样本  $X_{1},X_{2},\dots ,X_{n}$  的一个样本值,则随机点(  $X_{1}$ $X_{2},\dots ,X_{n})$  落在点  $(x_{1},x_{2},\dots ,x_{n})$  的邻域(边长分别为  $\mathrm{d}x_{1},\mathrm{d}x_{2},\dots ,\mathrm{d}x_{n}$  的  $n$  维立方体)内的概率近似地为

$$
\prod_{i = 1}^{n}f(x_{i};\theta)\mathrm{d}x_{i}, \tag{1.3}
$$

其值随  $\theta$  的取值而变化.与离散型的情况一样,我们取  $\theta$  的估计值  $\hat{\theta}$  使概率(1.3)式取到最大值,但因子  $\prod_{i = 1}^{n}\mathrm{d}x_{i}$  不随  $\theta$  而变,故只需考虑函数

$$
L(\theta) = L(x_{1},x_{2},\dots ,x_{n};\theta) = \prod_{i = 1}^{n}f(x_{i};\theta) \tag{1.4}
$$

的最大值.这里  $L(\theta)$  称为样本的似然函数.若

$$
L(x_{1},x_{2},\dots ,x_{n};\hat{\theta}) = \max_{\theta \in \Theta}L(x_{1},x_{2},\dots ,x_{n};\theta),
$$

则称  $\hat{\theta} (x_{1},x_{2},\dots ,x_{n})$  为  $\theta$  的最大似然估计值,称  $\hat{\theta} (X_{1},X_{2},\dots ,X_{n})$  为  $\theta$  的最大似然估计量.

这样,确定最大似然估计量的问题就归结为微分学中的求最大值的问题了.

在很多情形下,  $\boldsymbol {\mathscr{p}}(\boldsymbol {x};\boldsymbol {\theta})$  和  $f(x;\theta)$  关于  $\theta$  可微,这时  $\hat{\theta}$  常可从方程

$$
\frac{\mathrm{d}}{\mathrm{d}\theta} L(\theta) = 0 \tag{1.5}
$$

解得  $①$  .又因  $L(\theta)$  与  $\ln L(\theta)$  在同一  $\theta$  处取到极值,因此,  $\theta$  的最大似然估计  $\hat{\theta}$  也可以从方程

$$
\frac{\mathrm{d}}{\mathrm{d}\theta}\ln L(\theta) = 0 \tag{1.6}
$$

求得,而从后一方程求解往往比较方便.(1.6)式称为对数似然方程.

例4设  $X\sim b(1,\phi).X_{1},X_{2},\dots ,X_{n}$  是来自  $X$  的一个样本,试求参数  $\boldsymbol{\mathscr{p}}$  的最大似然估计量.

解设  $x_{1},x_{2},\dots ,x_{n}$  是相应于样本  $X_{1},X_{2},\dots ,X_{n}$  的一个样本值.  $X$  的分布律为

$$
P\{X = x\} = p^{x}(1 - p)^{1 - x},\quad x = 0,1.
$$

故似然函数为

而

$$
\begin{array}{l}{{{\cal L}(\phi)=\prod_{i=1}^{n}p^{x_{i}}(1-\phi)^{1-x_{i}}=\phi_{i=1}^{\sum_{i=1}^{n}x_{i}}(1-\phi)^{1-\sum_{i=1}^{n}x_{i}},}}\\ {{\ln{\cal L}(\phi)=\Big(\sum_{i=1}^{n}x_{i}\Big)\ln\phi+\Big(n-\sum_{i=1}^{n}x_{i}\Big)\ln(1-\phi),}}\\ {{\frac{\mathrm{d}}{\mathrm{d}\phi}\ln{\cal L}(\phi)=\frac{\sum_{i=1}^{n}x_{i}}{\phi}-\frac{n-\sum_{i=1}^{n}x_{i}}{1-\phi}=0,}}\end{array}
$$

令

解得  $\boldsymbol{\mathscr{p}}$  的最大似然估计值

$$
\hat{p} = \frac{1}{n}\sum_{i = 1}^{n}x_{i} = \bar{x}.
$$

$\boldsymbol{\mathscr{p}}$  的最大似然估计量为

$$
\hat{p} = \frac{1}{n}\sum_{i = 1}^{n}X_{i} = \overline{{X}}.
$$

我们看到这一估计量与相应的矩估计量是相同的.

最大似然估计法也适用于分布中含多个未知参数  $\theta_{1},\theta_{2},\dots ,\theta_{k}$  的情况.这时,似然函数  $L$  是这些未知参数的函数.分别令

$$
\frac{\partial}{\partial\theta_{i}} L = 0, i = 1,2,\dots ,k
$$

或令  $\frac{\partial}{\partial\theta_{i}}\ln L = 0, i = 1,2,\dots ,k.$  (1.7)

解上述由  $k$  个方程组成的方程组,即可得到各未知参数  $\theta_{i}(i = 1,2,\dots ,k)$  的最大似然估计值  $\hat{\theta}_{i}$ . (1.7)式称为对数似然方程组.

例5设总体  $X\sim N(\mu ,\sigma^{2}),\mu ,\sigma^{2}$  为未知参数,  $x_{1},x_{2},\dots ,x_{n}$  是来自  $X$  的一个样本值.求  $\mu ,\sigma^{2}$  的最大似然估计量.

解  $X$  的概率密度为

$$
f(x;\mu ,\sigma^{2}) = \frac{1}{\sqrt{2\pi}\sigma}\exp \left\{-\frac{1}{2\sigma^{2}} (x - \mu)^{2}\right\} ,
$$

似然函数为

$$
\begin{array}{l}{{{\cal L}(\mu,\sigma^{2})=\prod_{i=1}^{n}\frac{1}{\sqrt{2\pi}\sigma}\mathrm{exp}\left\{-\frac{1}{2\sigma^{2}}(x_{i}-\mu)^{2}\right\}}}\\ {{\quad=(2\pi)^{-n/2}(\sigma^{2})^{-n/2}\mathrm{exp}\left\{-\frac{1}{2\sigma^{2}}\sum_{i=1}^{n}(x_{i}-\mu)^{2}\right\}}.}\end{array}
$$

而

$$
\ln L = -\frac{n}{2}\ln (2\pi) - \frac{n}{2}\ln \sigma^{2} - \frac{1}{2\sigma^{2}}\sum_{i = 1}^{n}(x_{i} - \mu)^{2}.
$$

令

$$
\left\{ \begin{array}{l}\frac{\partial}{\partial\mu}\ln L = \frac{1}{\sigma^{2}}\Big(\sum_{i = 1}^{n}x_{i} - n\mu \Big) = 0, \\ \frac{\partial}{\partial\sigma^{2}}\ln L = -\frac{n}{2\sigma^{2}} +\frac{1}{2(\sigma^{2})^{2}}\sum_{i = 1}^{n}(x_{i} - \mu)^{2} = 0. \end{array} \right.
$$

由前一式解得  $\hat{\mu} = \frac{1}{n}\sum_{i = 1}^{n}x_{i} = \overline{{x}}$  ,代入后一式得  $\hat{\sigma}^{2} = \frac{1}{n}\sum_{i = 1}^{n}(x_{i} - \overline{{x}})^{2}$  .因此得  $\mu$  和  $\sigma^{2}$  的最大似然估计量分别为

$$
\hat{\mu} = \overline{{X}},\quad \hat{\sigma}^{2} = \frac{1}{n}\sum_{i = 1}^{n}(X_{i} - \overline{{X}})^{2}.
$$

它们与相应的矩估计量相同.

例6设总体  $X$  在  $[a,b]$  上服从均匀分布,  $a,b$  未知,  $x_{1},x_{2},\dots ,x_{n}$  是一个样本值.试求  $a,b$  的最大似然估计量.

解记  $x_{(1)} = \min \{x_{1},x_{2},\dots ,x_{n}\} ,x_{(n)} = \max \{x_{1},x_{2},\dots ,x_{n}\} .X$  的概率密度是

$$
f(x;a,b) = \left\{ \begin{array}{ll}\frac{1}{b - a}, & a\leqslant x\leqslant b, \\ 0, & \text{其他.} \end{array} \right.
$$

似然函数为

$$
L(a,b) = \left\{ \begin{array}{ll}\frac{1}{(b - a)^{n}}, & a\leqslant x_{1},x_{2},\dots ,x_{n}\leqslant b, \\ 0, & \text{其他.} \end{array} \right.
$$

由于  $a\leqslant x_{1},x_{2},\dots ,x_{n}\leqslant b$  ,等价于  $a\leqslant x_{(1)},x_{(n)}\leqslant b.$  似然函数可写成

$$
L(a,b) = \left\{ \begin{array}{ll}\frac{1}{(b - a)^{n}}, & a\leqslant x_{(1)},b\geqslant x_{(n)}, \\ 0, & \text{其他.} \end{array} \right.
$$

于是对于满足条件  $a\leqslant x_{(1)},b\geqslant x_{(n)}$  的任意  $a,b$  有

$$
L(a,b) = \frac{1}{(b - a)^{n}}\leqslant \frac{1}{[x_{(n)} - x_{(1)}]^{n}}.
$$

即  $L(a,b)$  在  $a = x_{(1)},b = x_{(n)}$  时取到最大值  $[x_{(n)} - x_{(1)}]^{- n}$  .故  $a,b$  的最大似然估计值为

$$
\hat{a} = x_{(1)} = \min_{1\leqslant i\leqslant n}x_{i},\quad \hat{b} = x_{(n)} = \max_{1\leqslant i\leqslant n}x_{i}.
$$

$a,b$  的最大似然估计量为

$$
\hat{a} = \min_{1\leqslant i\leqslant n}X_{i},\quad \hat{b} = \max_{1\leqslant i\leqslant n}X_{i}.
$$

此外,最大似然估计具有下述性质:设  $\theta$  的函数  $u = u(\theta),\theta \in \Theta$  具有单值反函数  $\theta = \theta (u),u\in \mathcal{U}_{\ast}$  又假设  $\hat{\theta}$  是  $X$  的概率分布中参数  $\theta$  的最大似然估计,则 $\hat{u} = u(\hat{\theta})$  是  $u(\theta)$  的最大似然估计.这一性质称为最大似然估计的不变性.

事实上,因为  $\hat{\theta}$  是  $\theta$  的最大似然估计,于是有

$$
L(x_{1},x_{2},\dots ,x_{n};\hat{\theta}) = \max_{\theta \in \Theta}L(x_{1},x_{2},\dots ,x_{n};\theta),
$$

其中  $x_{1},x_{2},\dots ,x_{n}$  是  $X$  的一个样本值,考虑到  $\hat{u} = u(\hat{\theta})$  ,且有  $\hat{\theta} = \theta (\hat{u})$  ,上式可写成

$$
L(x_{1},x_{2},\dots ,x_{n};\theta (\hat{u})) = \max_{u\in \mathcal{U}}L(x_{1},x_{2},\dots ,x_{n};\theta (u)).
$$

这就证明了  $\hat{u} = u(\hat{\theta})$  是  $u(\theta)$  的最大似然估计.

当总体分布中含有多个未知参数时,也具有上述性质.例如,在例5中已得到  $\sigma^{2}$  的最大似然估计为

$$
\hat{\sigma}^{2} = \frac{1}{n}\sum_{i = 1}^{n}(X_{i} - \overline{{X}})^{2}.
$$

函数  $u = u(\sigma^{2}) = \sqrt{\sigma^{2}}$  有单值反函数  $\sigma^{2} = u^{2}(u\geqslant 0)$  ,根据上述性质,得到标准差  $\sigma$  的最大似然估计为

$$
\hat{\sigma} = \sqrt{\hat{\sigma}^{2}} = \sqrt{\frac{1}{n}\sum_{i = 1}^{n}(X_{i} - \overline{{X}})^{2}}.
$$

我们还要提到的是,对数似然方程(1.6)或对数似然方程组(1.7)除了一些简单的情况外,往往没有有限函数形式的解,这就需要用数值方法求近似解.常用的算法是牛顿一拉弗森(Newton- Raphson)算法,对于(1.7)式有时也用拟牛顿算法,它们都是迭代算法,读者可参考有关的书籍.

# \*2 基于截尾样本的最大似然估计

在研究产品的可靠性时,需要研究产品寿命  $T$  的各种特征.产品寿命  $T$  是一个随机变量,它的分布称为寿命分布.为了对寿命分布进行统计推断,就需要通过产品的寿命试验,以取得寿命数据.

一种典型的寿命试验是,将随机抽取的  $n$  个产品在时间  $t = 0$  时,同时投入试验,直到每个产品都失效.记录每一个产品的失效时间,这样得到的样本(即由所有产品的失效时间  $0\leqslant t_{1}\leqslant t_{2}\leqslant \dots \leqslant t_{n}$  所组成的样本)称为完全样本.然而

产品的寿命往往较长,由于时间和财力的限制,我们不可能得到完全样本,于是就考虑截尾寿命试验。截尾寿命试验常用的有两种:一种是定时截尾寿命试验。假设将随机抽取的  $n$  个产品在时间  $t = 0$  时同时投入试验,试验进行到事先规定的截尾时间  $t_{0}$  停止。如试验截止时共有  $m$  个产品失效,它们的失效时间分别为

$$
0 \leqslant t_{1} \leqslant t_{2} \leqslant \dots \leqslant t_{m} \leqslant t_{0},
$$

此时  $m$  是一个随机变量,所得的样本  $t_{1}, t_{2}, \dots , t_{m}$  称为定时截尾样本。另一种是定数截尾寿命试验。假设将随机抽取的  $n$  个产品在时间  $t = 0$  时同时投入试验,试验进行到有  $m$  个( $m$  是事先规定的, $m < n$ )产品失效时停止。 $m$  个失效产品的失效时间分别为

$$
0 \leqslant t_{1} \leqslant t_{2} \leqslant \dots \leqslant t_{m},
$$

这里  $t_{m}$  是第  $m$  个产品的失效时间, $t_{m}$  是随机变量。所得的样本  $t_{1}, t_{2}, \dots , t_{m}$  称为定数截尾样本。用截尾样本来进行统计推断是可靠性研究中常见的问题。

设产品的寿命分布是指数分布,其概率密度为

$$
f(t) = \left\{ \begin{array}{ll}\frac{1}{\theta} \mathrm{e}^{-t / \theta}, & t > 0, \\ 0, & t \leqslant 0, \end{array} \right.
$$

$\theta > 0$  未知。假设有  $n$  个产品投入定数截尾试验,截尾数为  $m$ ,得到定数截尾样本  $0 \leqslant t_{1} \leqslant t_{2} \leqslant \dots \leqslant t_{m}$ ,现在要利用这一样本来估计未知参数  $\theta$  (即产品的平均寿命)。在时间区间  $[0, t_{m}]$  有  $m$  个产品失效,而有  $n - m$  个产品在  $t_{m}$  时尚未失效,即有  $n - m$  个产品的寿命超过  $t_{m}$ 。我们用最大似然估计法来估计  $\theta$ ,为了确定似然函数,需要知道上述观察结果出现的概率。我们知道一个产品在  $(t_{i}, t_{i} + \mathrm{d}t_{i}]$  失效的概率近似地为  $f(t_{i}) \mathrm{d}t_{i} = \frac{1}{\theta} \mathrm{e}^{- t_{i} / \theta} \mathrm{d}t_{i}, i = 1, 2, \dots , m$ ,其余  $n - m$  个产品寿命超过  $t_{m}$  的概率为  $\left(\int_{t_{m}}^{\infty} \frac{1}{\theta} \mathrm{e}^{- t / \theta} \mathrm{d}t\right)^{n - m} = (\mathrm{e}^{- t_{m} / \theta})^{n - m}$ ,故上述观察结果出现的概率近似地为

$$
\binom{n}{m}\left(\frac{1}{\theta}\mathrm{e}^{-t / \theta}\mathrm{d}t_{1}\right)\left(\frac{1}{\theta}\mathrm{e}^{-t / \theta}\mathrm{d}t_{2}\right)\cdots\left(\frac{1}{\theta}\mathrm{e}^{-t_{m} / \theta}\mathrm{d}t_{m}\right)\left(\mathrm{e}^{-t_{m} / \theta}\right)^{n - m}
$$

$$
= \binom{n}{m}\frac{1}{\theta^{m}}\mathrm{e}^{-\frac{1}{\theta} [t_{1} + t_{2} + \cdots + t_{m} + (n - m)t_{m}]} \mathrm{d}t_{1} \mathrm{d}t_{2} \cdots \mathrm{d}t_{m},
$$

其中  $\mathrm{d}t_{1}, \mathrm{~d}t_{2}, \dots , \mathrm{d}t_{m}$  为常数。因忽略一个常数因子不影响  $\theta$  的最大似然估计,故可取似然函数为

$$
L(\theta) = \frac{1}{\theta^{m}} \mathrm{e}^{-\frac{1}{\theta} [t_{1} + t_{2} + \cdots + t_{m} + (n - m)t_{m}]}.
$$

对数似然函数为

$$
\ln L(\theta) = -m \ln \theta - \frac{1}{\theta} [t_{1} + t_{2} + \dots + t_{m} + (n - m)t_{m}].
$$

$$
\frac{\mathrm{d}}{\mathrm{d}\theta}\ln L(\theta) = -\frac{m}{\theta} +\frac{1}{\theta^{2}}\big[t_{1} + t_{2} + \dots +t_{m} + (n - m)t_{m}\big] = 0.
$$

于是得到  $\theta$  的最大似然估计为

$$
\hat{\theta} = \frac{s(t_{m})}{m}.
$$

其中  $s(t_{m}) = t_{1} + t_{2} + \dots +t_{m} + (n - m)t_{m}$  称为总试验时间,它表示直至时刻  $t_{m}$  为止  $n$  个产品的试验时间的总和.

对于定时截尾样本

$$
0\leqslant t_{1}\leqslant t_{2}\leqslant \dots \leqslant t_{m}\leqslant t_{0}
$$

(其中  $t_{0}$  是截尾时间),与上面的讨论类似,可得似然函数为

$$
L(\theta) = \frac{1}{\theta^{m}}\mathrm{e}^{-\frac{1}{\theta} [t_{1} + t_{2} + \dots +t_{m} + (n - m)t_{0}]},
$$

$\theta$  的最大似然估计为

$$
\hat{\theta} = \frac{s(t_{0})}{m},
$$

其中  $s(t_{0}) = t_{1} + t_{2} + \dots +t_{m} + (n - m)t_{0}$  称为总试验时间,它表示直至时刻  $t_{0}$  为止  $n$  个产品的试验时间的总和.

例设电池的寿命服从指数分布,其概率密度为

$$
f(t) = \left\{ \begin{array}{ll}\frac{1}{\theta}\mathrm{e}^{-t / \theta}, & t > 0, \\ 0, & t\leqslant 0, \end{array} \right.
$$

$\theta >0$  未知.随机地取50只电池投入寿命试验,规定试验进行到其中有15只失效时结束试验,测得失效时间(以h计)为

$$
\begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c} & 115 & 119 & 131 & 138 & 142 & 147 & 148 & 155 & \\ 158 & 159 & 163 & 166 & 167 & 170 & 172 & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ & 158 & 159 & 163 & 166 & 167 & 170 & 172 & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ & 158 & 159 & 163 & 166 & 167 & 170 & 18 & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \end{array}
$$

试求电池的平均寿命  $\theta$  的最大似然估计.

解  $n = 50, m = 15, s(t_{13}) = 115 + 119 + \dots +170 + 172 + (50 - 15)\times 172 = 8270$ ,得  $\theta$  的最大似然估计为

$$
\hat{\theta} = \frac{8270}{15} = 551.33(\mathrm{h}).
$$

# $\S 3$  估计量的评选标准

自前一节可以看到,对于同一参数,用不同的估计方法求出的估计量可能不相同,如 §1 的例2和例6. 而且,很明显,原则上任何统计量都可以作为未知参数的估计量.我们自然会问,采用哪一个估计量为好呢?这就涉及用什么样的标

准来评价估计量的问题. 下面介绍几个常用的标准.

# (一) 无偏性

设  $X_{1}, X_{2}, \dots , X_{n}$  是总体  $X$  的一个样本,  $\theta \in \Theta$  是包含在总体  $X$  的分布中的待估参数, 这里  $\Theta$  是  $\theta$  的取值范围.

无偏性 若估计量  $\hat{\theta} = \hat{\theta} (X_{1}, X_{2}, \dots , X_{n})$  的数学期望  $E(\hat{\theta})$  存在, 且对于任意  $\theta \in \Theta$  有

$$
E(\hat{\theta}) = \theta , \tag{3.1}
$$

则称  $\hat{\theta}$  是  $\theta$  的无偏估计量.

估计量的无偏性是说对于某些样本值, 由这一估计量得到的估计值相对于真值来说偏大, 有些则偏小. 反复将这一估计量使用多次, 就"平均"来说其偏差为零. 在科学技术中  $E(\hat{\theta}) - \theta$  称为以  $\hat{\theta}$  作为  $\theta$  的估计的系统误差. 无偏估计的实际意义就是无系统误差.

例如, 设总体  $X$  的均值  $\mu$ , 方差  $\sigma^{2} > 0$  均未知, 由第六章 (3.19), (3.20) 式知

$$
E(\overline{X}) = \mu , E(S^{2}) = \sigma^{2}.
$$

即不论总体服从什么分布,样本均值  $\overline{{X}}$  是总体均值  $\mu$  的无偏估计;样本方差 $S^{2} = \frac{1}{n - 1}\sum_{i = 1}^{n}(X_{i} - \overline{{X}})^{2}$  是总体方差的无偏估计.而估计量  ${\frac{1}{n}}\sum_{i=1}^{n}(X_{i}- {\overline{{X}}})^{2}$  却不是  $\sigma^{2}$  的无偏估计,因此我们一般取  $S^{2}$  作为  $\sigma^{2}$  的估计量.

例1设总体  $X$  的  $k$  阶矩  $\mu_{k} = E(X^{k})$ $(k\geqslant 1)$  存在,又设  $X_{1},X_{2},\dots ,X_{n}$  是 $X$  的一个样本.试证明不论总体服从什么分布,样本  $k$  阶矩  $A_{k} = \frac{1}{n}\sum_{i = 1}^{n}X_{i}^{k}$  是总体  $k$  阶矩  $\mu_{k}$  的无偏估计量.

证  $X_{1}, X_{2}, \dots , X_{n}$  与  $X$  同分布, 故有

$$
E(X_{i}^{k}) = E(X^{k}) = \mu_{k}, \quad i = 1, 2, \dots , n.
$$

即有

$$
E(A_{k}) = \frac{1}{n} \sum_{i = 1}^{n} E(X_{i}^{k}) = \mu_{k}. \tag{3.2}
$$

例2 设总体  $X$  服从指数分布, 其概率密度为

$$
f(x; \theta) = \left\{ \begin{array}{ll} \frac{1}{\theta} \mathrm{e}^{-x / \theta}, & x > 0, \\ 0, & \text {其他,} \end{array} \right.
$$

其中参数  $\theta > 0$  为未知, 又设  $X_{1}, X_{2}, \dots , X_{n}$  是来自  $X$  的样本, 试证  $\overline{X}$  和  $n Z = n(\min \{X_{1}, X_{2}, \dots , X_{n}\})$  都是  $\theta$  的无偏估计量.

证因为  $E(\overline{X}) = E(X) = \theta$ , 所以  $\overline{X}$  是  $\theta$  的无偏估计量. 而  $Z = \min \{X_{1}, X_{2}, \dots , X_{n}\}$  具有概率密度

$$
f_{\min}(x; \theta) = \left\{ \begin{array}{ll} \frac{n}{\theta} \mathrm{e}^{-n x / \theta}, & x > 0, \\ 0, & \text {其他.} \end{array} \right.
$$

故知  $E(Z) = \frac{\theta}{n}$ ,

$$
E(n Z) = \theta .
$$

即  $n Z$  也是参数  $\theta$  的无偏估计量.

由此可见一个未知参数可以有不同的无偏估计量. 事实上, 在本例中  $X_{1}, X_{2}, \dots , X_{n}$  中的每一个都可以作为  $\theta$  的无偏估计量.

# (二) 有效性

现在来比较参数  $\theta$  的两个无偏估计量  $\hat{\theta}_{1}$  和  $\hat{\theta}_{2}$ , 如果在样本容量  $n$  相同的情况下,  $\hat{\theta}_{1}$  的观察值较  $\hat{\theta}_{2}$  在真值  $\theta$  的附近更密集, 我们就认为  $\hat{\theta}_{1}$  较  $\hat{\theta}_{2}$  更为理想. 由于方差是随机变量取值与其数学期望 (此时数学期望  $E(\hat{\theta}_{1}) = E(\hat{\theta}_{2}) = \theta$ ) 的偏离程度的度量, 所以无偏估计以方差小者为好. 这就引出了估计量的有效性这一概念.

有效性 设  $\hat{\theta}_{1} = \hat{\theta}_{1}(X_{1}, X_{2}, \dots , X_{n})$  与  $\hat{\theta}_{2} = \hat{\theta}_{2}(X_{1}, X_{2}, \dots , X_{n})$  都是  $\theta$  的无偏估计量, 若对于任意  $\theta \in \Theta$ , 有

$$
D(\hat{\theta}_{1}) \leqslant D(\hat{\theta}_{2}),
$$

且至少对于某一个  $\theta \in \Theta$  上式中的不等号成立, 则称  $\hat{\theta}_{1}$  较  $\hat{\theta}_{2}$  有效.

例3(续例2) 试证当  $n > 1$  时,  $\theta$  的无偏估计量  $\overline{X}$  较  $\theta$  的无偏估计量  $n Z$  有效.

证由于  $D(X) = \theta^{2}$  ,故有  $D(\overline{{X}}) = \theta^{2} / n$  .再者,由于  $D(Z) = \theta^{2} / n^{2}$  ,故有 $D(n Z) = \theta^{2}$  .当  $n > 1$  时  $D(n Z) > D(\overline{{X}})$  ,故  $\overline{{X}}$  较  $n Z$  有效. 口

# (三) 相合性

前面讲的无偏性与有效性都是在样本容量  $n$  固定的前提下提出的. 我们自然希望随着样本容量的增大, 一个估计量的值稳定于待估参数的真值. 这样, 对估计量又有下述相合性的要求.

相合性 设  $\hat{\theta} (X_{1}, X_{2}, \dots , X_{n})$  为参数  $\theta$  的估计量, 若对于任意  $\theta \in \Theta$ , 当  $n \rightarrow \infty$

时  $\hat{\theta} (X_{1},X_{2},\dots ,X_{n})$  依概率收敛于  $\theta$  ,则称  $\hat{\theta}$  为  $\theta$  的相合估计量.

即,若对于任意  $\theta \in \Theta$  都满足:对于任意  $\epsilon >0$  ,有

$$
\lim_{n\to \infty}P\{\mid \hat{\theta} -\theta \mid < \epsilon \} = 1,
$$

则称  $\hat{\theta}$  是  $\theta$  的相合估计量.

例如由第六章  $\S 3$  知,样本  $k(k\geqslant 1)$  阶矩是总体  $X$  的  $k$  阶矩  $\mu_{k} = E(X^{k})$  的相合估计量,进而若待估参数  $\theta = g(\mu_{1},\mu_{2},\dots ,\mu_{k})$  ,其中  $g$  为连续函数,则  $\theta$  的矩估计量  $\hat{\theta} = g(\hat{\mu}_{1},\hat{\mu}_{2},\dots ,\hat{\mu}_{k}) = g(A_{1},A_{2},\dots ,A_{k})$  是  $\theta$  的相合估计量.

由最大似然估计法得到的估计量,在一定条件下也具有相合性.其详细讨论已超出本书范围,从略.

相合性是对一个估计量的基本要求,若估计量不具有相合性,那么不论将样本容量  $n$  取得多么大,都不能将  $\theta$  估计得足够准确,这样的估计量是不可取的.

上述无偏性、有效性、相合性是评价估计量的一些基本标准,其他的标准这里就不讲了.

# $\S 4$  区间估计

对于一个未知量,人们在测量或计算时,常不以得到近似值为满足,还需估计误差,即要求知道近似值的精确程度(亦即所求真值所在的范围).类似地,对于未知参数  $\theta$  ,除了求出它的点估计  $\hat{\theta}$  外,我们还希望估计出一个范围,并希望知道这个范围包含参数  $\theta$  真值的可信程度.这样的范围通常以区间的形式给出,同时还给出此区间包含参数  $\theta$  真值的可信程度.这种形式的估计称为区间估计,这样的区间即所谓置信区间.现在我们引入置信区间的定义.

置信区间设总体  $X$  的分布函数  $F(x;\theta)$  含有一个未知参数  $\theta ,\theta \in \Theta (\Theta$  是  $\theta$  可能取值的范围),对于给定值  $\alpha$ $(0{<}\alpha {<}1)$  ,若由来自  $X$  的样本  $X_{1},X_{2},\dots ,X_{n}$  确定的两个统计量  $\underline{{\theta}} = \theta (X_{1},X_{2},\dots ,X_{n})$  和  $\bar{\theta}{=}\bar{\theta} (X_{1},X_{2},\dots ,X_{n})$ $(\theta {<}\bar{\theta})$  ,对于任意 $\theta \in \Theta$  满足

$$
P\{\underline{{\theta}} (X_{1},X_{2},\dots ,X_{n}){<}\theta {<}\bar{\theta} (X_{1},X_{2},\dots ,X_{n})\} \geqslant 1 - \alpha , \tag{4.1}
$$

则称随机区间  $(\underline{{\theta}},\bar{\theta})$  是  $\theta$  的置信水平为  $1 - \alpha$  的置信区间  $\theta$  和  $\bar{\theta}$  分别称为置信水平为  $1 - \alpha$  的双侧置信区间的置信下限和置信上限,  $1 - \alpha$  称为置信水平.

当  $X$  是连续型随机变量时,对于给定的  $\alpha$  ,我们总是按要求  $P\{\theta {<}\theta {<}\bar{\theta}\} = 1 - \alpha$  求出置信区间.而当  $X$  是离散型随机变量时,对于给定的  $\alpha$  ,常找不到区间  $(\underline{{\theta}},\bar{\theta})$

使得  $P\{\underline{{\theta}}{<}\theta {<}\overline{{\theta}}\}$  恰为  $1 - \alpha$  .此时我们去找区间  $(\theta ,\overline{{\theta}})$  使得  $P\{\underline{{\theta}}{<}\theta {<}\overline{{\theta}}\}$  至少为 $1 - \alpha$  ,且尽可能地接近  $1 - \alpha$

(4.1)式的含义如下:若反复抽样多次(各次得到的样本的容量相等,都是  $n$ ). 每个样本值确定一个区间  $(\underline{{\theta}}, \overline{{\theta}})$ , 每个这样的区间要么包含  $\theta$  的真值,要么不包含  $\theta$  的真值(参见图 7- 1). 按伯努利大数定律,在这么多的区间中,包含  $\theta$  真值的约占  $100(1 - \alpha)\%$ ,不包含  $\theta$  真值的约仅占  $100\alpha\%$ . 例如,若  $\alpha = 0.01$ ,反复抽样 1000 次,则得到的 1000 个区间中不包含  $\theta$  真值的约仅为 10 个.

例设总体  $X\sim N(\mu ,\sigma^{2}),\sigma^{2}$  为已知,  $\mu$  为未知,设  $X_{1},X_{2},\dots ,X_{n}$  是来自  $X$  的样本,求  $\mu$  的置信水平为  $1 - \alpha$  的置信区间.

解我们知道  $\overline{{X}}$  是  $\mu$  的无偏估计,且有

$$
\frac{\overline{{X}} - \mu}{\sigma / \sqrt{n}}{\sim} N(0,1). \tag{4.2}
$$

$\frac{\overline{{X}} - \mu}{\sigma / \sqrt{n}}$  所服从的分布  $N(0,1)$  不依赖于任何未知参数. 按标准正态分布的上  $\alpha$  分位数的定义,有(参见图 7- 2)

$$
P\left(\left|\frac{\overline{{X}} - \mu}{\sigma / \sqrt{n}}\right|< z_{\alpha /2}\right) = 1 - \alpha , \tag{4.3}
$$

即

$$
P\left\{\overline{{X}} -\frac{\sigma}{\sqrt{n}} z_{\alpha /2}< \mu < \overline{{X}} +\frac{\sigma}{\sqrt{n}} z_{\alpha /2}\right\} = 1 - \alpha . \tag{4.4}
$$

这样,我们就得到了  $\mu$  的一个置信水平为  $1 - \alpha$  的置信区间

$$
\Big(\overline{{X}} -\frac{\sigma}{\sqrt{n}} z_{\alpha /2},\quad \overline{{X}} +\frac{\sigma}{\sqrt{n}} z_{\alpha /2}\Big). \tag{4.5}
$$

这样的置信区间常写成

$$
\Big(\overline{{X}}\pm \frac{\sigma}{\sqrt{n}} z_{\alpha /2}\Big). \tag{4.6}
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图7-1

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图7-2

如果取  $1 - \alpha = 0.95$ , 即  $\alpha = 0.05$ , 又若  $\sigma = 1, n = 16$ , 查表得  $z_{\alpha /2} = z_{0.025} = 1.96$ . 于是我们得到一个置信水平为 0.95 的置信区间

$$
\left(\overline{X} \pm \frac{1}{\sqrt{16}} \times 1.96\right), \quad \text{即} (\overline{X} \pm 0.49). \tag{4.7}
$$

再者, 若由一个样本值算得样本均值的观察值  $\bar{x} = 5.20$ , 则得到一个区间

注意, 这已经不是随机区间了. 但我们仍称它为  $\theta$  的置信水平为 0.95 的置信区间. 其含义是: 若反复抽样多次, 每个样本值  $(n = 16)$  按 (4.7) 式确定一个区间, 按上面的解释, 在这么多的区间中, 包含  $\mu$  的约占  $95\%$ , 不包含  $\mu$  的约仅占  $5\%$ . 现在抽样得到区间 (4.71,5.69), 则该区间属于那些包含  $\mu$  的区间的可信程度为  $95\%$ , 或"该区间包含  $\mu$ "这一陈述的可信程度为  $95\%$ .

置信水平为  $1 - \alpha$  的置信区间并不是唯一的. 以上例来说, 若给定  $\alpha = 0.05$ , 则又有

$$
P\left\{-z_{0.04}< \frac{\overline{X} - \mu}{\sigma / \sqrt{n}} < z_{0.01}\right\} = 0.95,
$$

即  $P\left\{\overline{X} - \frac{\sigma}{\sqrt{n}} z_{0.01}< \mu < \overline{X} +\frac{\sigma}{\sqrt{n}} z_{0.04}\right\} = 0.95.$

故  $\left(\overline{X} - \frac{\sigma}{\sqrt{n}} z_{0.01}, \overline{X} +\frac{\sigma}{\sqrt{n}} z_{0.04}\right)$  (4.8)

也是  $\mu$  的置信水平为 0.95 的置信区间. 我们将它与 (4.5) 式中令  $\alpha = 0.05$  所得的置信水平为 0.95 的置信区间相比较, 可知由 (4.5) 式所确定的区间的长度为  $2 \times \frac{\sigma}{\sqrt{n}} z_{0.025} = 3.92 \times \frac{\sigma}{\sqrt{n}}$ , 这一长度要比区间 (4.8) 式的长度  $\frac{\sigma}{\sqrt{n}} (z_{0.04} + z_{0.01}) = 4.08 \times \frac{\sigma}{\sqrt{n}}$  短. 置信区间短表示估计的精度高. 故由 (4.5) 式给出的区间较 (4.8) 式为优. 易知, 像  $N(0,1)$  分布那样其概率密度的图形是单峰且对称的情况, 当  $n$  固定时, 以形如 (4.5) 式那样的区间其长度为最短, 我们自然选用它.

参考上例可得寻求未知参数  $\theta$  的置信区间的具体做法如下.

$1^{\circ}$  寻求一个样本  $X_{1}, X_{2}, \dots , X_{n}$  和  $\theta$  的函数  $W = W(X_{1}, X_{2}, \dots , X_{n}; \theta)$ , 使得  $W$  的分布不依赖于  $\theta$  以及其他未知参数, 称具有这种性质的函数  $W$  为枢轴量.

$2^{\circ}$  对于给定的置信水平  $1 - \alpha$ , 定出两个常数  $a, b$  使得

$$
P\{a< W(X_{1}, X_{2}, \dots , X_{n}; \theta)< b\} = 1 - \alpha .
$$

若能从  $a< W(X_{1}, X_{2}, \dots , X_{n}; \theta)< b$  得到与之等价的  $\theta$  的不等式  $\underline{\theta} < \theta < \overline{\theta}$ , 其中

$\theta = \underline{\theta} (X_{1},X_{2},\dots ,X_{n}),\bar{\theta} = \bar{\theta} (X_{1},X_{2},\dots ,X_{n})$  都是统计量,那么  $(\underline{\theta},\bar{\theta})$  就是  $\theta$  的一个置信水平为  $1 - \alpha$  的置信区间.

枢轴量  $W(X_{1},X_{2},\dots ,X_{n};\theta)$  的构造,通常可以从  $\theta$  的点估计着手考虑.常用的正态总体的参数的置信区间可以用上述步骤推得.

# $\S 5$  正态总体均值与方差的区间估计

# (一)单个总体  $N(\mu ,\sigma^{2})$  的情况

设已给定置信水平为  $1 - \alpha$  ,并设  $X_{1},X_{2},\dots ,X_{n}$  为总体  $N(\mu ,\sigma^{2})$  的样本.  $\overline{X}$ $S^{2}$  分别是样本均值和样本方差.

1. 均值  $\mu$  的置信区间

(1)  $\sigma^{2}$  为已知,此时由  $\S 4$  例1采用(4.2)式中的枢轴量  $\frac{\overline{X} - \mu}{\sigma / \sqrt{n}}$  ,已得到  $\mu$  的一个置信水平为  $1 - \alpha$  的置信区间为

$$
\Big(\overline{{X}}\pm \frac{\sigma}{\sqrt{n}} z_{a / 2}\Big). \tag{5.1}
$$

(2)  $\sigma^{2}$  为未知,此时不能使用(5.1)式给出的区间,因其中含未知参数  $\sigma$  .考虑到  $S^{2}$  是  $\sigma^{2}$  的无偏估计,将(4.2)式中的  $\sigma$  换成  $S = \sqrt{S^{2}}$  ,由第六章  $\S 3$  定理4,知

$$
\frac{\overline{{X}} - \mu}{S / \sqrt{n}}{\sim} t(n - 1), \tag{5.2}
$$

并且右边的分布  $t(n - 1)$  不依赖于任何未知参数.使用  $\frac{\overline{{X}} - \mu}{S / \sqrt{n}}$  作为枢轴量可得

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图7-3

(参见图7- 3)

$$
P\Bigg\{-t_{a / 2}(n - 1)< \frac{\overline{{X}} - \mu}{S / \sqrt{n}} < t_{a / 2}(n - 1)\Bigg\} = 1 - \alpha , \tag{5.3}
$$

即

$$
P\Bigg\{\overline{{X}} -\frac{S}{\sqrt{n}} t_{a / 2}(n - 1)< \mu < \overline{{X}} +\frac{S}{\sqrt{n}} t_{a / 2}(n - 1)\Bigg\} = 1 - \alpha .
$$

于是得  $\mu$  的一个置信水平为  $1 - \alpha$  的置信区间

$$
\Big(\overline{{X}}\pm \frac{S}{\sqrt{n}} t_{a / 2}(n - 1)\Big). \tag{5.4}
$$

例1有一大批糖果.现从中随机地取16袋,称得质量(以  $\mathbf{g}$  计)如下:

设袋装糖果的质量近似地服从正态分布,试求总体均值  $\mu$  的置信水平为0.95的置信区间.

解这里  $1 - \alpha = 0.95,\alpha /2 = 0.025,n - 1 = 15,t_{0.025}(15) = 2.1315$  ,由给出的数据算得  $\bar{x} = 503.75,s = 6.2022.$  由(5.4)式得均值  $\mu$  的一个置信水平为0.95的置信区间为

$$
\left(503.75\pm \frac{6.2022}{\sqrt{16}}\times 2.1315\right),
$$

即

这就是说估计袋装糖果质量的均值在  $500.4\mathrm{g}$  与  $507.1\mathrm{g}$  之间,这个估计的可信程度为  $95\%$  .若以此区间内任一值作为  $\mu$  的近似值,其误差不大于  $\frac{6.2022}{\sqrt{16}}\times$ $2.1315\times 2 = 6.61(\mathrm{g})$  ,这个误差估计的可信程度为  $95\%$  口

在实际问题中,总体方差  $\sigma^{2}$  未知的情况居多,故区间(5.4)式较区间(5.1)式有更大的实用价值.

2. 方差  $\sigma^{2}$  的置信区间

此处,根据实际问题的需要,只介绍  $\mu$  未知的情况,

$\sigma^{2}$  的无偏估计为  $S^{2}$  ,由第六章  $\S 3$  定理3知

$$
\frac{(n - 1)S^{2}}{\sigma^{2}}\sim \chi^{2}(n - 1), \tag{5.5}
$$

并且上式右端的分布不依赖于任何未知参数,取  $\frac{(n - 1)S^{2}}{\sigma^{2}}$  作为枢轴量,即得(参见图7- 4)

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图7-4

$$
P\left\{\chi_{1 - \alpha /2}^{2}(n - 1)< \frac{(n - 1)S^{2}}{\sigma^{2}}{< \chi_{\alpha /2}^{2}(n - 1)}\right\} = 1 - \alpha , \tag{5.6}
$$

即  $P\left\{\frac{(n - 1)S^{2}}{\chi_{\alpha /2}^{2}(n - 1)}{< \sigma^{2}}{< \frac{(n - 1)S^{2}}{\chi_{1 - \alpha /2}^{2}(n - 1)}}\right\} = 1 - \alpha .$  (5.6)

这就得到方差  $\sigma^{2}$  的一个置信水平为  $1 - \alpha$  的置信区间

$$
\Big(\frac{(n - 1)S^{2}}{\chi_{\alpha /2}^{2}(n - 1)},\frac{(n - 1)S^{2}}{\chi_{1 - \alpha /2}^{2}(n - 1)}\Big). \tag{5.7}
$$

由  $(5.6)^{\prime}$  式,还可得到标准差  $\sigma$  的一个置信水平为  $1 - \alpha$  的置信区间

$$
\left(\frac{\sqrt{n - 1}S}{\sqrt{\chi_{\alpha / 2}^{2}(n - 1)}},\frac{\sqrt{n - 1}S}{\sqrt{\chi_{1 - \alpha / 2}^{2}(n - 1)}}\right). \tag{5.8}
$$

注意,在概率密度函数不对称时,如  $\chi^{2}$  分布和  $F$  分布,习惯上仍是取对称的分位数(如图7一4中的上分位数  $\chi_{1 - \alpha /2}^{2}(n - 1)$  与  $\chi_{\alpha /2}^{2}(n - 1)$ )来确定置信区间的.

例2求例1中总体标准差  $\sigma$  的置信水平为0.95的置信区间.

解现在  $\alpha /2 = 0.025,1 - \alpha /2 = 0.975,n - 1 = 15$  ,查表得  $\chi_{\alpha /\infty}^{2}$  (15)=27.488,  $\chi_{0.975}^{2}(15) = 6.262$  ,又  $s = 6.2022$  ,由(5.8)式得所求的标准差  $\sigma$  的一个置信水平为0.95的置信区间为

# (二)两个总体  $N(\mu_{1},\sigma_{1}^{2}),N(\mu_{2},\sigma_{2}^{2})$  的情况

在实际中常遇到下面的问题:已知产品的某一质量指标服从正态分布,但由于原料、设备条件、操作人员不同,或工艺过程的改变等因素,引起总体均值、总体方差有所改变.我们需要知道这些变化有多大,这就需要考虑两个正态总体均值差或方差比的估计问题.

设已给定置信水平为  $1 - \alpha$  ,并设  $X_{1},X_{2},\dots ,X_{n_{1}}$  是来自第一个总体的样本; $Y_{1},Y_{2},\dots ,Y_{n_{2}}$  是来自第二个总体的样本,这两个样本相互独立.且设  $\overline{{X}},\overline{{Y}}$  分别为第一、第二个总体的样本均值,  $S_{1}^{2},S_{2}^{2}$  分别是第一、第二个总体的样本方差.

1. 两个总体均值差  $\mu_{1} - \mu_{2}$  的置信区间

(1)  $\sigma_{1}^{2},\sigma_{2}^{2}$  均为已知.因  $\overline{{X}},\overline{{Y}}$  分别为  $\mu_{1},\mu_{2}$  的无偏估计,故  $\overline{{X}} -\overline{{Y}}$  是  $\mu_{1} - \mu_{2}$  的无偏估计.由  $\overline{{X}},\overline{{Y}}$  的独立性以及  $\overline{{X}}\sim N(\mu_{1},\sigma_{1}^{2} / n_{1}),\overline{{Y}}\sim N(\mu_{2},\sigma_{2}^{2} / n_{2})$  得

$$
\overline{{X}} -\overline{{Y}}\sim N\Big(\mu_{1} - \mu_{2},\frac{\sigma_{1}^{2}}{n_{1}} +\frac{\sigma_{2}^{2}}{n_{2}}\Big)
$$

或

$$
\frac{(\overline{{X}} - \overline{{Y}}) - (\mu_{1} - \mu_{2})}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}} + \frac{\sigma_{2}^{2}}{n_{2}}}}\sim N(0,1), \tag{5.9}
$$

取(5.9)式左边的函数为枢轴量,即得  $\mu_{1} - \mu_{2}$  的一个置信水平为  $1 - \alpha$  的置信区间

$$
\left(\overline{{X}} -\overline{{Y}}\pm z_{\alpha /2}\sqrt{\frac{\sigma_{1}^{2}}{n_{1}} + \frac{\sigma_{2}^{2}}{n_{2}}}\right). \tag{5.10}
$$

(2)  $\sigma_{1}^{2} = \sigma_{2}^{2} = \sigma^{2}$  ,但  $\sigma^{2}$  为未知.此时,由第六章  $\S 3$  定理5

$$
\frac{(\overline{{X}} - \overline{{Y}}) - (\mu_{1} - \mu_{2})}{S_{w}\sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}}\sim t(n_{1} + n_{2} - 2). \tag{5.11}
$$

取(5.11)式左边的函数为枢轴量,可得  $\mu_{1} - \mu_{2}$  的一个置信水平为  $1 - \alpha$  的置信区间为

$$
\left(\overline{{X}} -\overline{{Y}}\pm t_{\alpha /2}(n_{1} + n_{2} - 2)S_{W}\sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}\right). \tag{5.12}
$$

此处  $S_{W}^{2} = \frac{(n_{1} - 1)S_{1}^{2} + (n_{2} - 1)S_{2}^{2}}{n_{1} + n_{2} - 2},\quad S_{W} = \sqrt{S_{W}^{2}}.$  (5.13)

例3为比较I,Ⅱ两种型号步枪子弹的枪口速度,随机地取I型子弹10发,得到枪口速度的平均值为  $\overline{{x}}_{1} = 500\mathrm{~m / s}$  ,标准差  $s_{1} = 1.10 \mathrm{m / s}$  ,随机地取Ⅱ型子弹20发,得到枪口速度的平均值为  $\overline{{x}}_{2} = 496 \mathrm{m / s}$  ,标准差  $s_{2} = 1.20 \mathrm{m / s}$  .假设两总体都可认为近似地服从正态分布,且由生产过程可认为方差相等.求两总体均值差  $\mu_{1} - \mu_{2}$  的一个置信水平为0.95的置信区间.

解按实际情况,可认为分别来自两个总体的样本是相互独立的.又因假设两总体的方差相等,但数值未知,故可用(5.12)式求均值差的置信区间.由于 $1 - \alpha = 0.95,\alpha /2 = 0.025,n_{1} = 10,n_{2} = 20,n_{1} + n_{2} - 2 = 28,t_{0.025}(28) = 2.0484.$ $s_{w}^{2} = (9\times 1.10^{2} + 19\times 1.20^{2}) / 28,s_{w} = \sqrt{s_{w}^{2}} = 1.1688$  ,故所求的两总体均值差 $\mu_{1} - \mu_{2}$  的一个置信水平为0.95的置信区间是

$$
\left(\overline{{x}}_{1} - \overline{{x}}_{2}\pm s_{w}\times t_{0.025}(28)\sqrt{\frac{1}{10} + \frac{1}{20}}\right) = (4\pm 0.93),
$$

即 (3.07,4.93).

本题中得到的置信区间的下限大于零,在实际中我们就认为  $\mu_{1}$  比  $\mu_{2}$  大.

例4为提高某一化学生产过程的得率,试图采用一种新的催化剂.为慎重起见,在实验工厂先进行试验.设采用原来的催化剂进行了  $n_{1} = 8$  次试验,得到得率的平均值  $\overline{{x}}_{1} = 91.73$  ,样本方差  $s_{1}^{2} = 3.89$  ;又采用新的催化剂进行了  $n_{2} = 8$  次试验,得到得率的平均值  $\overline{{x}}_{2} = 93.75$  ,样本方差  $s_{2}^{2} = 4.02$  .假设两总体都可认为服从正态分布,且方差相等,两样本独立.试求两总体均值差  $\mu_{1} - \mu_{2}$  的置信水平为0.95的置信区间.

解现在

$$
s_{w}^{2} = \frac{(n_{1} - 1)s_{1}^{2} + (n_{2} - 1)s_{2}^{2}}{n_{1} + n_{2} - 2} = 3.96,\quad s_{w} = \sqrt{3.96}.
$$

由(5.12)式得所求的置信区间为

$$
\left(\overline{{x}}_{1} - \overline{{x}}_{2}\pm t_{0.025}(14)s_{w}\sqrt{\frac{1}{8} + \frac{1}{8}}\right) = (-2.02\pm 2.13),
$$

即 (- 4.15,0.11).

由于所得置信区间包含零,在实际中我们就认为采用这两种催化剂所得的得率的均值没有显著差别. 口

2. 两个总体方差比  $\sigma_{1}^{2} / \sigma_{2}^{2}$  的置信区间

我们仅讨论总体均值  $\mu_{1}, \mu_{2}$  均为未知的情况,由第六章 §3 定理 5

$$
\frac{S_{1}^{2} / S_{2}^{2}}{\sigma_{1}^{2} / \sigma_{2}^{2}} \sim F(n_{1} - 1, n_{2} - 1), \tag{5.14}
$$

并且分布  $F(n_{1} - 1, n_{2} - 1)$  不依赖任何未知参数.取  $\frac{S_{1}^{2} / S_{2}^{2}}{\sigma_{1}^{2} / \sigma_{2}^{2}}$  为枢轴量得

$$
P\left\{F_{1 - \alpha /2}(n_{1} - 1, n_{2} - 1) < \frac{S_{1}^{2} / S_{2}^{2}}{\sigma_{1}^{2} / \sigma_{2}^{2}} < F_{\alpha /2}(n_{1} - 1, n_{2} - 1)\right\} = 1 = \alpha ,
$$

(5.15)

即

$$
P\left\{\frac{S_{1}^{2}}{S_{2}^{2}} \frac{1}{F_{\alpha / 2}(n_{1} - 1, n_{2} - 1)} < \frac{\sigma_{1}^{2}}{\sigma_{2}^{2}} < \frac{S_{1}^{2}}{S_{2}^{2}} \frac{1}{F_{1 - \alpha / 2}(n_{1} - 1, n_{2} - 1)}\right\} = 1 - \alpha .
$$

(5.15)

于是得  $\sigma_{1}^{2} / \sigma_{2}^{2}$  的一个置信水平为  $1 - \alpha$  的置信区间为

$$
\left(\frac{S_{1}^{2}}{S_{2}^{2}} \frac{1}{F_{\alpha / 2}(n_{1} - 1, n_{2} - 1)}, \frac{S_{1}^{2}}{S_{2}^{2}} \frac{1}{F_{1 - \alpha / 2}(n_{1} - 1, n_{2} - 1)}\right). \tag{5.16}
$$

例5研究由机器  $A$  和机器  $B$  生产的钢管的内径(以  $\mathrm{mm}$  计),随机抽取机器  $A$  生产的管子18只,测得样本方差  $s_{1}^{2} = 0.34$  ;抽取机器  $B$  生产的管子13只,测得样本方差  $s_{2}^{2} = 0.29$  .设两样本相互独立,且设由机器  $A$  ,机器  $B$  生产的管子的内径分别服从正态分布  $N(\mu_{1}, \sigma_{1}^{2}), N(\mu_{2}, \sigma_{2}^{2})$  ,这里  $\mu_{i}, \sigma_{i}^{2}(i = 1,2)$  均未知.试求方差比  $\sigma_{1}^{2} / \sigma_{2}^{2}$  的置信水平为0.90的置信区间.

解现在  $n_{1} = 18, s_{1}^{2} = 0.34, n_{2} = 13, s_{2}^{2} = 0.29, \alpha = 0.10, F_{\alpha /2}(n_{1} - 1, n_{2} - 1) = F_{0.05}(17,12) = 2.59, F_{1 - \alpha /2}(17,12) = F_{0.95}(17,12) = \frac{1}{F_{0.05}(12,17)} = \frac{1}{2.38}$ ,于是由(5.16)式得  $\sigma_{1}^{2} / \sigma_{2}^{2}$  的一个置信水平为0.90的置信区间为

$$
\left(\frac{0.34}{0.29} \times \frac{1}{2.59}, \frac{0.34}{0.29} \times 2.38\right),
$$

即 (0.45,2.79).

由于  $\sigma_{1}^{2} / \sigma_{2}^{2}$  的置信区间包含1,在实际中我们就认为  $\sigma_{1}^{2}, \sigma_{2}^{2}$  两者没有显著差别.

# §6 (0-1)分布参数的区间估计

设有一容量  $n > 50$  的大样本,它来自(0- 1)分布的总体  $X, X$  的分布律为

$$
f(x; p) = p^{x}(1 - p)^{1 - x}, \quad x = 0, 1, \tag{6.1}
$$

其中  $\boldsymbol{\mathscr{p}}$  为未知参数.现在来求  $\boldsymbol{\mathscr{p}}$  的置信水平为  $1 - \alpha$  的置信区间.

已知(0一1)分布的均值和方差分别为

$$
\mu = \phi ,\quad \sigma^{2} = \phi (1 - \phi). \tag{6.2}
$$

设  $X_{1},X_{2},\dots ,X_{n}$  是一个样本.因样本容量  $n$  较大,由中心极限定理,知

$$
\frac{\sum_{i = 1}^{n}X_{i} - n p}{\sqrt{n p(1 - p)}} = \frac{n\overline{{X}} - n p}{\sqrt{n p(1 - p)}} \tag{6.3}
$$

近似地服从  $N(0,1)$  分布,于是有

$$
P\left\{-z_{a / 2}< \frac{n\overline{{X}} - n p}{\sqrt{n p(1 - p)}} < z_{a / 2}\right\} \approx 1 - \alpha . \tag{6.4}
$$

而不等式  $- z_{a / 2}< \frac{n\overline{{X}} - n p}{\sqrt{n p(1 - p)}} < z_{a / 2}$  (6.5)

等价于

$$
(n + z_{a / 2}^{2})p^{2} - (2n\overline{{X}} +z_{a / 2}^{2})p + n\overline{{X}}^{2}< 0. \tag{6.6}
$$

记  $\scriptstyle{p_{1} = \frac{1}{2a} (- b - \sqrt{b^{2} - 4a c}),}$  (6.7)

$$
p_{2} = \frac{1}{2a} (-b + \sqrt{b^{2} - 4a c}), \tag{6.8}
$$

此处  $a = n + z_{a / 2}^{2},b = - (2n\overline{{X}} +z_{a / 2}^{2}),c = n\overline{{X}}^{2}$  .于是由(6.5)式得  $\boldsymbol{\mathscr{p}}$  的一个近似的置信水平为  $1 - \alpha$  的置信区间为

$$
(p_{1},p_{2}).
$$

例设自一大批产品的100个样品中,得一级品60个,求这批产品的一级品率  $\boldsymbol{\mathscr{p}}$  的置信水平为0.95的置信区间.

解一级品率  $\boldsymbol{\mathscr{p}}$  是(0一1)分布的参数,此处  $n = 100,\overline{{x}} = 60 / 100 = 0.6,1 - \alpha =$ $0.95,\alpha /2 = 0.025,z_{a / 2} = 1.96$  ,按(6.7),(6.8)式来求  $\boldsymbol{\mathscr{p}}$  的置信区间,其中

$$
a = n + z_{a / 2}^{2} = 103.84,\quad b = -(2n\overline{{x}} +z_{a / 2}^{2}) = -123.84,\quad c = n\overline{{x}}^{2} = 36.
$$

于是  $\scriptstyle{p_{1} = 0.50,\qquad p_{2} = 0.69. }$

故得  $\boldsymbol{\mathscr{p}}$  的一个置信水平为0.95的近似置信区间为

(0.50,0.69).

# $\S 7$  单侧置信区间

在上述讨论中,对于未知参数  $\theta$  ,我们给出两个统计量  $\theta ,\bar{\theta}$  ,得到  $\theta$  的双侧置信区间  $(\theta ,\bar{\theta})$  .但在某些实际问题中,例如,对于设备、元件的寿命来说,平均寿命长是我们所希望的,我们关心的是平均寿命  $\theta$  的"下限";与之相反,在考虑化学药品中杂

质含量的均值  $\mu$  时,我们常关心参数  $\mu$  的"上限"。这就引出了单侧置信区间的概念。

对于给定值  $\alpha (0< \alpha < 1)$ ,若由样本  $X_{1}, X_{2}, \dots , X_{n}$  确定的统计量  $\underline{\theta} = \underline{\theta} (X_{1}, X_{2}, \dots , X_{n})$ ,对于任意  $\theta \in \Theta$  满足

$$
P\{\theta >\underline{\theta}\} \geqslant 1 - \alpha , \tag{7.1}
$$

称随机区间  $(\theta , \infty)$  是  $\theta$  的置信水平为  $1 - \alpha$  的单侧置信区间,  $\theta$  称为  $\theta$  的置信水平为  $1 - \alpha$  的单侧置信下限。

又若统计量  $\bar{\theta} = \bar{\theta} (X_{1}, X_{2}, \dots , X_{n})$ ,对于任意  $\theta \in \Theta$  满足

$$
P\{\theta < \bar{\theta}\} \geqslant 1 - \alpha , \tag{7.2}
$$

称随机区间  $(- \infty , \bar{\theta})$  是  $\theta$  的置信水平为  $1 - \alpha$  的单侧置信区间,  $\bar{\theta}$  称为  $\theta$  的置信水平为  $1 - \alpha$  的单侧置信上限。

例如对于正态总体  $X$  ,若均值  $\mu$  ,方差  $\sigma^{2}$  均为未知,设  $X_{1},X_{2},\dots ,X_{n}$  是一个样本,由

$$
\frac{\overline{X} - \mu}{S / \sqrt{n}} \sim t(n - 1)
$$

有(见图7- 5)

$$
P\left\{\frac{\overline{X} - \mu}{S / \sqrt{n}} < t_{\alpha}(n - 1)\right\} = 1 - \alpha ,
$$

即  $P\left\{\mu > X - \frac{S}{\sqrt{n}} t_{\alpha}(n - 1)\right\} = 1 - \alpha .$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图7-5

于是得到  $\mu$  的置信水平为  $1 - \alpha$  的单侧置信区间

$$
\left(\overline{X} - \frac{S}{\sqrt{n}} t_{\alpha}(n - 1), \infty\right). \tag{7.3}
$$

$\mu$  的置信水平为  $1 - \alpha$  的单侧置信下限为

$$
\mu = \overline{X} - \frac{S}{\sqrt{n}} t_{\alpha}(n - 1). \tag{7.4}
$$

又由

$$
\frac{(n - 1)S^{2}}{\sigma^{2}} \sim \chi^{2}(n - 1),
$$

有(见图7- 6)

即

$$
\begin{array}{r l} & {P\Bigg\{\frac{(n - 1)S^{2}}{\sigma^{2}}{>}\chi_{1 - \alpha}^{2}(n - 1)\Bigg\} = 1 - \alpha ,}\\ & {\quad P\Bigg\{\sigma^{2}{<}\frac{(n - 1)S^{2}}{\chi_{1 - \alpha}^{2}(n - 1)}\Bigg\} = 1 - \alpha .} \end{array}
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图7-6

于是得  $\sigma^{2}$  的置信水平为  $1 - \alpha$  的单侧置信区间

$$
\left(0, \frac{(n - 1) S^{2}}{\chi_{1 - \alpha}^{2}(n - 1)}\right). \tag{7.5}
$$

$\sigma^{2}$  的置信水平为  $1 - \alpha$  的单侧置信上限为

$$
\overline{\sigma^{2}} = \frac{(n - 1) S^{2}}{\chi_{1 - \alpha}^{2}(n - 1)}. \tag{7.6}
$$

例从一批灯泡中随机地取5只作寿命试验,测得寿命(以h计)为

设灯泡寿命服从正态分布.求灯泡寿命均值的置信水平为0.95的单侧置信下限.

解  $1 - \alpha = 0.95, n = 5, t_{\alpha}(n - 1) = t_{0.05}(4) = 2.1318, \bar{x} = 1160, s^{2} = 9950$ . 由(7.4)式得所求单侧置信下限为

$$
\mu = \bar{x} - \frac{s}{\sqrt{n}} t_{\alpha}(n - 1) = 1065.
$$

小结

参数估计问题分为点估计和区间估计.点估计是适当地选择一个统计量作为未知参数的估计(称为估计量),若已取得一样本,将样本值代入估计量,得到估计量的值,以估计量的值作为未知参数的近似值(称为估计值).

本章介绍了两种求点估计的方法:矩估计法和最大似然估计法,

矩估计法的做法是:以样本矩作为总体矩的估计量,而以样本矩的连续函数作为相应的总体矩的连续函数的估计量,从而得到总体未知参数的估计.

最大似然估计法的基本想法是,若已观察到样本  $(X_{1}, X_{2}, \dots , X_{n})$  的样本值  $(x_{1}, x_{2}, \dots ,$

$x_{n}$  ),而取到这一样本值的概率为  $\boldsymbol{\mathscr{p}}$  (在离散型的情况),或  $(X_{1},X_{2},\dots ,X_{n})$  落在这一样本值 $(x_{1},x_{2},\dots ,x_{n})$  的邻域内的概率为  $\boldsymbol{\mathscr{p}}$  (在连续型的情况),而  $\boldsymbol{\mathscr{p}}$  与未知参数有关,我们就取  $\theta$  的估计值使概率  $\boldsymbol{\mathscr{p}}$  取到最大.

对于一个未知参数可以提出不同的估计量,因此自然提出比较估计量的好坏的问题,这就需要给出评定估计量好坏的标准.估计量是一个随机变量,对于不同的样本值,一般给出参数的不同估计值.因而在考虑估计量的好坏时,应从某种整体性能去衡量,而不能看它在个别样本之下表现如何.本章介绍了三个标准:无偏性、有效性和相合性.相合性是对估计量的一个基本要求,不具备相合性的估计量,我们一般是不考虑的.

点估计不能反映估计的精度,我们引人了区间估计.置信区间是一个随机区间  $(\underline{{\theta}},\overline{{\theta}})$  ,它覆盖未知参数具有预先给定的高概率(置信水平),即对于任意  $\theta \in \theta$  ,有

$$
P\{\theta < \theta < \overline{{\theta}}\} \geqslant 1 - \alpha .
$$

例如,对于正态分布  $N(\mu ,\sigma^{2}),\sigma^{2}$  未知,可得  $\mu$  的一个置信水平为  $1 - \alpha$  的置信区间为

$$
\left(\overline{{X}} -t_{\alpha /2}(n - 1)\frac{S}{\sqrt{n}},\quad \overline{{X}} +t_{\alpha /2}(n - 1)\frac{S}{\sqrt{n}}\right), \tag{5.4}
$$

就是说这一随机区间覆盖  $\mu$  的概率  $\geqslant 1 - \alpha$  .一旦有了一个样本值  $x_{1},x_{2},\dots ,x_{n}$  ,将它代入(5.4)式,得到一个数字区间

$$
\left(\bar{x} -t_{\alpha /2}(n - 1)\frac{s}{\sqrt{n}},\quad \bar{x} +t_{\alpha /2}(n - 1)\frac{s}{\sqrt{n}}\right)\overset {\mathrm{i}\overline{{\mathbb{E}}}\mathbb{E}}{=} (-c,c),
$$

$(- c,c)$  也称为  $\mu$  的置信水平为  $1 - \alpha$  的置信区间,意指"  $(- c,c)$  包含  $\mu$  "这一陈述的可信程度为  $1 - \alpha$  ,如果将这事实写成  $P\{- c< \mu < c\} = 1 - \alpha$  是错误的,因为  $(- c,c)$  是一个数字区间,要么有  $\mu \in (- c,c)$  ,此时  $P\{- c< \mu < c\} = 1$  ;要么有  $\mu \notin (- c,c)$  ,此时  $P\{- c< \mu < c\} = 0$

本章还介绍了单侧置信区间,例如,对于正态分布  $N(\mu ,\sigma^{2}),\sigma^{2}$  未知,可得  $\mu$  的置信水平为  $1 - \alpha$  的单侧置信区间为

(i)  $\left(-\infty ,\quad \overline{{X}} +t_{\alpha}(n - 1)\frac{S}{\sqrt{n}}\right)$  单侧置信上限为  $\overline{{\mu}} = \overline{{X}} +t_{\alpha}(n - 1)\frac{S}{\sqrt{n}}.$

(ii)  $\left(\overline{{X}} - t_{\alpha}(n - 1)\frac{S}{\sqrt{n}},\quad \infty\right)$  单侧置信下限为  $\underline{{\mu}} = \overline{{X}} - t_{\alpha}(n - 1)\frac{S}{\sqrt{n}}.$

在形式上,只需将置信区间(5.4)式的上下限中的"  $\alpha /2^{\prime \prime}$  改成"  $\alpha^{\prime \prime}$  ,就得到相应的单侧置信上下限了.

# 重要术语及主题

矩估计量 最大似然估计量

估计量的评选标准:无偏性、有效性、相合性

参数  $\theta$  的置信水平为  $1 - \alpha$  的置信区间 枢轴量

参数  $\theta$  的单侧置信上限和单侧置信下限

单个正态总体均值、方差的置信区间、单侧置信上限与单侧置信下限(见表7一1)

两个正态总体均值差、方差比的置信区间、单侧置信上限与单侧置信下限(见表7一1)

1-7  

<table><tr><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2&lt;ftd&gt;单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2&lt;f摇</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2&lt;f</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2&lt;f_f</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2&lt;f.f</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2&lt;fecel&gt;</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>单位：m2</td><td>F</td><td>S1/S2</td><td>F2/S3</td><td>F3/S4</td><td>F4/S5</td><td>F5/S6</td><td>F6/S7</td><td>F7/S8</td><td>F8/S9</td><td>F9/S10</td><td>F10/S11</td><td>F11/S12</td><td>F12/S13</td><td>F14/S14</td><td>F15/S15</td><td>F16/S16</td><td>F17/S17</td><td>F18/S18</td><td>F19/S19</td><td>F20/S20</td><td>F21/S21</td><td>F22/S22</td><td>F23/S23</td><td>F24/S24</td><td>F25/S25</td><td>F26/S26</td><td>F27/S27</td><td>F28/S28</td><td>F29/S29</td><td>F30/S30</td><td>F31/S31</td><td>F32/S32</td><td>F33/S33</td><td>F34/S34</td><td>F35/S35</td><td>F36/S36</td><td>F37/S37</td><td>F38/S38</td><td>F39/S39</td><td>F40/S40</td><td>F41/S41</td><td>F42/S42</td><td>F43/S43</td><td>F44/S44</td><td>F45/S45</td><td>F46/S46</td><td>F47/S47</td><td>F48/S48</td><td>F49/S49</td><td>F50/S50</td><td>F51/S51</td><td>F52/S52</td><td>F53/S53</td><td>F54/S54</td><td>F55/S55</td><td>F56/S56</td><td>F57/S57</td><td>F58/S58</td><td>F59/S59</td><td>F60/S60</td><td>F61/S61</td><td>F62/S62</td><td>F63/S63</td><td>F64/S64</td><td>F65/S65</td><td>F66/S66</td><td>F67/S67</td><td>F68/S68</td><td>F69/S69</td><td>F70/S70</td><td>F71/S71</td><td>F72/S72</td><td>F73/S73</td><td>F74/S74</td><td>F75/S75</td><td>F76/S76</td><td>F77/S77</td><td>F78/S78</td><td>F79/S79</td><td>F80/S80</td><td>F81/S81</td><td>F82/S82</td><td>F83/S83</td><td>F84/S84</td><td>F85/S85</td><td>F86/S86</td><td>F87/S87</td><td>F88/S88</td><td>F89/S89</td><td>F90/S90</td><td>F91/S91</td><td>F92/S92</td><td>F93/S93</td><td>F94/S94</td><td>F95/S95</td><td>F96/S96</td><td>F97/S97</td><td>F98/S98</td><td>F99/S99</td><td>F100/S100</td><td>F101/S101</td><td>F102/S102</td><td>F103/S103</td><td>F104/S104</td><td>F105/S105</td><td>F106/S106</td><td>F107/S107</td><td>F108/S108</td><td>F109/S109</td><td>F110/S110</td><td>F111/S111</td><td>F112/S112</td><td>F113/S113</td><td>F114/S114</td><td>F115/S115</td><td>F116/S116</td><td>F117/S117</td><td>F118/S118</td><td>F119/S119</td><td>F120/S120</td><td>F121/S121</td><td>F122/S122</td><td>F123/S123</td><td>F124/S124</td><td>F125/S125</td><td>F126/S126</td><td>F127/S127</td><td>F128/S128</td><td>F129/S129</td><td>F130/S130</td><td>F131/S131</td><td>F132/S132</td><td>F133/S133</td><td>F134/S134</td><td>F135/S135</td><td>F136/S136</td><td>F137/S137</td><td>F138/S138</td><td>F139/S139</td><td>F140/S140</td><td>F141/S141</td><td>F142/S142</td><td>F143/S143</td><td>F144/S144</td><td>F145/S145</td><td>F146/S146</td><td>F147/S147</td><td>F148/S148</td><td>F149/S149</td><td>F150/S150</td><td>F151/S151</td><td>F152/S152</td><td>F153/S153</td><td>F154/S154</td><td>F155/S155</td><td>F156/S156</td><td>F157/S157</td><td>F158/S158</td><td>F159/S159</td><td>F160/S160</td><td>F161/S161</td><td>F162/S162</td><td>F163/S163</td><td>F164/S164</td><td>F165/S165</td><td>F166/S166</td><td>F167/S167</td><td>F168/S168</td><td>F169/S169</td><td>F170/S170</td><td>F171/S171</td><td>F172/S172</td><td>F173/S173</td><td>F174/S174</td><td>F175/S175</td><td>F176/S176</td><td>F177/S177</td><td>F178/S178</td><td>F179/S179</td><td>F180/S180</td><td>F181/S181</td><td>F182/S182</td><td>F183/S183</td><td>F184/S184</td><td>F185/S185</td><td>F186/S186</td><td>F187/S187</td><td>F188/S188</td><td>F189/S189</td><td>F190/S190</td><td>F191/S191</td><td>F192/S192</td><td>F193/S193</td><td>F194/S194</td><td>F195/S195</td><td>F196/S196</td><td>F197/S197</td><td>F198/S198</td><td>F199/S199</td><td>F200/S200</td><td>F201/S201</td><td>F202/S202</td><td>F203/S203</td><td>F204/S204</td><td>F205/S205</td><td>F206/S206</td><td>F207/S207</td><td>F208/S208</td><td>F209/S209</td><td>F210/S210</td><td>F211/S211</td><td>F212/S212</td><td>F213/S213</td><td>F214/S214</td><td>F215/S215</td><td>F216/S216</td><td>F217/S217</td><td>F218/S218</td><td>F219/S219</td><td>F220/S220</td><td>F221/S221</td><td>F222/S222</td><td>F223/S223</td><td>F224/S224</td><td>F225/S225</td><td>F226/S226</td><td>F227/S227</td><td>F228/S228</td><td>F229/S229</td><td>F230/S230</td><td>F231/S231</td><td>F232/S232</td><td>F233/S233</td><td>F234/S234</td><td>F235/S235</td><td>F236/S236</td><td>F237/S237</td><td>F238/S238</td><td>F239/S239</td><td>F240/S240</td><td>F241/S241</td><td>F242/S242</td><td>F243/S243</td><td>F244/S244</td><td>F245/S245</td><td>F246/S246</td><td>F247/S247</td><td>F248/S248</td><td>F249/S249</td><td>F250/S250</td><td>F251/S251</td><td>F252/S252</td><td>F253/S253</td><td>F254/S254</td><td>F255/S255</td><td>F256/S256</td><td>F257/S257</td><td>F258/S258</td><td>F259/S259</td><td>F260/S260</td><td>F261/S261</td><td>F262/S262</td><td>F263/S263</td><td>F264/S264</td><td>F265/S265</td><td>F266/S266</td><td>F267/S267</td><td>F268/S268</td><td>F269/S269</td><td>F270/S270</td><td>F271/S271</td><td>F272/S272</td><td>F273/S273</td><td>F274/S274</td><td>F275/S275</td><td>F276/S276</td><td>F277/S277</td><td>F278/S278</td><td>F279/S279</td><td>F280/S280</td><td>F281/S281</td><td>F282/S282</td><td>F283/S283</td><td>F284/S284</td><td>F285/S285</td><td>F286/S286</td><td>F287/S287</td><td>F288/S288</td><td>F289/S289</td><td>F290/S290</td><td>F291/S291</td><td>F292/S292</td><td>F293/S293</td><td>F294/S294</td><td>F295/S295</td><td>F296/S296</td><td>F297/S297</td><td>F298/S298</td><td>F299/S299</td><td>F300/S300</td><td>F301/S301</td><td>F302/S302</td><td>F303/S303</td><td>F304/S304</td><td>F305/S305</td><td>F306/S306</td><td>F307/S307</td><td>F308/S308</td><td>F309/S309</td><td>F310/S310</td><td>F311/S311</td><td>F312/S312</td><td>F313/S313</td><td>F314/S314</td><td>F315/S315</td><td>F316/S316</td><td>F317/S317</td><td>F318/S318</td><td>F319/S319</td><td>F320/S320</td><td>F321/S321</td><td>F322/S322</td><td>F323/S323</td><td>F324/S324</td><td>F325/S325</td><td>F326/S326</td><td>F327/S327</td><td>F328/S328</td><td>F329/S329</td><td>F330/S330</td><td>F331/S331</td><td>F332/S332</td><td>F333/S333</td><td>F334/S334</td><td>F335/S335</td><td>F336/S336</td><td>F337/S337</td><td>F338/S338</td><td>F339/S339</td><td>F340/S340</td><td>F341/S341</td><td>F342/S342</td><td>F343/S343</td><td>F344/S344</td><td>F345/S345</td><td>F346/S346</td><td>F347/S347</td><td>F348/S348</td><td>F349/S349</td><td>F350/S350</td><td>F351/S351</td><td>F352/S352</td><td>F353/S353</td><td>F354/S354</td><td>F355/S355</td><td>F356/S356</td><td>F357/S357</td><td>F358/S358</td><td>F359/S359</td><td>F360/S360</td><td>F361/S361</td><td>F362/S362</td><td>F363/S363</td><td>F364/S364</td><td>F365/S365</td><td>F366/S366</td><td>F367/S367</td><td>F368/S368</td><td>F369/S369</td><td>F370/S370</td><td>F371/S371</td><td>F372/S372</td><td>F373/S373</td><td>F374/S374</td><td>F375/S375</td><td>F376/S376</td><td>F377/S377</td><td>F378/S378</td><td>F379/S379</td><td>F380/S380</td><td>F381/S381</td><td>F382/S382</td><td>F383/S383</td><td>F384/S384</td><td>F385/S385</td><td>F386/S386</td><td>F387/S387</td><td>F388/S388</td><td>F389/S389</td><td>F390/S390</td><td>F391/S391</td><td>F392/S392</td><td>F393/S393</td><td>F394/S394</td><td>F395/S395</td><td>F396/S396</td><td>F397/S397</td><td>F398/S398</td><td>F399/S399</td><td>F400/S400</td><td>F401/S401</td><td>F402/S402</td><td>F403/S403</td><td>F404/S404</td><td>F405/S405</td><td>F406/S406</td><td>F407/S407</td><td>F408/S408</td><td>F409/S409</td><td>F410/S410</td><td>F411/S411</td><td>F412/S412</td><td>F413/S413</td><td>F414/S414</td><td>F415/S415</td><td>F416/S416</td><td>F417/S417</td><td>F418/S418</td><td>F419/S419</td><td>F420/S420</td><td>F421/S421</td><td>F422/S422</td><td>F423/S423</td><td>F424/S424</td><td>F425/S425</td><td>F426/S426</td><td>F427/S427</td><td>F428/S428</td><td>F429/S429</td><td>F430/S430</td><td>F431/S431</td><td>F432/S432</td><td>F433/S433</td><td>F434/S434</td><td>F435/S435</td><td>F436/S436</td><td>F437/S437</td><td>F438/S438</td><td>F439/S439</td><td>F440/S440</td><td>F441/S441</td><td>F442/S442</td><td>F443/S443</td><td>F444/S444</td><td>F445/S445</td><td>F446/S446</td><td>F447/S447</td><td>F448/S448</td><td>F449/S449</td><td>F450/S450</td><td>F451/S451</td><td>F452/S452</td><td>F453/S453</td><td>F454/S454</td><td>F455/S455</td><td>F456/S456</td><td>F457/S457</td><td>F458/S458</td><td>F459/S459</td><td>F460/S460</td><td>F461/S461</td><td>F462/S462</td><td>F463/S463</td><td>F464/S464</td><td>F465/S465</td><td>F466/S466</td><td>F467/S467</td><td>F468/S468</td><td>F469/S469</td><td>F470/S470</td><td>F471/S471</td><td>F472/S472</td><td>F473/S473</td><td>F474/S474</td><td>F475/S475</td><td>F476/S476</td><td>F477/S477</td><td>F478/S478</td><td>F479/S479</td><td>F480/S480</td><td>F481/S481</td><td>F482/S482</td><td>F483/S483</td><td>F484/S484</td><td>F485/S485</td><td>F486/S486</td><td>F487/S487</td><td>F488/S488</td><td>F489/S489</td><td>F490/S490</td><td>F491/S491</td><td>F492/S492</td><td>F493/S493</td><td>F494/S494</td><td>F495/S495</td><td>F496/S496</td><td>F497/S497</td><td>F498/S498</td><td>F499/S499</td><td>F500/S500</td><td>F501/S501</td><td>F502/S502</td><td>F503/S503</td><td>F504/S504</td><td>F505/S505</td><td>F506/S506</td><td>F507/S507</td><td>F508/S508</td><td>F509/S509</td><td>F510/S510</td><td>F511/S511</td><td>F512/S512</td><td>F513/S513</td><td>F514/S514</td><td>F515/S515</td><td>F516/S516</td><td>F517/S517</td><td>F518/S518</td><td>F519/S519</td><td>F520/S520</td><td>F521/S521</td><td>F522/S522</td><td>F523/S523</td><td>F524/S524</td><td>F525/S525</td><td>F526/S526</td><td>F527/S527</td><td>F528/S528</td><td>F529/S529</td><td>F530/S530</td><td>F531/S531</td><td>F532/S532</td><td>F533/S533</td><td>F534/S534</td><td>F535/S535</td><td>F536/S536</td><td>F537/S537</td><td>F538/S538</td><td>F539/S539</td><td>F540/S540</td><td>F541/S541</td><td>F542/S542</td><td>F543/S543</td><td>F544/S544</td><td>F545/S545</td><td>F546/S546</td><td>F547/S547</td><td>F548/S548</td><td>F549/S549</td><td>F550/S550</td><td>F551/S551</td><td>F552/S552</td><td>F553/S553</td><td>F554/S554</td><td>F555/S555</td><td>F556/S556</td><td>F557/S557</td><td>F558/S558</td><td>F559/S559</td><td>F560/S560</td><td>F561/S561</td><td>F562/S562</td><td>F563/S563</td><td>F564/S564</td><td>F565/S565</td><td>F566/S566</td><td>F567/S567</td><td>F568/S568</td><td>F569/S569</td><td>F570/S570</td><td>F571/S571</td><td>F572/S572</td><td>F573/S573</td><td>F574/S574</td><td>F575/S575</td><td>F576/S576</td><td>F577/S577</td><td>F578/S578</td><td>F579/S579</td><td>F580/S580</td><td>F581/S581</td><td>F582/S582</td><td>F583/S583</td><td>F584/S584</td><td>F585/S585</td><td>F586/S586</td><td>F587/S587</td><td>F588/S588</td><td>F589/S589</td><td>F590/S590</td><td>F591/S591</td><td>F592/S592</td><td>F593/S593</td><td>F594/S594</td><td>F595/S595</td><td>F596/S596</td><td>F597/S597</td><td>F598/S598</td><td>F599/S599</td><td>F600/S600</td><td>F601/S601</td><td>F602/S602</td><td>F603/S603</td><td>F604/S604</td><td>F605/S605</td><td>F606/S606</td><td>F607/S607</td><td>F608/S608</td><td>F609/S609</td><td>F610/S610</td><td>F611/S611</td><td>F612/S612</td><td>F613/S613</td><td>F614/S614</td><td>F615/S615</td><td>F616/S616</td><td>F617/S617</td><td>F618/S618</td><td>F619/S619</td><td>F620/S620</td><td>F621/S621</td><td>F622/S622</td><td>F623/S623</td><td>F624/S624</td><td>F625/S625</td><td>F626/S626</td><td>F627/S627</td><td>F628/S628</td><td>F629/S629</td><td>F630/S630</td><td>F631/S631</td><td>F632/S632</td><td>F633/S633</td><td>F634/S634</td><td>F635/S635</td><td>F636/S636</td><td>F637/S637</td><td>F638/S638</td><td>F639/S639</td><td>F640/S640</td><td>F641/S641</td><td>F642/S642</td><td>F643/S643</td><td>F644/S644</td><td>F645/S645</td><td>F646/S646</td><td>F647/S647</td><td>F648/S648</td><td>F649/S649</td><td>F650/S650</td><td>F651/S651</td><td>F652/S652</td><td>F653/S653</td><td>F654/S654</td><td>F655/S655</td><td>F656/S656</td><td>F657/S657</td><td>F658/S658</td><td>F659/S659</td><td>F660/S660</td><td>F661/S661</td><td>F662/S662</td><td>F663/S663</td><td>F664/S664</td><td>F665/S665</td><td>F666/S666</td><td>F667/S667</td><td>F668/S668</td><td>F669/S669</td><td>F670/S669</td><td>F671/S661</td><td>F672/S662</td><td>F673/S663</td><td>F674/S664</td><td>F675/S665</td><td>F676/S666</td><td>F677/S667</td><td>F678/S668</td><td>F679/S669</td><td>F680/S669</td><td>F681/S661</td><td>F682/S662</td><td>F683/S663</td><td>F684/S664</td><td>F685/S665</td><td>F686/S666</td><td>F687/S667</td><td>F688/S668</td><td>F689/S669</td><td>F690/S669</td><td>F691/S661</td><td>F692/S662</td><td>F693/S663</td><td>F694/S664</td><td>F695/S665</td><td>F696/S666</td><td>F697/S667</td><td>F698/S668</td><td>F699/S669</td><td>F610/S669</td><td>F611/S661</td><td>F612/S662</td><td>F613/S663</td><td>F614/S664</td><td>F615/S665</td><td>F616/S666</td><td>F617/S667</td><td>F618/S668</td><td>F619/S669</td><td>F620/S620</td><td>F621/S621</td><td>F622/S622</td><td>F623/S623</td><td>F624/S624</td><td>F625/S625</td><td>F626/S626</td><td>F627/S627</td><td>F628/S628</td><td>F629/S630</td><td>F630/S630</td><td>F631/S631</td><td>F632/S632</td><td>F633/S633</td><td>F634/S634</td><td>F635/S635</td><td>F636/S636</td><td>F637/S637</td><td>F638/S638</td><td>F639/S638</td><td>F640/S640</td><td>F641/S641</td><td>F642/S642</td><td>F643/S643</td><td>F644/S644</td><td>F645/S645</td><td>F646/S646</td><td>F647/S647</td><td>F648/S648</td><td>F649/S648</td><td>F650/S650</td><td>F651/S651</td><td>F652/S652</td><td>F653/S653</td><td>F654/S654</td><td>F655/S655</td><td>F656/S656</td><td>F657/S657</td><td>F658/S658</td><td>F659/S658</td><td>F660/S660</td><td>F661/S661</td><td>F662/S662</td><td>F663/S663</td><td>F664/S664</td><td>F665/S665</td><td>F666/S666</td><td>F667/S667</td><td>F668/S668</td><td>F669/S668</td><td>F670/S669</td><td>F671/S661</td><td>F672/S662</td><td>F673/S663</td><td>F674/S664</td><td>F675/S665</td><td>F676/S666</td><td>F677/S667</td><td>F678/S668</td><td>F679/S668</td><td>F680/S669</td><td>F681/S661</td><td>F682/S662</td><td>F683/S663</td><td>F684/S664</td><td>F685/S665</td><td>F686/S666</td><td>F687/S667</td><td>F688/S668</td><td>F689/S668</td><td>F690/S669</td><td>F691/S661</td><td>F692/S662</td><td>F693/S663</td><td>F694/S664</td><td>F695/S665</td><td>F696/S666</td><td>F697/S667</td><td>F698/S668</td><td>F699/S668</td><td>F610/S669</td><td>F611/S661</td><td>F612/S662</td><td>F613/S663</td><td>F614/S664</td><td>F615/S665</td><td>F616/S666</td><td>F617/S667</td><td>F618/S668</td><td>F619/S668</td><td>F620/S620</td><td>F621/S621</td><td>F622/S622</td><td>F623/S623</td><td>F624/S624</td><td>F625/S625</td><td>F626/S626</td><td>F627/S627</td><td>F628/S628</td><td>F629/S632</td><td>F630/S630</td><td>F631/S631</td><td>F632/S632</td><td>F633/S633</td><td>F634/S634</td><td>F635/S635</td><td>F636/S636</td><td>F637/S637</td><td>F638/S638</td><td>F639/S636</td><td>F640/S640</td><td>F641/S641</td><td>F642/S642</td><td>F643/S643</td><td>F644/S644</td><td>F645/S645</td><td>F646/S646</td><td>F647/S647</td><td>F648/S648</td><td>F649/S646</td><td>F650/S650</td><td>F651/S651</td><td>F652/S652</td><td>F653/S653</td><td>F654/S654</td><td>F655/S655</td><td>F656/S656</td><td>F657/S657</td><td>F658/S658</td><td>F659/S656</td><td>F660/S660</td><td>F661/S661</td><td>F662/S662</td><td>F663/S663</td><td>F664/S664</td><td>F665/S665</td><td>F666/S666</td><td>F667/S667</td><td>F668/S668</td><td>F669/S666</td><td>F670/S669</td><td>F671/S661</td><td>F672/S662</td><td>F673/S663</td><td>F674/S664</td><td>F675/S665</td><td>F676/S666</td><td>F677/S667</td><td>F678/S668</td><td>F679/S666</td><td>F680/S669</td><td>F681/S661</td><td>F682/S662</td><td>F683/S663</td><td>F684/S664</td><td>F685/S665</td><td>F686/S666</td><td>F687/S667</td><td>F688/S668</td><td>F689/S666</td><td>F690/S669</td><td>F691/S661</td><td>F692/S662</td><td>F693/S663</td><td>F694/S664</td><td>F695/S665</td><td>F696/S666</td><td>F697/S667</td><td>F698/S668</td><td>F699/S666</td><td>F610/S669</td><td>F611/S661</td><td>F612/S662</td><td>F613/S663</td><td>F614/S664</td><td>F615/S665</td><td>F616/S666</td><td>F617/S667</td><td>F618/S668</td><td>F619/S666</td><td>F620/S620</td><td>F621/S661</td><td>F622/S662</td><td>F623/S663</td><td>F624/S664</td><td>F625/S665</td><td>F626/S666</td><td>F627/S667</td><td>F628/S668</td><td>F629/S632</td><td>F630/S630</td><td>F631/S631</td><td>F632/S632</td><td>F633/S633</td><td>F634/S634</td><td>F635/S635</td><td>F636/S636</td><td>F637/S637</td><td>F638/S6</td></tr></table>

# 习题

1. 随机地取8只活塞环,测得它们的直径为(以  $\mathrm{mm}$  计)

试求总体均值  $\mu$  及方差  $\sigma^{2}$  的矩估计值,并求样本方差  $s^{2}$

2. 设  $X_{1},X_{2},\dots ,X_{n}$  为总体的一个样本,  $x_{1},x_{2},\dots ,x_{n}$  为一相应的样本值.求下列各总体的概率密度或分布律中的未知参数的矩估计量和矩估计值.

(1)  $f(x)={\left\{\begin{array}{l l}{\theta c^{\theta}x^{-(\theta-1)}}\\ {0,}\end{array}\right.}$ $x > c$  (其中  $c > 0$  为已知,  $\theta >1,\theta$  为未知参数.其他,

(2)  $f(x)={\left\{\begin{array}{l l}{\sqrt{\theta}x^{\sqrt{\theta}-1},}&{0\leqslant x\leqslant1,}\\ {0,}&{{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}{\mathrm{~}}}\end{array}\right.}$  其中  $\theta >0,\theta$  为未知参数.其他,

(3)  $P\{X = x\} = \binom{m}{x} p^{x}(1 - p)^{m - x},x = 0,1,2,\dots ,m,$  其中  $0< p< 1,p$  为未知参数.

3. 求上题中各未知参数的最大似然估计值和估计量,

4. (1)设总体  $X$  具有分布律

$$
\frac{X\mid\quad1\quad\quad2\quad\quad3}{p_{k}\mid\quad\theta^{2}\quad2\theta(1-\theta)\quad(1-\theta)^{2}}
$$

其中  $\theta$ $(0< \theta < 1)$  为未知参数.已知取得了样本值  $x_{1} = 1,x_{2} = 2,x_{3} = 1.$  试求  $\theta$  的矩估计值和最大似然估计值.

(2)设  $X_{1},X_{2},\dots ,X_{n}$  是来自参数为  $\lambda$  的泊松分布总体的一个样本,试求  $\lambda$  的最大似然估计量及矩估计量.

(3)设随机变量  $X$  服从以  $r,p$  为参数的负二项分布,其分布律为

$$
P\{X = x_{k}\} = \binom{x_{k} - 1}{r - 1} p^{r}(1 - p)^{x_{k} - r},\quad x_{k} = r,r + 1,\dots ,
$$

其中  $r$  已知,  $\boldsymbol{\mathscr{p}}$  未知.设有样本值  $x_{1},x_{2},\dots ,x_{n}$  ,试求  $\boldsymbol{\mathscr{p}}$  的最大似然估计值.

5. 设某种电子器件的寿命(以  $\mathrm{h}$  计)T服从双参数的指数分布,其概率密度为

$$
f(t) = \left\{ \begin{array}{l l}{\frac{1}{\theta}\mathrm{e}^{-(t - c) / \theta},} & {t\geqslant c,}\\ {0,} & {\mathrm{~}\mathbb{H}\backslash \mathbb{H},} \end{array} \right.
$$

其中  $c$  ,  $\theta$ $(c,\theta >0)$  为未知参数.自一批这种器件中随机地取  $n$  件进行寿命试验.设它们的失效时间依次为  $x_{1}\leqslant x_{2}\leqslant \dots \leqslant x_{n}$

(1)求  $c$  与  $\theta$  的最大似然估计值.

(2)求  $c$  与  $\theta$  的矩估计量.

6. 一地质学家为研究密歇根湖湖滩地区的岩石成分,随机地自该地区取100个样品,每个样品有10块石子,记录了每个样品中属石灰石的石子数.假设这100次观察相互独立,并

且由过去经验知,它们都服从参数为  $m = 10, p$  的二项分布,  $p$  是这地区一块石子是石灰石的概率. 求  $p$  的最大似然估计值. 该地质学家所得的数据如下:

<table><tr><td>样品中属石灰石的石子数i</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td></tr><tr><td>观察到i块石灰石的样品个数</td><td>0</td><td>1</td><td>6</td><td>7</td><td>23</td><td>26</td><td>21</td><td>12</td><td>3</td><td>1</td><td>0</td></tr></table>

7. (1)设  $X_{1}, X_{2}, \dots , X_{n}$  是来自总体  $X$  的一个样本,且  $X \sim \pi (\lambda)$ ,求  $P\{X = 0\}$  的最大似然估计值.

(2)某铁路局证实一个扳道员在五年内所引起的严重事故的次数服从泊松分布. 求一个扳道员在五年内未引起严重事故的概率  $p$  的最大似然估计值. 使用下面122个观察值. 下表中,  $r$  表示一扳道员五年中引起严重事故的次数,  $s$  表示观察到的扳道员人数.

$$
\frac{r}{s}\left| \begin{array}{ccccccccc}0 & 1 & 2 & 3 & 4 & 5 \\ 44 & 42 & 21 & 9 & 4 & 2 \end{array} \right|
$$

8. (1)设  $X_{1}, X_{2}, \dots , X_{n}$  是来自概率密度为

$$
f(x; \theta) = \left\{ \begin{array}{ll} \theta x^{\theta -1}, & 0 < x < 1, \\ 0, & \text{其他} \end{array} \right.
$$

的总体的样本,  $\theta$  未知,求  $U = \mathrm{e}^{- 1 / \theta}$  的最大似然估计值.

(2)设  $X_{1}, X_{2}, \dots , X_{n}$  是来自正态总体  $N(\mu , 1)$  的样本,  $\mu$  未知,求  $\theta = P\{X > 2\}$  的最大似然估计值.

(3)设  $x_{1}, x_{2}, \dots , x_{n}$  是来自总体  $b(m, \theta)$  的样本值,又  $\theta = \frac{1}{3} (1 + \beta)$ ,求  $\beta$  的最大似然估计值.

9. (1)验证教材第六章 §3 定理5中的统计量

$$
S_{W}^{2} = \frac{n_{1} - 1}{n_{1} + n_{2} - 2} S_{1}^{2} + \frac{n_{2} - 1}{n_{1} + n_{2} - 2} S_{2}^{2} = \frac{(n_{1} - 1)S_{1}^{2} + (n_{2} - 1)S_{2}^{2}}{n_{1} + n_{2} - 2}
$$

是两总体公共方差  $\sigma^{2}$  的无偏估计量(  $S_{W}^{2}$  称为  $\sigma^{2}$  的合并估计).

(2)设总体  $X$  的数学期望为  $\mu , X_{1}, X_{2}, \dots , X_{n}$  是来自  $X$  的样本,  $a_{1}, a_{2}, \dots , a_{n}$  是任意常数,验证  $\left(\sum_{i = 1}^{n} a_{i} X_{i}\right) / \sum_{i = 1}^{n} a_{i}$  (其中  $\sum_{i = 1}^{n} a_{i} \neq 0$ ) 是  $\mu$  的无偏估计量.

10. 设  $X_{1}, X_{2}, \dots , X_{n}$  是来自总体  $X$  的一个样本,设  $E(X) = \mu , D(X) = \sigma^{2}$ .

(1)确定常数  $c$ ,使  $c \sum_{i = 1}^{n - 1} (X_{i + 1} - X_{i})^{2}$  为  $\sigma^{2}$  的无偏估计.

(2)确定常数  $c$ ,使  $\overline{X}^{2} - c S^{2}$  是  $\mu^{2}$  的无偏估计(  $\overline{X}, S^{2}$  是样本均值和样本方差).

11. 设总体  $X$  的概率密度为

$$
f(x; \theta) = \left\{ \begin{array}{ll} \frac{1}{\theta} x^{(1 - \theta) / \theta}, & 0 < x < 1, \\ 0, & \text{其他.} \end{array} \right.
$$

$X_{1}, X_{2}, \dots , X_{n}$  是来自总体  $X$  的样本.

(1) 验证  $\theta$  的最大似然估计量是  $\hat{\theta} = -\frac{1}{n}\sum_{i = 1}^{n}\ln X_{i}$ .

(2) 证明  $\hat{\theta}$  是  $\theta$  的无偏估计量.

12. 设  $X_{1},X_{2},X_{3},X_{4}$  是来自均值为  $\theta$  的指数分布总体的样本,其中  $\theta$  未知. 设有估计量

$$
\begin{array}{l}{{T_{1}=\frac{1}{6}(X_{1}+X_{2})+\frac{1}{3}(X_{3}+X_{4}),}}\\ {{T_{2}=\frac{1}{5}(X_{1}+2X_{2}+3X_{3}+4X_{4}),}}\\ {{T_{3}=\frac{1}{4}(X_{1}+X_{2}+X_{3}+X_{4}).}}\end{array}
$$

(1) 指出  $T_{1},T_{2},T_{3}$  中哪几个是  $\theta$  的无偏估计量.

(2) 在上述  $\theta$  的无偏估计中指出哪一个较为有效.

13. (1) 设  $\hat{\theta}$  是参数  $\theta$  的无偏估计,且有  $D(\hat{\theta}) > 0$ ,试证  $\hat{\theta}^{2} = \left(\hat{\theta}\right)^{2}$  不是  $\theta^{2}$  的无偏估计量. (2) 试证明均匀分布

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{\theta}, & 0< x\leqslant \theta , \\ 0, & \text{其他} \end{array} \right.
$$

中未知参数  $\theta$  的最大似然估计量不是无偏的.

14. 设从均值为  $\mu$ ,方差为  $\sigma^{2} > 0$  的总体中分别抽取容量为  $n_{1},n_{2}$  的两独立样本.  $\overline{X}_{1}$  和  $\overline{X}_{2}$  分别是两样本的均值. 试证:对于任意常数  $a,b(a + b = 1),Y = a\overline{X}_{1} + b\overline{X}_{2}$  都是  $\mu$  的无偏估计,并确定常数  $a,b$  使  $D(Y)$  达到最小.

15. 设有  $k$  台仪器,已知用第  $i$  台仪器测量时,测定值总体的标准差为  $\sigma_{i}(i = 1,2,\dots ,k)$  用这些仪器独立地对某一物理量  $\theta$  各观察一次,分别得到  $X_{1},X_{2},\dots ,X_{k}$ . 设仪器都没有系统误差,即  $E(X_{i}) = \theta (i = 1,2,\dots ,k)$ . 问  $a_{1},a_{2},\dots ,a_{k}$  取何值,方能使使用  $\hat{\theta} = \sum_{i = 1}^{k}a_{i}X_{i}$  估计  $\theta$  时,  $\hat{\theta}$  是无偏的,并且  $D(\hat{\theta})$  最小?

16. 设某种清漆的9个样品,其干燥时间(以h计)分别为

设干燥时间总体服从正态分布  $N(\mu ,\sigma^{2})$ . 在下述情况下,求  $\mu$  的置信水平为0.95的置信区间.

(1) 若由以往经验知  $\sigma = 0.6(\mathrm{~h})$

(2) 若  $\sigma$  为未知.

17. 分别使用金球和铂球测定引力常数(以  $10^{-11}\mathrm{m}^{3}\cdot \mathrm{kg}^{-1}\cdot \mathrm{s}^{-2}$  计).

(1) 用金球测定观察值为

(2) 用铂球测定观察值为

设测定值总体为  $N(\mu , \sigma^{2})$ ,  $\mu , \sigma^{2}$  均为未知。试就(1),(2)两种情况分别求  $\mu$  的置信水平为0.9的置信区间,并求  $\sigma^{2}$  的置信水平为0.9的置信区间。

18. 随机地取某种炮弹9发做试验,得炮口速度的样本标准差  $s = 11 \mathrm{~m / s}$ 。设炮口速度服从正态分布。求这种炮弹的炮口速度的标准差  $\sigma$  的置信水平为0.95的置信区间。

19. 设  $X_{1}, X_{2}, \dots , X_{n}$  是来自分布  $N(\mu , \sigma^{2})$  的样本,  $\mu$  已知,  $\sigma$  未知。

(1) 验证  $\sum_{i = 1}^{n} (X_{i} - \mu)^{2} / \sigma^{2} \sim \chi^{2}(n)$ 。利用这一结果构造  $\sigma^{2}$  的置信水平为  $1 - \alpha$  的置信区间。

(2) 设  $\mu = 6.5$ ,且有样本值7.5,2.0,12.1,8.8,9.4,7.3,1.9,2.8,7.0,7.3。试求  $\sigma$  的置信水平为0.95的置信区间。

20. 在第17题中,设用金球和用铂球测定时测定值总体的方差相等。求两个测定值总体均值差的置信水平为0.90的置信区间。

21. 随机地从  $A$  批导线中抽4根,又从  $B$  批导线中抽5根,测得电阻(以  $\Omega$  计)为

$A$  批导线:0.143 0.142 0.143 0.137

$B$  批导线:0.140 0.142 0.136 0.138 0.140

设测定数据分别来自分布  $N(\mu_{1}, \sigma^{2})$ ,  $N(\mu_{2}, \sigma^{2})$ ,且两样本相互独立。又  $\mu_{1}, \mu_{2}, \sigma^{2}$  均为未知。试求  $\mu_{1} - \mu_{2}$  的置信水平为0.95的置信区间。

22. 研究两种固体燃料火箭推进器的燃烧率。设两者都服从正态分布,并且已知燃烧率的标准差均近似地为  $0.05 \mathrm{~cm / s}$ ,取样本容量为  $n_{1} = n_{2} = 20$ 。得燃烧率的样本均值分别为  $\overline{x}_{1} = 18 \mathrm{~cm / s}$ ,  $\overline{x}_{2} = 24 \mathrm{~cm / s}$ ,设两样本独立。求两燃烧率总体均值差  $\mu_{1} - \mu_{2}$  的置信水平为0.99的置信区间。

23. 设两位化验员  $A, B$  独立地对某种聚合物含氯量用相同的方法各做10次测定,其测定值的样本方差依次为  $s_{A}^{2} = 0.5419$ ,  $s_{B}^{2} = 0.6065$ 。设  $\sigma_{A}^{2}, \sigma_{B}^{2}$  分别为  $A, B$  所测定的测定值总体的方差。设总体均为正态的,且两样本独立。求方差比  $\sigma_{A}^{2} / \sigma_{B}^{2}$  的置信水平为0.95的置信区间。

24. 在一批货物的容量为100的样本中,经检验发现有16只次品,试求这批货物次品率的置信水平为0.95的置信区间。

25. (1) 求第16题中  $\mu_{1} - \mu_{2}$  的置信水平为0.95的单侧置信上限。

(2) 求第21题中  $\mu_{1} - \mu_{2}$  的置信水平为0.95的单侧置信下限。

(3) 求第23题中方差比  $\sigma_{A}^{2} / \sigma_{B}^{2}$  的置信水平为0.95的单侧置信上限。

26. 为研究某种汽车轮胎的磨损特性,随机地选择16只轮胎,每只轮胎行驶到磨坏为止,记录所行驶的路程(以  $\mathrm{km}$  计)如下:

41250 40187 43175 41010 39265 41872 42654 41287

38970 40200 42550 41095 40680 43500 39775 40400

假设这些数据来自正态总体  $N(\mu , \sigma^{2})$ ,其中  $\mu , \sigma^{2}$  未知,试求  $\mu$  的置信水平为0.95的单侧置信下限。

27. 科学上的重大发现往往是由年轻人做出的。下面列出了自16世纪初期至20世纪早

期的十二项重大发现的发现者和他们发现时的年龄:

发现内容 发现者 发现时间 年龄

1. 地球绕太阳运转 哥白尼(Copernicus) 1513 40

2. 望远镜、天文学的基本定律 伽利略(Galileo) 1600 36

3. 运动原理、重力、微积分 牛顿(Newton) 1665 22

4. 电的本质 富兰克林(Franklin) 1746 40

5. 燃烧是与氧气联系着的 拉瓦锡(Lavoisier) 1774 31

6. 地球是在渐进过程中演化成的 莱尔(Lyell) 1830 33

7. 自然选择控制演化的证据 达尔文(Darwin) 1858 49

8. 光的场方程 麦克斯韦(Maxwell) 1864 33

9. 放射性 居里夫人(Marie Curie) 1898 31

10. 量子论 普朗克(Planck) 1901 43

11. 狭义相对论,  $E = mc^{2}$  爱因斯坦(Einstein) 1905 26

12. 量子论的数学基础 薛定谔(Schrödinger) 1926 39

设样本来自正态总体, 试求发现者的平均年龄  $\mu$  的置信水平为 0.95 的单侧置信上限.

# 第八章 假设检验

# $\S 1$  假设检验

统计推断的另一类重要问题是假设检验问题。在总体的分布函数完全未知或只知其形式、但不知其参数的情况,为了推断总体的某些未知特性,提出某些关于总体的假设。例如,提出总体服从泊松分布的假设,又如,对于正态总体提出数学期望等于  $\mu_{0}$  的假设等。我们要根据样本对所提出的假设作出是接受,还是拒绝的决策。假设检验是作出这一决策的过程。这里,先结合例子来说明假设检验的基本思想和做法。

例1 某车间用一台包装机包装葡萄糖。袋装糖的净重是一个随机变量,它服从正态分布。当机器正常时,其均值为  $0.5 \mathrm{~kg}$ ,标准差为  $0.015 \mathrm{~kg}$ 。某日开工后为检验包装机是否正常,随机地抽取它所包装的糖9袋,称得净重为(以  $\mathrm{kg}$  计)

0.497 0.506 0.518 0.524 0.498 0.511 0.520 0.515 0.512 问机器是否正常?

以  $\mu , \sigma$  分别表示这一天袋装糖的净重总体  $X$  的均值和标准差。由于长期实践表明标准差比较稳定,我们就设  $\sigma = 0.015$ 。于是  $X \sim N(\mu , 0.015^{2})$ ,这里  $\mu$  未知。问题是根据样本值来判断  $\mu = 0.5$  还是  $\mu \neq 0.5$ 。为此,我们提出两个相互对立的假设

$$
H_{0}:\mu = \mu_{0} = 0.5
$$

和

$$
H_{1}:\mu \neq \mu_{0}.
$$

然后,我们给出一个合理的法则,根据这一法则,利用已知样本作出决策是接受假设  $H_{0}$  (即拒绝假设  $H_{1}$ ),还是拒绝假设  $H_{0}$  (即接受假设  $H_{1}$ )。如果作出的决策是接受  $H_{0}$ ,则认为  $\mu = \mu_{0}$ ,即认为机器工作是正常的,否则,认为是不正常的。

由于要检验的假设涉及总体均值  $\mu$ ,故首先想到是否可借助样本均值  $\overline{X}$  这一统计量来进行判断。我们知道, $\overline{X}$  是  $\mu$  的无偏估计, $\overline{X}$  的观察值  $\overline{x}$  的大小在一定程度上反映  $\mu$  的大小。因此,如果假设  $H_{0}$  为真,则观察值  $\overline{x}$  与  $\mu_{0}$  的偏差  $|\overline{x} - \mu_{0}|$  一般不应太大。若  $|\overline{x} - \mu_{0}|$  过分大,我们就怀疑假设  $H_{1}$  的正确性而拒绝  $H_{0}$ ,

并考虑到当  $H_{0}$  为真时  $\frac{\overline{X} - \mu_{0}}{\sigma / \sqrt{n}} \sim N(0,1)$ . 而衡量  $\left|\overline{x} - \mu_{0}\right|$  的大小可归结为衡量  $\frac{\left|\overline{x} - \mu_{0}\right|}{\sigma / \sqrt{n}}$  的大小. 基于上面的想法, 我们可适当选定一正数  $k$ , 使当观察值  $\overline{x}$  满足  $\frac{\left|\overline{x} - \mu_{0}\right|}{\sigma / \sqrt{n}} \geqslant k$  时就拒绝假设  $H_{0}$ , 反之, 若  $\frac{\left|\overline{x} - \mu_{0}\right|}{\sigma / \sqrt{n}} < k$ , 则接受假设  $H_{0}$ .

然而, 由于作出决策的依据是一个样本, 当实际上  $H_{0}$  为真时仍可能作出拒绝  $H_{0}$  的决策 (这种可能性是无法消除的), 这是一种错误, 犯这种错误的概率记为

$P\{$  当  $H_{0}$  为真时拒绝  $H_{0}\}$  或  $P_{\mu_{0}}\left\{\right.$  拒绝  $H_{0}\}$  或  $P_{\mu \in H_{0}}\left\{\right.$  拒绝  $H_{0}\}$  记号  $P_{\mu_{0}}\left\{\right.$  表示参数  $\mu$  取  $\mu_{0}$  时事件  $\{\cdot \}$  的概率,  $P_{\mu \in H_{0}}\left\{\right.$  表示  $\mu$  取  $H_{0}$  规定的值时事件  $\{\cdot \}$  的概率. 我们无法排除犯这类错误的可能性, 因此自然希望将犯这类错误的概率控制在一定限度之内, 即给出一个较小的数  $\alpha (0 < \alpha < 1)$ , 使犯这类错误的概率不超过  $\alpha$ , 即使得

为了确定常数  $k$ , 我们考虑统计量  $\frac{\overline{X} - \mu_{0}}{\sigma / \sqrt{n}}$ . 由于只允许犯这类错误的概率最大为  $\alpha$ , 令 (1.1) 式右端取等号, 即令

由于当  $H_{0}$  为真时,  $Z = \frac{\overline{X} - \mu_{0}}{\sigma / \sqrt{n}} \sim N(0,1)$ , 由标准正态分布分位数的定义得 (如图 8- 1)

$$
k = z_{\alpha /2},
$$

因而, 若  $Z$  的观察值满足

$$
\left|z\right| = \left|\frac{\overline{x} - \mu_{0}}{\sigma / \sqrt{n}}\right| \geqslant k = z_{\alpha /2},
$$

则拒绝  $H_{0}$ , 而若

$$
\left|z\right| = \left|\frac{\overline{x} - \mu_{0}}{\sigma / \sqrt{n}}\right| < k = z_{\alpha /2},
$$

则接受  $H_{0}$

例如, 在本例中取  $\alpha = 0.05$ , 则有  $k = z_{0.05 / 2} = z_{0.025} = 1.96$ , 又已知  $n = 9, \sigma = 0.015$ , 再由样本算得  $\overline{x} = 0.511$ , 即有

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图8-1

$$
\left|\frac{\overline{x} - \mu_{0}}{\sigma / \sqrt{n}}\right| = 2.2 > 1.96,
$$

于是拒绝  $H_{0}$ ,认为这天包装机工作不正常.  $\square$

上例中所采用的检验法则是符合实际推断原理的.因通常  $\alpha$  总是取得较小,一般取  $\alpha = 0.01,0.05.$  因而若  $H_{0}$  为真,即当  $\mu = \mu_{0}$  时,  $\left\{\left|\frac{\overline{{X}} - \mu_{0}}{\sigma / \sqrt{n}}\right|\geqslant z_{\alpha /2}\right\}$  是一个小概率事件,根据实际推断原理,就可以认为,如果  $H_{0}$  为真,则由一次试验得到的观察值  $\overline{{x}}$  ,满足不等式  $\left|\frac{\overline{{x}} - \mu_{0}}{\sigma / \sqrt{n}}\right|\geqslant z_{\alpha /2}$  几乎是不会发生的.现在在一次观察中竟然出现了满足  $\left|\frac{\overline{{x}} - \mu_{0}}{\sigma / \sqrt{n}}\right|\geqslant z_{\alpha /2}$  的  $\overline{{x}}$  ,则我们有理由怀疑原来的假设  $H_{0}$  的正确性,因而拒绝  $H_{0}$  .若出现的观察值  $\overline{{x}}$  满足  $\left|\frac{\overline{{x}} - \mu_{0}}{\sigma / \sqrt{n}}\right|< z_{\alpha /2}$  ,此时没有理由拒绝假设 $H_{0}$  ,因此只能接受假设  $H_{0}$

在上例的做法中,我们看到当样本容量固定时,选定  $\alpha$  后,数  $k$  就可以确定,然后按照统计量  $Z = \frac{\overline{{X}} - \mu_{0}}{\sigma / \sqrt{n}}$  的观察值的绝对值  $|z|$  大于等于  $k$  还是小于  $k$  来作出决策.数  $k$  是检验上述假设的一个门槛值.如果  $|z| = \left|\frac{\overline{{x}} - \mu_{0}}{\sigma / \sqrt{n}}\right|\geqslant k$  ,则称  $\overline{{x}}$  与  $\mu_{0}$  的差异是显著的,这时拒绝  $H_{0}$  ;反之,如果  $|z| = \left|\frac{\overline{{x}} - \mu_{0}}{\sigma / \sqrt{n}}\right|< k$  ,则称  $\overline{{x}}$  与  $\mu_{0}$  的差异是不显著的,这时接受  $H_{0}$  .数  $\alpha$  称为显著性水平,上面关于  $\overline{{x}}$  与  $\mu_{0}$  有无显著差异的判断是在显著性水平  $\alpha$  之下作出的.

统计量  $Z = \frac{\overline{{X}} - \mu_{0}}{\sigma / \sqrt{n}}$  称为检验统计量.

前面的检验问题通常叙述成:在显著性水平  $\alpha$  下,检验假设

$$
H_{0}:\mu = \mu_{0},\quad H_{1}:\mu \neq \mu_{0}. \tag{1.2}
$$

也常说成"在显著性水平  $\alpha$  下,针对  $H_{1}$  检验  $H_{0}$  "  $H_{0}$  称为原假设或零假设,  $H_{1}$  称为备择假设(意指在原假设被拒绝后可供选择的假设).我们要进行的工作是,根据样本,按上述检验方法作出决策在  $H_{0}$  与  $H_{1}$  两者之间接受其一.

当检验统计量取某个区域  $C$  中的值时,我们拒绝原假设  $H_{0}$ ,则称区域  $C$  为拒绝域,拒绝域的边界点称为临界点.如在上例中拒绝域为  $|z|\geqslant z_{\alpha /2}$ ,而  $z = - z_{\alpha /2},z = z_{\alpha /2}$  为临界点.

由于检验法则是根据样本作出的,总有可能作出错误的决策.如上面所说的

那样, 在假设  $H_{0}$  实际上为真时, 我们可能犯拒绝  $H_{0}$  的错误, 称这类"弃真"的错误为第 I 类错误. 又当  $H_{0}$  实际上不真时, 我们也有可能接受  $H_{0}$ . 称这类"取伪"的错误为第 II 类错误. 犯第 II 类错误的概率记为

为此, 在确定检验法则时, 我们应尽可能使犯两类错误的概率都较小. 但是, 进一步讨论可知, 一般来说, 当样本容量固定时, 若减小犯一类错误的概率, 则犯另一类错误的概率往往增大. 若要使犯两类错误的概率都减小, 除非增加样本容量. 在给定样本容量的情况下, 一般来说, 我们总是控制犯第 I 类错误的概率, 使它不大于  $\alpha . \alpha$  的大小视具体情况而定, 通常  $\alpha$  取  $0.1, 0.05, 0.01, 0.005$  等值. 这种只对犯第 I 类错误的概率加以控制, 而不考虑犯第 II 类错误的概率的检验, 称为显著性检验.

形如(1.2)式中的备择假设  $H_{1}$ , 表示  $\mu$  可能大于  $\mu_{0}$ , 也可能小于  $\mu_{0}$ , 称为双边备择假设, 而称形如(1.2)的假设检验为双边假设检验.

有时, 我们只关心总体均值是否增大, 例如, 试验新工艺以提高材料的强度. 这时, 所考虑的总体的均值应该越大越好. 如果我们能判断在新工艺下总体均值较以往正常生产的大, 则可考虑采用新工艺. 此时, 我们需要检验假设

$$
H_{0}: \mu \leqslant \mu_{0}, \quad H_{1}: \mu > \mu_{0}. \tag{1.3}
$$

形如(1.3)的假设检验, 称为右边检验. 类似地, 有时我们需要检验假设

$$
H_{0}: \mu \geqslant \mu_{0}, \quad H_{1}: \mu < \mu_{0}. \tag{1.4}
$$

形如(1.4)的假设检验, 称为左边检验. 右边检验和左边检验统称为单边检验.

下面来讨论单边检验的拒绝域.

设总体  $X \sim N(\mu , \sigma^{2}), \mu$  未知、  $\sigma$  为已知,  $X_{1}, X_{2}, \dots , X_{n}$  是来自  $X$  的样本. 给定显著性水平  $\alpha$ . 我们来求检验问题(1.3)

$$
H_{0}: \mu \leqslant \mu_{0}, \quad H_{1}: \mu > \mu_{0}
$$

的拒绝域.

因  $H_{0}$  中的全部  $\mu$  都比  $H_{1}$  中的  $\mu$  要小, 当  $H_{1}$  为真时, 观察值  $\overline{x}$  往往偏大, 因此, 拒绝域的形式为

下面来确定常数  $k$ , 其做法与例 1 中的做法类似:

$P\{$  当  $H_{0}$  为真时拒绝  $H_{0}\} = P_{\mu \in H_{0}}\{\overline{X} \geqslant k\}$

$$
= P_{\mu \leqslant \mu_{0}}\left\{\frac{\overline{X} - \mu_{0}}{\sigma / \sqrt{n}} \geqslant \frac{k - \mu_{0}}{\sigma / \sqrt{n}}\right\}
$$

$$
\leqslant P_{\mu \leqslant \mu_{0}}\left\{\frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \geqslant \frac{k - \mu_{0}}{\sigma / \sqrt{n}}\right\}
$$

上式不等号成立是由于 \(\mu \leqslant \mu_{0}, \frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \geqslant \frac{\overline{X} - \mu_{0}}{\sigma / \sqrt{n}}\), 事件 \(\left\{\frac{\overline{X} - \mu_{0}}{\sigma / \sqrt{n}} \geqslant \frac{k - \mu_{0}}{\sigma / \sqrt{n}}\right\} \subset \left\{\frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \geqslant \frac{k - \mu_{0}}{\sigma / \sqrt{n}}\right\} \subset \left\{\frac{k - \mu_{0}}{\sigma / \sqrt{n}}\right\} \subset \left\{\frac{k - \mu_{0}}{\sigma / \sqrt{n}}\right\} \subset \left\{\frac{k - \mu_{0}}{\sigma / \sqrt{n}}\right\} \subset \left\{\frac{k - \mu_{0}}{\sigma / \sqrt{n}}\right\} \subset \left\{ \begin{array}{l} \frac{k - \mu_{0}}{\sigma / \sqrt{n}} \\ \frac{k - \mu_{0}}{\sigma / \sqrt{n}} \end{array} \right\} \subset \left\{ \begin{array}{l} \frac{k - \mu_{0}}{\sigma / \sqrt{n}} \\ \frac{k - \mu_{0}}{\sigma / \sqrt{n}} \end{array} \right\} \subset \left\{ \begin{array}{l} \frac{k - \mu_{0}}{\sigma / \sqrt{n}} \\ \frac{k - \mu_{0}}{\sigma \sqrt{n}} \end{array} \right\} \subset \left\{ \begin{array}{l} \frac{k - \mu_{0}}{\sigma / \sqrt{n}} \\ \frac{k - \mu_{0}}{\sigma \sqrt{n}} \end{array} \right\} \subset \left\{ \begin{array}{l} \frac{k - \mu_{0}}{\sigma / \sqrt{n}} \\ \frac{1}{\sigma \sqrt{n}} \end{array} \right\} \subset \left\{ \begin{array}{l} \frac{k - \mu_{0}}{\sigma / \sqrt{n}} \\ \frac{k - \mu_{0}}{\sigma \sqrt{n}} \end{array} \right\} \subset \left\{ \begin{array}{l} \frac{k - \mu_{0}}{\sigma / \sqrt{n}} \\ \left\{ \begin{array}{l} \frac{k - \mu_{0}}{\sigma / \sqrt{n}} \\ \frac{k - \mu_{0}}{\sigma \sqrt{n}} \end{array} \right\} \subset \left\{ \begin{array}{l} \frac{k - \mu_{0}}{\sigma / \sqrt{n}} \\ \frac{k - \mu_{0}}{\sigma \sqrt{n}} \end{
\]

$$
P_{\mu \leqslant \mu_{0}}\left\{\frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \geqslant \frac{k - \mu_{0}}{\sigma / \sqrt{n}}\right\} = \alpha . \tag{1.5}
$$

由于  $\frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \sim N(0,1)$ , 由(1.5)得到

$\frac{k - \mu_{0}}{\sigma / \sqrt{n}} = z_{\alpha}$  (如图8- 2),  $k = \mu_{0} + \frac{\sigma}{\sqrt{n}} z_{\alpha}$ , 即

得检验问题(1.3)的拒绝域为

$$
\overline{x} \geqslant \mu_{0} + \frac{\sigma}{\sqrt{n}} z_{\alpha},
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_4.pdf-0a62150b-0bdb-49f5-9d50-8a23f52fd273_4467314652c8573c7240c17d608e5aa1e484fbd3b544d5c3970d3ab46b807500.jpg)  
图8-2

即  $z = \frac{\overline{x} - \mu_{0}}{\sigma / \sqrt{n}} \geqslant z_{\alpha}$ . (1.6)

类似地, 可得左边检验问题(1.4)

$$
H_{1}:\mu \geqslant \mu_{0}, H_{1}:\mu < \mu_{0}
$$

的拒绝域为

$$
z = \frac{\overline{x} - \mu_{0}}{\sigma / \sqrt{n}} \leqslant -z_{\alpha}. \tag{1.7}
$$

例2 公司从生产商购买牛奶. 公司怀疑生产商在牛奶中掺水以牟利. 通过测定牛奶的冰点, 可以检验出牛奶是否掺水. 天然牛奶的冰点温度近似服从正态分布, 均值  $\mu_{0} = - 0.545^{\circ} \mathrm{C}$ , 标准差  $\sigma = 0.008^{\circ} \mathrm{C}$ . 牛奶掺水可使冰点温度升高而接近于水的冰点温度  $(0^{\circ} \mathrm{C})$ . 测得生产商提交的5批牛奶的冰点温度, 其均值为  $\overline{x} = - 0.535^{\circ} \mathrm{C}$ , 问是否可以认为生产商在牛奶中掺了水? 取  $\alpha = 0.05$ .

解 按题意需检验假设

这是右边检验问题, 其拒绝域如(1.6)式所示, 即为

$$
z = \frac{\overline{x} - \mu_{0}}{\sigma / \sqrt{n}} \geqslant z_{0.05} = 1.645.
$$

现在  $z = \frac{- 0.535 - (- 0.545)}{0.008 / \sqrt{5}} = 2.7951 > 1.645, z$  的值落在拒绝域中, 所以我们在显著性水平  $\alpha = 0.05$  下拒绝  $H_{0}$ , 即认为生产商在牛奶中掺了水.

(2)利用遍历性定理解.

10. 设时齐马尔可夫链的一步转移概率矩阵为

$$
\begin{array}{r}{\pmb {P} = \left[ \begin{array}{c c c}{q} & {p} & 0\\ {q} & 0 & p\\ 0 & {q} & p \end{array} \right],\quad q = 1 - p,\quad p\in (0,1).} \end{array}
$$

试证明此链具有遍历性,并求其极限分布.

11. 设时齐马尔可夫链的一步转移概率矩阵为

$$
\begin{array}{r}{\pmb {P} = \left[ \begin{array}{c c c}{1 / 2} & {1 / 2} & 0\\ {1 / 2} & {1 / 2} & 0\\ 0 & 0 & 1 \end{array} \right],} \end{array}
$$

试证明此链不具有遍历性.

# 第十四章 平稳随机过程

平稳随机过程是其概率性质在时间平移下不变的随机过程。这一思想抓住了没有固定时空起点的物理系统中的最自然的现象,因而有着广泛的应用。本章着重在二阶矩过程的范围内讨论平稳随机过程的各态历经性、相关函数和功率谱密度函数以及它们的性质。

# $\S 1$  平稳随机过程的概念

平稳性是指随机过程  $X(t), t \in T = (- \infty , \infty)$  的统计特性不随时间的推移而变化。严格地说这就要求对于任意正整数  $n, t_{1}, t_{2}, \dots , t_{n}, \tau \in T, n$  维随机变量

$$
(X(t_{1}), X(t_{2}), \dots , X(t_{n}))
$$

和  $(X(t_{1} + \tau), X(t_{2} + \tau), \dots , X(t_{n} + \tau))$  (1.1)

具有相同的分布函数。我们称这样的随机过程为严平稳随机过程,简称严平稳过程。注意这里要求参数集  $T = (- \infty , \infty)$  是为了对任何  $t_{1}, t_{2}, \dots , t_{n} \in T$ ,它们在时间平移  $\tau$  以后依然有  $t_{1} + \tau , t_{2} + \tau , \dots , t_{n} + \tau \in T$ 。当然,只要相应的  $\tau$  能满足以上要求, $T$  也可以取  $[0, \infty), \{0, \pm 1, \pm 2, \dots \}$  或  $\{0, 1, 2, \dots \}$ 。

判别一个随机过程的严平稳性需要知道其所有有限维分布,这是不易办到的。在实际问题中常用的是

定义(平稳过程)给定二阶矩过程  $\{X(t), t \in T\}$ ,如果对任意  $t, t + \tau \in T$

$$
E[X(t)X(t + \tau)] = R_{X}(\tau) \tag{1.2}
$$

不依赖于  $t$ ,则称  $\{X(t), t \in T\}$  为宽平稳随机过程或广义平稳随机过程,简称平稳过程。

另外,同时考虑两个平稳过程  $X(t)$  和  $Y(t)$  时,如果它们的互相关函数也只是时间差的单变量函数,记为  $R_{XY}(\tau)$ ,即

$$
R_{XY}(t, t + \tau) = E[X(t)Y(t + \tau)] = R_{XY}(\tau) \tag{1.3}
$$

与  $t$  无关,那么我们称  $X(t)$  和  $Y(t)$  是平稳相关的,或称这两个过程是联合平稳的。

易见,上一章中的泊松过程和维纳过程都是平稳过程。下面再举两个例子。

例1(随机相位周期过程)设  $s(t)$  是一周期为  $T$  的函数,  $\Theta$  是在  $(0,T)$  上服从均匀分布的随机变量,称  $X(t) = s(t + \Theta)$  为随机相位周期过程.试讨论它的平稳性.

解由假设,  $\Theta$  的概率密度为

$$
f(\theta)={\binom{1/T,}{0,}}\quad{\mathrm{~}}\theta\in(0,T),
$$

于是,  $X(t)$  的均值函数为

$$
\begin{array}{l}{{ E\big[X(t)\big]=E\big[s(t+\Theta)\big]}}\\ {{\quad=\int_{0}^{T}s(t+\theta)\frac{1}{T}\mathrm{d}\theta{=}\frac{1}{T}\int_{t}^{t+T}s(\phi)\mathrm{d}\phi.}}\end{array}
$$

利用  $s(\phi)$  的周期性可知

$$
E[X(t)] = \frac{1}{T}\int_{0}^{T}s(\phi)\mathrm{d}\phi
$$

是常数.而自相关函数

$$
\begin{array}{l}{{R_{X}(t,t+\tau)=E\big[s(t+\Theta)s(t+\tau+\Theta)\big]}}\\ {{\quad=\int_{0}^{T}s(t+\theta)s(t+\tau+\theta)\frac{1}{T}\mathrm{d}\theta{=}\frac{1}{T}\int_{t}^{t+T}s(\phi)s(\phi+\tau)\mathrm{d}\phi.}}\end{array}
$$

同样,利用  $s(\phi)s(\phi +\tau)$  的周期性,可知自相关函数仅与  $\tau$  有关.所以随机相位周期过程是平稳的.特别,第十二章  $\S 2$  例2中的随机相位正弦波是平稳的. 口

例2(随机电报信号)信号  $X(t)$  由只取  $I$  或  $- I$  的电流给出(图14一1画出了  $X(t)$  的一条样本曲线),这里

$$
P\{X(t) = I\} = P\{X(t) = -I\} = 1 / 2.
$$

而正负号在区间  $(t,t + \tau)$  内变化的次数  $N(t,t + \tau)$  是随机的,且假设  $N(t,t + \tau)$  服从泊松分布,亦即事件

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
图14-1

$$
A_{k} = \{N(t,t + \tau) = k\}
$$

的概率为

$$
P(A_{k}) = \frac{(\lambda\tau)^{k}}{k!}\mathrm{e}^{-\lambda \tau},\quad k = 0,1,2,\dots ,
$$

其中  $\lambda >0$  是单位时间内变号次数的数学期望.试讨论  $X(t)$  的平稳性.

解显然,  $E[X(t)] = 0$  .现在来计算  $R_{X}(t,t + \tau) = E[X(t)X(t + \tau)]$  .先设 $\tau >0$  ,注意到如果电流在  $(t,t + \tau)$  内变号偶数次,则  $X(t)$  和  $X(t + \tau)$  同号且乘积为  $I^{2}$  ;如果变号奇数次,则乘积为  $- I^{2}$  .因为事件

$$
\{X(t)X(t + \tau) = I^{2}\}
$$

的概率为  $P(A_{0}) + P(A_{2}) + P(A_{4}) + \dots$  ,而事件

$$
\{X(t)X(t + \tau) = -I^{2}\}
$$

的概率为  $P(A_{1}) + P(A_{3}) + P(A_{5}) + \dots$  ,于是

$$
\begin{array}{l}{{R_{X}(t,t+\tau)=E\big[X(t)X(t+\tau)\big]=I^{2}\sum_{k=0}^{\infty}P(A_{2k})-I^{2}\sum_{k=0}^{\infty}P(A_{2k+1})}}\\ {{\qquad=I^{2}\mathrm{e}^{-\lambda\tau}\sum_{k=0}^{\infty}\frac{(-\lambda\tau)^{k}}{k!}{=}I^{2}\mathrm{e}^{-2\lambda\tau}.}}\end{array}
$$

注意,上述结果与  $t$  无关.若  $\tau < 0$  ,只需令  $s = \tau +\tau$  ,则有

$$
R_{X}(t,t + \tau) = R_{X}(s,s - \tau) = I^{2}\mathrm{e}^{2\lambda \tau}.
$$

故这一过程的自相关函数

$$
R_{X}(t,t + \tau)\frac{\mathsf{i}\mathsf{i}\mathsf{i}\mathsf{i}\mathsf{i}}{\mathsf{i}\mathsf{i}\mathsf{i}} R_{X}(\tau) = I^{2}\mathrm{e}^{-2\lambda |\tau |}
$$

只与  $\tau$  有关.其图形如图  $14 - 2$  所示.因此,随机电报信号是一平稳过程.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
图14-2

# $\S 2$  各态历经性

本节主要讨论根据试验记录确定平稳过程的均值和自相关函数的理论依据和方法.

首先注意,如果按照数学期望的定义来计算平稳过程  $X(t)$  的数字特征,就需要预先确定  $X(t)$  的一族样本函数或一维、二维分布函数,但这实际上是不易办到的.事实上,即使我们用统计试验方法,例如可以把均值和自相关函数近似地表示为

$$
\mu_{X}\approx \frac{1}{N}\sum_{k = 1}^{N}x_{k}(t_{1}),
$$

$$
R_{X}(t_{2} - t_{1}) \approx \frac{1}{N} \sum_{k = 1}^{N} x_{k}(t_{1}) x_{k}(t_{2}),
$$

那也需要对一个平稳过程重复进行大量观察,以便获得数量很多的一族样本函数  $x_{k}(t), k = 1,2, \dots , N$ ,而这正是实际困难所在.

但是,平稳过程的统计特性是不随时间的推移而变化的,于是我们自然期望在一个很长时间内观察得到的一个样本曲线,可以作为得到这个过程的数字特征的充分依据.本节给出的各态历经定理将证实:对平稳过程而言,只要满足一些较宽的条件,那么集平均(均值和自相关函数等)实际上可以用一个样本函数在整个时间轴上的平均值来代替.这样,在解决实际问题时就节约了大量的工作量.

在叙述各态历经性之前,我们先简要地介绍往后多处要遇到的有关随机过程积分的概念.

给定二阶矩过程  $\{X(t), t \in T\}$ ,如果它的每一个样本函数在  $[a, b] \subset T$  上的积分都存在,我们就说随机过程  $X(t)$  在  $[a, b]$  上的积分存在,并记为

$$
Y = \int_{a}^{b} X(t) \mathrm{d}t. \tag{2.1}
$$

显然,  $Y$  是一随机变量.

但是,在某些情形下,对于随机过程的所有样本函数来说,在  $[a, b]$  上的积分未必全都存在.此时,引入所谓均方意义上的积分,即考虑  $[a, b]$  内的一组分点

$$
a = t_{0}< t_{1}< t_{2}< \dots < t_{n} = b,
$$

且记

$$
\Delta t_{i} = t_{i} - t_{i - 1}, \quad \tau_{i} \in [t_{i - 1}, t_{i}], \quad i = 1,2, \dots , n,
$$

如果有满足

$$
\lim_{n \to \infty} E\left\{\left[Y - \sum_{i = 1}^{n} X(\tau_{i}) \Delta t_{i}\right]^{2}\right\} = 0
$$

的随机变量  $Y$  存在,则称  $Y$  为  $X(t)$  在  $[a, b]$  上的均方积分  $①$ ,并仍以符号(2.1)记之.可以证明:二阶矩过程  $X(t)$  在  $[a, b]$  上的均方积分存在的充分条件是自相关函数的二重积分,即

$$
\int_{a}^{b}\int_{a}^{b}R_{X}(s,t)\mathrm{d}s\mathrm{d}t
$$

存在.而且此时还有

$$
E(Y) = \int_{a}^{b}E\big[X(t)\big]\mathrm{d}t \tag{2.2}
$$

成立.就是说,过程  $X(t)$  的积分均值等于过程的均值函数的积分.

现在引入随机过程  $X(t)$  沿整个时间轴上的两种时间平均

$$
\langle X(t)\rangle = \lim_{T\to \infty}\frac{1}{2T}\int_{-T}^{T}X(t)\mathrm{d}t \tag{2.3}
$$

和

$$
\langle X(t)X(t + \tau)\rangle = \lim_{T\to \infty}\frac{1}{2T}\int_{-T}^{T}X(t)X(t + \tau)\mathrm{d}t, \tag{2.4}
$$

分别称为随机过程  $X(t)$  的时间均值和时间相关函数.我们可以沿用高等数学中的方法求积分和极限,其结果一般来说是随机的.

以下讨论时间平均与集平均之间的关系.先看一个例子,

例(随机相位正弦波)计算随机相位正弦波  $X(t) = a\cos (\omega t + \Theta)$  的时间均值  $\langle X(t)\rangle$  和时间相关函数  $\langle X(t)X(t + \tau)\rangle$

$$
\begin{array}{r l} & {\langle X(t)\rangle = \lim_{T\to \infty}\frac{1}{2T}\int_{-T}^{T}a\cos (\omega t + \Theta)\mathrm{d}t = \lim_{T\to \infty}\frac{a\cos(\Theta\sin\omega T}{\omega T} = 0,}\\ & {\langle X(t)X(t + \tau)\rangle = \lim_{T\to \infty}\frac{1}{2T}\int_{-T}^{T}a^{2}\cos (\omega t + \Theta)\cos [\omega (t + \tau) + \Theta ]\mathrm{d}t = \frac{a^{2}}{2}\cos \omega \tau .} \end{array}
$$

与第十二章  $\S 2$  例2比较可知

$$
\mu_{X} = E\big[X(t)\big] = \langle X(t)\rangle ,
$$

$$
R_{X}(\tau) = E\big[X(t)X(t + \tau)\big] = \langle X(t)X(t + \tau)\rangle .
$$

这表明对于随机相位正弦波,用时间平均与集平均分别算得的均值和自相关函数是相等的.这一特性并不是随机相位正弦波所独有的.下面引人一般概念.

定义(各态历经性) 设  $X(t)$  是一平稳过程.

$1^{\circ}$  如果

$$
\langle X(t)\rangle = E\big[X(t)\big] = \mu_{X} \tag{2.5}
$$

以概率1成立,则称过程  $X(t)$  的均值具有各态历经性,

$2^{\circ}$  如果对任意实数  $\tau$

$$
\langle X(t)X(t + \tau)\rangle = E\big[X(t)X(t + \tau)\big] = R_{X}(\tau) \tag{2.6}
$$

以概率1成立,则称过程  $X(t)$  的自相关函数具有各态历经性.特别当  $\tau = 0$  时,称均方值具有各态历经性.

$3^{\circ}$  如果  $X(t)$  的均值和自相关函数都具有各态历经性, 则称  $X(t)$  是各态历经过程, 或者说  $X(t)$  是各态历经的.

定义中"以概率1成立"是对  $X(t)$  的所有样本函数而言的.

各态历经性也称遍历性. 按定义, 上例中的随机相位正弦波是各态历经过程. 当然, 并不是任意一个平稳过程都具有各态历经性. 例如平稳过程

$$
X(t) = Y,
$$

其中  $Y$  是方差异于零的随机变量, 就不是各态历经过程. 事实上,  $\langle X(t) \rangle = \langle Y \rangle = Y$ , 亦即时间均值随  $Y$  取不同可能值而不同. 因  $Y$  的方差异于零, 这样  $\langle X(t) \rangle$  就不可能以概率1等于常数  $E[X(t)] = E(Y)$ .

一个平稳过程应该满足怎样的条件才是各态历经的呢? 下面两个定理从理论上回答了这个问题.

定理1(均值各态历经定理) 平稳过程  $X(t)$  的均值具有各态历经性的充要条件是

$$
\lim_{T \to \infty} \frac{1}{T} \int_{0}^{2T} \left(1 - \frac{\tau}{2T}\right) \left[R_{X}(\tau) - \mu_{X}^{2}\right] \mathrm{d}\tau = 0. \tag{2.7}
$$

证 先计算  $\langle X(t) \rangle$  的均值与方差. 由(2.3)式

$$
E[\langle X(t) \rangle ] = E\left[\lim_{T \to \infty} \frac{1}{2T} \int_{-T}^{T} X(t) \mathrm{d}t\right],
$$

交换极限与期望的运算顺序, 并注意到  $E[X(t)] = \mu_{X}$ , 即有

$$
E[\langle X(t) \rangle ] = \lim_{T \to \infty} \frac{1}{2T} \int_{-T}^{T} E[X(t)] \mathrm{d}t = \mu_{X}.
$$

而  $\langle X(t) \rangle$  的方差为

$$
\begin{array}{r l} & {D[\langle X(t)\rangle ] = E\{\big[\langle X(t)\rangle -\mu_{X}\big]^{2}\}}\\ & {\qquad = \underset {T\to \infty}{\lim}E\Big\{\Big[\frac{1}{2T}\int_{-T}^{T}X(t)\mathrm{d}t\Big]^{2}\Big\} -\mu_{X}^{2}}\\ & {\qquad = \underset {T\to \infty}{\lim}E\Big[\frac{1}{4T^{2}}\int_{-T}^{T}X(t_{1})\mathrm{d}t_{1}\Big]_{-T}^{T}X(t_{2})\mathrm{d}t_{2}\Big] - \mu_{X}^{2}}\\ & {\qquad = \underset {T\to \infty}{\lim}\frac{1}{4T^{2}}\int_{-T}^{T}\int_{-T}^{T}E\big[X(t_{1})X(t_{2})\big]\mathrm{d}t_{1}\mathrm{d}t_{2} - \mu_{X}^{2},} \end{array}
$$

由  $X(t)$  的平稳性,  $E[X(t_{1})X(t_{2})] = R_{X}(t_{2} - t_{1})$ , 上式可改写为

$$
D[\langle X(t) \rangle ] = \lim_{T \to \infty} \frac{1}{4T^{2}} \int_{-T}^{T} \int_{-T}^{T} R_{X}(t_{2} - t_{1}) \mathrm{d}t_{1} \mathrm{d}t_{2} - \mu_{X}^{2}. \tag{2.8}
$$

为了简化上式右端的积分, 引入变量变换  $\tau_{1} = t_{1} + t_{2}$  和  $\tau_{2} = t_{2} - t_{1}$ . 此变换的雅可比(Jacobi)式是

$$
\left|\frac{\partial(t_{1},t_{2})}{\partial(\tau_{1},\tau_{2})}\right| = \frac{1}{2},
$$

而积分区域转化为  $D = \{(\tau_{1},\tau_{2})\mid - 2T\leqslant \tau_{1}\pm \tau_{2}\leqslant 2T\}$ . 于是(2.8)式中的二重积分用新变量可表示为

$$
\int_{-T}^{T}\int_{-T}^{T}R_{X}(t_{2} - t_{1})\mathrm{d}t_{1}\mathrm{d}t_{2} = \iint_{D}R_{X}(\tau_{2})\frac{1}{2}\mathrm{d}\tau_{1}\mathrm{d}\tau_{2}. \tag{2.9}
$$

注意到被积函数  $R_{X}(\tau_{2})$  是  $\tau_{2}$  的偶函数,且与  $\tau_{1}$  无关,因而积分值为在区域  $G = \{(\tau_{1},\tau_{2})\mid \tau_{1},\tau_{2}\geqslant 0,\tau_{1} + \tau_{2}\leqslant 2T\}$  (如图14一3所示)上积分值的4倍,即

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
图14-3

$$
\begin{array}{l}{{\int_{-T}^{T}\int_{-T}^{T}R_{X}(t_{2}-t_{1})\mathrm{d}t_{1}\mathrm{d}t_{2}=4\iint_{G}R_{X}(\tau_{2})\frac{1}{2}\mathrm{d}\tau_{1}\mathrm{d}\tau_{2}}}\\ {{\quad=2\int_{0}^{T}\mathrm{d}\tau_{2}\int_{0}^{2T-\tau_{2}}R_{X}(\tau_{2})\mathrm{d}\tau_{1}=2\int_{0}^{2T}(2T-\tau)R_{X}(\tau)\mathrm{d}\tau.}}\end{array}
$$

把这个式子代入(2.8)式就有

$$
\begin{array}{l}{{D\big[\langle X(t)\rangle\big]=\lim _{T\to\infty}\frac{1}{T}\int_{0}^{2T}\Big(1-\frac{\tau}{2T}\Big)R_{X}(\tau)\mathrm{d}\tau-\mu_{X}^{2}}}\\ {{=\lim _{T\to\infty}\frac{1}{T}\int_{0}^{2T}\Big(1-\frac{\tau}{2T}\Big)\big[R_{X}(\tau)-\mu_{X}^{2}\big]\mathrm{d}\tau.}}\end{array} \tag{2.10}
$$

由第四章  $\S 2$  方差的性质  $4^{\circ}$  知道  $\langle X(t)\rangle = E[\langle X(t)\rangle ]$  以概率1成立的充要条件是  $D[\langle X(t)\rangle ] = 0$ . 结合(2.10)式,定理得证.  $\square$

推论在  $\lim_{\tau \to \infty}R_{X}(\tau)$  存在的条件下,若  $\lim_{\tau \to \infty}R_{X}(\tau) = \mu_{X}^{2}$ ,则(2.7)式成立,均值具有各态历经性;若  $\lim_{\tau \to \infty}R_{X}(\tau)\neq \mu_{X}^{2}$ ,则(2.7)式不成立,均值不具有各态历经性.(证略.)

注意,对前例中的随机相位正弦波而言,  $\lim_{\tau \to \infty}R_{X}(\tau)$  不存在,但它的均值具有各态历经性.

在定理1的证明中将  $X(t)$  换成  $X(t)X(t + \tau)$ ,就可得

定理2(自相关函数各态历经定理) 平稳过程  $X(t)$  的自相关函数  $R_{X}(\tau)$  具有各态历经性的充要条件是

$$
\lim_{T\to \infty}\frac{1}{T}\int_{0}^{2T}\left(1 - \frac{\tau_{1}}{2T}\right)\left[B(\tau_{1}) - R_{X}^{2}(\tau)\right]\mathrm{d}\tau_{1} = 0, \tag{2.11}
$$

其中  $B(\tau_{1}) = E\big[X(t)X(t + \tau)X(t + \tau_{1})X(t + \tau +\tau_{1})\big].$

在(2.11)式中令  $\tau = 0$  ,就可得到均方值具有各态历经性的充要条件.如若在定理2中以  $X(t)Y(t + \tau)$  代替  $X(t)X(t + \tau)$  ,以  $R_{XY}(\tau)$  代替  $R_{X}(\tau)$  来进行讨论,那么还可以相应地得到互相关函数各态历经性的充要条件.

在实际应用中通常只考虑定义在  $t\in [0,\infty)$  上的平稳过程,此时上面的所有时间平均都应以  $t\in [0,\infty)$  上的时间平均来代替,而相应的各态历经定理可表示为下述形式:

定理3(均值各态历经定理)

$$
\lim_{T\to \infty}\frac{1}{T}\int_{0}^{T}X(t)\mathrm{d}t = E\big[X(t)\big] = \mu_{X}
$$

以概率1成立的充要条件是

$$
\lim_{T\to \infty}\frac{1}{T}\int_{0}^{T}\left(1 - \frac{\tau}{T}\right)\left[R_{X}(\tau) - \mu_{X}^{2}\right]\mathrm{d}\tau = 0. \tag{2.12}
$$

定理4(自相关函数各态历经定理)

$$
\lim_{T\to \infty}\frac{1}{T}\int_{0}^{T}X(t)X(t + \tau)\mathrm{d}t = E\big[X(t)X(t + \tau)\big] = R_{X}(\tau)
$$

以概率1成立的充要条件是

$$
\lim_{T\to \infty}\frac{1}{T}\int_{0}^{T}\left(1 - \frac{\tau_{1}}{T}\right)\left[B(\tau_{1}) - R_{X}^{2}(\tau)\right]\mathrm{d}\tau_{1} = 0. \tag{2.13}
$$

各态历经定理的重要价值在于它从理论上给出了如下保证:一个平稳过程 $X(t),t\in [0,\infty)$  ,只要它满足条件(2.12)和(2.13),便可以根据"以概率1成立"的含义,从一次试验所得到的样本函数  $x(t)$  来确定出该过程的均值和自相关函数,即

$$
\lim_{T\to \infty}\frac{1}{T}\int_{0}^{T}x(t)\mathrm{d}t = \mu_{X} \tag{2.14}
$$

和

$$
\lim_{T\to \infty}\frac{1}{T}\int_{0}^{T}x(t)x(t + \tau)\mathrm{d}t = R_{X}(\tau). \tag{2.15}
$$

这就是本节开头所预告的论断,

如果试验记录  $x(t)$  只在时间区间  $[0,T]$  上给出,则相应于(2.14)和(2.15)式,有以下无偏估计式:

$$
\mu_{X} \approx \hat{\mu}_{X} = \frac{1}{T} \int_{0}^{T} x(t) \mathrm{d}t \tag{2.16}
$$

和

$$
\begin{array}{l}{{R_{X}(\tau)\approx\hat{R}_{X}(\tau)=\frac{1}{T-\tau}\int_{0}^{T-\tau}x(t)x(t+\tau)\mathrm{d}t}}\\ {{\quad=\frac{1}{T-\tau}\int_{\tau}^{T}x(t)x(t-\tau)\mathrm{d}t,\quad0\leqslant\tau<T.}}\end{array} \tag{2.17}
$$

不过在实际问题中一般不可能给出  $x(t)$  的表达式,因而通常通过模拟方法或数值计算方法来进行估计.

最后指出,各态历经定理的条件是比较宽的,应用中遇到的大多数平稳过程都能够满足.不过,要去验证它们是否成立却是十分困难的.因此在实践中,通常事先假定所研究的平稳过程具有各态历经性,并从这个假定出发,对相关资料进行分析和处理,看所得的结论是否与实际相符.如果不符,则要修改假设,另作处理.

# $\S 3$  相关函数的性质

在第十二章中已经指出,用数字特征来描绘随机过程,要比用分布函数来描绘随机过程更为简便实用.由上节的分析看到,对于具有各态历经性的平稳过程,其均值和相关函数可以用一个样本函数来估计.在这种场合下,利用均值和相关函数来研究随机过程更方便.特别是对于正态平稳过程,它的均值和相关函数能完全地刻画其统计特性.为了方便地使用数字特征去研究随机过程,下面的定理给出了相关函数的主要性质.

定理(相关函数的性质)设  $X(t)$  和  $Y(t)$  是平稳相关过程,  $R_{X}(\tau), R_{Y}(\tau), R_{XY}(\tau)$  分别是它们的自相关函数和互相关函数.则

$$
1^{\circ} R_{X}(0) = E[X^{2}(t)] = \Psi_{X}^{2} \geqslant 0.
$$

$2^{\circ} R_{X}(- \tau) = R_{X}(\tau)$ ,即  $R_{X}(\tau)$  是偶函数.而互相关函数既不是偶函数也不是奇函数,但满足  $R_{XY}(- \tau) = R_{YX}(\tau)$

$3^{\circ}$  自相关函数和自协方差函数满足不等式

$$
\mid R_{X}(\tau)\mid \leqslant R_{X}(0),\quad \mid C_{X}(\tau)\mid \leqslant C_{X}(0) = \sigma_{X}^{2}.
$$

$4^{\circ} R_{X}(\tau)$  是非负定的,即对任意数组  $t_{1}, t_{2}, \dots , t_{n} \in T$  和任意实函数  $g(t)$  都有

$$
\sum_{i,j = 1}^{n} R_{X}(t_{i} - t_{j}) g(t_{i}) g(t_{j}) \geqslant 0.
$$

$5^{\circ}$  如果平稳过程  $X(t)$  满足条件  $P\{X(t + T_{0}) = X(t)\} = 1$ ,则称它为周期是

$T_{0}$  的平稳过程. 这样的平稳过程的自相关函数也是周期为  $T_{0}$  的周期函数.

证  $1^{\circ}$  和  $2^{\circ}$  可由定义直接推出. 结合柯西一施瓦茨不等式、自相关函数和自协方差函数的定义就可得到  $3^{\circ}$ . 根据自相关函数的定义和均值的运算性质, 即有

$$
\begin{array}{r l r}{{\sum_{i,j=1}^{n}R_{X}(t_{i}-t_{j})g(t_{i})g(t_{j})=\sum_{i,j=1}^{n}E[X(t_{i})X(t_{j})]g(t_{i})g(t_{j})}}\\ &{}&{=E\Big[\sum_{i,j=1}^{n}X(t_{i})X(t_{j})g(t_{i})g(t_{j})\Big]}\\ &{}&{=E\Big\{\Big[\sum_{i=1}^{n}X(t_{i})g(t_{i})\Big]^{2}\Big\}\geqslant0.}\end{array}
$$

这就证明了  $4^{\circ}$ . 最后来证明  $5^{\circ}$ . 由平稳性,  $E[X(t) - X(t + T_{0})] = 0$ . 又由第四章 §2 方差的性质, 条件  $P\{X(t + T_{0}) = X(t)\} = 1$  与  $E\{[X(t + T_{0}) - X(t)]^{2}\} = 0$  等价. 于是, 由柯西一施瓦茨不等式,

$\{E[X(t)(X(t + \tau +T_{0}) - X(t + \tau))]\}^{2} \leqslant E[X^{2}(t)]E\{[X(t + \tau +T_{0}) - X(t + \tau)]^{2}\}$  右端为零, 推知

$$
E\{X(t)[X(t + \tau +T_{0}) - X(t + \tau)]\} = 0,
$$

展开即得  $R_{X}(\tau +T_{0}) = R_{X}(\tau)$ .

在下节中将看到  $R_{X}(0)$  表示平稳过程  $X(\tau)$  的"平均功率". 由性质  $2^{\circ}$ , 在实际问题中只需计算或测量  $R_{X}(\tau), R_{Y}(\tau), R_{XY}(\tau)$  和  $R_{YX}(\tau)$  在  $\tau \geqslant 0$  的值.

性质  $3^{\circ}$  表明自相关函数 (自协方差函数) 都在  $\tau = 0$  处取最大值. 类似地, 可以推出以下有关互相关函数和互协方差函数的不等式:

$$
\left|R_{XY}(\tau)\right|^{2} \leqslant R_{X}(0)R_{Y}(0), \quad \left|C_{XY}(\tau)\right|^{2} \leqslant C_{X}(0)C_{Y}(0).
$$

在应用上常用的还有标准自协方差函数和标准互协方差函数, 它们的定义为

$$
\rho_{X}(\tau) = \frac{C_{X}(\tau)}{C_{X}(0)}, \quad \rho_{XY}(\tau) = \frac{C_{XY}(\tau)}{\sqrt{C_{X}(0)C_{Y}(0)}}.
$$

由上述不等式知:  $\left|\rho_{X}(\tau)\right| \leqslant 1$  和  $\left|\rho_{XY}(\tau)\right| \leqslant 1$ . 且当  $\rho_{XY}(\tau) = 0$  时,  $X(t)$  和  $Y(t)$  不相关.

对于平稳过程而言, 自相关函数的非负定性是最本质的. 因为理论上可以证明: 任一连续函数, 只要具有非负定性, 就必为某平稳过程的自相关函数.

另外, 在实际中各种具有零均值的非周期性噪声和干扰一般当  $|\tau |$  值适当

增大时,  $X(t + \tau)$  和  $X(t)$  即呈现独立或不相关, 于是有

$$
\lim_{\tau \to \infty}R_{X}(\tau) = \lim_{\tau \to \infty}C_{X}(\tau) = 0.
$$

下面是一个应用例子.

例(噪声与信号)设某接收机输出电压  $V(t)$  是周期信号  $S(t)$  和噪声电压  $N(t)$  之和, 即

$$
V(t) = S(t) + N(t).
$$

又设  $S(t)$  和  $N(t)$  是两个互不相关(实际问题中一般都是如此)的各态历经过程, 且  $E[N(t)] = 0$ . 根据第十二章 §2(2.12)式,  $V(t)$  的自相关函数应为

$$
R_{V}(\tau) = R_{S}(\tau) + R_{N}(\tau).
$$

由性质  $5^{\circ}, R_{S}(\tau)$  是周期函数, 又因为一般噪声电压  $N(t)$  当  $|\tau |$  值适当增大时,  $N(t + \tau)$  和  $N(t)$  即呈现独立或不相关, 即有

$$
\lim_{\tau \to \infty}R_{N}(\tau) = 0.
$$

于是, 对于充分大的  $\tau$  值有

$$
R_{V}(\tau) \approx R_{S}(\tau).
$$

作为特例, 假设接收机输出电压中周期信号和噪声电压的自相关函数分别为

$$
R_{S}(\tau) = \frac{a^{2}}{2} \cos \tau \omega ,
$$

$$
R_{N}(\tau) = b^{2} \mathrm{e}^{-\alpha |\tau |}, \quad \alpha > 0.
$$

那么即使噪声平均功率(见下节)  $R_{N}(0) = b^{2}$  远大于信号平均功率  $R_{S}(0) = a^{2} / 2$  当  $|\tau |$  充分大时, 依然有

$$
R_{V}(\tau) = \frac{a^{2}}{2} \cos \tau \omega + b^{2} \mathrm{e}^{-\alpha |\tau |} \approx \frac{a^{2}}{2} \cos \tau \omega .
$$

也就是说我们可以从强噪声中检测到微弱的正弦信号(见图 14- 4).

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
图14-4

# §4 平稳随机过程的功率谱密度

傅里叶(Fourier)变换是确立时间函数频率结构的有效工具, 下面我们来讨论如何运用这一工具来分析平稳过程的频率结构——功率谱密度.

# (一) 平稳过程的功率谱密度

设有时间函数  $x(t), t \in (- \infty , \infty)$  (为了便于理解物理术语, 可把  $x(t)$  设想

为加于单位电阻上的电压). 如果  $x(t)$  的总能量有限, 即

$$
\int_{-\infty}^{\infty}x^{2}(t)\mathrm{d}t< \infty , \tag{4.1}
$$

那么,  $x(t)$  的傅里叶变换存在或者说具有频谱

$$
F_{x}(\omega) = \int_{-\infty}^{\infty}x(t)\mathrm{e}^{-\mathrm{i}\omega t}\mathrm{d}t.
$$

且同时有傅里叶逆变换

$$
x(t) = \frac{1}{2\pi}\int_{-\infty}^{\infty}F_{x}(\omega)\mathrm{e}^{\mathrm{i}\omega t}\mathrm{d}\omega .
$$

$F_{x}(\omega)$  一般是复函数, 其共轭函数为  $F_{x}^{*}(\omega) = F_{x}(- \omega)$ . 在  $x(t)$  和  $F_{x}(\omega)$  之间成立有帕塞瓦尔(Parseval)等式

$$
\int_{-\infty}^{\infty}x^{2}(t)\mathrm{d}t = \frac{1}{2\pi}\int_{-\infty}^{\infty}\left|F_{x}(\omega)\right|^{2}\mathrm{d}\omega ,
$$

等式左边表示  $x(t)$  在  $(- \infty ,\infty)$  上的总能量, 而右边的被积函数  $\left|F_{x}(\omega)\right|^{2}$  相应地称为  $x(t)$  的能谱密度. 这样, 帕塞瓦尔等式又可理解为总能量的谱表示式.

但是, 应用中很多重要的时间函数的总能量是无限的. 正弦函数就是一例. 平稳过程的样本函数一般来说也是如此. 这时我们转而研究  $x(t)$  在  $(- \infty ,\infty)$  上的平均功率, 即

$$
\lim_{T\to \infty}\frac{1}{2T}\int_{-T}^{T}x^{2}(t)\mathrm{d}t.
$$

在以下讨论中, 我们都假定这个平均功率是存在的,

为了用傅里叶变换给出平均功率的谱表示式, 先由给定的  $x(t)$  构造一个截尾函数

$$
x_{T}(t) = \left\{ \begin{array}{ll}x(t), & |t|\leqslant T, \\ 0, & |t| > T. \end{array} \right. \tag{4.2}
$$

易知  $x_{T}(t)$  满足(4.1). 记  $x_{T}(t)$  的傅里叶变换为

$$
F_{x}(\omega ,T) = \int_{-\infty}^{\infty}x_{T}(t)\mathrm{e}^{-\mathrm{i}\omega t}\mathrm{d}t = \int_{-\infty}^{T}x(t)\mathrm{e}^{-\mathrm{i}\omega t}\mathrm{d}t, \tag{4.3}
$$

并写出它的帕塞瓦尔等式

$$
\int_{-\infty}^{\infty}x_{T}^{2}(t)\mathrm{d}t = \frac{1}{2\pi}\int_{-\infty}^{\infty}\left|F_{x}(\omega ,T)\right|^{2}\mathrm{d}\omega ,
$$

将上式两边除以  $2T$ , 并利用  $x_{T}(t)$  的定义(4.2), 得

$$
\frac{1}{2T}\int_{-T}^{T}x^{2}(t)\mathrm{d}t = \frac{1}{4\pi T}\int_{-\infty}^{\infty}\left|F_{x}(\omega ,T)\right|^{2}\mathrm{d}\omega . \tag{4.4}
$$

令  $T\rightarrow \infty ,x(t)$  在  $(- \infty ,\infty)$  上的平均功率即可表示为

$$
\lim_{T\to \infty}\frac{1}{2T}\int_{-T}^{T}x^{2}(t)\mathrm{d}t = \frac{1}{2\pi}\int_{-\infty}^{\infty}\lim_{T\to \infty}\frac{1}{2T}\left|F_{x}(\omega ,T)\right|^{2}\mathrm{d}\omega . \tag{4.5}
$$

类似能谱密度,我们把(4.5)式右端的被积式称作函数  $x(t)$  的平均功率谱密度,简称功率谱密度,并记为

$$
S_{x}(\omega) = \lim_{T\to \infty}\frac{1}{2T}\left|F_{x}(\omega ,T)\right|^{2}. \tag{4.6}
$$

而(4.5)的右端就是平均功率的谱表示式,

现在我们把平均功率和功率谱密度的概念推广到平稳过程  $X(t),t\in$ $(- \infty ,\infty)$  .为此,相应于(4.3)和(4.4)式写出

$$
F_{X}(\omega ,T) = \int_{-T}^{T}X(t)\mathrm{e}^{-\mathrm{i}\omega t}\mathrm{d}t, \tag{4.7}
$$

和  $\frac{1}{2T}\int_{- T}^{T}X^{2}(t)\mathrm{d}t = \frac{1}{4\pi T}\int_{- \infty}^{\infty}\left|F_{X}(\omega ,T)\right|^{2}\mathrm{d}\omega .$

显然,(4.7)和(4.8)式中的积分都是随机的.我们将(4.8)式左端的均值的极限,即

$$
\lim_{T\to \infty}E\biggl [\frac{1}{2T}\int_{-T}^{T}X^{2}(t)\mathrm{d}t\biggr ] \tag{4.9}
$$

定义为平稳过程  $X(t)$  的平均功率.

交换(4.9)式中积分与均值的运算顺序,并注意到平稳过程的均方值是常数  $\Psi_{X}^{2}$  ,于是

$$
\lim_{T\to \infty}E\biggl [\frac{1}{2T}\int_{-T}^{T}X^{2}(t)\mathrm{d}t\biggr ] = \lim_{T\to \infty}\frac{1}{2T}\int_{-T}^{T}E\bigl [X^{2}(t)\bigr ]\mathrm{d}t = \Psi_{X}^{2}, \tag{4.10}
$$

即平稳过程的平均功率等于该过程的均方值或  $R_{X}(0)$

接着,把(4.8)式的右端代入(4.10)式的左端,交换运算顺序后可得

$$
\Psi_{X}^{2} = \frac{1}{2\pi}\int_{-\infty}^{\infty}\lim_{T\to \infty}\frac{1}{2T} E\big[\mid F_{X}(\omega ,T)\mid^{2}\big]\mathrm{d}\omega . \tag{4.11}
$$

相应于(4.5),(4.6)式,我们把(4.11)式中的被积式称为平稳过程  $X(t)$  的平均功率谱密度,简称为功率谱密度,并记为  $S_{X X}(\omega)$  或  $S_{X}(\omega)$  ,即

$$
S_{X}(\omega) = \lim_{T\to \infty}\frac{1}{2T} E\big[\mid F_{X}(\omega ,T)\mid^{2}\big]. \tag{4.12}
$$

利用记号  $S_{X}(\omega)$  ,(4.11)式可简写为

$$
\Psi_{X}^{2} = \frac{1}{2\pi}\int_{-\infty}^{\infty}S_{X}(\omega)\mathrm{d}\omega , \tag{4.13}
$$

此式称为平稳过程  $X(t)$  的平均功率的谱表示式.

功率谱密度  $S_{X}(\omega)$  通常也简称为自谱密度或谱密度  $①$ , 它是从频率这个角度描述  $X(t)$  的统计规律的最主要的数字特征. 由(4.13)式知, 它的物理意义是表示  $X(t)$  的平均功率关于频率的分布.

# (二)谱密度的性质

下面的定理给出了谱密度的两个重要性质,

定理(谱密度的性质)设  $X(t), t \in (- \infty , \infty)$  为平稳过程. 则

$1^{\circ} S_{X}(\omega)$  是  $\omega$  的实的、非负的偶函数.

$2^{\circ}$  若  $X(t)$  的自相关函数  $R_{X}(\tau)$  满足  $\int_{- \infty}^{\infty} |R_{X}(\tau)| \mathrm{d}\tau < \infty$ , 则它和  $S_{X}(\omega)$  构成傅里叶变换对, 即

$$
S_{X}(\omega) = \int_{-\infty}^{\infty} R_{X}(\tau) \mathrm{e}^{-\mathrm{i}\omega \tau} \mathrm{d}\tau , \tag{4.14}
$$

$$
R_{X}(\tau) = \frac{1}{2\pi} \int_{-\infty}^{\infty} S_{X}(\omega) \mathrm{e}^{\mathrm{i}\omega \tau} \mathrm{d}\omega . \tag{4.15}
$$

(4.14)和(4.15)式统称为维纳一辛钦(Wiener- Khinchin)公式. 而且由于  $R_{X}(\tau)$  和  $S_{X}(\omega)$  都是偶函数, 利用欧拉(Euler)公式, 它们还可写成

$$
S_{X}(\omega) = 2 \int_{0}^{\infty} R_{X}(\tau) \cos \omega \tau \mathrm{d}\tau , \tag{4.16}
$$

$$
R_{X}(\tau) = \frac{1}{\pi} \int_{0}^{\infty} S_{X}(\omega) \cos \omega \tau \mathrm{d}\omega . \tag{4.17}
$$

证在(4.12)式中, 量

$$
|F_{X}(\omega , T)|^{2} = F_{X}(\omega , T) F_{X}(-\omega , T)
$$

是  $\omega$  的实的、非负的偶函数, 所以它的均值的极限也必是实的、非负的偶函数. 这就得到  $1^{\circ}$ .

为证  $2^{\circ}$ , 将(4.7)代入(4.12)式, 得

$$
S_{X}(\omega) = \lim_{T \to \infty} \frac{1}{2T} E\left[\int_{-T}^{T} X(t_{1}) \mathrm{e}^{\mathrm{i}\omega t_{1}} \mathrm{d}t_{1} \int_{-T}^{T} X(t_{2}) \mathrm{e}^{-\mathrm{i}\omega t_{2}} \mathrm{d}t_{2}\right].
$$

把括号内的积分乘积改写成重积分形式, 交换积分与均值的运算顺序, 并注意到

$$
E\big[X(t_{1}) X(t_{2})\big] = R_{X}(t_{2} - t_{1}),
$$

即有

$$
S_{X}(\omega) = \lim_{T \to \infty} \frac{1}{2T} \int_{-T}^{T} \int_{-T}^{T} E\big[X(t_{1}) X(t_{2})\big] \mathrm{e}^{-\mathrm{i}\omega (t_{2} - t_{1})} \mathrm{d}t_{1} \mathrm{d}t_{2}
$$

$$
= \lim_{T\to \infty}\frac{1}{2T}\int_{-T}^{T}\int_{-T}^{T}R_{X}(t_{2} - t_{1})\mathrm{e}^{-\mathrm{i}\omega (t_{2} - t_{1})}\mathrm{d}t_{1}\mathrm{d}t_{2}.
$$

接着,依照  $\S 2$  定理1的证明,作变量变换  $\tau_{1} = t_{1} + t_{2},\tau_{2} = t_{2} - t_{1}$  ,可以得到

$$
\begin{array}{l}{{S_{X}(\omega)=\lim _{T\rightarrow\infty}\int_{-2T}^{2T}\Big(1-\frac{\left|\tau\right|}{2T}\Big)R_{X}(\tau)\mathrm{e}^{-\mathrm{i}\omega\tau}\mathrm{d}\tau}}\\ {{=\lim _{T\rightarrow\infty}\int_{-\infty}^{\infty}R_{X}^{T}(\tau)\mathrm{e}^{-\mathrm{i}\omega\tau}\mathrm{d}\tau},}}\end{array} \tag{4.18}
$$

式中

$$
R_{X}^{T}(\tau) = \left\{ \begin{array}{l l}{\Big(1 - \frac{\left|\tau\right|}{2T}\Big)R_{X}(\tau),} & {\left|\tau \right|\leqslant 2T,}\\ {0,} & {\left|\tau \right| > 2T.} \end{array} \right.
$$

当  $T\rightarrow \infty$  时,注意到对每个  $\tau ,R_{X}^{T}(\tau)\to R_{X}(\tau)$  ,于是由(4.18)式就可得到公式(4.14).由傅里叶逆变换的公式即得(4.15)式. 口

维纳一辛钦公式又称为平稳过程自相关函数的谱表示式,它们揭示了从时间角度描述平稳过程  $X(t)$  的统计规律和从频率角度描述  $X(t)$  的统计规律之间的联系.据此,在应用上我们可以根据实际情况选择时间域方法或等价的频率域方法.实际的计算可以利用傅里叶变换手册,表14一1列出了若干个常用的自相关函数以及对应的谱密度.

表14-1  

<table><tr><td></td><td>RX(τ)</td><td>SX(ω)</td></tr><tr><td>1</td><td>e^−a|τ|</td><td>2a/a²+ω²</td></tr><tr><td>2</td><td>max{1−|τ|,0}</td><td>4sin²(ωT/2)Tω²</td></tr><tr><td>3</td><td>e^−a|τ|cosω0τ</td><td>a/a²+(ω−ω0)²+a²+(ω+ω0)²</td></tr><tr><td>4</td><td>sinω0τ/ω0τ</td><td>χ[−ω0,ω0] (ω)</td></tr><tr><td>5</td><td>1</td><td>2πδ(ω)</td></tr><tr><td>6</td><td>δ(τ)</td><td>1</td></tr><tr><td>7</td><td>cosω0τ</td><td>πδ(ω−ω0)+πδ(ω+ω0)</td></tr></table>

注:  $\chi_{A}$  表示集  $A$  的特征函数,定义为  $\chi_{A}(\tau) = \left\{ \begin{array}{ll}1, & \tau \in A, \\ 0, & \tau \notin A. \end{array} \right.$

例1 已知平稳过程  $X(t)$  的自相关函数为

$$
R_{X}(\tau) = \mathrm{e}^{-a|\tau |}\cos \omega_{0}\tau ,
$$

求  $X(t)$  的谱密度  $S_{X}(\omega)$

解 由表14- 1可直接查出

$$
S_{X}(\omega) = \frac{a}{a^{2} + (\omega - \omega_{0})^{2}} +\frac{a}{a^{2} + (\omega + \omega_{0})^{2}}.
$$

例2 已知平稳过程  $X(t)$  的谱密度

$$
S_{X}(\omega) = \frac{\omega^{2} + 4}{\omega^{4} + 10\omega^{2} + 9},
$$

求  $X(t)$  的自相关函数和均方值,

解 用查表方法. 先把  $S_{X}(\omega)$  改写成部分分式之和, 即

$$
S_{X}(\omega) = \frac{\omega^{2} + 4}{(\omega^{2} + 1)(\omega^{2} + 9)} = \frac{1}{8}\left(\frac{3}{\omega^{2} + 1^{2}} +\frac{5}{\omega^{2} + 3^{2}}\right). \tag{4.19}
$$

由于傅里叶逆变换(4.15)也是线性变换, 所以可对上式右端两项分别查表14- 1第1栏后相加, 经整理后得

$$
R_{X}(\tau) = \frac{1}{48} (9\mathrm{e}^{-|\tau |} + 5\mathrm{e}^{-3|\tau |}).
$$

而均方值为

$$
\Psi_{X}^{2} = R_{X}(0) = \frac{7}{24}.
$$

形如(4.19)式的谱密度属于有理谱密度. 根据谱密度性质  $1^{\circ}$ , 其一般形式应为

$$
S_{X}(\omega) = S_{0}\frac{\omega^{2n} + a_{2n - 2}\omega^{2n - 2} + \cdots + a_{0}}{\omega^{2m} + b_{2m - 2}\omega^{2m - 2} + \cdots + b_{0}},
$$

式中  $S_{0} > 0$ . 又由于要求均方值有限, 所以由(4.13)式还应有  $m > n$ , 且分母应无实数根. 有理谱密度是实用上最常见的一类谱密度. 已知有理谱密度要求自相关函数, 通常使用例2中的部分分式方法结合查表来进行.

另外, 已知平稳过程的自相关函数的估计, 由维纳一辛钦公式及数值积分就可以得到谱密度的估计.

最后需要指出的是, 在实际问题中常常碰到这样一些平稳过程 (例如随机相位正弦波), 讨论它们的自相关函数和谱密度需要用到狄拉克 (Dirac) 的  $\delta$  函数, 定义如下:

$$
\left\{ \begin{array}{l l}{\delta (t) = 0,\quad t\neq 0,}\\ {\int_{-\infty}^{\infty}\delta (t)\mathrm{d}t = 1.} \end{array} \right.
$$

通常用图 14- 5 中的单位有向线段来表示.

$\delta$  函数的最重要的性质是:对任一在  $t = 0$  连续的函数  $f(t)$ ,有

$$
\int_{-\infty}^{\infty} \delta (t) f(t) \mathrm{d}t = f(0).
$$

一般,若函数  $f(t)$  在  $t = t_{0}$  连续,就有(筛选性)

$$
\int_{-\infty}^{\infty} \delta (t - t_{0}) f(t) \mathrm{d}t = f(t_{0}).
$$

据此,可以写出以下傅里叶变换对:

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
图14-5

$$
\int_{-\infty}^{\infty} \delta (\tau) \mathrm{e}^{-\mathrm{i} \omega \tau} \mathrm{d}\tau = 1 \leftrightarrow \delta (\tau) = \frac{1}{2\pi} \int_{-\infty}^{\infty} 1 \cdot \mathrm{e}^{\mathrm{i} \omega \tau} \mathrm{d}\omega , \tag{4.20}
$$

$$
\int_{-\infty}^{\infty} \frac{1}{2\pi} \mathrm{e}^{-\mathrm{i} \omega \tau} \mathrm{d}\tau = \delta (\omega) \leftrightarrow \frac{1}{2\pi} = \frac{1}{2\pi} \int_{-\infty}^{\infty} \delta (\omega) \mathrm{e}^{\mathrm{i} \omega \tau} \mathrm{d}\omega . \tag{4.21}
$$

(4.21)式表明:当自相关函数  $R_{X}(\tau) = 1$  时,谱密度  $S_{X}(\omega) = 2\pi \delta (\omega)$ 。其次,还可求得正弦型自相关函数  $R_{X}(\tau) = a \cos \omega_{0} \tau$  的谱密度为

$$
S_{X}(\omega) = a \pi \left[ \delta (\omega - \omega_{0}) + \delta (\omega + \omega_{0}) \right]. \tag{4.22}
$$

事实上,

$$
\begin{array}{l}{{S_{X}(\omega)=\int_{-\infty}^{\infty}a c\cos\omega_{0}\tau\mathrm{e}^{-\mathrm{i}\omega\tau}\mathrm{d}\tau}}\\ {{\quad=\frac{a}{2}\int_{-\infty}^{\infty}(\mathrm{e}^{\mathrm{i}\omega_{0}\tau}+\mathrm{e}^{-\mathrm{i}\omega_{0}\tau})\mathrm{e}^{-\mathrm{i}\omega\tau}\mathrm{d}\tau}}\\ {{\quad=\frac{a}{2}\Big[\int_{-\infty}^{\infty}\mathrm{e}^{-\mathrm{i}(\omega-\omega_{0})\tau}\mathrm{d}\tau+\int_{-\infty}^{\infty}\mathrm{e}^{-\mathrm{i}(\omega+\omega_{0})\tau}\mathrm{d}\tau\Big],}}\end{array}
$$

利用变换式(4.21)即得(4.22)式,

由此可见,自相关函数为常数或正弦型函数的平稳过程,其谱密度都是离散的。对应的变换可见表 14- 1 第 5,7 栏。

例3 求自相关函数

$$
R_{V}(\tau) = \frac{a^{2}}{2} \cos \omega_{0} \tau + b^{2} \mathrm{e}^{-a |\tau |}
$$

所对应的谱密度  $S_{V}(\omega)$

解 利用傅里叶变换的线性性质及表 14- 1 第 1 和第 7 栏即可知道

$$
S_{V}(\omega) = \frac{\pi a^{2}}{2} \left[ \delta (\omega - \omega_{0}) + \delta (\omega + \omega_{0}) \right] + \frac{2a b^{2}}{a^{2} + \omega^{2}}.
$$

相应的谱密度如图 14- 6 所示。此图说明了谱密度是如何表明噪声以外的周期信号的。

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
图14-6

白噪声 均值为零而谱密度为正常数, 即

$$
S_{X}(\omega) = S_{0} > 0, \quad \omega \in (-\infty , \infty)
$$

的平稳过程  $X(t)$  称为白噪声过程, 简称白噪声. 其名出于白光具有均匀的光谱. 由表14- 1第6栏,

$$
R_{X}(\tau) = S_{0} \delta (\tau).
$$

由上式可知, 白噪声也可以定义为均值为零、自相关函数为  $\delta$  函数的随机过程, 且这个过程在  $t_{1} \neq t_{2}$  时,  $X(t_{1})$  和  $X(t_{2})$  是不相关的.

# 小结

本章讨论的平稳过程是指宽平稳随机过程. 其特点是均值函数为常数, 自相关函数只依赖于时间差. 类似地, 如果两个平稳过程的互相关函数只依赖于时间差, 则称它们是平稳相关的. 因此, 判定平稳性仅涉及随机过程的均值函数、自相关函数和互相关函数等数字特征的计算.

按定义用集平均来计算随机过程的数字特征是十分困难的. 所幸的是在实际应用中常见的许多平稳过程的数字特征具有各态历经性, 也就是说这些数字特征可以用一个样本函数的时间平均来近似计算, 这为在应用中估计这些数字特征带来极大的方便.

自相关函数是平稳过程在时间域上的主要数字特征, 它的傅里叶变换称为功率谱密度, 是相应的随机过程在频率域上的数字特征. 维纳一辛钦公式揭示了两者之间的转换关系.

# 重要术语及主题

(宽)平稳过程 平稳相关 时间均值和时间相关函数 各态历经性 各态历经性过程 自相关函数 互相关函数 傅里叶变换 功率谱密度 维纳一辛钦公式 白噪声

# 习题

1. 设有随机过程  $X(t) = A \cos (\omega t + \theta), t \in (-\infty , \infty)$ , 其中  $A$  是服从瑞利分布的随机变量, 其概率密度为

$$
f(a) = \left\{ \begin{array}{ll}\frac{a}{\sigma^{2}}\mathrm{e}^{-\frac{a^{2}}{2\sigma^{2}}}, & a > 0, \\ 0, & a\leqslant 0. \end{array} \right.
$$

$\Theta$  是在  $(0,2\pi)$  上服从均匀分布且与  $A$  相互独立的随机变量,  $\omega$  是一常数. 问  $X(t)$  是不是平稳过程?

2. 设  $X(t)$  和  $Y(t)$  是相互独立的平稳过程, 试证以下随机过程也是平稳过程:

(1)  $Z_{1}(t) = X(t)Y(t)$

(2)  $Z_{2}(t) = X(t) + Y(t)$

3. 设  $\{X(t),t\in (-\infty ,\infty)\}$  是平稳过程,  $R_{X}(\tau)$  是其自相关函数,  $a$  是常数. 试问随机过程  $Y(t) = X(t + a) - X(t)$  是不是平稳过程? 为什么?

4. 设  $\{N(t),t\geqslant 0\}$  是强度为  $\lambda$  的泊松过程, 定义随机过程  $Y(t) = N(t + L) - N(t)$ , 其中常数  $L > 0$ . 试求  $Y(t)$  的均值函数和自相关函数, 并问  $Y(t)$  是否是平稳过程?

5. 设平稳过程  $\{X(t),t\in (-\infty ,\infty)\}$  的自相关函数为  $R_{X}(\tau) = \mathrm{e}^{-a|\tau |}(1 + a|\tau |)$ , 其中常数  $a > 0$ , 而  $E[X(t)] = 0$ . 试问  $X(t)$  的均值是否具有各态历经性? 为什么?

6. 第1题中的随机过程  $X(t) = A\cos (\omega t + \Theta)$  是否是各态历经过程? 为什么?

7. (1) 设  $C_{X}(\tau)$  是平稳过程  $X(t)$  的协方差函数, 试证若  $C_{X}(\tau)$  绝对可积, 即

$$
\int_{-\infty}^{\infty}\left|C_{X}(\tau)\right|\mathrm{d}\tau < \infty ,
$$

则  $X(t)$  的均值具有各态历经性.

(2) 证明本章 §1 例1中的随机相位周期过程  $X(t) = s(t + \Theta)$  是各态历经过程.

8. 设  $X(t)$  是随机相位周期过程, 题8图表示它的一个样本函数  $x(t)$ , 其中周期  $T$  和波幅  $A$  都是常数; 而相位  $t_{0}$  是在  $(0,T)$  上服从均匀分布的随机变量.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
题8图

(1) 求  $\mu_{X},\Psi_{X}^{2}$

(2) 求  $\langle X(t)\rangle$  和  $\langle X^{0}(t)\rangle$

9. 设平稳过程  $X(t)$  的自相关函数为  $R_{X}(\tau)$ , 证明

$$
P\left\{\left|X(t + \tau) - X(t)\right|\geqslant a\right\} \leqslant 2\left[R_{X}(0) - R_{X}(\tau)\right] / a^{2},\quad a > 0.
$$

10. 设  $X(t)$  为平稳过程, 其自相关函数  $R_{X}(\tau)$  是以  $T_{0}$  为周期的函数. 证明  $X(t)$  是周期为  $T_{0}$  的平稳过程.

11. 设  $X(t)$  是雷达的发射信号, 遇目标后返回接收机的微弱信号是  $a X(t - \tau_{1}),a\ll 1,\tau_{1}$  是信号返回时间, 由于接收到的信号总是伴有噪声的, 记噪声为  $N(t)$ , 于是接收到的全信号为

$$
Y(t) = a X(t - \tau_{1}) + N(t).
$$

(1)若  $X(t)$  和  $N(t)$  是平稳相关的,证明  $X(t)$  和  $Y(t)$  也平稳相关.

(2)在(1)的条件下,假设  $N(t)$  的均值为零且与  $X(t)$  是相互独立的,求  $R_{X Y}(\tau)$  (这是利用互相关函数从全信号中检测小信号的相关接收法).

12. 平稳过程  $\{X(t), t \in (-\infty , \infty)\}$  的自相关函数为

$$
R_{X}(\tau) = 4 \mathrm{e}^{-|\tau |} \cos \pi \tau + \cos 3 \pi \tau ,
$$

求:(1)  $X(t)$  的均方值.

(2)  $X(t)$  的谱密度.

13. 已知平稳过程  $X(t)$  的谱密度为

$$
S_{X}(\omega) = \frac{\omega^{2}}{\omega^{4} + 3 \omega^{2} + 2},
$$

求  $X(t)$  的均方值.

14. 已知平稳过程  $X(t)$  的自相关函数为

$$
R_{X}(\tau) = \left\{ \begin{array}{ll} 1 - \frac{|\tau|}{T}, & |\tau | \leqslant T, \\ 0, & |\tau | > T. \end{array} \right.
$$

求谱密度  $S_{X}(\omega)$

15. 已知平稳过程  $X(t)$  的谱密度为

$$
S_{X}(\omega) = \left\{ \begin{array}{ll} 8 \delta (\omega) + 20 \left(1 - \frac{|\omega|}{10}\right), & |\omega | < 10, \\ 0, & |\omega | \geqslant 10. \end{array} \right.
$$

求  $X(t)$  的自相关函数.

16. 设随机过程

$$
Y(t) = X(t) \cos (\omega_{0} t + \Theta), \quad t \in (-\infty , \infty),
$$

其中  $X(t)$  是平稳过程,  $\Theta$  为在区间  $(0,2\pi)$  上均匀分布的随机变量,  $\omega_{0}$  为常数,且  $X(t)$  与  $\Theta$  相互独立. 记  $X(t)$  的自相关函数为  $R_{X}(\tau)$ , 功率谱密度为  $S_{X}(\omega)$ , 试证:

(1)  $Y(t)$  是平稳过程,且它的自相关函数为

$$
R_{Y}(\tau) = \frac{1}{2} R_{X}(\tau) \cos \omega_{0} \tau .
$$

(2)  $Y(t)$  的功率谱密度为

$$
S_{Y}(\omega) = \frac{1}{4} \left[ S_{X}(\omega - \omega_{0}) + S_{X}(\omega + \omega_{0}) \right].
$$

17. 设平稳过程  $X(t)$  的谱密度为  $S_{X}(\omega)$ , 证明  $Y(t) = X(t) + X(t - T)$  的谱密度是

$$
S_{Y}(\omega) = 2 S_{X}(\omega) (1 + \cos \omega T).
$$

# 第十五章 时间序列分析

我们在实际问题中经常会遇到一系列随时间变化而又相互关联并包含着不确定性的数据.例如某地区的月降雨量纪录、上证指数每日的收盘价、一条流水线上每天出现的次品数等,这些都可以看成是离散参数随机过程  $\{X_{t},t = 0,\pm 1$ $\pm 2,\dots \}$  .由于  $t$  经常代表时间,常称这样的离散参数随机过程为时间序列.时间序列分析就是利用观测或试验所得到的动态数据来建立可以应用的模型.本章着重讨论较为简单但有着广泛应用的平稳时间序列的自回归滑动平均模型,简称ARMA.

# $\S 1$  平稳时间序列

定义若时间序列  $\{X_{t},t = 0,\pm 1,\pm 2,\dots \}$  满足条件(1)  $E(X_{t}) = \mu$  和(2)  $E(X_{t}X_{t + k})$  均与  $t$  无关,则称之为平稳时间序列.

平稳时间序列是平稳随机过程的一个特例

运用时间序列的关键在于刻画序列各项之间的关系.为此常会用到下面两种相关函数:

自相关函数  $\rho_{k} = \gamma_{k} / \gamma_{0}$  ,其中

$$
\gamma_{k} = E[(X_{t} - \mu)(X_{t + k} - \mu)],\quad k = 0,\pm 1,\pm 2,\dots
$$

为自协方差函数.可知当  $\{X_{t},t = 0,\pm 1,\pm 2,\dots \}$  为平稳时间序列时,  $\gamma_{k},\rho_{k}$  都与  $t$  无关并具有下列性质:

(1)对称性:  $\gamma_{k} = \gamma_{-k}$

(2)非负定性:对任意正整数  $k$

$$
\begin{array}{r}{\pmb{R}_{k}=\left[\begin{array}{c c c c c}{1}&{\rho_{1}}&{\rho_{2}}&{\cdots}&{\rho_{k-1}}\\ {\rho_{1}}&{1}&{\rho_{1}}&{\cdots}&{\rho_{k-2}}\\ {\vdots}&{\vdots}&{\vdots}&&{\vdots}\\ {\rho_{k-1}}&{\rho_{k-2}}&{\rho_{k-3}}&{\cdots}&{1}\end{array}\right]}\end{array}
$$

是非负定矩阵.

(3)满足柯西不等式:  $\mid \gamma_{k}\mid \leqslant \gamma_{0},\mid \rho_{k}\mid \leqslant 1$

自相关函数描述  $X_{t}$  与  $X_{t + k}$  之间的相关性.

偏相关函数用  $X_{t}$  的前  $k$  个时刻的值  $X_{t - 1},\dots ,X_{t - k}$  对  $X_{t}$  作最小方差估

计,即求  $a_{k1},a_{k2},\dots ,a_{k s}$  使得  $E\Big[\Big(X_{t} - \sum_{i = 1}^{k}a_{k i}X_{t - i}\Big)^{2}\Big]$  最小.当  $\{X_{t},t = 0,\pm 1$ $\pm 2,\dots \}$  为平稳时间序列时,  $a_{k k}$  与  $t$  无关,  $a_{k k}$  称为该时间序列的偏相关函数.

偏相关函数描述  $X_{t}$  与  $X_{t - 1},\dots ,X_{t - k}$  的联系.

例1(白噪声)设时间序列  $\{\epsilon_{t},t = 0,1,\dots \}$  满足:(1)  $E(\epsilon_{t}) = 0$ ;(2)  $E(\epsilon_{t}\epsilon_{s}) = \sigma_{\epsilon}^{2}\delta_{ts}$ ,其中

$$
\delta_{ts} = \left\{ \begin{array}{ll}1, & t = s, \\ 0, & t \neq s. \end{array} \right.
$$

易知  $E(\epsilon_{t}\epsilon_{t + k}) = \sigma_{\epsilon}^{2}\delta_{k0}$  与  $t$  无关,因此  $\{\epsilon_{t},t = 0,1,\dots \}$  为平稳时间序列,称  $\{\epsilon_{t},t = 0,1,\dots \}$  为白噪声序列.  $\square$

例2(平稳时间序列的延迟)对给定的平稳时间序列  $\{X_{t},t = 0,\pm 1$ $\pm 2,\dots \}$  和正整数  $d$ ,定义它的  $d$  步延迟序列  $\{Y_{t} = X_{t - d},t = 0,\pm 1,\pm 2,\dots \}$ .易知  $E(Y_{t}) = E(X_{t - d}) = \mu$  和  $E(Y_{t}Y_{t + k}) = E(X_{t - d}X_{t + k - d})$  均与  $t$  无关.因此  $\{Y_{t},t = 0,\pm 1,\pm 2,\dots \}$  也是平稳时间序列.  $\square$

由于延迟会经常用到,我们引进下述延迟算子:

定义设  $\{X_{t},t = 0,\pm 1,\pm 2,\dots \}$  为时间序列,算子  $B$  满足等式  $B X_{t} = X_{t - 1}$  称它为一步延迟算子.用  $B^{k}$  表示连续应用一步延迟算子  $k$  次,并称之为  $k$  步延迟算子,则有  $B^{k}X_{t} = X_{t - k}$

# $\S 2$  线性自回归滑动平均模型

平稳时间序列的线性模型相对简单并具有广泛应用,本节讨论常用的线性自回归滑动平均模型.由于平稳时间序列各项的均值相同,则平移总可以把序列的均值归零,因此以下只关注均值为零的序列.

定义设均值为零的平稳时间序列  $\{X_{t},t = 0,\pm 1,\pm 2,\dots \}$  满足等式

$$
X_{t} - \phi_{1}X_{t - 1} - \dots -\phi_{p}X_{t - p} = \epsilon_{t} - \theta_{1}\epsilon_{t - 1} - \dots -\theta_{q}\epsilon_{t - q}, \tag{2.1}
$$

其中  $\{\epsilon_{t},t = 0,\pm 1,\pm 2,\dots \}$  为白噪声序列,且多项式方程  $\Phi (u) = 1 - \phi_{1}u - \dots - \phi_{p}u^{p} = 0$  和  $\Theta (u) = 1 - \theta_{1}u - \dots - \theta_{q}u^{q} = 0$  没有公共根,则称之为  $p$  阶自回归  $q$  阶滑动平均时间序列,简称  $\operatorname {ARMA}(p,q)$  序列.系数  $\phi_{1},\phi_{2},\dots ,\phi_{p},\theta_{1},\theta_{2},\dots ,\theta_{q}$  称为模型的参数.  $p,q$  称为阶.利用延迟算子和多项式  $\Phi ,\Theta$  可以写出  $\operatorname {ARMA}(p,q)$  序列的算子表达式:

$$
\Phi (B)X_{t} = \Theta (B)\epsilon_{t}.
$$

在  $\operatorname {ARMA}(p,q)$  模型中,如果  $q = 0$ ,则滑动平均现象不存在,此时得到纯  $p$  阶自回归模型,将它简记为  $\operatorname {AR}(p)$ .我们将  $\operatorname {AR}(p)$  模型表示为

$$
X_{t} = \sum_{i = 1}^{p}\phi_{i}X_{t - i} + \epsilon_{t}. \tag{2.2}
$$

如果  $\scriptstyle{p = 0}$  ,则自回归现象不存在,就得到纯  $q$  阶滑动平均模型,将它简记为  $\mathrm{MA}(q)$  我们将  $\mathrm{MA}(q)$  模型表示为

$$
X_{t} = \epsilon_{t} - \sum_{i = 1}^{q}\theta_{i}\epsilon_{t - i}. \tag{2.3}
$$

$\mathrm{ARMA}(\boldsymbol {\phi},\boldsymbol {q})$  是上述两种简单模型的混合.对于一个实际的时间序列问题,自相关函数和偏相关函数可以帮助我们有效地判定较为简单的  $\operatorname {AR}(\boldsymbol {\phi})$  和  $\mathrm{MA}(q)$  模型的适用性并估计阶数  $\boldsymbol{\mathscr{p}}$  和  $q$

先讨论  $\operatorname {AR}(\boldsymbol {\phi})$  的偏相关函数.为了确定偏相关函数  $a_{k k}$  ,我们寻找  $a_{k1}$ $a_{k2},\dots ,a_{k k}$  使得

$$
f = E\Big[\Big(X_{t} - \sum_{i = 1}^{k}a_{k i}X_{t - i}\Big)^{2}\Big] \tag{2.4}
$$

达到最小.将(2.2)式代人(2.4)式得到

$$
\begin{array}{l}{{f=E\Big[\Big(\sum_{i=1}^{p}\phi_{i}X_{t-i}+\epsilon_{t}-\sum_{j=1}^{k}a_{k j}X_{t-j}\Big)^{2}\Big]}}\\ {{=E\Big\{\Big[\epsilon_{t}+\sum_{i=1}^{p}(\phi_{i}-a_{k i})X_{t-i}-\sum_{j=p+1}^{k}a_{k j}X_{t-j}\Big]^{2}\Big\}}}\\ {{=E(\epsilon_{t}^{2})+2E\Big\{\epsilon_{t}\Big[\sum_{i=1}^{p}(\phi_{i}-a_{k i})X_{t-i}-\sum_{j=p+1}^{k}a_{k j}X_{t-j}\Big]\Big\}}}\\ {{+E\Big\{\Big[\sum_{i=1}^{p}(\phi_{i}-a_{k i})X_{t-i}-\sum_{j=p+1}^{k}a_{k j}X_{t-j}\Big]^{2}\Big\}.}}\end{array}
$$

注意到  $t > s$  时  $E(\epsilon_{t}X_{s}) = 0$  ,上式中第二项为零.由于  $E(\epsilon_{t}^{2})$  为常数,要使  $f$  达到最小,第三项作为完全平方必须为零.因此  $a_{k i} = \phi_{i}$  ,当  $1\leqslant i\leqslant p;a_{k j} = 0$  ,当  $\boldsymbol{\mathscr{p}}+$ $1\leqslant j\leqslant k$  .这样得到偏相关函数

$$
a_{k k}=\left\{\begin{array}{l l}{\phi_{k},}&{1\leqslant k\leqslant p,}\\ {0,}&{k>p,}\end{array}\right.
$$

上式表明  $k > p$  时  $a_{k k} = 0$  .我们称  $X_{t}$  的偏相关函数在  $\boldsymbol{\mathscr{p}}$  处截尾.

与之对照的是  $\mathrm{MA}(q)$  模型的自相关函数的截尾性.由  $\mathrm{MA}(q)$  的定义(2.3)式可知

$$
\gamma_{k} = E(X_{t}X_{t + k}) = E\Big[\Big(\epsilon_{t} - \sum_{i = 1}^{q}\theta_{i}\epsilon_{t - i}\Big)\Big(\epsilon_{t + k} - \sum_{j = 1}^{q}\theta_{j}\epsilon_{t + k - j}\Big)\Big]. \tag{2.5}
$$

当  $k > q$  时上式两个括号中  $\epsilon_{s}$  所在的时间点  $s$  无一相同,因此  $\gamma_{k} = 0$  .又易算出 $\gamma_{0} = \sigma_{\epsilon}^{2}\Big(1 + \sum_{i = 1}^{q}\theta_{i}^{2}\Big)$  当  $1\leqslant k\leqslant q$  时我们将  $\gamma_{k}$  写成

$$
\gamma_{k} = E\Big[\Big(\epsilon_{t} - \sum_{i = 1}^{q}\theta_{i}\epsilon_{t - i}\Big)\epsilon_{t + k}\Big] - \sum_{i = 1}^{q}\theta_{i}E\big(\epsilon_{t}\epsilon_{t + k - i}\big) + \sum_{i = 1}^{q}\sum_{j = 1}^{q}\theta_{i}\theta_{j}E\big(\epsilon_{t - i}\epsilon_{t + k - j}\big).
$$

上式第一项显然为零.第二项中只有  $i = k$  的一项非零,其值为  $- \theta_{k}\sigma_{\epsilon}^{2}$ .第三项中只有那些满足  $t - i = t + k - j$  (也就是  $j = i + k$ )的项非零.所以  $\gamma_{k} = \sigma_{\epsilon}^{2}\Big(- \theta_{k} + \sum_{i = 1}^{q - k}\theta_{i}\theta_{i + k}\Big)$ .综合起来有

$$
\gamma_{k} = \left\{ \begin{array}{l l}{\sigma_{\epsilon}^{2}\Big(1 + \sum_{i = 1}^{q}\theta_{i}^{2}\Big),} & {k = 0,}\\ {\sigma_{\epsilon}^{2}\Big(-\theta_{k} + \sum_{i = 1}^{q - k}\theta_{i}\theta_{i + k}\Big),} & {1\leqslant k\leqslant q,}\\ {0,} & {k > q.} \end{array} \right. \tag{2.6}
$$

于是

$$
\rho_{k} = \left\{ \begin{array}{l l}{1,} & {k = 0,}\\ {-\theta_{k} + \sum_{i = 1}^{q - k}\theta_{i}\theta_{i + k}}\\ {1 + \sum_{i = 1}^{q}\theta_{i}^{2},} & {1\leqslant k\leqslant q,}\\ {0,} & {k > q,} \end{array} \right. \tag{2.7}
$$

即自相关函数在  $k = q$  处截尾.

我们自然要问  $\operatorname {AR}(p)$  模型的自相关函数和  $\operatorname {MA}(q)$  模型的偏相关函数具有什么特点.先看  $\operatorname {AR}(1)$  模型:

$$
X_{t} = \phi_{1}X_{t - 1} + \epsilon_{t}. \tag{2.8}
$$

注意到  $E(X_{t - 1}\epsilon_{t}) = 0$ ,在等式(2.8)两边取方差得到

$$
D(X_{t}) = \phi_{1}^{2}D(X_{t - 1}) + D(\epsilon_{t}).
$$

由  $X_{t}$  的平稳性知  $\sigma^{2} = D(X_{t}) = D(X_{t - 1})$ .记  $\sigma_{\epsilon}^{2} = D(\epsilon_{t})$ ,有

$$
\sigma^{2} = \frac{\sigma_{\epsilon}^{2}}{1 - \phi_{1}^{2}}.
$$

这样参数  $\phi_{1}$  必须满足  $|\phi_{1}|< 1$ .在此条件下  $\Phi^{- 1}(u) = (1 - \phi_{1}u)^{- 1} = \sum_{i = 1}^{\infty}\phi_{i}^{i}u^{i}$  存在,从而可以将(2.8)式改写为

$$
X_{t} = \Phi^{-1}(B)\epsilon_{t} = \sum_{i = 0}^{\infty}\phi_{i}^{i}\epsilon_{t - i}. \tag{2.9}
$$

与  $q$  阶滑动平均模型  $\sum_{i = 0}^{q}\phi_{i}^{i}\epsilon_{t - i}$  比较,我们可将(2.9)式看作是一个  $q = \infty$  的滑动

平均模型,由此可以推断它不会截尾.事实上将等式

$$
\gamma_{k} = E(X_{t}X_{t + k}) = E\big[X_{t}(\phi_{1}X_{t + k - 1} + \epsilon_{t + k})\big] = \phi_{1}\gamma_{k - 1}
$$

除以  $\gamma_{0}$  得到

$$
\rho_{k} = \phi_{1}\rho_{k - 1}.
$$

因  $\rho_{0} = 1$  ,用上式递推可知  $\rho_{k} = \phi_{1}^{k} = \mathrm{e}^{k\ln \phi_{1}}\neq 0$  ,但以指数速度衰减至零.我们称  $X_{t}$  的自相关函数拖尾.

对于一般的  $\operatorname {AR}(p)$  模型  $\Phi (B)X_{t} = \epsilon_{t}$  ,只要  $\Phi (u) = 0$  的根都在单位圆外, $\Phi^{- 1}(B)$  就存在,从而自相关函数也是拖尾的.模型的自相关函数可以利用

$$
E[\Phi (B)X_{t + k}X_{t}] / \gamma_{0} = E(\epsilon_{t + k}X_{t}) / \gamma_{0} = 0
$$

得到差分方程

$$
\rho_{k} - \phi_{1}\rho_{k - 1} - \dots -\phi_{p}\rho_{k - p} = 0
$$

来解出(见本章末附录).

用类似的方法,只要  $\Theta (u) = 0$  的根都在单位圆外,就可以把  $\operatorname {MA}(q)$  模型 $X_{t} = \Theta (B)\epsilon_{t}$  看成  $\scriptstyle{p = \infty}$  的自回归模型  $\Theta^{- 1}(B)X_{t} = \epsilon_{t}$  ,从而推断其偏相关函数拖尾.为了计算偏相关函数  $a_{k k}$  ,设  $a_{k1},a_{k2},\dots ,a_{k k}$  使得

$$
\begin{array}{l}{{f=E\left[\left(X_{t}-\sum_{i=1}^{k}a_{k i}X_{t-i}\right)^{2}\right]}}\\ {{=E\left[X_{t}^{2}-2X_{t}\sum_{i=1}^{k}a_{k i}X_{t-i}+\left(\sum_{i=1}^{k}a_{k i}X_{t-i}\right)^{2}\right]}}\\ {{=E(X_{t}^{2})-2\sum_{i=1}^{k}a_{k i}E(X_{t}X_{t-i})+\sum_{i=1}^{k}\sum_{j=1}^{k}a_{k i}a_{k j}E(X_{t-i}X_{t-j})}}\\ {{=\gamma_{0}-2\sum_{i=1}^{k}a_{k i}\gamma_{i}+\sum_{i=1}^{k}\sum_{j=1}^{k}a_{k i}a_{k j}\gamma_{i-j}}}\end{array} \tag{2.10}
$$

达到最小.将最优条件  $\frac{\partial f}{\partial a_{k j}} = 0(j = 1,2,\dots ,k)$  除以  $2\gamma_{0}$  ,写成矩阵方程

$$
\left[ \begin{array}{c c c c c}{1} & {\rho_{1}} & {\rho_{2}} & \dots & {\rho_{k - 1}}\\ {\rho_{1}} & 1 & {\rho_{1}} & \dots & {\rho_{k - 2}}\\ \vdots & \vdots & \vdots & & \vdots \\ {\rho_{k - 1}} & {\rho_{k - 2}} & {\rho_{k - 3}} & \dots & 1 \end{array} \right]\left[ \begin{array}{c}{a_{k1}}\\ {a_{k2}}\\ \vdots \\ {a_{k k}} \end{array} \right] = \left[ \begin{array}{c}{\rho_{1}}\\ {\rho_{2}}\\ \vdots \\ {\rho_{k}} \end{array} \right], \tag{2.11}
$$

当  $k = 1$  时可以直接得到  $a_{11} = \rho_{1}$  .令  $k = 2$  ,解

$$
\left[ \begin{array}{c c}{1} & {\rho_{1}}\\ {\rho_{1}} & 1 \end{array} \right]\left[ \begin{array}{c}{a_{21}}\\ {a_{22}} \end{array} \right] = \left[ \begin{array}{c}{\rho_{1}}\\ {\rho_{2}} \end{array} \right] \tag{2.12}
$$

得到

$$
a_{22} = \frac{\rho_{2} - a_{11}^{2}}{1 - a_{11}^{2}}.
$$

当  $k$  较大时下面的莱文森一德宾(Levinson- Durbin  $(\widehat{\mathbf{l}})$  )递推公式可以用来有效地计算偏相关函数:

$$
a_{k k} = \frac{\rho_{k} - \sum_{j = 1}^{k - 1}\rho_{k - j}a_{(k - 1)j}}{1 - \sum_{j = 1}^{k - 1}\rho_{j}a_{(k - 1)j}}, \tag{2.13}
$$

其中  $a_{k j} = a_{(k - 1) j} - a_{k k}a_{(k - 1)(k - j)}, j = 1,2, \dots , k - 1. ②$

例(AR和MA序列的自相关函数和偏相关函数) 考虑AR(2)模型

$$
X_{t} = 0.4 X_{t - 1} + 0.4 X_{t - 2} + \epsilon_{t} \tag{2.14}
$$

和MA(2)模型

$$
X_{t} = \epsilon_{t} + 0.6 \epsilon_{t - 1} - 0.4 \epsilon_{t - 2}, \tag{2.15}
$$

试用模拟方法分别生成上述两个模型长度为200的时间序列,并展示对应的自相关函数和偏相关函数的图形.

解R程序中的arima.sim()函数可以用来以模拟方法生成ARMA模型对应的时间序列.试用下面的R程序语句:

>sim.ar<- arima.sim(list(ar=c(0.4,0.4)),n=200)

生成200项(2.14)式描述的AR(2)模型,并且将它们存入sim.ar.式中list(ar=c(0.4,0.4))设定生成AR模型,且该模型的参数为  $\phi_{1} = 0.4$  和  $\phi_{2} = 0.4$ .类似地试用语句

>sim.ma<- arima.sim(list(ma=c(0.6,- 0.4)),n=200)

生成200项(2.15)式描述的MA(2)模型,并将它们存入sim.ma.这里需要特别注意的是R语言中的  $\mathrm{MA}(q)$  模型写成

$$
X_{t} = \epsilon_{t} + \sum_{i = 1}^{q} \theta_{i} \epsilon_{t - i},
$$

即系数前为正号,而定义(2.3)式中MA模型系数  $\theta_{i}$  前为负号.因此在输入(2.15)式的系数时要注意这一约定.

自相关函数和偏相关函数的图形可以分别用R函数acf()和pacf()得到.下面的R程序中先用par(mfrow=c(2,2))规定4个将要得到的图形应排成 $2 \times 2$ 矩阵,再作例题中要求的4个图形,执行后会在计算机显示屏幕弹出新窗口(见图15- 1)给出自相关函数和偏相关函数的图形.在acf()和pacf()的图中,横轴上下两侧的虚线是统计上是否显著不同于零的临界值,当时间序列的自

相关函数或偏相关函数的值落在这两条虚线以内的区域时,视为无法区别于0. 在acf()和 pacf()函数中,采用标准正态分布的  $95\%$  置信区间来确定临界值 $\pm 2 / \sqrt{n}$  ,其中  $n$  为时间序列的长度.从图  $15 - 1$  中可以清楚地看到生成的AR(2)序列的偏相关函数(从滞后  $\mathrm{Lag} = 1$  开始)在  $\mathrm{Lag} = 2$  处截尾,而它的自相关函数是拖尾的.成为对比的是生成的MA(2)序列的自相关函数(从滞后  $\mathrm{Lag} = 0$  开始)在  $\mathrm{Lag} = 2$  处截尾(在  $\mathrm{Lag} = 9$  处大约等于临界值),而它的偏相关函数是拖尾的.相关R程序如下:

>par(mfrow = c(2,2))

>acf(sim.ar,main = "ACF of AR(2)")

>acf(sim.ma,main = "ACF of MA(2)")

>pacf(sim.ar,main = "PACF of AR(2)")

>pacf(sim.ma,main = "PACF of MA(2)")

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
图15-1

由于ARMA模型比AR模型和MA模型都更一般,它的自相关函数和偏相关函数都拖尾.表15- 1总结了ARMA  $(p,q)$  模型及其特例AR  $(p)$  和MA  $(q)$  的性质.

对于非平稳的时间序列  $X_{t}$ ,我们常考虑其导出的差分序列  $Y_{t} = X_{t} - X_{t - 1}$ .例如金融市场中的证券指数(如上证指数)有长期的增长趋势,因而作为时间序列是

非平稳的.但其相应的对数序列的差分序列却是平稳的,它反映证券指数的百分比增益在固定范围内波动.如果差分序列仍非平稳,还可以考虑再做差分,也就是考虑原时间序列的二阶差分.当  $X_{t}$  的  $d$  阶差分序列满足  $\mathrm{ARMA}(\boldsymbol {\phi},\boldsymbol {q})$  模型时,我们说  $X_{t}$  满足  $\mathrm{ARIMA}(\boldsymbol {\phi},\boldsymbol {d},\boldsymbol {q})$  模型.当  $d = 0$  时,  $\mathrm{ARIMA}(\boldsymbol {\phi},\boldsymbol {0},\boldsymbol {q}) = \mathrm{ARMA}(\boldsymbol {\phi},\boldsymbol {q})$

表15一1 三种线性模型的性质  

<table><tr><td>模型</td><td>MA(q)</td><td>AR(p)</td><td>ARMA(p,q)</td></tr><tr><td>基本方程</td><td>Xt=θ(B)εt</td><td>Φ(B)Xt=εt</td><td>Φ(B)Xt=θ(B)εt</td></tr><tr><td>自相关函数</td><td>截尾</td><td>拖尾</td><td>拖尾</td></tr><tr><td>偏相关函数</td><td>拖尾</td><td>截尾</td><td>拖尾</td></tr></table>

# $\S 3$  模型的应用

在实际应用中观察时间序列得到的总是一个有限的样本.我们必须依据这些有限的信息来初步判断适用的模型,然后对模型的参数进行估计.由于我们依据的是不完全的信息,上述做法完全可能导致不同类型的,或同类但不同阶数的模型.要最终确定可以应用的模型,还须对得到的模型进行考核,经考核合格的模型才能用于对时间序列的实际预报.下面我们结合R函数的应用来逐一讨论这些步骤.

# (一)模型识别

将对时间序列进行观测得到的有限样本记为  $y_{1},y_{2},\dots ,y_{n}$  ,其中  $n$  为样本长度,用

$$
\overline{{y}} = \frac{\sum_{i = 1}^{n}y_{i}}{n}
$$

作为这个时间序列均值的估计.再令  $x_{i} = y_{i} - \overline{{y}} (i = 1,2,\dots ,n)$  ,得到一个零均值序列.用

$$
\hat{\gamma}_{k} = \frac{1}{n}\sum_{i = 1}^{n - k}x_{i}x_{i + k} \tag{3.1}
$$

作为协方差函数的估计.虽然(3.1)式是有偏估计,但它可以保证自相关函数的非负定性.而且由于实际应用中  $n$  都很大(至少大于50)且远大于  $k$  (通常  $k<$ $n / 10)$  ,(3.1)式与无偏估计  $\sum_{i = 1}^{n - k}x_{i}x_{i + k} / (n - k)$  相差很小.

由上节表15一1可知,如果已知模型为  $\operatorname {AR}(p)$  或  $\operatorname {MA}(q)$ ,则可用偏相关函数或自相关函数来确定它们的阶数。但是对于一般的ARMA模型,偏相关函数和自相关函数都是拖尾的。因此这两种相关函数难以直接用来有效地确定ARMA模型的阶数。针对这一问题,Tsay和Tiao发展了广义自相关函数(EACF)。①其原理是如果已知ARMA模型的AR部分的阶数  $p$ ,那么其系数可以通过对观测数据用回归方法得到,余下的MA部分的阶数可以用自相关函数的截尾性确定。广义自相关函数方法中对每个给定的AR阶数  $p$ ,将对应的MA部分的自相关函数按时间差由小到大表示为行向量。

例  $1②$  (广义自相关函数)表15一2和表15一3是3M公司的股票自1946年2月到2008年12月(共  $T = 755$  个月)月回报对数的广义自相关函数表。其中表15一2为数值表,表15一3为对应的简化表。简化表的做法是以  $2\sqrt{T}$  为界,绝对值小于这个界的用O来表示,大于这个界的用X来表示。理论上说简化广义自相关函数矩阵中O项构成的三角形的左上角的位置就指示了ARMA的阶数(参见下述例2),但在这个例子里当  $p = 0$  时  $q = 2,5,9,11$  处的值  $- 0.08$ , $0.08, - 0.08,0.09$  的绝对值只比  $2 / \sqrt{755} = 0.073$  略大一点点。如果略微放松截尾的界值,则  $p = 0$ , $q = 2,5,9,11$  处的X就会变成O,这样我们可以看出  $(p,q) = (0,0)$ 。实际情况经常不是非黑即白的。

表15-2 EACF数值表  

<table><tr><td rowspan="2">p</td><td colspan="13">q</td></tr><tr><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td></tr><tr><td>0</td><td>-0.06</td><td>-0.04</td><td>-0.08</td><td>0</td><td>0.02</td><td>0.08</td><td>0.01</td><td>0.01</td><td>-0.03</td><td>-0.08</td><td>0.05</td><td>0.09</td><td>-0.01</td></tr><tr><td>1</td><td>-0.47</td><td>0.01</td><td>-0.07</td><td>-0.02</td><td>0</td><td>0.08</td><td>-0.03</td><td>0</td><td>-0.01</td><td>-0.07</td><td>0.04</td><td>0.09</td><td>-0.02</td></tr><tr><td>2</td><td>-0.38</td><td>-0.35</td><td>-0.07</td><td>0.02</td><td>-0.01</td><td>0.08</td><td>0.03</td><td>0.01</td><td>0</td><td>-0.03</td><td>0.02</td><td>0.04</td><td>0.04</td></tr><tr><td>3</td><td>-0.18</td><td>0.14</td><td>0.38</td><td>-0.02</td><td>0</td><td>0.04</td><td>-0.02</td><td>0.02</td><td>-0.00</td><td>-0.02</td><td>0.02</td><td>0.01</td><td>0.04</td></tr><tr><td>4</td><td>0.42</td><td>0.03</td><td>0.45</td><td>-0.01</td><td>0</td><td>0</td><td>-0.01</td><td>0.03</td><td>0.01</td><td>0</td><td>0.02</td><td>0</td><td>0.01</td></tr><tr><td>5</td><td>-0.11</td><td>0.21</td><td>0.45</td><td>0.01</td><td>0.20</td><td>-0.01</td><td>0</td><td>0.04</td><td>-0.01</td><td>-0.01</td><td>0.03</td><td>0.01</td><td>0.03</td></tr><tr><td>6</td><td>-0.21</td><td>-0.25</td><td>0.24</td><td>0.31</td><td>0.17</td><td>-0.04</td><td>0</td><td>0.04</td><td>-0.01</td><td>-0.03</td><td>0.01</td><td>0.01</td><td>0.04</td></tr></table>

<table><tr><td rowspan="2">p</td><td colspan="13">q</td></tr><tr><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td></tr><tr><td>0</td><td>O</td><td>O</td><td>X</td><td>O</td><td>O</td><td>X</td><td>O</td><td>O</td><td>O</td><td>X</td><td>O</td><td>X</td><td>O</td></tr><tr><td>1</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>X</td><td>O</td></tr><tr><td>2</td><td>X</td><td>X</td><td>O</td><td>O</td><td>O</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>3</td><td>X</td><td>X</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>4</td><td>X</td><td>O</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>5</td><td>X</td><td>X</td><td>X</td><td>O</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr><tr><td>6</td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td><td>O</td></tr></table>

在R中已有由eacf()函数直接给出的广义自相关函数简化表,下面举例说明其应用.

例2 调用eacf()函数处理时间序列要用到R中的特殊函数库fBasics和TSA.打开R后点击菜单中的程序包,再选子菜单中的加载程序包,就可以从函数库的目录中选择这两个库并加载①.然后用下面的指令调用:

> library(fBasics)

> library(TSA)

再用指令arima.sim生成对应于模型

$$
X_{t} = 0.3X_{t - 1} - 0.7X_{t - 2} + \epsilon_{t} + 0.5\epsilon_{t - 1},
$$

长度为  $n = 120$  的时间序列并存入  $x$

$>$  x<- arima.sim(list(order  $=$  c(2,0,1),ar  $=$  c(0.3,- 0.7),ma  $=$ $\mathsf{c}(0.5),\mathsf{n} = 120)$

注意当模型中同时具有AR和MA部分时,要先用order  $= \mathsf{c}(\mathsf{p},0,\mathsf{q})$  给定AR部分的阶数  $\boldsymbol{\mathscr{p}}$  和MA部分的阶数  $q$  ,中间的0是指差分的阶数.接着用R的eacf()函数来识别模型:

> eacf(x,ar.max  $= 6$  ,ma.max  $= 6$

AR/MA

0123456

0xxxxxxx

1xxxxxxx

2x00000 如前所述,在输出矩阵中符号对应的

3x00000 最大的上三角形子矩阵的左上角指示模

4x00000 型的阶数.在本例中eacf()函数正确地

5xx0000 确定了模型为ARMA(2,1).

值得指出的是,由于时间序列的随机性,应用eacf()函数于一组特定的观察值并不一定能保证正确地识别模型.反复运行上述两条指令可发现eacf()函数只是以比较大的概率正确地识别模型,误判是可能发生的.

# (二)参数估计

知道了模型的阶数以后,还要估计模型的参数,未知参数除了模型中的系数外还包括  $\sigma_{\epsilon}^{2}$  .大致来说参数估计的方法是用观测样本和(3.1)式得到的估计值 $\hat{\gamma}_{i}$  代替  $\S 2$  公式(2.6)中的  $\gamma_{i}$  ,可估计模型  $\mathrm{MA}(q)$  的参数  $\theta_{i}(i = 1,2,\dots ,q)$  和  $\sigma_{\epsilon}^{2}$  类似地,由  $\hat{\gamma}_{i}$  得到估计值  $\hat{\rho}_{i} = \hat{\gamma}_{i} / \hat{\gamma}_{0}$  并代入矩阵方程(2.11),可以解出模型  $\operatorname {AR}(p)$  的参数  $\phi_{i}(i = 1,2,\dots ,p)$  的估计.一般的  $\operatorname {ARMA}(p,q)$  模型的参数估计是上述两种模型参数估计方法的结合.R函数库中的arima()函数可以用来对模型进行参数估计,指令如下(符号  $\%$  后为说明):

${\mathsf{>}}{\mathsf{m}}={\mathsf{a r i m a}}({\mathsf{x}},{\mathsf{o r d e r}}={\mathsf{c}}(2,0,1))\ {\mathsf{\%}}$  按ARMA(2,1)模型作参数估计并存人  $\mathfrak{m}$ $>m\%$  显示结果

Call:

arima  $\mathbf{\Psi}(\mathbf{x} = \mathbf{x}$  ,order  $= \mathsf{c}(2,0,1)$

Coefficients:

ar1 ar2 mal intercept

0.2334 - 0.7202 0.5936 0.0548

s.e. 0.0721 0.0675 0.0860 0.0997

sigma2 estimated as 1.03:log likelihood  $=$  - 173.36,aic  $=$  354.72

可以看到函数arima()得到了相对准确的参数估计值  $\hat{\phi}_{1} = 0.2334,\hat{\phi}_{2} = - 0.7202,$ $\hat{\theta}_{1} = 0.5936$  ,并给出了相应的标准误差(s.e.),同时它也估计出  $\sigma_{\epsilon}^{2} = 1.03$  .值得说明的是,这里截距(intercept)  $m = 0.0548$  的意义为时间序列  $X_{t} - m$  满足给出的模型.在这个例子里  $m = 0.0548$  可以近似看作为零.

# (三)模型考核

前面说过在时间序列模型识别过程中误判的可能是存在的,因此通过上面的

模型识别与参数估计得到的模型需要通过考核。如果通不过考核,就需要考虑其他可能的模型。下面用例2来介绍常用的考核方法。上述模型识别与参数估计给出

$$
X_{t} = \hat{\phi}_{1}X_{t - 1} + \hat{\phi}_{2}X_{t - 2} + \epsilon_{t} + \hat{\theta}_{1}\epsilon_{t - 1}.
$$

用  $x_{t}, t = 1,2, \dots , n$  记时间序列的观察值。当  $t \leqslant 0$  时,设  $x_{t} = \epsilon_{t} = 0$  是合理的。这样可以自上式解出

$$
\begin{array}{r l} & {\hat{\epsilon}_{1} = x_{1},}\\ & {\hat{\epsilon}_{2} = x_{2} - \hat{\phi}_{1}x_{1} - \hat{\theta}_{1}\hat{\epsilon}_{1},}\\ & {\hat{\epsilon}_{3} = x_{3} - \hat{\phi}_{1}x_{2} - \hat{\phi}_{2}x_{1} - \hat{\theta}_{1}\hat{\epsilon}_{2},}\\ & {\hat{\epsilon}_{4} = x_{4} - \hat{\phi}_{1}x_{3} - \hat{\phi}_{2}x_{2} - \hat{\phi}_{3}x_{1} - \hat{\theta}_{1}\hat{\epsilon}_{3},} \end{array}
$$

如此递推得到  $\epsilon_{t}$  序列的估计  $\hat{\epsilon}_{t}, t = 1,2, \dots , n$ 。如果模型很接近实际情况,那么  $\hat{\epsilon}_{t}$ ,  $t = 1,2, \dots , n$  应有白噪声序列的特征。这是用以考核模型的基础。对于ARMA  $(p, q)$  模型,我们常用其自相关函数是否接近于零来做判断,也就是检验假设  $H_{0}: \hat{\rho}_{1} = \hat{\rho}_{2} = \dots = \hat{\rho}_{k} = 0$ 。用效果比较好的Box- Ljung方法考察统计量

$$
Q = n(n + 2) \sum_{k = 1}^{h} \frac{\hat{\rho}_{k}^{2}}{n - k},
$$

其中  $\hat{\rho}_{k}$  是  $\hat{\epsilon}_{t}, t = 1,2, \dots , n$  的自相关函数。当  $\hat{\epsilon}_{t}, t = 1,2, \dots , n$  为白噪声序列时, $Q$  应服从自由度为  $h$  的  $\chi^{2}$  分布。R的函数库包含Box.test函数,可以直接调用Box- Ljung方法,指令是:

>Box.test(m $residuals, lag = 12, \text{type} = \text{Ljung}, \text{fitdf} = 3)$

Box- Ljung test

data: m\(residuals

X- squared = 2.9414, df = 9, p- value = 0.9666

调用这个函数时一般用  $\text{lag} = n / 10$  来给出自由度,并用  $\text{fitdf} = p + q$  给出约束的数目。于是对于此例,自由度就是  $\text{df} = \text{lag} - p - q = 9$ 。 $p$  值为0.9666,远大于拒绝假设  $H_{0}$  的显著性水平0.05。因而按0.05的显著性水平,这个模型可以通过考核。

# (四)预报

在金融、气象、经济和工程实践中经常遇到的问题是如何根据历史和现状来预测将来的情况,因此建立并考核时间序列模型的最终目的是对时间序列进行预报。下面以零均值时间序列为例来讨论预报问题。设  $x_{i}, i = 1,2, \dots , n$  为一个零均值时间序列的观察值,用它来对  $x_{n + l}, l > 0$  作估计,并将这个估计值记为

$\hat{x}_{n}(l)$ . 这里  $l$  表示预报的是  $n$  个观测数据之后的第  $l$  个数据, 叫做  $l$  步预报. 在作  $l$  步预报时总会遇到  $n$  以后的白噪声的值. 注意到当  $s > t$  时

$$
E(\epsilon_{s}X_{t}) = 0,
$$

也就是说  $x_{i},i = 1,2,\dots ,n$  与  $t > n$  以后的  $\epsilon_{t}$  是不相关的. 所以我们约定  $l > 0$  时

$$
\hat{\epsilon}_{n + l} = 0,
$$

也就是说将  $n$  以后的  $\epsilon_{n + l}$  的估计值都取为零. 预报的原理是去寻找  $\hat{x}_{n}(l)$  作为  $x_{i},i = 1,2,\dots ,n$  的一个线性函数  $\hat{x}_{n}(l) = \sum_{i = 1}^{n}c_{i}x_{i}$  使得

$$
E\{\left[x_{n + l} - \hat{x}_{n}(l)\right]^{2}\}
$$

达到最小, 这样的  $\hat{x}_{n}(l)$  称为  $x_{n + l}$  的线性最小方差估计. 下面来讨论 AR, MA 和 ARMA 模型的具体预报方法.

# AR 模型的预报

由(2.2)式知用估计好的参数  $\hat{\phi}_{i}(i = 1,2,\dots ,p)$  可将模型写成

$$
x_{n + l} = \hat{\phi}_{1}x_{n + l - 1} + \hat{\phi}_{2}x_{n + l - 2} + \dots +\hat{\phi}_{p}x_{n + l - p} + \hat{\epsilon}_{n + l}.
$$

已知  $l > 0$  时  $\epsilon_{n + l}$  的估计  $\hat{\epsilon}_{n + l} = 0$ , 因此估计公式成为

$$
x_{n + l} = \hat{\phi}_{1}x_{n + l - 1} + \hat{\phi}_{2}x_{n + l - 2} + \dots +\hat{\phi}_{p}x_{n + l - p}.
$$

当  $l = 1$  时

$$
\hat{x}_{n}(1) = \hat{\phi}_{1}x_{n} + \hat{\phi}_{2}x_{n - 1} + \dots +\hat{\phi}_{p}x_{n - p + 1}.
$$

当  $l = 2$  时公式右边所需的  $x_{n + 1}$  用  $\hat{x}_{n}(1)$  来替代, 得到

$$
\hat{x}_{n}(2) = \hat{\phi}_{1}\hat{x}_{n}(1) + \hat{\phi}_{2}x_{n} + \dots +\hat{\phi}_{p}x_{n - p + 2}.
$$

类似地, 当  $l = 3$  时

$$
\hat{x}_{n}(3) = \hat{\phi}_{1}\hat{x}_{n}(2) + \hat{\phi}_{2}\hat{x}_{n}(1) + \hat{\phi}_{3}x_{n} + \dots +\hat{\phi}_{p}x_{n - p + 3}.
$$

不断递推就可以得到任意第  $l$  步的预报值. 只是  $l$  越大, 预报的准确性就越差. 如果对  $k\leqslant 0$  约定  $\hat{x}_{n}(k) = x_{n + k}$ , 那么上面的预报公式可以简约地写成

$$
\hat{x}_{n}(l) = \sum_{i = 1}^{p}\hat{\phi}_{i}\hat{x}_{n}(l - i).
$$

# MA 模型的预报

估计好参数  $\hat{\theta}_{i},i = 1,2,\dots ,q$  后模型为

$$
x_{n + l} = \epsilon_{n + l} - \hat{\theta}_{1}\epsilon_{n + l - 1} - \dots -\hat{\theta}_{q}\epsilon_{n + l - q}. \tag{3.2}
$$

当  $s > n$  时  $\epsilon_{s} = 0$ , 因此  $l > q$  时上式的右端各项均为零. 因此  $\hat{x}_{n}(l) = 0$

当  $1\leqslant l\leqslant q$  时, 由(3.2)式可知关键在于预报  $\hat{\epsilon}_{i},i = n - q + 1,\dots ,n$ . 将(3.2)式改写为

$$
\epsilon_{t} = x_{t} + \hat{\theta}_{1} \epsilon_{t - 1} + \dots + \hat{\theta}_{q} \epsilon_{t - q}.
$$

注意到当  $s \leqslant 0$  时  $\epsilon_{s} = 0$ , 我们可以用递推的方法得到

$$
\begin{array}{r l} & {\hat{\epsilon}_{1} = x_{1},}\\ & {\hat{\epsilon}_{2} = x_{2} + \hat{\theta}_{1}\hat{\epsilon}_{1}}\\ & {\quad = x_{2} + \hat{\theta}_{1}x_{1},}\\ & {\hat{\epsilon}_{3} = x_{3} + \hat{\theta}_{1}\hat{\epsilon}_{2} + \hat{\theta}_{2}\hat{\epsilon}_{1}}\\ & {\quad = x_{3} + \hat{\theta}_{1}(x_{2} + \hat{\theta}_{1}x_{1}) + \hat{\theta}_{2}x_{1},} \end{array}
$$

算出  $\hat{\epsilon}_{i}, i = n - q + 1, \dots , n$  以后, 把它们代回 (3.2) 式就可以得到预报值  $\hat{x}_{n}(l)$ ,  $l = 1, 2, \dots , q$ .

# ARMA模型的预报

结合AR和MA模型的预报方法就可以预报ARMA模型.先把ARMA模型写成

$$
x_{n + l} = \hat{\phi}_{1} x_{n + l - 1} + \dots + \hat{\phi}_{p} x_{n + l - p} + \epsilon_{n + l} - \hat{\theta}_{1} \epsilon_{n + l - 1} - \dots - \hat{\theta}_{q} \epsilon_{n + l - q}. \tag{3.3}
$$

当  $l > q$  时, 有  $\epsilon_{n + l} = \epsilon_{n + l - 1} = \dots = \epsilon_{n + l - q} = 0$ , 于是ARMA模型 (3.3) 变成

$$
x_{n + l} = \hat{\phi}_{1} x_{n + l - 1} + \dots + \hat{\phi}_{p} x_{n + l - p}.
$$

我们可以应用和AR模型相同的预报方法,

当  $1 \leqslant l \leqslant q$  时, 可以用类似MA模型的方法得到  $\hat{\epsilon}_{i}, i = n - q + 1, \dots , n$ , 然后把它们代回 (3.3) 式, 再应用AR模型的预报方法得到  $\hat{x}_{n}(l), l = 1, 2, \dots , q$ .

R函数库中的predict()函数可以用来方便地对考核过的ARIMA模型进行预报.下面再以例2中生成的时间序列为例来说明如何使用predict()函数来预报并作图.指令

$\geq \texttt{m.p r e d} < - \texttt{p r e d i c t} (\mathtt{a r i m a}(\mathtt{x},\mathtt{o r d e r} = \mathtt{c}(2,0,1)),\mathtt{n.a h e a d} = 10)$

按ARMA(2,1)模型生成对  $\mathbf{x}$  的10步预报并存入m.pred.预报结果m.pred中包含两部分信息:预报值m.pred  $\mathbb{S}$  pred和预报标准误差m.pred  $\mathbb{S}$  se.下面的指令运用这些信息作出预报,如图15一2所示.

$\geq \texttt{p l o t} (\mathbf{x},\mathbf{x}\mathbf{l}\mathbf{i}\mathbf{m} = \mathbf{c}(0,130))\mathbf{\Omega}$ $\%$  图示原始数据并预留  $130 - 120 = 10$  步预报空间 $\geq \mathsf{l i n e s}(\mathsf{m}.\mathsf{p r e d}\mathbb{S}\mathsf{p r e d},\mathsf{l w d} = 2)\mathsf{\Omega}_{\mathcal{G}}$  图示预报值,lwd  $= 2$  指定线条为2倍标准线粗

$\geq \mathsf{l i n e s}(\mathsf{m}.\mathsf{p r e d}\mathbb{S}\mathsf{p r e d} + 2*\mathsf{m}.\mathsf{p r e d}\mathbb{S}\mathsf{s e},\mathsf{l t y} = 2)\mathsf{\Omega}_{\mathcal{G}}$  图示预报值上限,lty  $= 2$  指定用虚线

>lines(m.pred $pred - 2 * m.pred$ se, lty = 2) % 图示预报值下限, lty = 2 指定用虚线

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
图15-2

下例将以上讨论的方法应用于实际数据.

例3 已公布的统计数据列举了10年期国债利率从2005年1月至2014年12月的120个月度变化情况.试用其一阶差分时间序列的前面114项建立模型,对最后5项进行预报并与实际数据比较.

解 先从本书数字课程网站下载数据文件shuju.csv,存入子目录C:/R- example(或任何其他子目录),并用指令

>setwd("C:/R- example")

将上述子目录设置为R的工作目录.然后用下面的指令读入数据,计算差分序列并画出其前114项的ACF和PACF图形(见图15- 3).

>bond10 = read.csv(file = "shuju.csv", head = TRUE, sep = ",")

>l = length(bond10 $Yield)$  计算序列长度

>h <- diff(bond10 $Yield)$  计算利率差分序列

>x <- h[1:(1 - 5)] % 保留最后五项

>par(mfrow = c(2,1))

>acf(x)

>pacf(x)

观察自相关函数和偏相关函数图形的截尾性质可见AR(1),MA(1)以及MA(6)都是可能的模型.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
图15-3

我们先考虑AR(1)模型并用arima()函数来估计参数如下:

$\mathbf{\sigma} > \mathbf{m}1 = \mathbf{a}\mathbf{r}\mathbf{i}\mathbf{m}\mathbf{a}(\mathbf{x},\mathbf{o}\mathbf{r}\mathbf{d}\mathbf{e}\mathbf{r} = \mathbf{c}(1,0,0))$

>>ml

Call:

arima(x=x,order=c(1,0,0))

Coefficients:

ar1 intercept 0.2207 - 0.0149 s.e. 0.0909 0.0257

sigma^2 estimated as 0.04607:log likelihood = 13.64,aic = - 21.27 参数估计的结果给出如下模型:

$$
x_{t} = -0.0149 + 0.2207x_{t - 1} + \sqrt{0.04607}\theta_{t},
$$

其中  $\theta_{t} \sim N(0,1)$ . 接下来用Box- Ljung方法来考核模型. 指令是  $\geq \text{Box.test} (\text{m1}$  residuals, lag = 12, type = 'Ljung', fitdf = 1)

Box- Ljung test

data: m1\$residuals

X- squared = 12.7208,df = 11,p- value = 0.312

对于此例,自由度是  $\mathrm{df} = 11$ .  $p$  值为0.312,远大于拒绝假设  $H_{0}$  的显著性水平0.05. 因而按0.05的显著性水平,这个模型可以通过考核. 接下来我们用AR(1)模型来作预报并和保留的5个数据相比较. 由图15- 4可见实际数据和预报相当接近.

>>ml.pred<- predict(arima(x,order = c(1,0,0)),n.ahead = 5)

>plot(x,xlim=c(0,119))

>lines(m1. pred\(pred, lwd = 2)

>lines(m1. pred $pred + 2 * m1. pred$ se,lty=2)

>lines(m1. pred $pred - 2 * m1. pred$ se,lty=2)

>lines(h,lwd=1)

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
图15-4

最后我们指出用同样方法可得出MA(1)和MA(6)也能通过考核并很好预报上述差分序列(习题).由此可见对于实际问题,适合的模型可能不是唯一的,取舍通常要视实际情况而定.

# 小结

时间序列有着广泛的应用.本章着重讨论平稳时间序列的线性自回归滑动平均模型及其特例自回归模型和滑动平均模型.自相关函数和偏相关函数是刻画时间序列的重要数字特征,它们可以有效地区分自回归滑动平均模型和它的子模型,并可以用来估计这些模型的阶数.

在实际应用中,我们可以通过观察得到时间序列的有限样本.根据样本可以判断适用的模型,然后进行参数估计.如果得到的模型通过考核,则可以用来对时间序列给出预报.整个应用过程中所需的步骤都已经程序化,我们通过应用实例介绍了如何使用相关的函数来建模.

# 重要术语及主题

时间序列 平稳时间序列 线性自回归滑动平均模型 自回归模型 滑动平均模型 自相关函数 偏相关函数 模型识别 参数估计 模型考核 预报

# 附录 差分方程的解

我们看到  $\operatorname {AR}(\boldsymbol {\mathbf{\rho}})$  模型的自相关函数满足方程

$$
\rho_{k} - \phi_{1}\rho_{k - 1} - \dots -\phi_{p}\rho_{k - p} = 0, \tag{1}
$$

这是一个典型的差分方程.为求解,设  $\rho_{k} = x^{k}$  ,代入(1)式并除以  $x^{k - p}$  得到代数方程

$$
x^{p} - \phi_{1}x^{p - 1} - \dots -\phi_{p - 1}x - \phi_{p} = 0. \tag{2}
$$

(2)式称为差分方程(1)的特征方程.易见,如果  $\xi$  是代数方程(2)的根,则  $\rho_{k} = \xi^{k}$  为差分方程(1)的解.代数方程(2)一般有  $\boldsymbol{\mathscr{p}}$  个根  $\xi_{1},\xi_{2},\dots ,\xi_{p}$  (假设没有重根).由于差分方程(1)是线性的,其解的线性组合仍然是解.由此得到差分方程(1)的解的一般形式为

$$
\rho_{k} = a_{1}\xi_{1}^{k} + a_{2}\xi_{2}^{k} + \dots +a_{p}\xi_{p}^{k},
$$

其中  $a_{1},a_{2},\dots ,a_{p}$  为参数,它们可由前  $\boldsymbol{\mathscr{p}}$  个自相关函数的值来确定,

# 习题

1. 用延迟算子表示下列模型:

(1)  $X_{t} - 0.5X_{t - 1} = \epsilon_{t}$

(2)  $X_{t} = \epsilon_{t} - 0.7\epsilon_{t - 1} - 0.24\epsilon_{t - 2}$

(3)  $X_{t} - 0.5X_{t - 1} = \epsilon_{t} - 0.7\epsilon_{t - 1} - 0.24\epsilon_{t - 2}$

(4)  $X_{t} - 1.5X_{t - 1} + 0.5X_{t - 2} = \epsilon_{t}$

(5)  $X_{t} - X_{t - 1} = \epsilon_{t} - 0.5\epsilon_{t - 1}$

2. 将上题中的模型(1)一(5)按  $\operatorname {ARMA}(\boldsymbol {\mathbf{\rho}},\boldsymbol {\mathbf{\rho}})$  分类.

3. 证明自相关函数的性质:(1)  $\rho_{k} = \rho_{-k}$  和(2)  $\left|\rho_{k}\right|\leqslant 1$

4. 求  $X_{t} = \epsilon_{t} - 0.5\epsilon_{t - 1} - 0.24\epsilon_{t - 2}$  的自相关函数.

5. 将  $\S 2$  例中运用的R程序用于下列模型:

(1)  $X_{t} - 0.5X_{t - 1} = \epsilon_{t}$

(2)  $X_{t} = \epsilon_{t} - 0.7\epsilon_{t - 1} - 0.24\epsilon_{t - 2}$

6. 反复运行  $\S 3$  例2中的arima.sim()和eacf()至少100次,函数正确识别模型的频率有多大?与同学的结果作综合比较,这个频率稳定吗?

7. 讨论MA(1)和MA(6)模型对  $\S 3$  例3中10年期国债利率的一阶差分时间序列的适用性.

# 选做习题

1. 一打靶场备有 5 支某种型号的枪, 其中 3 支已经校正, 2 支未经校正. 某人使用已校正的枪击中目标的概率为  $p_{1}$ , 使用未经校正的枪击中目标的概率为  $p_{2}$ . 他随机地取一支枪进行射击, 已知他射击了 5 次, 都未击中, 求他使用的是已校正的枪的概率 (设各次射击的结果相互独立).

2. 某人共买了 11 个水果, 其中有 3 个是二级品, 8 个是一级品. 随机地将水果分给  $A, B, C$  三人, 各人分别得到 4 个、6 个、1 个.

(1) 求  $C$  未拿到二级品的概率.

(2) 已知  $C$  未拿到二级品, 求  $A, B$  均拿到二级品的概率.

(3) 求  $A, B$  均拿到二级品而  $C$  未拿到二级品的概率.

3. 一系统  $L$  由两个只能传输字符 0 和 1 的独立工作的子系统  $L_{1}$  与  $L_{2}$  串联而成 (如题 3 图), 每个子系统输入为 0 输出为 0 的概率为  $p(0 < p < 1)$ ; 而输入为 1 输出为 1 的概率也是

$p$ . 今在图中  $a$  端输入字符 1, 求系统  $L$  的  $b$  端输出字符 0 的概率.

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
题3图

4. 甲、乙两人轮流掷一颗骰子, 每轮掷一次, 谁先掷得 6 点谁得胜, 从甲开始掷, 问甲、乙得胜的概率各为多少?

5. 将一颗骰子掷两次, 考虑事件  $A =$  "第一次掷得点数 2 或 5",  $B =$  "两次点数之和至少为 7", 求  $P(A), P(B)$ , 并问事件  $A, B$  是否相互独立.

6.  $A, B$  两人轮流射击, 每次每人射击一枪, 射击的次序为  $A, B, A, B, A, \dots$ , 射击直至击中两枪为止. 设每人击中的概率均为  $p$ , 且各次击中与否相互独立. 求击中的两枪是由同一人射击的概率. (提示: 分别考虑两枪是由  $A$  击中的与两枪是由  $B$  击中的两种情况, 若两枪是由  $A$  击中的, 则射击必然在奇数次结束. 又当  $|x| < 1$  时,  $1 + 2x + 3x^{2} + \dots = 1 / (1 - x)^{2}$ .)

7. 有 3 个独立工作的元件 1、元件 2、元件 3, 它们的可靠性分别为  $p_{1}, p_{2}, p_{3}$ . 设由它们组成一个"3 个元件取 2 个元件的表决系统", 记为  $2 / 3[G]$ . 这一系统的运行方式是当且仅当 3 个元件中至少有 2 个正常工作时这一系统正常工作. 求这一  $2 / 3[G]$  系统的可靠性.

8. 在如题 8 图所示的桥式结构的电路中, 第  $i$  个继电器触点闭合的概率为  $p_{i}, i = 1, 2, 3, 4, 5$ . 各继电器工作相互独立.

(1) 以继电器触点 1 是否闭合为条件, 求  $A$  到  $B$  之间为通路的概率.

(2) 已知  $A$  到  $B$  为通路的条件下, 求继电器触点 3 闭

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
题8图

合的概率.

9. 进行非学历考试,规定考甲、乙两门课程,每门课程考试第一次未通过都只允许考第二次.考生仅在课程甲通过后才能考课程乙,如两门课程都通过可获得一张资格证书.设某考生通过课程甲的各次考试的概率为  $p_{1}$ ,通过课程乙的各次考试的概率为  $p_{2}$ ,设各次考试的结果相互独立.又设考生参加考试直至获得资格证书或者不准予再考为止.以  $X$  表示考生总共需考试的次数.求  $X$  的分布律.

10. (1)5只电池中有2只是次品,每次取一只测试,直到将2只次品都找到.设第2只次品在第  $X$  (  $X = 2,3,4,5$  )次找到,求  $X$  的分布律(注:实际上第5次检测可无须进行).

(2)5只电池中2只是次品,每次取一只,直到找出2只次品或3只正品为止.写出需要测试的次数的分布律.

11. 向某一目标发射炮弹,设炮弹弹着点离目标的距离为  $R$  (以  $10 \mathrm{~m}$  计),  $R$  服从瑞利分布,其概率密度为

$$
f_{R}(r) = \left\{ \begin{array}{ll}\frac{2r}{25} \mathrm{e}^{-r^{2} / 25}, & r > 0, \\ 0, & r \leqslant 0. \end{array} \right.
$$

若弹着点离目标不超过5个单位时,目标被摧毁,

(1)求发射一枚炮弹能摧毁目标的概率,

(2)为使至少有一枚炮弹能摧毁目标的概率不小于0.94,问最少需要独立发射多少枚炮弹?

12. 设一枚深水炸弹击沉一潜艇的概率为  $1 / 3$ ,击伤的概率为  $1 / 2$ ,击不中的概率为  $1 / 6$ .并设击伤两次也会导致潜艇下沉.求施放4枚深水炸弹能击沉潜艇的概率.(提示:先求击不沉的概率.)

13. 一盒中装有4只白球,8只黑球,从中取3只球,每次一只,作不放回抽样.

(1)求第1次和第3次都取到白球的概率.(提示:考虑第2次的抽取.)

(2)求在第1次取到白球的条件下,前3次都取到白球的概率,

14. 设元件的寿命  $T$  (以  $\mathrm{h}$  计)服从指数分布,分布函数为

$$
F(t) = \left\{ \begin{array}{ll}1 - \mathrm{e}^{-0.03t}, & t > 0, \\ 0, & t \leqslant 0. \end{array} \right.
$$

(1)已知元件至少工作了  $30 \mathrm{~h}$ ,求它能再至少工作  $20 \mathrm{~h}$  的概率.

(2)由3个独立工作的此种元件组成一个  $2 / 3[G]$  系统(参见第7题).求这一系统的寿命  $X > 20$  的概率.

15. (1)已知随机变量  $X$  的概率密度为  $f_{X}(x) = \frac{1}{2} \mathrm{e}^{-|x|}, -\infty < x < \infty$ ,求  $X$  的分布函数.

(2)已知随机变量  $X$  的分布函数为  $F_{X}(x)$ ,另有随机变量

$$
Y = \left\{ \begin{array}{ll}1, & X > 0, \\ -1, & X \leqslant 0, \end{array} \right.
$$

试求  $Y$  的分布律和分布函数.

16. (1) 设随机变量  $X$  服从泊松分布, 其分布律为

$$
P\{X = k\} = \frac{\lambda^{k}\mathrm{e}^{-\lambda}}{k!}, \quad k = 0,1,2,\dots ,
$$

问当  $k$  取何值时  $P\{X = k\}$  为最大?

(2) 设随机变量  $X$  服从二项分布, 其分布律为

$$
P\{X = k\} = \binom{n}{k} p^{k}(1 - p)^{n - k}, \quad k = 0,1,2,\dots ,n.
$$

问当  $k$  取何值时  $P\{X = k\}$  为最大?

17. 若离散型随机变量  $X$  具有分布律

则称  $X$  服从取值为  $1,2,\dots ,n$  的离散型均匀分布. 对于任意非负实数  $x$  ,记  $[x]$  为不超过  $x$  的最大整数. 设随机变量  $U \sim U(0,1)$  ,证明  $X = [nU] + 1$  服从取值为  $1,2,\dots ,n$  的离散型均匀分布.

18. 设随机变量  $X \sim U(-1,2)$  ,求  $Y = \left|X\right|$  的概率密度.

19. 设随机变量  $X$  的概率密度为

$$
f_{X}(x) = \left\{ \begin{array}{ll}0, & x< 0, \\ \frac{1}{2}, & 0 \leqslant x< 1, \\ \frac{1}{2x^{2}}, & 1 \leqslant x< \infty . \end{array} \right.
$$

求  $Y = \frac{1}{X}$  的概率密度.

20. 设随机变量  $X$  服从参数为  $1 / \lambda$  的指数分布. 验证随机变量  $Y = [X]$  服从参数为  $1 - \mathrm{e}^{-\lambda}$  的几何分布. 这一事实表明连续型随机变量的函数可以是离散型随机变量.

21. 投掷一枚硬币直至正面出现为止,引入随机变量

$X =$  投掷总次数.

$Y = \left\{ \begin{array}{ll}1, & \text {若首次投掷得到正面,} \\ 0, & \text {若首次投掷得到反面.} \end{array} \right.$

(1) 求  $X$  和  $Y$  的联合分布律及边缘分布律.

(2) 求条件概率  $P\{X = 1 \mid Y = 1\} , P\{Y = 2 \mid X = 1\}$ .

22. 设随机变量  $X \sim \pi (\lambda)$  ,随机变量  $Y = \max \{X,2\}$  . 试求  $X$  和  $Y$  的联合分布律及边缘分布律.

23. 设  $X,Y$  是相互独立的泊松随机变量,参数分别为  $\lambda_{1},\lambda_{2}$  ,求给定  $X + Y = n$  的条件下

$X$  的条件分布.

24. 一教授将两篇论文分别交给两个打字员打印. 以  $X, Y$  分别表示第一篇和第二篇论文的打印错误. 设  $X \sim \pi (\lambda), Y \sim \pi (\mu), X, Y$  相互独立.

(1)求  $X,Y$  的联合分布律.

(2)求两篇论文总共至多1个打印错误的概率.

25. 一等边三角形  $ROT$  (如题25图)的边长为1, 在三角形内随机地取点  $Q(X, Y)$  (意指随机点  $(X, Y)$  在三角形  $ROT$  内均匀分布).

(1)写出随机变量  $(X, Y)$  的概率密度.

(2)求点  $Q$  到底边  $OT$  的距离的分布函数,

26. 设随机变量  $(X, Y)$  具有概率密度

$$
f(x, y) = \left\{ \begin{array}{ll} p \mathrm{e}^{-x(y + 1)}, & x > 0, y > 0, \\ 0, & \text{其他.} \end{array} \right.
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_8.pdf-90fe657d-831b-4405-abb8-7662412d711a_8f1642bf706449aad7ee59b4f72fc58fdb067200943d3bbdda76842e10a103ea.jpg)  
题25图

(1)求边缘概率密度  $f_{X}(x), f_{Y}(y)$

(2)求条件概率密度  $f_{X|Y}(x|y), f_{Y|X}(y|x)$

27. 设有随机变量  $U$  和  $V$  ,它们都仅取  $1, -1$  两个值. 已知

$$
P\{U = 1\} = 1 / 2,
$$

$$
P\{V = 1|U = 1\} = 1 / 3 = P\{V = -1|U = -1\} .
$$

(1)求  $U$  和  $V$  的联合分布律.

(2)求  $x$  的方程  $x^{2} + U x + V = 0$  至少有一个实根的概率.

(3)求  $x$  的方程  $x^{2} + (U + V)x + U + V = 0$  至少有一个实根的概率.

28. 某图书馆一天的读者人数  $X \sim \pi (\lambda)$ , 任一读者借书的概率为  $p$ , 各读者借书与否相互独立. 记一天读者借书的人数为  $Y$ , 求  $X$  和  $Y$  的联合分布律.

29. 设随机变量  $X, Y$  相互独立, 且都服从均匀分布  $U(0, 1)$ , 求两变量之一至少为另一变量之值之两倍的概率.

30. 一家公司有一份保单招标, 两家保险公司竞标. 规定标书的保险费必须在 20 万元至 22 万元之间. 若两份标书保险费相差 2000 元或 2000 元以上, 招标公司将选择报价低者, 否则就重新招标. 设两家保险公司的报价是相互独立的, 且都在 20 万至 22 万之间均匀分布. 试求招标公司需重新招标的概率.

31. 设随机变量  $X \sim N(0, \sigma_{1}^{2}), Y \sim N(0, \sigma_{2}^{2})$ , 且  $X, Y$  相互独立, 求概率

$$
P\{0< \sigma_{2}X - \sigma_{1}Y< 2\sigma_{1}\sigma_{2}\} .
$$

32. NBA篮球赛中有这样的规律, 两支实力相当的球队比赛时, 每节主队得分与客队得分之差为正态随机变量, 均值为 1.5, 方差为 6, 并且假设四节的比分差是相互独立的. 问:

(1)主队胜的概率有多大?

(2)在前半场主队落后5分的情况下,主队得胜的概率有多大?

(3)在第一节主队赢5分的情况下,主队得胜的概率有多大?

33. 产品的某种性能指标的测量值  $X$  是随机变量, 设  $X$  的概率密度为

$$
f_{X}(x) = \left\{ \begin{array}{ll}x \mathrm{e}^{-\frac{1}{2} x^{2}}, & x > 0, \\ 0, & \text {其他.} \end{array} \right.
$$

测量误差  $Y \sim U(- \epsilon , \epsilon), X, Y$  相互独立. 求  $Z = X + Y$  的概率密度  $f_{Z}(z)$ , 并验证

$$
P\{Z > \epsilon \} = \frac{1}{2 \epsilon} \int_{0}^{2 \epsilon} \mathrm{e}^{-u^{2} / 2} \mathrm{d} u.
$$

34. 在一化学过程中, 产品中有份额  $X$  为杂质, 而在杂质中有份额  $Y$  是有害的, 而其余部分不影响产品的质量. 设  $X \sim U(0,0.1), Y \sim U(0,0.5)$ , 且  $X$  和  $Y$  相互独立. 求产品中有害杂质份额  $Z$  的概率密度.

35. 设随机变量  $(X,Y)$  的概率密度为

$$
f(x,y) = \left\{ \begin{array}{ll} \mathrm{e}^{-y}, & 0 < x < y, \\ 0, & \text {其他.} \end{array} \right.
$$

(1) 求  $(X, Y)$  的边缘概率密度.

(2) 问  $X, Y$  是否相互独立?

(3) 求  $X + Y$  的概率密度  $f_{X + Y}(z)$

(4) 求条件概率密度  $f_{X + Y}(x \mid y)$

(5) 求条件概率  $P\{X > 3 \mid Y < 5\}$

(6) 求条件概率  $P\{X > 3 \mid Y = 5\}$

36. 设某图书馆的读者借阅甲种图书的概率为  $p$ , 借阅乙种图书的概率为  $\alpha$ , 设每人借阅甲、乙图书的行动相互独立, 读者之间的行动也相互独立.

(1) 某天恰有  $n$  个读者, 求借阅甲种图书的人数的数学期望.

(2) 某天恰有  $n$  个读者, 求甲、乙两种图书中至少借阅一种的人数的数学期望.

37. 某种鸟在某时间区间  $(0, t_{0}]$  下蛋数为  $1 \sim 5$  只, 下  $r$  只蛋的概率与  $r$  成正比. 一个拾蛋人在时刻  $t_{0}$  去收集鸟蛋, 但他仅当鸟窝中多于 3 只蛋时才从中取走一只蛋. 在某处有这种鸟的鸟窝 6 个 (每个鸟窝保存完好, 各鸟窝中蛋的只数相互独立).

(1) 写出一个鸟窝中鸟蛋只数  $X$  的分布律.

(2) 对于指定的一个鸟窝, 求拾蛋人在该鸟窝中拾到一只蛋的概率.

(3) 求拾蛋人在 6 个鸟窝中拾到蛋的总数  $Y$  的分布律及数学期望.

(4) 求  $P\{Y < 4\} , P\{Y > 4\}$

(5) 当一个拾蛋人在这 6 个鸟窝中拾过蛋后, 紧接着又有一个拾蛋人到这些鸟窝中拾蛋, 也仅当鸟窝中多于 3 只蛋时, 拾取一只蛋, 求第二个拾蛋人拾得蛋数  $Z$  的数学期望.

38. 设袋中有  $r$  只白球、  $N - r$  只黑球. 在袋中取球  $n$ $(n \leqslant r)$  次, 每次任取一只作不放回抽样, 以  $Y$  表示取到白球的个数, 求  $E(Y)$ . (提示: 引入随机变量:

$$
X_{i}={\left\{\begin{array}{l l}{1,}&{{\frac{\#}{\#}}{\frac{\#}{\#}}i{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\ #}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}}\\ {0,}&{{\frac{\#}{\#}}{\frac{\#}{\#}}i{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}}\\ {\#{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\mathcal{A}}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\frac{\#}{\#}}{\#}}\end{array}\right.}
$$

则  $Y = X_{1} + X_{2} + \dots + X_{n}$ .

39. 抛一颗骰子直到所有点数全部出现为止, 求所需抛掷次数  $Y$  的数学期望. (提示: 令

$X_{1} = 1, X_{2} =$  "第一个点数得到后, 等待第二个不同点数所需的等待次数",  $X_{3} =$  "第一、二两点数得到后, 等待第三个不同点数所需的等待次数",  $X_{4}, X_{5}, X_{6}$  类似, 则  $Y = X_{1} + X_{2} + \dots +$ $X_{6}$ . 又几何分布  $P\{X = k\} = (1 - p)^{k - 1} p, k = 1,2, \dots$  的数学期望  $E(X) = \frac{1}{p}$ .

40. 设随机变量  $X, Y$  相互独立. 且  $X, Y$  分别服从以  $1 / \alpha , 1 / \beta$  为均值的指数分布. 求  $E(X^{2} + Y \mathrm{e}^{-X})$ .

41. 一酒吧间柜台前有 6 张凳子, 服务员预测, 若两个陌生人进来就座的话, 他们之间至少相隔两张凳子. (提示: 先列出两人之间至少隔两张凳子的不同情况.)

(1) 若真有两个陌生人入内, 他们随机地就座, 问服务员预言为真的概率是多少?

(2) 设两位顾客是随机就座的, 求顾客之间凳子数的数学期望.

42. 设随机变量  $X_{1}, X_{2}, \dots , X_{100}$  相互独立, 且都服从  $U(0,1)$ , 又设  $Y = X_{1} \cdot X_{2} \cdot \dots \cdot X_{100}$ , 求概率  $P\{Y< 10^{-40}\}$  的近似值.

43. 来自某个城市的长途电话呼唤的持续时间  $X$  (以  $\min$  计) 是一个随机变量, 它的分布函数是

$$
F(x) = \left\{ \begin{array}{ll} 1 - \frac{1}{2} \mathrm{e}^{-\frac{x}{3}} - \frac{1}{2} \mathrm{e}^{-\left[\frac{x}{3}\right]}, & x \geqslant 0, \\ 0, & x < 0 \end{array} \right.
$$

其中  $\left[\frac{x}{3}\right]$  是不大于  $\frac{x}{3}$  的最大整数.

(1) 画出  $F(x)$  的图形.

(2) 说明  $X$  是什么类型的随机变量.

(3) 求  $P\{X = 4\} , P\{X = 3\} , P\{X< 4\} , P\{X > 6\}$ . (提示:  $P\{X = a\} = F(a) - F(a - 0)$ .)

44. 一汽车保险公司分析一组(250人)签约的客户中的赔付情况. 据历史数据分析, 在未来的一周中一组客户中至少提出一项索赔的客户数  $X$  占  $10\%$ . 写出  $X$  的分布, 并求  $X > 250 \times 0.12$  (即  $X > 30$ ) 的概率. 设各客户是否提出索赔相互独立.

45. 在区间(0,1)随机地取一点  $X$ . 定义  $Y = \min \{X, 0.75\}$ .

(1) 求随机变量  $Y$  的值域.

(2) 求  $Y$  的分布函数, 并画出它的图形.

(3) 说明  $Y$  不是连续型随机变量,  $Y$  也不是离散型随机变量.

46. 设  $X_{1}, X_{2}$  是数学期望为  $\theta$  的指数分布总体  $X$  的容量为 2 的样本, 设  $Y = \sqrt{X_{1} X_{2}}$ , 试证明  $E\left(\frac{4Y}{\pi}\right) = \theta$ .

47. 设总体  $X\sim N(\mu ,\sigma^{2}),X_{1},X_{2},\dots ,X_{n}$  是一个样本.  $\overline{{X}},S^{2}$  分别为样本均值和样本方差,试证  $E[(\overline{{X}} S^{2})^{2}] = \Big(\frac{\sigma^{2}}{n} +\mu^{2}\Big)\Big(\frac{2\sigma^{4}}{n - 1} +\sigma^{4}\Big)$  .(提示:注意到  $\overline{{X}}$  与  $S^{2}$  相互独立,且有 $\frac{(n - 1)S^{2}}{\sigma^{2}}{\sim}\chi^{2}(n - 1).\Big)$

48. 设总体  $X$  具有概率密度

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{\theta^{2}} x e^{-x / \theta}, & x > 0, \\ 0, & x \leqslant 0, \end{array} \right.
$$

其中  $\theta > 0$  为未知参数,  $X_{1}, X_{2}, \dots , X_{n}$  是来自  $X$  的样本,  $x_{1}, x_{2}, \dots , x_{n}$  是相应的样本观察值.

(1)求  $\theta$  的最大似然估计量.

(2)求  $\theta$  的矩估计量.

(3)问求得的估计量是否是无偏估计量?

49. 设  $X_{1}, X_{2}, \dots , X_{n_{1}}$  以及  $Y_{1}, Y_{2}, \dots , Y_{n_{2}}$  为分别来自总体  $N(\mu_{1}, \sigma^{2})$  与  $N(\mu_{2}, \sigma^{2})$  的样本,且它们相互独立.  $\mu_{1}, \mu_{2}, \sigma^{2}$  均未知,试求  $\mu_{1}, \mu_{2}, \sigma^{2}$  的最大似然估计量.

50. 为了研究一批贮存着的产品的可靠性,在产品投入贮存时,即在时刻  $t_{0} = 0$  时,随机地选定  $n$  件产品,然后在预先规定的时刻  $t_{1}, t_{2}, \dots , t_{k}$  取出来进行检测(检测时确定已失效的去掉,将未失效的继续投入贮存),今得到以下的寿命试验数据:

<table><tr><td>检测时刻(月)</td><td>t1</td><td>t2</td><td>...</td><td>tk</td><td></td><td></td></tr><tr><td>区间(ti-1,ti)</td><td>(0,ti]</td><td>(ti,ti]</td><td>...</td><td>(tk-1,ti]</td><td>(tk,∞)</td><td></td></tr><tr><td>在(ti-1,ti)
的失效数</td><td>d1</td><td>d2</td><td>...</td><td>dk</td><td>s</td><td>∑k
i=1
di+s=n</td></tr></table>

这种数据称为区间数据.设产品寿命  $T$  服从指数分布,其概率密度为

$$
f(t) = \left\{ \begin{array}{ll}\lambda \mathrm{e}^{-\lambda t}, & t > 0, \\ 0, & \text{其他}, \end{array} \right. \lambda > 0 \text{未知}.
$$

(1)试基于上述数据写出  $\lambda$  的对数似然方程.(提示:考虑事件"  $n$  只产品分别在区间(0, $t_{1}]$  ,  $(t_{1},t_{2}]$  ,…,  $(t_{k - 1},t_{k}]$  失效  $d_{1},d_{2},\dots ,d_{k}$  只,而直至  $t_{k}$  还有  $s$  只未失效"的概率.)

(2)设  $d_{1}< n, s< n$ ,我们可以用数值解法求得  $\lambda$  的最大似然估计值,在计算机上计算是容易的.特别,取检测时间是等间隔的,即取  $t_{i} = i t_{1}, i = 1,2, \dots , k$ .验证,此时可得  $\lambda$  的最大似然估计为

$$
\hat{\lambda} = \frac{1}{t_{1}} \ln \left[1 + \frac{n - s}{\sum_{i = 2}^{k} (i - 1) d_{i} + s k}\right].
$$

51. 设某种电子器件的寿命  $T$  (以  $h$  计)服从指数分布,概率密度为

$$
f(t) = \left\{ \begin{array}{ll}\lambda \mathrm{e}^{-\pi t}, & t > 0, \\ 0, & \text{其他}, \end{array} \right.
$$

其中  $\lambda > 0$  未知.从这批器件中任取  $n$  只在时刻  $t = 0$  时投入独立寿命试验.试验进行到预定时间  $T_{0}$  结束.此时,有  $k$  (  $0< k< n$  )只器件失效,试求  $\lambda$  的最大似然估计.(提示:考虑"试验直至时刻  $T_{0}$  为止,有  $k$  只器件失效,而有  $n - k$  只未失效"这一事件的概率,从而写出  $\lambda$  的似然方程.)

52. 设系统由两个独立工作的成败型元件串联而成(成败型元件只有两种状态:正常工作或失效).元件1、元件2的可靠性分别为  $p_{1}, p_{2}$ ,它们均未知.随机地取  $N$  个系统投入试验,当系统中至少有一个元件失效时系统失效,现得到以下的试验数据: $n_{1}$  表示仅元件1失

效的系统数,  $n_{2}$  表示仅元件2失效的系统数,  $n_{12}$  表示元件1、元件2至少有一个失效的系统数,  $s$  表示未失效的系统数,  $n_{1} + n_{2} + n_{12} + s = N.$  这里  $n_{12}$  为隐蔽数据,也就是只知系统失效,但不能知道是由元件1或元件2单独失效引起的,还是由元件1,2均失效引起的,设隐蔽与系统失效的真正原因独立.

(1)试写出  $\boldsymbol{\mathscr{p}}_{1},\boldsymbol{\mathscr{p}}_{2}$  的似然函数.

(2)设有系统寿命试验数据  $N = 20,n_{1} = 5,n_{2} = 3,n_{12} = 1,s = 11.$  试求  $\boldsymbol{\mathscr{p}}_{1},\boldsymbol{\mathscr{p}}_{2}$  的最大似然估计值.(提示:  $\boldsymbol{\mathscr{p}}_{1}$  应满足方程  $(\boldsymbol{\mathscr{p}}_{1} - 1)(12\boldsymbol{\mathscr{p}}_{1}^{2} + 11\boldsymbol{\mathscr{p}}_{1} - 14) = 0.$  )

53. (1)设总体  $X$  具有分布律

<table><tr><td>X</td><td>1</td><td>2</td><td>3</td></tr><tr><td>p k</td><td>θ</td><td>θ</td><td>1-2θ</td></tr></table>

$\theta >0$  未知,今有样本

试求  $\theta$  的最大似然估计值和矩估计值,

(2)设总体  $X$  服从  $\boldsymbol{\Gamma}$  分布,其概率密度为

$$
f(x) = \left\{ \begin{array}{l l}{\frac{1}{\beta^{a} \Gamma(\alpha)} x^{a - 1} \mathrm{e}^{-x / \beta},} & {x > 0,}\\ {0,} & {\mathrm{~H~}\backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \mathrm{~H~}\backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \mathrm{~H~}\mathrm{~H~}\backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \begin{array}{l}{\mathrm{~H~}\backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \end{array} \right.}
$$

其形状参数  $\alpha >0$  为已知,尺度参数  $\beta >0$  未知.今有样本值  $x_{1},x_{2},\dots ,x_{n}$  ,求  $\beta$  的最大似然估计值.

54. (1)设随机变量  $Z = \ln X\sim N(\mu ,\sigma^{2})$  ,即  $X$  服从对数正态分布,验证  $E(X) = \exp \left\{\mu +\frac{1}{2}\sigma^{2}\right\}$ .

(2)设自(1)中总体  $X$  中取一容量为  $n$  的样本  $x_{1},x_{2},\dots ,x_{n}$  ,求  $E(X)$  的最大似然估计.此处设  $\mu ,\sigma^{2}$  均为未知.

(3)已知在文学家萧伯纳的An Intelligent Woman's Guide To Socialism一书中,一个句子的单词数近似地服从对数正态分布,设  $\mu$  及  $\sigma^{2}$  为未知.今自该书中随机地取20个句子,这些句子中的单词数分别为

$$
\begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c} & 52 & 24 & 15 & 67 & 15 & 22 & 63 & 26 & 16 & 32\\ & 7 & 33 & 28 & 14 & 7 & 29 & 10 & 6 & 59 & 30 \end{array}
$$

问这本书中,一个句子单词数均值的最大似然估计值等于多少?

55. 考虑进行定数截尾寿命试验,假设将随机抽取的  $n$  件产品在时间  $t = 0$  时同时投入试验.试验进行到  $m$  件  $(m{<}n)$  产品失效时停止,  $m$  件失效产品的失效时间分别为  $0\leqslant t_{1}\leqslant t_{2}\leqslant \dots$ $\leqslant t_{m},t_{m}$  是第  $m$  件产品的失效时间.设产品的寿命分布为韦布尔分布,其概率密度为

$$
f(t) = \left\{ \begin{array}{l l}{\frac{\beta}{\eta^{\beta}} t^{\beta -1}\mathrm{e}^{-\left(\frac{t}{\eta}\right)^{\beta}},} & {t > 0,}\\ {0,} & {\mathrm{~H~}\backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backslash \backlash} \end{array} \right.
$$

其中参数  $\beta >0$  已知. 求参数  $\eta$  的最大似然估计.

56. 设某大城市郊区的一条林荫道两旁开设了许多小商店, 这些商店的开设延续时间 (以月计) 是一个随机变量, 现随机地取 30 家商店, 将它们的延续时间按自小到大排序, 选其中前 8 家商店, 它们的延续时间分别是

$$
3.2 5.9 5.9 6.5 16.5 20.3 40.4 50.9
$$

假设商店开设延续时间的长度是韦布尔随机变量. 其概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{\beta}{\eta} x^{\beta -1} \mathrm{e}^{-\left(\frac{x}{\eta}\right)^{\beta}}, & x > 0, \\ 0, & \text {其他,} \end{array} \right.
$$

其中  $\beta = 0.8$

(1)试用上题结果,写出  $\eta$  的最大似然估计.

(2)按(1)的结果求商店开设延续时间至少为2年的概率的估计.

57. 设分别自总体  $N(\mu_{1}, \sigma^{2})$  和  $N(\mu_{2}, \sigma^{2})$  中抽取容量为  $n_{1}, n_{2}$  的两独立样本, 其样本方差分别为  $S_{1}^{2}, S_{2}^{2}$ . 试证, 对于任意常数  $a, b$ $(a + b = 1)$ ,  $Z = a S_{1}^{2} + b S_{2}^{2}$  都是  $\sigma^{2}$  的无偏估计, 并确定常数  $a, b$ , 使  $D(Z)$  达到最小.

58. 设总体  $X\sim N(\mu ,\sigma^{2}),X_{1},X_{2},\dots ,X_{n}$  是来自  $X$  的样本.已知样本方差  $S^{2} =$ ${\frac{1}{n-1}}\sum_{i=1}^{n}(X_{i}-{\overline{{X}}})^{2}$  是  $\sigma^{2}$  的无偏估计.验证样本标准差  $s$  不是标准差  $\sigma$  的无偏估计.(提示:记  $Y = \frac{(n - 1)S^{2}}{\sigma^{2}}$  ,则  $Y\sim \chi^{2}\left(n - 1\right)$  ,而  $S = \frac{\sigma}{\sqrt{n - 1}}\sqrt{Y}$  是  $Y$  的函数,利用  $\chi^{2}\left(n - 1\right)$  的概率密度可得  $E(S) = \sqrt{\frac{2}{n - 1}}\frac{\Gamma(n / 2)\sigma}{\Gamma(n - 1) / 2)}\neq \sigma .$  )

59. 设总体  $X$  服从指数分布, 其概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{\theta} \mathrm{e}^{-x / \theta}, & x > 0, \\ 0, & \text {其他.} \end{array} \right.
$$

$\theta >0$  未知. 从总体中抽取一容量为  $n$  的样本  $X_{1}, X_{2}, \dots , X_{n}$

(1)证明  $\frac{2n \overline{X}}{\theta} \sim \chi^{2}(2n)$

(2)求  $\theta$  的置信水平为  $1 - \alpha$  的单侧置信下限.

(3)某种元件的寿命(以h计)服从上述指数分布,现从中抽得一容量  $n = 16$  的样本,测得样本均值为  $5010\mathrm{~h~}$  ,试求元件的平均寿命的置信水平为0.90的单侧置信下限.

60. 设总体  $X \sim U(0, \theta), X_{1}, X_{2}, \dots , X_{n}$  是来自  $X$  的样本.

(1)验证  $Y = \max \{X_{1}, X_{2}, \dots , X_{n}\}$  的分布函数为

$$
F_{Y}(y) = \left\{ \begin{array}{ll}0, & y< 0, \\ y^{n} / \theta^{n}, & 0 \leqslant y< \theta , \\ 1, & y \geqslant \theta . \end{array} \right.
$$

(2)验证  $U = Y / \theta$  的概率密度为

$$
f_{U}(u) = \left\{ \begin{array}{ll}n u^{n - 1}, & 0< u< 1, \\ 0, & \text {其他.} \end{array} \right.
$$

(3) 给定正数  $\alpha , 0< \alpha < 1$ , 求  $U$  的分布的上  $\alpha /2$  分位数  $h_{\alpha /2}$  以及上  $1 - \alpha /2$  分位数  $h_{1 - \alpha /2}$ .

(4) 利用(2),(3)求参数  $\theta$  的置信水平为  $1 - \alpha$  的置信区间.

(5) 设某人上班的等车时间  $X\sim U(0,\theta),\theta$  未知. 现在有样本  $x_{1} = 4,2,x_{2} = 3,5,x_{3} = 1.7,x_{4} = 1.2,x_{5} = 2.4$ , 求  $\theta$  的置信水平为 0.95 的置信区间.

61. 设总体  $X$  服从指数分布, 概率密度为

$$
f(x) = \left\{ \begin{array}{ll}\frac{1}{\theta} \mathrm{e}^{-x / \theta}, & x > 0, \\ 0, & \text {其他,} \end{array} \right. \quad \theta >0.
$$

设  $X_{1},X_{2},\dots ,X_{n}$  是来自  $X$  的一个样本. 试取第 59 题中当  $\theta = \theta_{0}$  时的统计量  $\chi^{2} = \frac{2n\overline{X}}{\theta_{0}}$  作为检验统计量, 检验假设  $H_{0}:\theta = \theta_{0},H_{1}:\theta \neq \theta_{0}$ . 取显著性水平为  $\alpha$  (注意:  $E(\overline{X}) = \theta$ ).

设某种电子元件的寿命(以  $\mathrm{h}$  计)服从均值为  $\theta$  的指数分布, 随机取 12 只元件测得它们的寿命分别为

340 430 560 920 1380 1520 1660 1770 2100 2320 2350 2650 试取显著性水平  $\alpha = 0.05$ , 检验假设  $H_{0}:\theta = 1450, H_{1}:\theta \neq 1450$ .

62. 经过十一年的试验, 达尔文于 1876 年得到 15 对玉米样品的数据如下表, 每对作物除授粉方式不同外, 其他条件都是相同的. 试用逐对比较法检验不同授粉方式对玉米高度是否有显著的影响  $(\alpha = 0,05)$ . 问应增设什么条件才能用逐对比较法进行检验?

<table><tr><td>授粉方式</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td></td></tr><tr><td>异株授粉的作物高度(xi)</td><td>23 1/8</td><td>12</td><td>20 3/8</td><td>22</td><td>19 1/8</td><td>21 4/8</td><td>22 1/8</td><td></td></tr><tr><td>同株授粉的作物高度(yi)</td><td>27 3/8</td><td>21</td><td>20</td><td>20</td><td>19 3/8</td><td>18 5/8</td><td>18 5/8</td><td></td></tr><tr><td>授粉方式</td><td>8</td><td>9</td><td>10</td><td>11</td><td>12</td><td>13</td><td>14</td><td>15</td></tr><tr><td>异株授粉的作物高度(xi)</td><td>20 3/8</td><td>18 2/8</td><td>21 5/8</td><td>23 2/8</td><td>21</td><td>22 1/8</td><td>23</td><td>12</td></tr><tr><td>同株授粉的作物高度(yi)</td><td>15 2/8</td><td>16 4/8</td><td>18</td><td>16 2/8</td><td>18</td><td>12 6/8</td><td>15 4/8</td><td>18</td></tr></table>

63. 一内科医生声称, 如果患者每天傍晚聆听一种特殊的轻音乐会降低血压(舒张压, 以  $\mathrm{mmHg}$  计,  $1\mathrm{mmHg} = 133.3224\mathrm{Pa}$ ). 今选取了 10 个患者在试验之前和试验之后分别测量了血压, 得到以下的数据:

<table><tr><td>患者</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td></tr><tr><td>试验之前(xi)</td><td>86</td><td>92</td><td>95</td><td>84</td><td>80</td><td>78</td><td>98</td><td>95</td><td>94</td><td>96</td></tr><tr><td>试验之后(yi)</td><td>84</td><td>83</td><td>81</td><td>78</td><td>82</td><td>74</td><td>86</td><td>85</td><td>80</td><td>82</td></tr></table>

设  $D_{i} = X_{i} - Y_{i}(i = 1,2,\dots ,10)$  为来自正态总体  $N(\mu_{D},\sigma_{D}^{2})$  的样本,  $\mu_{D},\sigma_{D}^{2}$  均未知。试检验是否可以认为医生的意见是对的(取  $\alpha = 0.05$ )。

64. 以下是各种颜色的汽车的销售情况:

<table><tr><td>颜色</td><td>红</td><td>黄</td><td>蓝</td><td>绿</td><td>棕</td></tr><tr><td>车辆数</td><td>40</td><td>64</td><td>46</td><td>36</td><td>14</td></tr></table>

试检验顾客对这些颜色是否有偏爱,即检验销售情况是否是均匀的(取  $\alpha = 0.05$ )。

65. 某种闪光灯,每盏灯含4个电池,随机地取150盏灯,经检测得到以下的数据:

<table><tr><td>一盏灯损坏的电池数x</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>灯的盏数</td><td>26</td><td>51</td><td>47</td><td>16</td><td>10</td></tr></table>

试取  $\alpha = 0.05$  检验一盏灯损坏的电池数  $X\sim b(4,\theta)$  ( $\theta$  未知)。

66. 临界闪烁频率(cff)是人眼对于闪烁光源能够分辨出它在闪烁的最高频率(以  $\mathrm{Hz}$  计)。超过cff的频率,即使光源实际是在闪烁的,人看起来也是连续的(不闪烁的)。一项研究旨在判定cff的均值是否与人眼的虹膜颜色有关,所得数据如下:

<table><tr><td>虹膜颜色</td><td>棕色</td><td>绿色</td><td>蓝色</td><td></td></tr><tr><td rowspan="4">临界闪烁频率(cff)</td><td>26.8</td><td>26.3</td><td>26.4</td><td>29.1</td></tr><tr><td>27.9</td><td>24.8</td><td>24.2</td><td>27.2</td></tr><tr><td>23.7</td><td>25.7</td><td>28.0</td><td>29.9</td></tr><tr><td>25.0</td><td>24.5</td><td>26.9</td><td>28.5</td></tr></table>

试在显著性水平0.05下,检验各种虹膜颜色相应的cff的均值有无显著的差异。设各个总体服从正态分布,且方差相等,不同颜色下的样本之间相互独立。

67. 下面列出了挪威人自1938—1947年间年人均脂肪消耗量与患动脉粥样硬化症而死亡的死亡率之间相关的一组数据:

<table><tr><td>年份</td><td>1938</td><td>1939</td><td>1940</td><td>1941</td><td>1942</td><td>1943</td><td>1944</td><td>1945</td><td>1946</td><td>1947</td></tr><tr><td>脂肪消耗量x
(kg/人年)</td><td>14.4</td><td>16.0</td><td>11.6</td><td>11.0</td><td>10.0</td><td>9.6</td><td>9.2</td><td>10.4</td><td>11.4</td><td>12.5</td></tr><tr><td>死亡率y
(1/(105人年))</td><td>29.1</td><td>29.7</td><td>29.2</td><td>26.0</td><td>24.0</td><td>23.1</td><td>23.0</td><td>23.1</td><td>25.2</td><td>26.1</td></tr></table>

设对于给定的  $x, Y$  为正态变量, 且方差与  $x$  无关.

(1) 求回归直线方程  $\hat{y} = a + \hat{b} x$ .

(2) 在显著性水平  $\alpha = 0.05$  下检验假设  $H_{0}: b = 0, H_{1}: b \neq 0$ .

(3) 求  $\hat{y} \mid_{x = 13}$ .

(4) 求  $x = 13$  处  $\mu (x)$  的置信水平为 0.95 的置信区间.

(5) 求  $x = 13$  处  $Y$  的新观察值  $Y_{0}$  的置信水平为 0.95 的预测区间.

68. 下面给出 1924-1992 年奥林匹克运动会女子  $100 \mathrm{~m}$  仰泳的最佳成绩 (以 s 计) (其中 1940 年及 1944 年未举行奥运会):

<table><tr><td>年份</td><td>1924</td><td>1928</td><td>1932</td><td>1936</td><td>1948</td><td>1952</td><td>1956</td><td>1960</td></tr><tr><td>成绩</td><td>83.2</td><td>82.2</td><td>79.4</td><td>78.9</td><td>74.4</td><td>74.3</td><td>72.9</td><td>69.3</td></tr><tr><td>年份</td><td>1964</td><td>1968</td><td>1972</td><td>1976</td><td>1980</td><td>1984</td><td>1988</td><td>1992</td></tr><tr><td>成绩</td><td>67.7</td><td>66.2</td><td>65.8</td><td>61.8</td><td>60.9</td><td>62.6</td><td>60.9</td><td>60.7</td></tr></table>

(1) 画出散点图.

(2) 求成绩关于年份的线性回归方程.

(3) 检验回归效果是否显著 (取  $\alpha = 0.05$ ).

# 参读材料一 随机变量样本值的产生

# (一)随机数和伪随机数

在概率统计的应用中,常需要模拟各种分布的随机变量,即需要产生各种分布随机变量的简单随机样本的样本值。某一分布随机变量的样本值,就称为这一分布的随机数。例如指数分布随机变量的样本值就称为指数分布随机数。特别,区间(0,1)上均匀分布的随机变量的样本值称为均匀分布随机数,简称随机数。我们先来考虑如何产生均匀分布随机数,其他分布随机数一般可以由均匀分布随机数通过变换得到。

产生均匀分布随机数的方法很多,目前使用最广泛的方法是在计算机上利用数学的递推公式来产生。这种按确定性算法得到的序列,不可能是真正来自区间(0,1)上均匀分布的独立同分布样本值序列,我们称它为伪随机数。

在大多数计算机中都装有产生伪随机数序列的算法程序,我们都假设由这些程序产生的伪随机数序列能通过独立性和均匀分布检验,可作为随机数序列来使用,需要时用特定的命令加以调用就是。

# (二)产生离散型随机变量样本值的方法

设离散型随机变量  $X$  具有分布律

$$
P\{X = x_{i}\} = p_{i}, \quad i = 1,2,\dots , \quad \sum_{i = 1}^{\infty}p_{i} = 1. \tag{*1}
$$

现在来产生  $X$  的随机数。

先产生伪随机数  $u$  ,令

$$
X = \left\{ \begin{array}{l l}{x_{1},} & {u< p_{1},}\\ {x_{2},} & {p_{1}\leqslant u< p_{1} + p_{2},}\\ \vdots & \vdots \\ {x_{i},} & {\sum_{j = 1}^{i - 1}p_{j}\leqslant u< \sum_{j = 1}^{i}p_{j},}\\ \vdots & \vdots \end{array} \right. \tag{*2}
$$

由于

$$
P\{X = x_{i}\} = P\left\{\sum_{j = 1}^{i - 1}p_{j}\leqslant u< \sum_{j = 1}^{i}p_{j}\right\} = \sum_{j = 1}^{i}p_{j} - \sum_{j = 1}^{i - 1}p_{j} = p_{i}, \quad i = 1,2,\dots ,
$$

所以  $X$  具有给定的分布律。

产生随机变量  $X$  的样本值也叫做对随机变量  $X$  进行模拟或抽样,上述模拟离散型随机变量的方法的算法为:

产生伪随机数  $u$

若  $u< p_{1}$  ,令  $X = x_{1}$  ,停止。

若  $u< p_{1} + p_{2}$  ,令  $X = x_{2}$  ,停止。

若  $u< p_{1} + p_{2} + p_{3}$ , 令  $X = x_{3}$ , 停止.

例1设随机变量  $X$  具有分布律

$$
\frac{X = i}{p_{i}}\left| \begin{array}{cccc}1 & 2 & 3 & 4 \\ 0.20 & 0.15 & 0.25 & 0.40 \end{array} \right.
$$

试产生  $X$  的样本值.

解取算法为:  $p$  生伪随机数  $\boldsymbol{u}$

若  $u< 0.20$  ,令  $X = 1$  ,停止.

若  $u< 0.35$  ,令  $X = 2$  ,停止.

若  $u< 0.60$  ,令  $X = 3$  ,停止.

否则,令  $X = 4$

例2设随机变量  $X$  具有分布律

$$
P\{X = i\} = \frac{1}{n}, \quad i = 1,2,\dots ,n, \tag{*3}
$$

试产生  $X$  的样本值(  $X$  称为取值为  $1,2,\dots ,n$  的离散型均匀分布随机变量).

解在  $(\ast_{1})$  式中,令  $x_{i} = i,i = 1,2,\dots ,n;p_{1} = p_{2} = \dots = p_{n} = \frac{1}{n}$  就得到  $(\ast_{3})$  式.再由  $(\ast_{2})$  式,得

若  $\frac{i - 1}{n}\leq u< \frac{i}{n}$  ,则令  $X = i$  ,即若  $i - 1\leqslant n u< i$  ,则令  $X = i = [n u] + 1,i = 1,2,\dots ,n.$  因此,若  $u$  是伪随机数,则  $X = [n u] + 1$  就是分布  $(\ast_{3})$  的样本值. 口

例3试产生以  $n,p$  为参数的二项分布  $b(n,p)$  的样本值.

解设  $U_{1},U_{2},\dots ,U_{n}$  相互独立,且它们都在区间(0,1)上服从均匀分布.令

$$
X_{i}=\left\{\begin{array}{l l}{1,}&{U_{i}< p,}\\ {0,}&{U_{i}\geqslant p,}\end{array}\right.\quad i=1,2,\cdots,n,
$$

则有  $P\{X_{i} = 1\} = P\{U_{i}< p\} = p,P\{X_{i} = 0\} = 1 - p$  ,故  $X_{i}\sim b(1,p)$  .又因  $U_{1},U_{2},\dots ,U_{n}$  相互独立,故有  $X = \sum_{i = 1}^{n}X_{i}\sim b(n,p)$  .据此,只要产生  $n$  个伪随机数  $u_{1},u_{2},\dots ,u_{n}$  ,统计其中使得 $u_{i}< p~(i = 1,2,\dots ,n)$  的个数为  $k$  ,则得  $X$  的样本值为  $k$  口

(三)产生连续型随机变量样本值的方法

先证明一个定理.

定理设随机变量  $U = U(0,1),F(x)$  是某一随机变量的分布函数,且  $F(x)$  为严格单调增加且连续的函数,则随机变量  $F^{- 1}(U)$  具有分布函数  $F(x)$  ,其中  $F^{- 1}(x)$  是  $F(x)$  的反函数.

证由于  $F(x)$  严格单调增加且连续,因此其反函数  $F^{- 1}(x)$  存在(即有  $F[F^{- 1}(x)] = x)$  ,且严格单调增加并连续,即得随机变量  $F^{- 1}(U)$  的分布函数为

$$
\begin{array}{r}{P\{F^{-1}(U)\leqslant x\} = P\{F[F^{-1}(U)]\leqslant F(x)\}}\\ {= P\{U\leqslant F(x)\} = F(x).} \end{array}
$$

由定理,若要产生以  $F(x)(F(x)$  严格单调增加且连续)为分布函数的随机变量  $X$  ,只需

产生  $U\sim U(0,1)$  ,令  $X = F^{- 1}(U)$  就行了.又若要产生  $X$  的样本值  $x$  ,只需产生  $U$  的样本值  $u$  令  $\scriptstyle x = F^{- 1}(u)$  即得.这一产生  $X$  的样本值的方法,称为逆变换法.这种方法在随机变量具有严格单调增加且连续的分布函数  $F(x)$  且  $F^{- 1}(x)$  能够用显式表示时,都能使用.

说明:在上述定理中对  $F(x)$  在  $(- \infty , \infty)$  上的严格单调连续的要求可放宽为  $F(x)$  在某一区间(有限或无限)上取值从0到1,并在此区间上严格单调增加且连续即可.

例4设随机变量  $X$  具有指数分布,其分布函数为

$$
F(x) = \left\{ \begin{array}{ll}1 - \mathrm{e}^{-x / \theta}, & x > 0, \\ 0, & \text{其他}, \quad \theta > 0, \end{array} \right.
$$

试产生随机变量  $X$

解设  $U\sim U(0,1)$  ,令  $U = 1 - \mathrm{e}^{- X / \theta}$  ,解得

$$
X = -\theta \ln (1 - U).
$$

因为当  $U\sim U(0,1)$  时,也有  $1 - U\sim U(0,1)$  ,从而

$$
X = -\theta \ln U
$$

就是所要产生的指数分布的随机变量.只要有伪随机数  $u$  ,就有  $X$  的随机数  $- \theta \ln u$

例5设随机变量  $X$  具有韦布尔分布,其分布函数为

$$
F(x) = \left\{ \begin{array}{ll}1 - \mathrm{e}^{-(x / \eta)^{\beta}}, & x > 0, \\ 0, & \text{其他}, \quad \beta > 0, \eta > 0. \end{array} \right.
$$

试产生随机变量  $X$

解设  $U\sim U(0,1)$  ,令  $U = 1 - \mathrm{e}^{- (X / \eta)^{\beta}}$  ,解得

$$
X = \eta \left[-\ln (1 - U)\right]^{1 / \beta}.
$$

因为  $1 - U\sim U(0,1)$  ,故

$$
X = \eta (-\ln U)^{1 / \beta}
$$

就是所要产生的韦布尔分布的随机变量,

例6正态随机变量的产生.

标准正态变量的分布函数  $\Phi (x)$  的反函数不存在显式,故不能用逆变换法产生标准正态变量.下面介绍一种近似方法.

设  $U_{i}\sim U(0,1), i = 1,2,\dots ,n$  ,且它们相互独立,由于  $E(U_{i}) = 1 / 2,D(U_{i}) = 1 / 12$  ,由中心极限定理,当  $n$  较大时近似地有

$$
Z = \frac{\sum_{i = 1}^{n}U_{i} - \frac{n}{2}}{\sqrt{n}\sqrt{\frac{1}{12}}}\sim N(0,1).
$$

取  $n = 12$  ,知近似地有

$$
Z = \sum_{i = 1}^{12}U_{i} - 6\sim N(0,1),
$$

这就是说,只需产生12个伪随机数  $u_{1},u_{2},\dots ,u_{12}$  ,将它们加起来,再减去6,就能近似地得到标准正态变量的样本值了.这样做是很方便的.

又若  $X\sim N(\mu ,\sigma^{2}), Z\sim N(0,1)$  ,利用关系式

$$
X = \mu +\sigma Z
$$

就能得到一般的正态随机变量  $X$  的样本值.

# 参读材料二 蒙特卡罗方法

我们聚焦于由给定的模型直接产生大量的样本。这些样本反映了模型的统计性能,有关模型的问题能由研究样本的统计性能得到回答。我们研究样本的统计性能得到关于模型的问题的回答,这样的方法称为蒙特卡罗方法,又称为蒙特卡罗模拟。

如果我们能在计算机上模拟一统计模型,那么就能自模型产生一大批数据样本,也就能用研究这些样本的性质代替对模型本身的研究,从而得到所需的结果。

例1 长方形金属板的长度  $X$  和宽度  $Y$  分别服从分布  $X \sim U(2.9,3.1)$  和  $Y \sim U(1.9,2.1)$ ,  $X, Y$  均以  $\mathrm{m}$  计,且两者相互独立。试估计金属板面积  $XY$  的数学期望。

解  $X,Y$  的分布函数分别为

$$
F_{X}(x) = \left\{ \begin{array}{l l}{0,} & {x< 2.9,}\\ {\frac{x - 2.9}{0.2},2.9\leqslant x< 3.1,} & {F_{Y}(y) = \left\{ \begin{array}{l l}{0,} & {y< 1.9,}\\ {\frac{y - 1.9}{0.2},1.9\leqslant y< 2.1,}\\ {1,} & {y\geqslant 2.1.} \end{array} \right.} \end{array} \right.
$$

现在分别产生  $X, Y$  的随机数。设  $U = U(0,1)$ ,令  $U = \frac{X - 2.9}{0.2}$ ,得

$$
X = 2.9 + 0.2U. \tag{*₁}
$$

设  $U \sim U(0,1)$ ,令  $V = \frac{Y - 1.9}{0.2}$ ,得

$$
Y = 1.9 + 0.2V. \tag{*₂}
$$

按  $(\ast_{1})$  式产生随机变量  $X$  的10000个随机数,按  $(\ast_{2})$  式产生  $Y$  的10000个随机数,这样就得到  $A = XY$  的样本容量为10000的样本值,列表如下:

<table><tr><td>长度x</td><td>宽度y</td><td>面积xy</td></tr><tr><td>3.055 969</td><td>2.091 012</td><td>6.390 068</td></tr><tr><td>2.976 204</td><td>2.037 167</td><td>6.063 026</td></tr><tr><td>:</td><td>:</td><td>:</td></tr><tr><td>3.003 077</td><td>1.929 107</td><td>5.793 258</td></tr></table>

以  $A$  的样本均值  $\frac{1}{10000} \sum_{i = 1}^{1000} x_{i} y_{i}$  作为金属板面积  $A$  的数学期望的估计,得到面积  $A$  的数学期望的近似值为  $6.000762 \mathrm{~m}^{2}$ 。

此例说明,用蒙特卡罗方法得到的  $A$  的数学期望,与  $A$  的数学期望的真值  $E(A) = E(XY) = E(X)E(Y) = 6 \mathrm{~m}^{2}$  非常接近。

例2设一设备需经两个独立的组装阶段.第一阶段的组装时间  $X$  (以h计)是一个随机变量,服从均值为1的指数分布,第二阶段的组装时间  $Y$  也是一个随机变量且  $Y\sim N(3,1)$  ,试估计整个组装时间  $X + Y$

解下面用蒙特卡罗方法给出  $X + Y$  的直方图,

设  $U\sim U(0,1)$  ,在参读材料一例4中令  $\theta = 1$  ,则

$$
X = -\ln U \tag{*}
$$

就是均值为1的指数分布随机变量.又按参读材料一例6,设  $U_{i}\sim U(0,1),i = 1,2,\dots ,12$  ,且它们相互独立,则  $X = \sum_{i = 1}^{12}U_{i} - 6\overset {\mathrm{~i~}}{\sim}N(0,1)$  ,于是

$$
Y = X + 3 \tag{*}
$$

近似服从正态分布  $N(3,1)$  .在计算机上分别按  $(\ast_{3})$  式和  $(\ast_{4})$  式产生  $X$  和  $Y$  的独立的样本值(样本容量为10000),利用这10000个数据作出  $X + Y$  的频率直方图,如图1所示,我们就可以用直方图顶部的台阶形曲线作为  $X + Y$  的概率密度曲线的近似.从而可以对随机变量 $X + Y$  的性质作出统计推断.例如,  $X + Y$  落在区间(3.4,4.2)的概率可估计为

$$
P\{3.4{<}X{+}Y{<}4.2\} \approx 0.62.
$$

R语言的程序和作出的直方图如下:

${>}\mathrm{N}=10000$  ;  $z< -$  numeric(N)

${>}$  for(i in 1:N)  $\left\{ \begin{array}{r l} \end{array} \right.$

$\begin{array}{r l} & {\mathrm{~\mathfrak~{~x~}~} < - \left(- \log (\mathrm{runif}(1,0,1))\right)}\\ & {\mathrm{~\mathfrak~{~y~}~} < - \mathrm{~rnorm}(1,3,1)} \end{array}$

$\begin{array}{r l} & {\mathrm{~\mathfrak~{~y~}~} < - \mathrm{~rnorm}(1,3,1)}\\ & {\mathrm{~\mathfrak~{~z~}~}[\mathrm{~i~}]< - \mathrm{~x~} + \mathrm{~y~}} \end{array}$

$+\quad \mathbf{z}[\mathbf{i}]< - \mathbf{x} + \mathbf{y}$

$+\left\{ \begin{array}{r l} \end{array} \right.$

${>}$  hist(z)

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_9.pdf-0912f019-1cce-45cf-a2df-cefa5cbfbcb7_b462079ee958eb82ee77c6d3f8b8f3440dd4602ff7216098a1a96d32a32786cc.jpg)  
Histogram of z 图1

在统计数据分析中,许多人们感兴趣的问题能够归结为求某个随机变量  $X$  的函数  $h\left(X\right)$  的数学期望  $E[h(X)]$  .令  $\phi (x)$  表示  $X$  的概率密度,由强大数定律,若  $X_{1},X_{2},\dots ,X_{n}$  是相互独

立的同分布的随机变量序列, 它们与随机变量  $X$  有相同的分布, 则有

$$
P\left\{\lim_{n\to \infty}\frac{1}{n}\sum_{i = 1}^{n}h(X_{i}) = E\big[h(X)\big]\right\} = 1. \tag{*5}
$$

在上式中, 将  $n$  取定为充分大的数, 就能得到下述求数学期望近似值的方法.

定义 用于估计数学期望  $E\big[h(X)\big]$  的蒙特卡罗方法是一种数值方法, 它基于近似式:

$$
E\big[h(X)\big] \approx \frac{1}{n}\sum_{i = 1}^{n}h(X_{i}), \tag{*6}
$$

其中  $X_{1}, X_{2}, \dots , X_{n}$  是相互独立且与  $X$  有相同分布的随机变量序列.

为了估计  $E\big[h(X)\big]$  的值, 需要自模型产生大量的样本  $X_{i}$ . 例如在  $(\ast_{6})$  式中取  $h(X) =$ $X$ , 得到

$$
E(X) \approx \frac{1}{n}\sum_{i = 1}^{n}X_{i} = \overline{X}.
$$

这就是我们经常使用的数学期望的估计式,

例3 试估计数学期望  $E\big[\sin (X^{2})\big]$ , 其中  $X \sim N(\mu , \sigma^{2}), \mu = 1, \sigma^{2} = 0.1^{2}$

解 用分析的方法求得  $E\big[\sin (X^{2})\big]$  的精确解是困难的, 但容易用蒙特卡罗方法求得它的估计值. 我们取  $n$  充分大, 例如取  $n = 1000$ , 以分布  $N(\mu , \sigma^{2})$  产生样本  $X_{1}, X_{2}, \dots , X_{1000}$ , 由  $(\ast_{6})$  式即得

$$
E\big[\sin (X^{2})\big] \approx \frac{1}{1000}\sum_{i = 1}^{1000}\sin (x_{i}^{2}) = 0.8357785.
$$

R语言的程序如下:

$\geq \mathbb{N} = 1000; \mathbb{k} = 0.0$

$\geq \mathbf{for}(\mathbf{i} \mathbf{in} \mathbf{1}: \mathbb{N})\{ \begin{array}{r l} \end{array} \}$

$+\mathrm{~\bf~x{<}~} - \mathrm{~r n o r m}(1,1,0.1)\mathrm{~\bf~\%~}$  用rnorm( )产生1个服从分布  $N(1,0.1^{2})$  的随机数

$+\mathrm{~\bf~k{<}~} - \mathrm{~k~} + \sin (\mathrm{~x}{\mathrm{~}}2)$

$+\Big\}$

$\geq \mathbf{k} / 1000$

[1] 0.8357785

例4 设  $X_{1}, X_{2}$  是来自分布  $N(0,1)$  的两个相互独立的随机变量, 试估计数学期望  $E(|X_{1} - X_{2}|)$

解 独立地, 自分布  $N(0,1)$  抽取  $n = 1000$  个容量为 2 的样本

$$
(x_{1}^{(i)}, x_{2}^{(i)}), i = 1,2, \dots , 1000.
$$

得到所求的  $E(|X_{1} - X_{2}|)$  的估计为

$$
E(|X_{1} - X_{2}|) \approx \frac{1}{1000}\sum_{i = 1}^{1000}\left|x_{1}^{(i)} - x_{2}^{(i)}\right| = 1.120209.
$$

R语言的程序如下:

$\geq \mathbb{N} = 1000; \mathbb{g} < - \text{numeric} (\mathbb{N})$

$\geq \mathbf{for}(\mathbf{i} \mathbf{in} \mathbf{1}: \mathbb{N})\{ \begin{array}{r l} \end{array} \}$

$+\mathrm{~\bf~x{<}~} - \mathrm{~r n o r m}(2)$

+ g[i]<- abs(x[1]- x[2])

$+\Big\}$

> est<- mean(g); est

[1] 1.120209

我们还能利用  $(\ast_{\mathrm{~6~}})$  式来估计积分

$$
\int_{a}^{b}f(x)\mathrm{d}x.
$$

设随机变量  $X_{1},X_{2},\dots ,X_{n}$  相互独立,且具有相同的分布,其概率密度为

$$
\phi (x) = \left\{{\frac{1}{b - a}},\quad a< x< b,\right.
$$

则由  $(\ast_{\mathrm{~6~}})$  式有

$$
\int_{a}^{b}f(x)\mathrm{d}x = (b - a)\int_{a}^{b}f(x)\phi (x)\mathrm{d}x = (b - a)E[f(x)]\approx \frac{b - a}{n}\sum_{i = 1}^{n}f(x_{i}).
$$

即对于充分大的  $n$  ,有

$$
\int_{a}^{b}f(x)\mathrm{d}x\approx \frac{b - a}{n}\sum_{i = 1}^{n}f(x_{i}). \tag{*7}
$$

例5试估计积分  $\int_{0}^{2\pi}\mathrm{e}^{\cos x}\mathrm{d}x$

解独立地自概率密度为

$$
\phi (x) = \left\{{\frac{1}{2\pi}},\quad 0< x< 2\pi ,\right.
$$

的均匀分布抽取样本  $x_{1},x_{2},\dots ,x_{1000}$  ,由  $(\ast_{7})$  式得到

$$
\int_{0}^{2\pi}\mathrm{e}^{\cos x}\mathrm{d}x\approx \frac{2\pi}{1000}\sum_{i = 1}^{1000}\mathrm{e}^{\cos x_{i}} = 7.75655.
$$

R语言的程序如下:

$\mathrm{>N = 1000;k = 0. 0}$

$\mathrm{>for(i~in~1:N)}\left\{ \begin{array}{rl} \end{array} \right.$

$+\mathrm{\quad \mathbf~{~x~}~} < - \mathrm{\quad \mathbf~{~r~}~}\mathrm{\quad \mathbf~{~r~}~}\mathrm{\quad \mathbf~{~r~}~}\mathrm{\quad \mathbf~{~r~}~}\mathrm{\quad \mathbf~{~r~}~}\mathrm{\quad \mathbf~{~r~}~}\mathrm{\quad \mathbf~{~r~}~}\mathrm{\quad \mathbf~{~r~}~}\mathrm{~\mathbf~{~r~}~}\mathrm{\quad \mathbf~{~r~}~}\mathrm{~\mathbf~{~r~}~}\mathrm{~\mathbf~{~r~}~}\mathrm{~\mathbf~{~r~}~}\mathrm{~\mathbf~{~r~}~}\mathrm{~\mathbf~{~r~}~}\mathrm{~\mathbf~{~r~}~}\mathrm{~\mathbf~{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{\quad \mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~}\mathrm{~\mathsf{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathsf{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathsf{~\mathsf{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~\mathrm{~r~}~}$  用runif( )产生1个服从分布U(0,2π)的随机变量,在R中用pi表示  $\pi$

$+\mathrm{\quad \mathbf~{~k~}~} < - \mathrm{\quad \mathbf~{~k~}~} + \mathrm{\quad \exp(\cos\mathrm{\quad \left(~x~\right)~}~}$

$+\mathrm{\quad \lambda~}$

>k\*2\*pi/1000

[1] 7.75655

表附

<table><tr><td>分布</td><td>参数</td><td>分布律或概率密度</td><td>数学期望</td><td>方差</td><td></td></tr><tr><td>(0-1)分布</td><td>0&lt;p&gt;0&lt;1</td><td>P(X=k)=p^k(1-p)^{1-k}, k=0,1</td><td>p</td><td></td><td></td></tr><tr><td rowspan="2">二项分布</td><td>n≥1</td><td>P(X=k)=n^k(p^k(1-p)^{-k}</td><td rowspan="2">np</td><td rowspan="2">np(1-p)</td><td></td></tr><tr><td>0&lt;p&gt;0&lt;1</td><td>k=0,1,...,n</td><td></td></tr><tr><td rowspan="2">负二项分布
(帕斯卡分布)</td><td>r≥1</td><td>P(X=k)=k^1(p^r(1-p)^{k-r}</td><td rowspan="2">r</td><td rowspan="2">r(1-p)</td><td></td></tr><tr><td>0&lt;p&gt;0,r+r+1,...</td><td>p</td><td></td></tr><tr><td rowspan="2">几何分布</td><td rowspan="2">0&lt;p&gt;0&lt;1</td><td rowspan="2">P(X=k)=(1-p)^{k-1}p</td><td>1</td><td>1-p</td><td></td></tr><tr><td>k=1,2,...</td><td>p</td><td>p^2</td></tr><tr><td rowspan="2">超几何分布</td><td>N,Mn
(M≤N)</td><td>P(X=k)=
(M)(N-M)/(n-k-1)</td><td>nM</td><td>nM
N
(1-M)/N
N
(1-M)/N-1</td><td></td></tr><tr><td>(n≤N)</td><td>k为整数,max(0,n-N+N)≤k≤min(n,M)</td><td>N</td><td></td><td></td></tr><tr><td rowspan="2">泊松分布</td><td rowspan="2">λ&amp;gt;0</td><td>P(X=k)=λ^k e^λ
k!</td><td rowspan="2">λ</td><td rowspan="2">λ</td><td rowspan="2">λ</td></tr><tr><td>k=0,1,2,...</td></tr><tr><td>均匀分布</td><td>α&lt;b&gt;1
b-a, α&lt;x&gt;</td><td>α+b
2
12</td><td></td><td></td><td></td></tr></table>


</p>

<table><tr><td>分布</td><td>参数</td><td>分布律或概率密度</td><td>数学期望</td><td>方差</td></tr><tr><td>正态分布</td><td>μ</td><td>f(x) = 1/√(2πσ)e^(-x^2/2σ^2)</td><td>μ</td><td>σ</td></tr><tr><td>Γ分布</td><td>α&amp;gt;0</td><td>f(x) = {1/β^2Γ(α)e^(-x^2/2e^(-x^2/2e^(-x^2/2e^(-x^2/2e^(-x^2/2e^(-x^2/2e^(-x^2/2e^(-x^2/2e^(-x^2/2e^(-x^2/2e^(-x^2/2e^(-x^2/2e^(-x^2/2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-1e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x1e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-12e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-)2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-x2e^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(2e^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^-(xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(- xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe(2e^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(2e^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe^(-xe(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e(2e</td><td></td><td></td></tr></table>

<table><tr><td>分布</td><td>参数</td><td>分布律或概率密度</td><td>数学期望</td><td>方差</td></tr><tr><td>β分布</td><td>α&amp;gt;0
β&amp;gt;0</td><td>f(x+β)
T(n)T(β)
0, 
x&amp;lt;α&amp;lt;1
其他</td><td>α
α+β</td><td>αβ
(α+β)2(α+β+1)</td></tr><tr><td>对数
正态分布</td><td>μ
σ&amp;gt;0</td><td>f(x)=
1/√2πσx
0, 
e-(lnx+μ)2/(e2x), x&amp;gt;0
其他</td><td>e^+2
e^2+α2(e-1)</td><td>不存在</td></tr><tr><td>柯西分布</td><td>α
λ&amp;gt;0</td><td>f(x)=
1/πx+ (x-α)2
1/πx+ (x+α)2
0, 
n≥1</td><td>不存在</td><td>n
n+2,n&amp;gt;2</td></tr><tr><td>t分布</td><td>0</td><td></td><td>0,n&amp;gt;1</td><td>n</td></tr><tr><td>F分布</td><td>n1,n2</td><td>f(x)=
1/√(n+1)2
1/√(n+1)(n+2)2
0, 
n1,n2&amp;gt;0
nx&amp;gt;0</td><td>n2
n2-2
n2-(n2-2)3
n2&amp;gt;4
nx&amp;gt;4</td><td></td></tr></table>

# 附表2 标准正态分布表

$$
\Phi (x) = \int_{-\infty}^{x} \frac{1}{\sqrt{2\pi}} e^{-x^{2} / 2} \mathrm{~d}t
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_9.pdf-0912f019-1cce-45cf-a2df-cefa5cbfbcb7_b462079ee958eb82ee77c6d3f8b8f3440dd4602ff7216098a1a96d32a32786cc.jpg)

<table><tr><td>x</td><td>0.00</td><td>0.01</td><td>0.02</td><td>0.03</td><td>0.04</td><td>0.05</td><td>0.06</td><td>0.07</td><td>0.08</td><td>0.09</td></tr><tr><td>0.0</td><td>0.5000</td><td>0.5040</td><td>0.5080</td><td>0.5120</td><td>0.5160</td><td>0.5199</td><td>0.5239</td><td>0.5279</td><td>0.5319</td><td>0.5359</td></tr><tr><td>0.1</td><td>0.5398</td><td>0.5438</td><td>0.5478</td><td>0.5517</td><td>0.5557</td><td>0.5596</td><td>0.5636</td><td>0.5675</td><td>0.5714</td><td>0.5753</td></tr><tr><td>0.2</td><td>0.5793</td><td>0.5832</td><td>0.5871</td><td>0.5910</td><td>0.5948</td><td>0.5987</td><td>0.6026</td><td>0.6064</td><td>0.6103</td><td>0.6141</td></tr><tr><td>0.3</td><td>0.6179</td><td>0.6217</td><td>0.6255</td><td>0.6293</td><td>0.6331</td><td>0.6368</td><td>0.6406</td><td>0.6443</td><td>0.6480</td><td>0.6517</td></tr><tr><td>0.4</td><td>0.6554</td><td>0.6591</td><td>0.6628</td><td>0.6664</td><td>0.6700</td><td>0.6736</td><td>0.6772</td><td>0.6808</td><td>0.6844</td><td>0.6879</td></tr><tr><td>0.5</td><td>0.6915</td><td>0.6950</td><td>0.6985</td><td>0.7019</td><td>0.7054</td><td>0.7088</td><td>0.7123</td><td>0.7157</td><td>0.7190</td><td>0.7224</td></tr><tr><td>0.6</td><td>0.7257</td><td>0.7291</td><td>0.7324</td><td>0.7357</td><td>0.7389</td><td>0.7422</td><td>0.7454</td><td>0.7486</td><td>0.7517</td><td>0.7549</td></tr><tr><td>0.7</td><td>0.7580</td><td>0.7611</td><td>0.7642</td><td>0.7673</td><td>0.7704</td><td>0.7734</td><td>0.7764</td><td>0.7794</td><td>0.7823</td><td>0.7852</td></tr><tr><td>0.8</td><td>0.7881</td><td>0.7910</td><td>0.7939</td><td>0.7967</td><td>0.7995</td><td>0.8023</td><td>0.8051</td><td>0.8078</td><td>0.8106</td><td>0.8133</td></tr><tr><td>0.9</td><td>0.8159</td><td>0.8186</td><td>0.8212</td><td>0.8238</td><td>0.8264</td><td>0.8289</td><td>0.8315</td><td>0.8340</td><td>0.8365</td><td>0.8389</td></tr><tr><td>1.0</td><td>0.8413</td><td>0.8438</td><td>0.8461</td><td>0.8485</td><td>0.8508</td><td>0.8531</td><td>0.8554</td><td>0.8577</td><td>0.8599</td><td>0.8621</td></tr><tr><td>1.1</td><td>0.8643</td><td>0.8665</td><td>0.8686</td><td>0.8708</td><td>0.8729</td><td>0.8749</td><td>0.8770</td><td>0.8790</td><td>0.8810</td><td>0.8830</td></tr><tr><td>1.2</td><td>0.8849</td><td>0.8869</td><td>0.8888</td><td>0.8907</td><td>0.8925</td><td>0.8944</td><td>0.8962</td><td>0.8980</td><td>0.8997</td><td>0.9015</td></tr><tr><td>1.3</td><td>0.9032</td><td>0.9049</td><td>0.9066</td><td>0.9082</td><td>0.9099</td><td>0.9115</td><td>0.9131</td><td>0.9147</td><td>0.9162</td><td>0.9177</td></tr><tr><td>1.4</td><td>0.9192</td><td>0.9207</td><td>0.9222</td><td>0.9236</td><td>0.9251</td><td>0.9265</td><td>0.9278</td><td>0.9292</td><td>0.9306</td><td>0.9319</td></tr><tr><td>1.5</td><td>0.9332</td><td>0.9345</td><td>0.9357</td><td>0.9370</td><td>0.9382</td><td>0.9394</td><td>0.9406</td><td>0.9418</td><td>0.9429</td><td>0.9441</td></tr><tr><td>1.6</td><td>0.9452</td><td>0.9463</td><td>0.9474</td><td>0.9484</td><td>0.9495</td><td>0.9505</td><td>0.9515</td><td>0.9525</td><td>0.9535</td><td>0.9545</td></tr><tr><td>1.7</td><td>0.9554</td><td>0.9564</td><td>0.9573</td><td>0.9582</td><td>0.9591</td><td>0.9599</td><td>0.9608</td><td>0.9616</td><td>0.9625</td><td>0.9633</td></tr><tr><td>1.8</td><td>0.9641</td><td>0.9649</td><td>0.9656</td><td>0.9664</td><td>0.9671</td><td>0.9678</td><td>0.9686</td><td>0.9693</td><td>0.9699</td><td>0.9706</td></tr><tr><td>1.9</td><td>0.9713</td><td>0.9719</td><td>0.9726</td><td>0.9732</td><td>0.9738</td><td>0.9744</td><td>0.9750</td><td>0.9756</td><td>0.9761</td><td>0.9767</td></tr><tr><td>2.0</td><td>0.9772</td><td>0.9778</td><td>0.9783</td><td>0.9788</td><td>0.9793</td><td>0.9798</td><td>0.9803</td><td>0.9808</td><td>0.9812</td><td>0.9817</td></tr><tr><td>2.1</td><td>0.9821</td><td>0.9826</td><td>0.9830</td><td>0.9834</td><td>0.9838</td><td>0.9842</td><td>0.9846</td><td>0.9850</td><td>0.9854</td><td>0.9857</td></tr><tr><td>2.2</td><td>0.9861</td><td>0.9864</td><td>0.9868</td><td>0.9871</td><td>0.9875</td><td>0.9878</td><td>0.9881</td><td>0.9884</td><td>0.9887</td><td>0.9890</td></tr><tr><td>2.3</td><td>0.9893</td><td>0.9896</td><td>0.9898</td><td>0.9901</td><td>0.9904</td><td>0.9906</td><td>0.9909</td><td>0.9911</td><td>0.9913</td><td>0.9916</td></tr><tr><td>2.4</td><td>0.9918</td><td>0.9920</td><td>0.9922</td><td>0.9925</td><td>0.9927</td><td>0.9929</td><td>0.9931</td><td>0.9932</td><td>0.9934</td><td>0.9936</td></tr><tr><td>2.5</td><td>0.9938</td><td>0.9940</td><td>0.9941</td><td>0.9943</td><td>0.9945</td><td>0.9946</td><td>0.9948</td><td>0.9949</td><td>0.9951</td><td>0.9952</td></tr><tr><td>2.6</td><td>0.9953</td><td>0.9955</td><td>0.9956</td><td>0.9957</td><td>0.9959</td><td>0.9960</td><td>0.9961</td><td>0.9962</td><td>0.9963</td><td>0.9964</td></tr><tr><td>2.7</td><td>0.9965</td><td>0.9966</td><td>0.9967</td><td>0.9968</td><td>0.9969</td><td>0.9970</td><td>0.9971</td><td>0.9972</td><td>0.9973</td><td>0.9974</td></tr><tr><td>2.8</td><td>0.9974</td><td>0.9975</td><td>0.9976</td><td>0.9977</td><td>0.9977</td><td>0.9978</td><td>0.9979</td><td>0.9979</td><td>0.9980</td><td>0.9981</td></tr><tr><td>2.9</td><td>0.9981</td><td>0.9982</td><td>0.9982</td><td>0.9983</td><td>0.9984</td><td>0.9984</td><td>0.9985</td><td>0.9985</td><td>0.9986</td><td>0.9986</td></tr><tr><td>3.0</td><td>0.9987</td><td>0.9987</td><td>0.9987</td><td>0.9988</td><td>0.9988</td><td>0.9989</td><td>0.9989</td><td>0.9989</td><td>0.9990</td><td>0.9990</td></tr><tr><td>3.1</td><td>0.9990</td><td>0.9991</td><td>0.9991</td><td>0.9991</td><td>0.9992</td><td>0.9992</td><td>0.9992</td><td>0.9992</td><td>0.9993</td><td>0.9993</td></tr><tr><td>3.2</td><td>0.9993</td><td>0.9993</td><td>0.9994</td><td>0.9994</td><td>0.9994</td><td>0.9994</td><td>0.9994</td><td>0.9995</td><td>0.9995</td><td>0.9995</td></tr><tr><td>3.3</td><td>0.9995</td><td>0.9995</td><td>0.9995</td><td>0.9996</td><td>0.9996</td><td>0.9996</td><td>0.9996</td><td>0.9996</td><td>0.9996</td><td>0.9997</td></tr><tr><td>3.4</td><td>0.9997</td><td>0.9997</td><td>0.9997</td><td>0.9997</td><td>0.9997</td><td>0.9997</td><td>0.9997</td><td>0.9997</td><td>0.9997</td><td>0.9998</td></tr></table>

# 附表3 泊松分布表

$$
P\{X \leqslant x\} = \sum_{k = 0}^{x} \frac{\chi^k \mathrm{e}^{-\lambda}}{k!}
$$

<table><tr><td rowspan="2">x</td><td colspan="9">λ</td></tr><tr><td>0.1</td><td>0.2</td><td>0.3</td><td>0.4</td><td>0.5</td><td>0.6</td><td>0.7</td><td>0.8</td><td>0.9</td></tr><tr><td>0</td><td>0.9048</td><td>0.8187</td><td>0.7408</td><td>0.6730</td><td>0.6065</td><td>0.5488</td><td>0.4998</td><td>0.4493</td><td>0.4066</td></tr><tr><td>1</td><td>0.9953</td><td>0.9825</td><td>0.9631</td><td>0.9384</td><td>0.9098</td><td>0.8781</td><td>0.8442</td><td>0.8088</td><td>0.7725</td></tr><tr><td>2</td><td>0.9998</td><td>0.9989</td><td>0.9964</td><td>0.9921</td><td>0.9856</td><td>0.9769</td><td>0.9659</td><td>0.9526</td><td>0.9371</td></tr><tr><td>3</td><td>1.0000</td><td>0.9999</td><td>0.9997</td><td>0.9992</td><td>0.9982</td><td>0.9966</td><td>0.9942</td><td>0.9909</td><td>0.9865</td></tr><tr><td>4</td><td></td><td>1.0000</td><td>1.0000</td><td>0.9999</td><td>0.9998</td><td>0.9996</td><td>0.9992</td><td>0.9986</td><td>0.9977</td></tr><tr><td>5</td><td></td><td></td><td></td><td>1.0000</td><td>1.0000</td><td>1.0000</td><td>0.9999</td><td>0.9998</td><td>0.9997</td></tr><tr><td>6</td><td></td><td></td><td></td><td></td><td></td><td></td><td>1.0000</td><td>1.0000</td><td>1.0000</td></tr></table>

<table><tr><td rowspan="2">x</td><td colspan="9">λ</td></tr><tr><td>1.0</td><td>1.5</td><td>2.0</td><td>2.5</td><td>3.0</td><td>3.5</td><td>4.0</td><td>4.5</td><td>5.0</td></tr><tr><td>0</td><td>0.3679</td><td>0.2231</td><td>0.1353</td><td>0.0821</td><td>0.0498</td><td>0.0302</td><td>0.0183</td><td>0.0111</td><td>0.0067</td></tr><tr><td>1</td><td>0.7358</td><td>0.5578</td><td>0.4060</td><td>0.2873</td><td>0.1991</td><td>0.1359</td><td>0.0916</td><td>0.0611</td><td>0.0404</td></tr><tr><td>2</td><td>0.9197</td><td>0.8088</td><td>0.6767</td><td>0.5438</td><td>0.4232</td><td>0.3208</td><td>0.2381</td><td>0.1736</td><td>0.1247</td></tr><tr><td>3</td><td>0.9810</td><td>0.9344</td><td>0.8571</td><td>0.7576</td><td>0.6472</td><td>0.5366</td><td>0.4335</td><td>0.3423</td><td>0.2650</td></tr><tr><td>4</td><td>0.9963</td><td>0.9814</td><td>0.9473</td><td>0.8912</td><td>0.8153</td><td>0.7254</td><td>0.6288</td><td>0.5321</td><td>0.4405</td></tr><tr><td>5</td><td>0.9994</td><td>0.9955</td><td>0.9834</td><td>0.9580</td><td>0.9161</td><td>0.8576</td><td>0.7851</td><td>0.7029</td><td>0.6160</td></tr><tr><td>6</td><td>0.9999</td><td>0.9991</td><td>0.9955</td><td>0.9858</td><td>0.9665</td><td>0.9347</td><td>0.8899</td><td>0.8311</td><td>0.7622</td></tr><tr><td>7</td><td>1.0000</td><td>0.9998</td><td>0.9989</td><td>0.9958</td><td>0.9881</td><td>0.9733</td><td>0.9489</td><td>0.9134</td><td>0.8666</td></tr><tr><td>8</td><td></td><td>1.0000</td><td>0.9998</td><td>0.9989</td><td>0.9962</td><td>0.9901</td><td>0.9786</td><td>0.9597</td><td>0.9319</td></tr><tr><td>9</td><td></td><td></td><td>1.0000</td><td>0.9997</td><td>0.9989</td><td>0.9967</td><td>0.9919</td><td>0.9829</td><td>0.9682</td></tr><tr><td>10</td><td></td><td></td><td></td><td>0.9999</td><td>0.9997</td><td>0.9999</td><td>0.9972</td><td>0.9933</td><td>0.9863</td></tr><tr><td>11</td><td></td><td></td><td></td><td>1.0000</td><td>0.9999</td><td>0.9997</td><td>0.9991</td><td>0.9976</td><td>0.9945</td></tr><tr><td>12</td><td></td><td></td><td></td><td></td><td>1.0000</td><td>0.9999</td><td>0.9997</td><td>0.9992</td><td>0.9980</td></tr></table>

<table><tr><td rowspan="2">x</td><td colspan="9">λ</td></tr><tr><td>5.5</td><td>6.0</td><td>6.5</td><td>7.0</td><td>7.5</td><td>8.0</td><td>8.5</td><td>9.0</td><td>9.5</td></tr><tr><td>0</td><td>0.0041</td><td>0.0025</td><td>0.0015</td><td>0.0009</td><td>0.0006</td><td>0.0003</td><td>0.0002</td><td>0.0001</td><td>0.0001</td></tr><tr><td>1</td><td>0.0266</td><td>0.0174</td><td>0.0113</td><td>0.0073</td><td>0.0047</td><td>0.0030</td><td>0.0019</td><td>0.0012</td><td>0.0008</td></tr><tr><td>2</td><td>0.0884</td><td>0.0620</td><td>0.0430</td><td>0.0296</td><td>0.0203</td><td>0.0138</td><td>0.0093</td><td>0.0062</td><td>0.0042</td></tr><tr><td>3</td><td>0.2017</td><td>0.1512</td><td>0.1118</td><td>0.0818</td><td>0.0591</td><td>0.0424</td><td>0.0301</td><td>0.0212</td><td>0.0149</td></tr><tr><td>4</td><td>0.3575</td><td>0.2851</td><td>0.2237</td><td>0.1730</td><td>0.1321</td><td>0.0996</td><td>0.0744</td><td>0.0550</td><td>0.0403</td></tr><tr><td>5</td><td>0.5289</td><td>0.4457</td><td>0.3690</td><td>0.3007</td><td>0.2414</td><td>0.1912</td><td>0.1496</td><td>0.1157</td><td>0.0885</td></tr><tr><td>6</td><td>0.6860</td><td>0.6063</td><td>0.5265</td><td>0.4497</td><td>0.3782</td><td>0.3134</td><td>0.2566</td><td>0.2068</td><td>0.1649</td></tr><tr><td>7</td><td>0.8095</td><td>0.7440</td><td>0.6728</td><td>0.5987</td><td>0.5246</td><td>0.4530</td><td>0.3856</td><td>0.3239</td><td>0.2687</td></tr><tr><td>8</td><td>0.8944</td><td>0.8472</td><td>0.7916</td><td>0.7291</td><td>0.6620</td><td>0.5925</td><td>0.5231</td><td>0.4557</td><td>0.3918</td></tr><tr><td>9</td><td>0.9462</td><td>0.9161</td><td>0.8774</td><td>0.8305</td><td>0.7764</td><td>0.7166</td><td>0.6530</td><td>0.5874</td><td>0.5218</td></tr><tr><td>10</td><td>0.9747</td><td>0.9574</td><td>0.9332</td><td>0.9015</td><td>0.8022</td><td>0.8159</td><td>0.7634</td><td>0.7060</td><td>0.6453</td></tr><tr><td>11</td><td>0.9890</td><td>0.9799</td><td>0.9661</td><td>0.9466</td><td>0.9208</td><td>0.8881</td><td>0.8487</td><td>0.8030</td><td>0.7520</td></tr><tr><td>12</td><td>0.9955</td><td>0.9912</td><td>0.9840</td><td>0.9730</td><td>0.9573</td><td>0.9362</td><td>0.9091</td><td>0.8758</td><td>0.8364</td></tr><tr><td>13</td><td>0.9983</td><td>0.9964</td><td>0.9929</td><td>0.9872</td><td>0.9784</td><td>0.9658</td><td>0.9486</td><td>0.9261</td><td>0.8981</td></tr><tr><td>14</td><td>0.9994</td><td>0.9986</td><td>0.9970</td><td>0.9943</td><td>0.9897</td><td>0.9827</td><td>0.9726</td><td>0.9585</td><td>0.9400</td></tr><tr><td>15</td><td>0.9998</td><td>0.9995</td><td>0.9988</td><td>0.9976</td><td>0.9954</td><td>0.9918</td><td>0.9862</td><td>0.9780</td><td>0.9665</td></tr><tr><td>16</td><td>0.9999</td><td>0.9998</td><td>0.9996</td><td>0.9990</td><td>0.9980</td><td>0.9963</td><td>0.9934</td><td>0.9889</td><td>0.9823</td></tr><tr><td>17</td><td>1.0000</td><td>0.9999</td><td>0.9998</td><td>0.9996</td><td>0.9992</td><td>0.9984</td><td>0.9970</td><td>0.9947</td><td>0.9911</td></tr><tr><td>18</td><td></td><td>1.0000</td><td>0.9999</td><td>0.9999</td><td>0.9997</td><td>0.9994</td><td>0.9987</td><td>0.9976</td><td>0.9957</td></tr><tr><td>19</td><td></td><td></td><td>1.0000</td><td>1.0000</td><td>0.9999</td><td>0.9997</td><td>0.9995</td><td>0.9989</td><td>0.9980</td></tr><tr><td>20</td><td></td><td></td><td></td><td></td><td>1.0000</td><td>0.9999</td><td>0.9998</td><td>0.9996</td><td>0.9991</td></tr></table>

# 附表4  $t$  分布表

$$
P\left\{t(n) > t_{\alpha}(n)\right\} = \alpha
$$

<table><tr><td>n</td><td>α</td><td>0.20</td><td>0.15</td><td>0.10</td><td>0.05</td><td>0.025</td><td>0.01</td><td>0.005</td></tr><tr><td>1</td><td>1.376</td><td>1.963</td><td>3.0777</td><td>6.3138</td><td>12.7062</td><td>31.8207</td><td>63.6574</td><td></td></tr><tr><td>2</td><td>1.061</td><td>1.386</td><td>1.8856</td><td>2.9200</td><td>4.3027</td><td>6.9646</td><td>9.9248</td><td></td></tr><tr><td>3</td><td>0.978</td><td>1.250</td><td>1.6377</td><td>2.3534</td><td>3.1824</td><td>4.5407</td><td>5.8409</td><td></td></tr><tr><td>4</td><td>0.941</td><td>1.190</td><td>1.5332</td><td>2.1318</td><td>2.7764</td><td>3.7469</td><td>4.6041</td><td></td></tr><tr><td>5</td><td>0.920</td><td>1.156</td><td>1.4759</td><td>2.0150</td><td>2.5706</td><td>3.3649</td><td>4.0322</td><td></td></tr><tr><td>6</td><td>0.906</td><td>1.134</td><td>1.4398</td><td>1.9432</td><td>2.4469</td><td>3.1427</td><td>3.7074</td><td></td></tr><tr><td>7</td><td>0.896</td><td>1.119</td><td>1.4149</td><td>1.8946</td><td>2.3646</td><td>2.9980</td><td>3.4995</td><td></td></tr><tr><td>8</td><td>0.889</td><td>1.108</td><td>1.3968</td><td>1.8595</td><td>2.3060</td><td>2.8965</td><td>3.3554</td><td></td></tr><tr><td>9</td><td>0.883</td><td>1.100</td><td>1.3830</td><td>1.8331</td><td>2.2622</td><td>2.8214</td><td>3.2498</td><td></td></tr><tr><td>10</td><td>0.879</td><td>1.093</td><td>1.3722</td><td>1.8125</td><td>2.2281</td><td>2.7638</td><td>3.1693</td><td></td></tr><tr><td>11</td><td>0.876</td><td>1.088</td><td>1.3634</td><td>1.7959</td><td>2.2010</td><td>2.7181</td><td>3.1058</td><td></td></tr><tr><td>12</td><td>0.873</td><td>1.083</td><td>1.3562</td><td>1.7823</td><td>2.1788</td><td>2.6810</td><td>3.0545</td><td></td></tr><tr><td>13</td><td>0.870</td><td>1.079</td><td>1.3502</td><td>1.7709</td><td>2.1604</td><td>2.6503</td><td>3.0123</td><td></td></tr><tr><td>14</td><td>0.868</td><td>1.076</td><td>1.3450</td><td>1.7613</td><td>2.1448</td><td>2.6245</td><td>2.9768</td><td></td></tr><tr><td>15</td><td>0.866</td><td>1.074</td><td>1.3406</td><td>1.7531</td><td>2.1315</td><td>2.6025</td><td>2.9467</td><td></td></tr><tr><td>16</td><td>0.865</td><td>1.071</td><td>1.3368</td><td>1.7459</td><td>2.1199</td><td>2.5835</td><td>2.9208</td><td></td></tr><tr><td>17</td><td>0.863</td><td>1.069</td><td>1.3334</td><td>1.7396</td><td>2.1098</td><td>2.5669</td><td>2.8982</td><td></td></tr><tr><td>18</td><td>0.862</td><td>1.067</td><td>1.3304</td><td>1.7341</td><td>2.1009</td><td>2.5524</td><td>2.8784</td><td></td></tr><tr><td>19</td><td>0.861</td><td>1.066</td><td>1.3277</td><td>1.7291</td><td>2.0930</td><td>2.5395</td><td>2.8609</td><td></td></tr><tr><td>20</td><td>0.860</td><td>1.064</td><td>1.3253</td><td>1.7247</td><td>2.0860</td><td>2.5280</td><td>2.8453</td><td></td></tr><tr><td>21</td><td>0.859</td><td>1.063</td><td>1.3232</td><td>1.7207</td><td>2.0796</td><td>2.5177</td><td>2.8314</td><td></td></tr><tr><td>22</td><td>0.858</td><td>1.061</td><td>1.3212</td><td>1.7171</td><td>2.0739</td><td>2.5083</td><td>2.8188</td><td></td></tr><tr><td>23</td><td>0.858</td><td>1.060</td><td>1.3195</td><td>1.7139</td><td>2.0687</td><td>2.4999</td><td>2.8073</td><td></td></tr><tr><td>24</td><td>0.857</td><td>1.059</td><td>1.3178</td><td>1.7109</td><td>2.0639</td><td>2.4922</td><td>2.7969</td><td></td></tr><tr><td>25</td><td>0.856</td><td>1.058</td><td>1.3163</td><td>1.7081</td><td>2.0595</td><td>2.4851</td><td>2.7874</td><td></td></tr><tr><td>26</td><td>0.856</td><td>1.058</td><td>1.3150</td><td>1.7056</td><td>2.0555</td><td>2.4786</td><td>2.7787</td><td></td></tr><tr><td>27</td><td>0.855</td><td>1.057</td><td>1.3137</td><td>1.7033</td><td>2.0518</td><td>2.4727</td><td>2.7707</td><td></td></tr><tr><td>28</td><td>0.855</td><td>1.056</td><td>1.3125</td><td>1.7011</td><td>2.0484</td><td>2.4671</td><td>2.7633</td><td></td></tr><tr><td>29</td><td>0.854</td><td>1.055</td><td>1.3114</td><td>1.6991</td><td>2.0452</td><td>2.4620</td><td>2.7564</td><td></td></tr><tr><td>30</td><td>0.854</td><td>1.055</td><td>1.3104</td><td>1.6973</td><td>2.0423</td><td>2.4573</td><td>2.7500</td><td></td></tr><tr><td>31</td><td>0.8535</td><td>1.0541</td><td>1.3095</td><td>1.6955</td><td>2.0395</td><td>2.4528</td><td>2.7440</td><td></td></tr><tr><td>32</td><td>0.8531</td><td>1.0536</td><td>1.3086</td><td>1.6939</td><td>2.0369</td><td>2.4487</td><td>2.7385</td><td></td></tr><tr><td>33</td><td>0.8527</td><td>1.0531</td><td>1.3077</td><td>1.6924</td><td>2.0345</td><td>2.4448</td><td>2.7333</td><td></td></tr><tr><td>34</td><td>0.8524</td><td>1.0526</td><td>1.3070</td><td>1.6909</td><td>2.0322</td><td>2.4411</td><td>2.7284</td><td></td></tr><tr><td>35</td><td>0.8521</td><td>1.0521</td><td>1.3062</td><td>1.6896</td><td>2.0301</td><td>2.4377</td><td>2.7238</td><td></td></tr><tr><td>36</td><td>0.8518</td><td>1.0516</td><td>1.3055</td><td>1.6883</td><td>2.0281</td><td>2.4345</td><td>2.7195</td><td></td></tr><tr><td>37</td><td>0.8515</td><td>1.0512</td><td>1.3049</td><td>1.6871</td><td>2.0262</td><td>2.4314</td><td>2.7154</td><td></td></tr><tr><td>38</td><td>0.8512</td><td>1.0508</td><td>1.3042</td><td>1.6860</td><td>2.0244</td><td>2.4286</td><td>2.7116</td><td></td></tr><tr><td>39</td><td>0.8510</td><td>1.0504</td><td>1.3036</td><td>1.6849</td><td>2.0227</td><td>2.4258</td><td>2.7079</td><td></td></tr><tr><td>40</td><td>0.8507</td><td>1.0501</td><td>1.3031</td><td>1.6839</td><td>2.0211</td><td>2.4233</td><td>2.7045</td><td></td></tr><tr><td>41</td><td>0.8505</td><td>1.0498</td><td>1.3025</td><td>1.6829</td><td>2.0195</td><td>2.4208</td><td>2.7012</td><td></td></tr><tr><td>42</td><td>0.8503</td><td>1.0494</td><td>1.3020</td><td>1.6820</td><td>2.0181</td><td>2.4185</td><td>2.6981</td><td></td></tr><tr><td>43</td><td>0.8501</td><td>1.0491</td><td>1.3016</td><td>1.6811</td><td>2.0167</td><td>2.4163</td><td>2.6951</td><td></td></tr><tr><td>44</td><td>0.8499</td><td>1.0488</td><td>1.3011</td><td>1.6802</td><td>2.0154</td><td>2.4141</td><td>2.6923</td><td></td></tr><tr><td>45</td><td>0.8497</td><td>1.0485</td><td>1.3006</td><td>1.6794</td><td>2.0141</td><td>2.4121</td><td>2.6896</td><td></td></tr></table>

# 附表5  $\chi^{2}$  分布表

$$
P\left\{\chi^{2}(n) > \chi_{a}^{2}(n)\right\} = \alpha
$$

<table><tr><td>α
n</td><td>0.995</td><td>0.99</td><td>0.975</td><td>0.95</td><td>0.90</td><td>0.10</td><td>0.05</td><td>0.025</td><td>0.01</td><td>0.005</td></tr><tr><td>1</td><td>0.000</td><td>0.000</td><td>0.001</td><td>0.004</td><td>0.016</td><td>2.706</td><td>3.843</td><td>5.025</td><td>6.637</td><td>7.879</td></tr><tr><td>2</td><td>0.010</td><td>0.020</td><td>0.051</td><td>0.103</td><td>0.211</td><td>4.605</td><td>5.992</td><td>7.378</td><td>9.210</td><td>10.597</td></tr><tr><td>3</td><td>0.072</td><td>0.115</td><td>0.216</td><td>0.352</td><td>0.584</td><td>6.251</td><td>7.815</td><td>9.348</td><td>11.344</td><td>12.837</td></tr><tr><td>4</td><td>0.207</td><td>0.297</td><td>0.484</td><td>0.711</td><td>1.064</td><td>7.779</td><td>9.488</td><td>11.143</td><td>13.277</td><td>14.860</td></tr><tr><td>5</td><td>0.412</td><td>0.554</td><td>0.831</td><td>1.145</td><td>1.610</td><td>9.236</td><td>11.070</td><td>12.832</td><td>15.085</td><td>16.748</td></tr><tr><td>6</td><td>0.676</td><td>0.872</td><td>1.237</td><td>1.635</td><td>2.204</td><td>10.645</td><td>12.592</td><td>14.440</td><td>16.812</td><td>18.548</td></tr><tr><td>7</td><td>0.989</td><td>1.239</td><td>1.690</td><td>2.167</td><td>2.833</td><td>12.017</td><td>14.067</td><td>16.012</td><td>18.474</td><td>20.276</td></tr><tr><td>8</td><td>1.344</td><td>1.646</td><td>2.180</td><td>2.733</td><td>3.490</td><td>13.362</td><td>15.507</td><td>17.534</td><td>20.090</td><td>21.954</td></tr><tr><td>9</td><td>1.735</td><td>2.088</td><td>2.700</td><td>3.325</td><td>4.168</td><td>14.684</td><td>16.919</td><td>19.022</td><td>21.665</td><td>23.587</td></tr><tr><td>10</td><td>2.156</td><td>2.558</td><td>3.247</td><td>3.940</td><td>4.865</td><td>15.987</td><td>18.307</td><td>20.483</td><td>23.209</td><td>25.188</td></tr><tr><td>11</td><td>2.603</td><td>3.053</td><td>3.816</td><td>4.575</td><td>5.578</td><td>17.275</td><td>19.675</td><td>21.920</td><td>24.724</td><td>26.755</td></tr><tr><td>12</td><td>3.074</td><td>3.571</td><td>4.404</td><td>5.226</td><td>6.304</td><td>18.549</td><td>21.026</td><td>23.337</td><td>26.217</td><td>28.300</td></tr><tr><td>13</td><td>3.565</td><td>4.107</td><td>5.009</td><td>5.892</td><td>7.041</td><td>19.812</td><td>22.362</td><td>24.735</td><td>27.687</td><td>29.817</td></tr><tr><td>14</td><td>4.075</td><td>4.660</td><td>5.629</td><td>6.571</td><td>7.790</td><td>21.064</td><td>23.685</td><td>26.119</td><td>29.141</td><td>31.319</td></tr><tr><td>15</td><td>4.600</td><td>5.229</td><td>6.262</td><td>7.261</td><td>8.547</td><td>22.307</td><td>24.996</td><td>27.488</td><td>30.577</td><td>32.799</td></tr><tr><td>16</td><td>5.142</td><td>5.812</td><td>6.908</td><td>7.962</td><td>9.312</td><td>23.542</td><td>26.296</td><td>28.845</td><td>32.000</td><td>34.267</td></tr><tr><td>17</td><td>5.697</td><td>6.407</td><td>7.564</td><td>8.682</td><td>10.085</td><td>24.769</td><td>27.587</td><td>30.190</td><td>33.408</td><td>35.716</td></tr><tr><td>18</td><td>6.265</td><td>7.015</td><td>8.231</td><td>9.390</td><td>10.865</td><td>25.989</td><td>28.869</td><td>31.526</td><td>34.805</td><td>37.156</td></tr><tr><td>19</td><td>6.843</td><td>7.632</td><td>8.906</td><td>10.117</td><td>11.651</td><td>27.203</td><td>30.143</td><td>32.852</td><td>36.190</td><td>38.580</td></tr><tr><td>20</td><td>7.434</td><td>8.260</td><td>9.591</td><td>10.851</td><td>12.443</td><td>28.412</td><td>31.410</td><td>34.170</td><td>37.566</td><td>39.997</td></tr><tr><td>21</td><td>8.033</td><td>8.897</td><td>10.283</td><td>11.591</td><td>13.240</td><td>29.615</td><td>32.670</td><td>35.478</td><td>38.930</td><td>41.399</td></tr><tr><td>22</td><td>8.643</td><td>9.542</td><td>10.982</td><td>12.338</td><td>14.042</td><td>30.813</td><td>33.924</td><td>36.781</td><td>40.289</td><td>42.796</td></tr><tr><td>23</td><td>9.260</td><td>10.195</td><td>11.688</td><td>13.090</td><td>14.848</td><td>32.007</td><td>35.172</td><td>38.075</td><td>41.637</td><td>44.179</td></tr><tr><td>24</td><td>9.886</td><td>10.856</td><td>12.401</td><td>13.848</td><td>15.659</td><td>33.196</td><td>36.415</td><td>39.364</td><td>42.980</td><td>45.558</td></tr><tr><td>25</td><td>10.519</td><td>11.524</td><td>13.120</td><td>14.611</td><td>16.473</td><td>34.382</td><td>37.652</td><td>40.646</td><td>44.314</td><td>46.925</td></tr><tr><td>26</td><td>11.160</td><td>12.198</td><td>13.844</td><td>15.379</td><td>17.292</td><td>35.563</td><td>38.885</td><td>41.923</td><td>45.642</td><td>48.290</td></tr><tr><td>27</td><td>11.807</td><td>12.878</td><td>14.573</td><td>16.151</td><td>18.114</td><td>36.741</td><td>40.113</td><td>43.194</td><td>46.962</td><td>49.642</td></tr><tr><td>28</td><td>12.461</td><td>13.565</td><td>15.308</td><td>16.928</td><td>18.939</td><td>37.916</td><td>41.337</td><td>44.461</td><td>48.278</td><td>50.993</td></tr><tr><td>29</td><td>13.120</td><td>14.256</td><td>16.147</td><td>17.708</td><td>19.768</td><td>39.087</td><td>42.557</td><td>45.722</td><td>49.586</td><td>52.333</td></tr><tr><td>30</td><td>13.787</td><td>14.954</td><td>16.791</td><td>18.493</td><td>20.599</td><td>40.256</td><td>43.773</td><td>46.979</td><td>50.892</td><td>53.672</td></tr><tr><td>31</td><td>14.457</td><td>15.655</td><td>17.538</td><td>19.280</td><td>21.433</td><td>41.422</td><td>44.985</td><td>48.231</td><td>52.190</td><td>55.000</td></tr><tr><td>32</td><td>15.134</td><td>16.362</td><td>18.291</td><td>20.072</td><td>22.271</td><td>42.585</td><td>46.194</td><td>49.480</td><td>53.486</td><td>56.328</td></tr><tr><td>33</td><td>15.814</td><td>17.073</td><td>19.046</td><td>20.866</td><td>23.110</td><td>43.745</td><td>47.400</td><td>50.724</td><td>54.774</td><td>57.646</td></tr><tr><td>34</td><td>16.501</td><td>17.789</td><td>19.806</td><td>21.664</td><td>23.952</td><td>44.903</td><td>48.602</td><td>51.966</td><td>56.061</td><td>58.964</td></tr><tr><td>35</td><td>17.191</td><td>18.508</td><td>20.569</td><td>22.465</td><td>24.796</td><td>46.059</td><td>49.802</td><td>53.203</td><td>57.340</td><td>60.272</td></tr><tr><td>36</td><td>17.887</td><td>19.233</td><td>21.336</td><td>23.269</td><td>25.643</td><td>47.212</td><td>50.998</td><td>54.437</td><td>58.619</td><td>61.581</td></tr><tr><td>37</td><td>18.584</td><td>19.960</td><td>22.105</td><td>24.075</td><td>26.492</td><td>48.363</td><td>52.192</td><td>55.667</td><td>59.891</td><td>62.880</td></tr><tr><td>38</td><td>19.289</td><td>20.691</td><td>22.878</td><td>24.884</td><td>27.343</td><td>49.513</td><td>53.384</td><td>56.896</td><td>61.162</td><td>64.181</td></tr><tr><td>39</td><td>19.994</td><td>21.425</td><td>23.654</td><td>25.695</td><td>28.196</td><td>50.660</td><td>54.572</td><td>58.119</td><td>62.426</td><td>65.473</td></tr><tr><td>40</td><td>20.706</td><td>22.164</td><td>24.433</td><td>26.509</td><td>29.050</td><td>51.805</td><td>55.758</td><td>59.342</td><td>63.691</td><td>66.766</td></tr></table>

注:当  $n > 40$  时,  $\chi_{a}^{2}(n) \approx \frac{1}{2} \left(z_{a} + \sqrt{2n - 1}\right)^{2}$ .

# 附表6  $F$  分布表

$$
P\{F(n_{1},n_{2}) > F_{\alpha}(n_{1},n_{2})\} = \alpha \qquad (\alpha = 0,10)
$$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_9.pdf-0912f019-1cce-45cf-a2df-cefa5cbfbcb7_b462079ee958eb82ee77c6d3f8b8f3440dd4602ff7216098a1a96d32a32786cc.jpg)

<table><tr><td>n1
n2</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>12</td><td>15</td><td>20</td><td>24</td><td>30</td><td>40</td><td>60</td><td>120</td><td>∞</td></tr><tr><td>1</td><td>39.86</td><td>49.50</td><td>53.59</td><td>54.83</td><td>57.24</td><td>58.20</td><td>58.91</td><td>59.44</td><td>59.80</td><td>60.19</td><td>60.71</td><td>61.22</td><td>61.74</td><td>62.00</td><td>62.26</td><td>62.53</td><td>62.79</td><td>63.06</td><td>63.33</td></tr><tr><td>2</td><td>8.53</td><td>9.00</td><td>9.16</td><td>9.24</td><td>9.29</td><td>9.33</td><td>9.35</td><td>9.37</td><td>9.38</td><td>9.39</td><td>9.41</td><td>9.42</td><td>9.44</td><td>9.45</td><td>9.46</td><td>9.47</td><td>9.47</td><td>9.48</td><td>9.49</td></tr><tr><td>3</td><td>5.54</td><td>5.46</td><td>5.39</td><td>5.34</td><td>5.31</td><td>5.28</td><td>5.27</td><td>5.25</td><td>5.24</td><td>5.23</td><td>5.22</td><td>5.20</td><td>5.18</td><td>5.18</td><td>5.17</td><td>5.16</td><td>5.15</td><td>5.14</td><td>5.13</td></tr><tr><td>4</td><td>4.54</td><td>4.32</td><td>4.19</td><td>4.11</td><td>4.05</td><td>4.01</td><td>3.98</td><td>3.95</td><td>3.94</td><td>3.92</td><td>3.90</td><td>3.87</td><td>3.84</td><td>3.83</td><td>3.82</td><td>3.80</td><td>3.79</td><td>3.78</td><td>3.76</td></tr><tr><td>5</td><td>4.06</td><td>3.78</td><td>3.62</td><td>3.52</td><td>3.45</td><td>3.40</td><td>3.37</td><td>3.34</td><td>3.32</td><td>3.30</td><td>3.27</td><td>3.24</td><td>3.21</td><td>3.19</td><td>3.17</td><td>3.16</td><td>3.14</td><td>3.12</td><td>3.10</td></tr><tr><td>6</td><td>3.78</td><td>3.46</td><td>3.29</td><td>3.18</td><td>3.11</td><td>3.05</td><td>3.01</td><td>2.98</td><td>2.96</td><td>2.94</td><td>2.90</td><td>2.87</td><td>2.84</td><td>2.82</td><td>2.80</td><td>2.78</td><td>2.76</td><td>2.74</td><td>2.72</td></tr><tr><td>7</td><td>3.59</td><td>3.26</td><td>3.07</td><td>2.96</td><td>2.88</td><td>2.83</td><td>2.78</td><td>2.75</td><td>2.75</td><td>2.70</td><td>2.67</td><td>2.63</td><td>2.59</td><td>2.58</td><td>2.56</td><td>2.54</td><td>2.51</td><td>2.49</td><td>2.47</td></tr><tr><td>8</td><td>3.46</td><td>3.11</td><td>2.92</td><td>2.81</td><td>2.73</td><td>2.67</td><td>2.62</td><td>2.59</td><td>2.56</td><td>2.54</td><td>2.50</td><td>2.46</td><td>2.42</td><td>2.40</td><td>2.38</td><td>2.36</td><td>2.34</td><td>2.32</td><td>2.29</td></tr><tr><td>9</td><td>3.36</td><td>3.01</td><td>2.81</td><td>2.69</td><td>2.61</td><td>2.55</td><td>2.51</td><td>2.47</td><td>2.44</td><td>2.42</td><td>2.38</td><td>2.34</td><td>2.30</td><td>2.28</td><td>2.25</td><td>2.23</td><td>2.21</td><td>2.18</td><td>2.16</td></tr><tr><td>10</td><td>3.29</td><td>2.92</td><td>2.73</td><td>2.61</td><td>2.52</td><td>2.46</td><td>2.41</td><td>2.38</td><td>2.35</td><td>2.32</td><td>2.28</td><td>2.24</td><td>2.20</td><td>2.18</td><td>2.16</td><td>2.13</td><td>2.11</td><td>2.08</td><td>2.06</td></tr><tr><td>11</td><td>3.23</td><td>2.86</td><td>2.66</td><td>2.54</td><td>2.45</td><td>2.39</td><td>2.34</td><td>2.30</td><td>2.27</td><td>2.25</td><td>2.21</td><td>2.17</td><td>2.12</td><td>2.10</td><td>2.08</td><td>2.05</td><td>2.03</td><td>2.00</td><td>1.97</td></tr><tr><td>12</td><td>3.18</td><td>2.81</td><td>2.61</td><td>2.48</td><td>2.39</td><td>2.33</td><td>2.28</td><td>2.24</td><td>2.21</td><td>2.19</td><td>2.15</td><td>2.10</td><td>2.06</td><td>2.04</td><td>2.01</td><td>1.99</td><td>1.96</td><td>1.93</td><td>1.90</td></tr><tr><td>13</td><td>3.14</td><td>2.76</td><td>2.56</td><td>2.43</td><td>2.35</td><td>2.28</td><td>2.23</td><td>2.20</td><td>2.16</td><td>2.14</td><td>2.10</td><td>2.05</td><td>2.01</td><td>1.98</td><td>1.96</td><td>1.93</td><td>1.90</td><td>1.88</td><td>1.85</td></tr><tr><td>14</td><td>3.10</td><td>2.73</td><td>2.52</td><td>2.39</td><td>2.31</td><td>2.24</td><td>2.19</td><td>2.15</td><td>2.12</td><td>2.10</td><td>2.05</td><td>2.01</td><td>1.96</td><td>1.94</td><td>1.91</td><td>1.89</td><td>1.86</td><td>1.83</td><td>1.80</td></tr><tr><td>15</td><td>3.07</td><td>2.70</td><td>2.49</td><td>2.36</td><td>2.27</td><td>2.21</td><td>2.16</td><td>2.12</td><td>2.09</td><td>2.06</td><td>2.02</td><td>1.97</td><td>1.92</td><td>1.90</td><td>1.87</td><td>1.85</td><td>1.82</td><td>1.79</td><td>1.76</td></tr><tr><td>16</td><td>3.05</td><td>2.67</td><td>2.46</td><td>2.33</td><td>2.24</td><td>2.18</td><td>2.13</td><td>2.09</td><td>2.06</td><td>2.03</td><td>1.99</td><td>1.94</td><td>1.89</td><td>1.87</td><td>1.84</td><td>1.81</td><td>1.78</td><td>1.75</td><td>1.72</td></tr><tr><td>17</td><td>3.03</td><td>2.64</td><td>2.44</td><td>2.31</td><td>2.22</td><td>2.15</td><td>2.10</td><td>2.06</td><td>2.03</td><td>2.00</td><td>1.96</td><td>1.91</td><td>1.86</td><td>1.84</td><td>1.81</td><td>1.78</td><td>1.75</td><td>1.72</td><td>1.69</td></tr><tr><td>18</td><td>3.01</td><td>2.62</td><td>2.42</td><td>2.29</td><td>2.20</td><td>2.13</td><td>2.08</td><td>2.04</td><td>2.00</td><td>1.98</td><td>1.93</td><td>1.89</td><td>1.84</td><td>1.81</td><td>1.78</td><td>1.75</td><td>1.72</td><td>1.69</td><td>1.66</td></tr><tr><td>19</td><td>2.99</td><td>2.61</td><td>2.40</td><td>2.27</td><td>2.18</td><td>2.11</td><td>2.06</td><td>2.02</td><td>1.98</td><td>1.96</td><td>1.91</td><td>1.86</td><td>1.81</td><td>1.79</td><td>1.76</td><td>1.73</td><td>1.70</td><td>1.67</td><td>1.63</td></tr><tr><td>20</td><td>2.97</td><td>2.59</td><td>2.38</td><td>2.25</td><td>2.16</td><td>2.09</td><td>2.04</td><td>2.00</td><td>1.96</td><td>1.94</td><td>1.89</td><td>1.84</td><td>1.79</td><td>1.77</td><td>1.74</td><td>1.71</td><td>1.68</td><td>1.64</td><td>1.61</td></tr><tr><td>21</td><td>2.96</td><td>2.57</td><td>2.36</td><td>2.23</td><td>2.14</td><td>2.08</td><td>2.02</td><td>1.98</td><td>1.95</td><td>1.92</td><td>1.87</td><td>1.83</td><td>1.78</td><td>1.75</td><td>1.72</td><td>1.69</td><td>1.66</td><td>1.62</td><td>1.59</td></tr><tr><td>22</td><td>2.95</td><td>2.56</td><td>2.35</td><td>2.22</td><td>2.13</td><td>2.06</td><td>2.01</td><td>1.97</td><td>1.93</td><td>1.90</td><td>1.86</td><td>1.81</td><td>1.76</td><td>1.73</td><td>1.70</td><td>1.67</td><td>1.64</td><td>1.60</td><td>1.57</td></tr><tr><td>23</td><td>2.94</td><td>2.55</td><td>2.34</td><td>2.21</td><td>2.11</td><td>2.05</td><td>1.99</td><td>1.95</td><td>1.92</td><td>1.89</td><td>1.84</td><td>1.80</td><td>1.74</td><td>1.72</td><td>1.69</td><td>1.66</td><td>1.62</td><td>1.59</td><td>1.55</td></tr><tr><td>24</td><td>2.93</td><td>2.54</td><td>2.33</td><td>2.19</td><td>2.10</td><td>2.04</td><td>1.98</td><td>1.94</td><td>1.91</td><td>1.88</td><td>1.83</td><td>1.78</td><td>1.73</td><td>1.70</td><td>1.67</td><td>1.64</td><td>1.61</td><td>1.57</td><td>1.53</td></tr><tr><td>25</td><td>2.92</td><td>2.53</td><td>2.32</td><td>2.18</td><td>2.09</td><td>2.02</td><td>1.97</td><td>1.93</td><td>1.88</td><td>1.87</td><td>1.82</td><td>1.77</td><td>1.72</td><td>1.69</td><td>1.66</td><td>1.63</td><td>1.59</td><td>1.56</td><td>1.52</td></tr><tr><td>26</td><td>2.91</td><td>2.52</td><td>2.31</td><td>2.17</td><td>2.08</td><td>2.01</td><td>1.96</td><td>1.92</td><td>1.88</td><td>1.86</td><td>1.81</td><td>1.76</td><td>1.71</td><td>1.68</td><td>1.65</td><td>1.61</td><td>1.58</td><td>1.54</td><td>1.50</td></tr><tr><td>27</td><td>2.90</td><td>2.51</td><td>2.30</td><td>2.17</td><td>2.07</td><td>2.00</td><td>1.95</td><td>1.91</td><td>1.87</td><td>1.85</td><td>1.80</td><td>1.75</td><td>1.70</td><td>1.67</td><td>1.64</td><td>1.60</td><td>1.57</td><td>1.53</td><td>1.49</td></tr><tr><td>28</td><td>2.89</td><td>2.50</td><td>2.29</td><td>2.16</td><td>2.06</td><td>2.00</td><td>1.94</td><td>1.90</td><td>1.87</td><td>1.84</td><td>1.79</td><td>1.74</td><td>1.69</td><td>1.66</td><td>1.63</td><td>1.59</td><td>1.56</td><td>1.52</td><td>1.48</td></tr><tr><td>29</td><td>2.89</td><td>2.50</td><td>2.28</td><td>2.15</td><td>2.06</td><td>1.99</td><td>1.93</td><td>1.89</td><td>1.86</td><td>1.83</td><td>1.78</td><td>1.73</td><td>1.68</td><td>1.65</td><td>1.62</td><td>1.58</td><td>1.55</td><td>1.51</td><td>1.47</td></tr><tr><td>30</td><td>2.88</td><td>2.49</td><td>2.28</td><td>2.14</td><td>2.05</td><td>1.98</td><td>1.93</td><td>1.88</td><td>1.85</td><td>1.82</td><td>1.77</td><td>1.72</td><td>1.67</td><td>1.64</td><td>1.61</td><td>1.57</td><td>1.54</td><td>1.50</td><td>1.46</td></tr><tr><td>40</td><td>2.84</td><td>2.44</td><td>2.23</td><td>2.09</td><td>2.00</td><td>1.93</td><td>1.87</td><td>1.83</td><td>1.79</td><td>1.76</td><td>1.71</td><td>1.66</td><td>1.61</td><td>1.57</td><td>1.54</td><td>1.51</td><td>1.47</td><td>1.42</td><td>1.38</td></tr><tr><td>60</td><td>2.79</td><td>2.39</td><td>2.18</td><td>2.04</td><td>1.95</td><td>1.87</td><td>1.82</td><td>1.77</td><td>1.74</td><td>1.71</td><td>1.66</td><td>1.60</td><td>1.54</td><td>1.51</td><td>1.48</td><td>1.44</td><td>1.40</td><td>1.35</td><td>1.29</td></tr><tr><td>120</td><td>2.75</td><td>2.35</td><td>2.13</td><td>1.99</td><td>1.90</td><td>1.82</td><td>1.77</td><td>1.72</td><td>1.68</td><td>1.65</td><td>1.60</td><td>1.55</td><td>1.48</td><td>1.45</td><td>1.41</td><td>1.37</td><td>1.32</td><td>1.26</td><td>1.19</td></tr><tr><td>∞</td><td>2.71</td><td>2.30</td><td>2.08</td><td>1.94</td><td>1.85</td><td>1.77</td><td>1.72</td><td>1.67</td><td>1.63</td><td>1.60</td><td>1.55</td><td>1.49</td><td>1.42</td><td>1.38</td><td>1.34</td><td>1.30</td><td>1.24</td><td>1.17</td><td>1.00</td></tr></table>

(0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000

<table><tr><td>n1</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>12</td><td>15</td><td>20</td><td>24</td><td>30</td><td>40</td><td>60</td><td>120</td><td>∞</td></tr><tr><td>n2</td><td>648</td><td>800</td><td>864</td><td>900</td><td>922</td><td>937</td><td>948</td><td>957</td><td>963</td><td>969</td><td>977</td><td>985</td><td>993</td><td>997</td><td>1000</td><td>1010</td><td>1010</td><td>1020</td><td></td></tr><tr><td>1</td><td>38.5</td><td>39.0</td><td>39.2</td><td>39.3</td><td>39.4</td><td>39.5</td><td>39.6</td><td>39.7</td><td>39.8</td><td>39.9</td><td>39.1</td><td>40.0</td><td>41.0</td><td>42.0</td><td>43.0</td><td>44.0</td><td>45.0</td><td>46.0</td><td></td></tr><tr><td>2</td><td>17.4</td><td>16.0</td><td>15.4</td><td>15.1</td><td>14.9</td><td>14.7</td><td>14.6</td><td>14.5</td><td>14.4</td><td>14.3</td><td>14.2</td><td>14.1</td><td>14.0</td><td>14.0</td><td>14.0</td><td>14.0</td><td>14.0</td><td>14.0</td><td></td></tr><tr><td>3</td><td>12.2</td><td>10.6</td><td>9.9</td><td>9.60</td><td>9.36</td><td>9.20</td><td>9.07</td><td>8.98</td><td>8.96</td><td>8.84</td><td>8.75</td><td>8.66</td><td>8.56</td><td>8.51</td><td>8.46</td><td>8.41</td><td>8.36</td><td>8.31</td><td></td></tr><tr><td>4</td><td>10.0</td><td>8.43</td><td>7.78</td><td>7.39</td><td>7.15</td><td>6.98</td><td>6.85</td><td>6.76</td><td>6.68</td><td>6.62</td><td>6.52</td><td>6.43</td><td>6.33</td><td>6.28</td><td>6.23</td><td>6.18</td><td>6.12</td><td>6.07</td><td></td></tr><tr><td>5</td><td>8.81</td><td>7.20</td><td>6.60</td><td>6.23</td><td>5.99</td><td>5.82</td><td>5.70</td><td>5.60</td><td>5.52</td><td>5.46</td><td>5.37</td><td>5.27</td><td>5.17</td><td>5.12</td><td>5.07</td><td>5.01</td><td>4.96</td><td>4.90</td><td></td></tr><tr><td>6</td><td>8.81</td><td>7.20</td><td>6.60</td><td>6.23</td><td>5.99</td><td>5.82</td><td>5.70</td><td>5.60</td><td>5.52</td><td>5.46</td><td>5.37</td><td>5.27</td><td>5.17</td><td>5.12&lt;f</td><td>5.07</td><td>5.01</td><td>4.96</td><td>4.90</td><td></td></tr><tr><td>7</td><td>8.07</td><td>6.54</td><td>5.89</td><td>5.52</td><td>5.29</td><td>5.12</td><td>4.99</td><td>4.90</td><td>4.82</td><td>4.76</td><td>4.67</td><td>4.57</td><td>4.47</td><td>4.42</td><td>4.36</td><td>4.31</td><td>4.25</td><td>4.20</td><td></td></tr><tr><td>8</td><td>7.57</td><td>6.06</td><td>5.42</td><td>5.05</td><td>4.82</td><td>4.65</td><td>4.53</td><td>4.43</td><td>4.36</td><td>4.30</td><td>4.20</td><td>4.10</td><td>4.00</td><td>3.95</td><td>3.89</td><td>3.84</td><td>3.78</td><td>3.73</td><td></td></tr><tr><td>9</td><td>7.21</td><td>5.71</td><td>5.08</td><td>4.72</td><td>4.48</td><td>4.32</td><td>4.20</td><td>4.10</td><td>4.03</td><td>3.96</td><td>3.87</td><td>3.77</td><td>3.67</td><td>3.61</td><td>3.56</td><td>3.51</td><td>3.45</td><td>3.39</td><td></td></tr><tr><td>10</td><td>6.94</td><td>5.46</td><td>4.88</td><td>4.47</td><td>4.24</td><td>4.07</td><td>3.95</td><td>3.85</td><td>3.78</td><td>3.72</td><td>3.62</td><td>3.52</td><td>3.42</td><td>3.37</td><td>3.31</td><td>3.26</td><td>3.20</td><td>3.14</td><td></td></tr><tr><td>11</td><td>6.72</td><td>5.26</td><td>4.63</td><td>4.28</td><td>4.04</td><td>3.88</td><td>3.76</td><td>3.66</td><td>3.59</td><td>3.53</td><td>3.43</td><td>3.33</td><td>3.23</td><td>3.17</td><td>3.12</td><td>3.06</td><td>3.00</td><td>2.94</td><td></td></tr><tr><td>12</td><td>6.55</td><td>5.10</td><td>4.47</td><td>4.12</td><td>3.89</td><td>3.73</td><td>3.61</td><td>3.51</td><td>3.44</td><td>3.37</td><td>3.28</td><td>3.18</td><td>3.07</td><td>3.02</td><td>2.96</td><td>2.91</td><td>2.85</td><td>2.79</td><td></td></tr><tr><td>13</td><td>6.41</td><td>4.97</td><td>4.35</td><td>4.00</td><td>3.77</td><td>3.60</td><td>3.48</td><td>3.39</td><td>3.31</td><td>3.25</td><td>3.15</td><td>3.05</td><td>3.05</td><td>2.89</td><td>2.84</td><td>2.78</td><td>2.72</td><td>2.66</td><td></td></tr><tr><td>14</td><td>6.30</td><td>4.86</td><td>4.24</td><td>3.89</td><td>3.66</td><td>3.50</td><td>3.38</td><td>3.29</td><td>3.21</td><td>3.15</td><td>3.05</td><td>2.95</td><td>2.84</td><td>2.79</td><td>2.73</td><td>2.67</td><td>2.61</td><td>2.55</td><td></td></tr><tr><td>15</td><td>6.20</td><td>4.77</td><td>4.15</td><td>3.80</td><td>3.58</td><td>3.41</td><td>3.29</td><td>3.20</td><td>3.12</td><td>3.06</td><td>2.96</td><td>2.86</td><td>2.76</td><td>2.70</td><td>2.64</td><td>2.59</td><td>2.52</td><td>2.46</td><td></td></tr><tr><td>16</td><td>6.12</td><td>4.69</td><td>4.08</td><td>3.73</td><td>3.50</td><td>3.34</td><td>3.22</td><td>3.12</td><td>3.05</td><td>2.99</td><td>2.89</td><td>2.79</td><td>2.68</td><td>2.63</td><td>2.57</td><td>2.51</td><td>2.45</td><td>2.38</td><td></td></tr><tr><td>17</td><td>6.04</td><td>4.62</td><td>4.01</td><td>3.66</td><td>3.44</td><td>3.28</td><td>3.16</td><td>3.06</td><td>2.98</td><td>2.92</td><td>2.82</td><td>2.72</td><td>2.62</td><td>2.56</td><td>2.50</td><td>2.44</td><td>2.38</td><td>2.32</td><td></td></tr><tr><td>18</td><td>5.98</td><td>4.56</td><td>3.95</td><td>3.61</td><td>3.38</td><td>3.22</td><td>3.10</td><td>3.01</td><td>2.93</td><td>2.87</td><td>2.77</td><td>2.67</td><td>2.56</td><td>2.50</td><td>2.44</td><td>2.38</td><td>2.32</td><td>2.26</td><td></td></tr><tr><td>19</td><td>5.92</td><td>4.51</td><td>3.95</td><td>3.56</td><td>3.33</td><td>3.17</td><td>3.05</td><td>2.96</td><td>2.88</td><td>2.82</td><td>2.72</td><td>2.62</td><td>2.51</td><td>2.45</td><td>2.39</td><td>2.33</td><td>2.27</td><td>2.20</td><td></td></tr><tr><td>20</td><td>5.87</td><td>4.46</td><td>3.85</td><td>3.51</td><td>3.29</td><td>3.13</td><td>3.01</td><td>2.91</td><td>2.84</td><td>2.77</td><td>2.68</td><td>2.57</td><td>2.46</td><td>2.41</td><td>2.35</td><td>2.29</td><td>2.22</td><td>2.16</td><td></td></tr><tr><td>21</td><td>5.83</td><td>4.42</td><td>3.82</td><td>3.48</td><td>3.25</td><td>3.09</td><td>2.97</td><td>2.87</td><td>2.80</td><td>2.73</td><td>2.64</td><td>2.53</td><td>2.42</td><td>2.37</td><td>2.31</td><td>2.25</td><td>2.18</td><td>2.11</td><td></td></tr><tr><td>22</td><td>5.79</td><td>4.38</td><td>3.78</td><td>3.44</td><td>3.22</td><td>3.05</td><td>2.93</td><td>2.84</td><td>2.76</td><td>2.70</td><td>2.60</td><td>2.50</td><td>2.39</td><td>2.33</td><td>2.27</td><td>2.21</td><td>2.14</td><td>2.08</td><td></td></tr><tr><td>23</td><td>5.75</td><td>4.35</td><td>3.75</td><td>3.41</td><td>3.18</td><td>3.02</td><td>2.90</td><td>2.81</td><td>2.73</td><td>2.67</td><td>2.57</td><td>2.47</td><td>2.36</td><td>2.30</td><td>2.24</td><td>2.18</td><td>2.11</td><td>2.04</td><td></td></tr><tr><td>24</td><td>5.72</td><td>4.32</td><td>3.72</td><td>3.35</td><td>3.15</td><td>3.09</td><td>2.99</td><td>2.87</td><td>2.78</td><td>2.70</td><td>2.64</td><td>2.54</td><td>2.44</td><td>2.33</td><td>2.27</td><td>2.18</td><td>2.08</td><td>2.01</td><td></td></tr><tr><td>25</td><td>5.69</td><td>4.29</td><td>3.69</td><td>3.35</td><td>3.13</td><td>3.13</td><td>2.97</td><td>2.85</td><td>2.75</td><td>2.68</td><td>2.61</td><td>2.51</td><td>2.41</td><td>2.30</td><td>2.24</td><td>2.18</td><td>2.05</td><td>2.01</td><td></td></tr><tr><td>26</td><td>5.66</td><td>4.27</td><td>3.67</td><td>3.33</td><td>3.10</td><td>3.10</td><td>2.94</td><td>2.82</td><td>2.73</td><td>2.65</td><td>2.59</td><td>2.49</td><td>2.39</td><td>2.28</td><td>2.22</td><td>2.16</td><td>2.09</td><td>2.03</td><td></td></tr><tr><td>27</td><td>5.63</td><td>4.24</td><td>3.65</td><td>3.31</td><td>3.08</td><td>2.92</td><td>2.80</td><td>2.71</td><td>2.63</td><td>2.57</td><td>2.47</td><td>2.36</td><td>2.25</td><td>2.19</td><td>2.13</td><td>2.07</td><td>2.00</td><td>1.93</td><td></td></tr><tr><td>28</td><td>5.61</td><td>4.22</td><td>3.65</td><td>3.31</td><td>3.08</td><td>2.90</td><td>2.78</td><td>2.69</td><td>2.61</td><td>2.55</td><td>2.45</td><td>2.34</td><td>2.23</td><td>2.17</td><td>2.11</td><td>2.05</td><td>1.98</td><td>1.93</td><td></td></tr><tr><td>29</td><td>5.59</td><td>4.20</td><td>3.63</td><td>3.29</td><td>3.06</td><td>2.88</td><td>2.76</td><td>2.67</td><td>2.59</td><td>2.53</td><td>2.43</td><td>2.32</td><td>2.21</td><td>2.15</td><td>2.09</td><td>2.03</td><td>1.96</td><td>1.89</td><td></td></tr><tr><td>30</td><td>5.57</td><td>4.18</td><td>3.59</td><td>3.25</td><td>3.03</td><td>2.87</td><td>2.75</td><td>2.65</td><td>2.57</td><td>2.51</td><td>2.41</td><td>2.31</td><td>2.20</td><td>2.15</td><td>2.09</td><td>2.01</td><td>1.94</td><td>1.89</td><td></td></tr><tr><td>31</td><td>5.42</td><td>4.05</td><td>3.45</td><td>3.13</td><td>2.90</td><td>2.74</td><td>2.62</td><td>2.53</td><td>2.45</td><td>2.39</td><td>2.29</td><td>2.18</td><td>2.18</td><td>2.07</td><td>2.01</td><td>1.94</td><td>1.88</td><td>1.72</td><td></td></tr><tr><td>32</td><td>5.29</td><td>3.93</td><td>3.31</td><td>3.01</td><td>2.90</td><td>2.79</td><td>2.63</td><td>2.51</td><td>2.41</td><td>2.33</td><td>2.27</td><td>2.17</td><td>2.06</td><td>2.01</td><td>1.88</td><td>1.74</td><td>1.67</td><td>1.58</td><td></td></tr><tr><td>33</td><td>5.15</td><td>3.80</td><td>3.28</td><td>2.89</td><td>2.67</td><td>2.52</td><td>2.39</td><td>2.30</td><td>2.22</td><td>2.16</td><td>2.05</td><td>1.94</td><td>1.82</td><td>1.76</td><td>1.69</td><td>1.61</td><td>1.53</td><td>1.43</td><td></td></tr><tr><td>34</td><td>5.02</td><td>3.69</td><td>3.12</td><td>2.79</td><td>2.57</td><td>2.41</td><td>2.29</td><td>2.19</td><td>2.11</td><td>2.05</td><td>1.94</td><td>1.83</td><td>1.71</td><td>1.64</td><td>1.57</td><td>1.48</td><td>1.39</td><td>1.27</td><td></td></tr></table>

(000)000  

<table><tr><td>n1</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>12</td><td>15</td><td>20</td><td>24</td><td>30</td><td>40</td><td>60</td><td>120</td><td>∞</td></tr><tr><td>n2</td><td>4052</td><td>4999</td><td>5403</td><td>5625</td><td>5764</td><td>5859</td><td>5928</td><td>5981</td><td>6022</td><td>6056</td><td>6106</td><td>6157</td><td>6209</td><td>6235</td><td>6261</td><td>6287</td><td>6313</td><td>6339</td><td>6366</td></tr><tr><td>1</td><td>4052</td><td>4999</td><td>5403</td><td>5625</td><td>5764</td><td>5859</td><td>5928</td><td>5981</td><td>6022</td><td>6056</td><td>6106</td><td>6157</td><td>6209</td><td>6235&lt;ftd&gt;6261</td><td>6287</td><td>6313</td><td>6339</td><td>6366</td><td></td></tr><tr><td>2</td><td>98.5</td><td>99.0</td><td>99.2</td><td>99.2</td><td>99.3</td><td>99.3</td><td>99.4</td><td>99.4</td><td>99.4</td><td>99.4</td><td>99.4</td><td>99.4</td><td>99.4</td><td>99.5</td><td>99.5</td><td>99.5</td><td>99.5</td><td>99.5</td><td>99.5</td></tr><tr><td>3</td><td>34.1</td><td>30.8</td><td>29.5</td><td>28.7</td><td>28.2</td><td>27.9</td><td>27.7</td><td>27.5</td><td>27.3</td><td>27.2</td><td>27.1</td><td>26.9</td><td>26.7</td><td>26.6</td><td>26.5</td><td>26.5</td><td>26.5</td><td>26.5</td><td>26.5</td></tr><tr><td>4</td><td>21.2</td><td>18.0</td><td>16.7</td><td>16.0</td><td>15.5</td><td>15.2</td><td>15.0</td><td>14.8</td><td>14.7</td><td>14.5</td><td>14.4</td><td>14.2</td><td>14.0</td><td>13.9</td><td>13.8</td><td>13.7</td><td>13.7</td><td>13.6</td><td>13.5</td></tr><tr><td>5</td><td>16.3</td><td>13.3</td><td>12.1</td><td>11.4</td><td>11.0</td><td>10.7</td><td>10.5</td><td>10.3</td><td>10.2</td><td>10.1</td><td>9.89</td><td>9.72</td><td>9.55</td><td>9.47</td><td>9.38</td><td>9.29</td><td>9.29</td><td>9.11</td><td>9.02</td></tr><tr><td>6</td><td>13.7</td><td>10.9</td><td>9.78</td><td>9.15</td><td>8.75</td><td>8.47</td><td>8.26</td><td>8.10</td><td>7.98</td><td>7.87</td><td>7.72</td><td>7.56</td><td>7.40</td><td>7.31</td><td>7.23</td><td>7.14</td><td>7.06</td><td>6.97</td><td>6.88</td></tr><tr><td>7</td><td>12.2</td><td>9.55</td><td>8.45</td><td>7.85</td><td>7.46</td><td>7.19</td><td>6.99</td><td>6.84</td><td>6.72</td><td>6.62</td><td>6.47</td><td>6.31</td><td>6.16</td><td>6.07</td><td>5.99</td><td>5.91</td><td>5.82</td><td>5.74</td><td>5.65</td></tr><tr><td>8</td><td>11.3</td><td>8.65</td><td>7.59</td><td>7.01</td><td>6.63</td><td>6.37</td><td>6.18</td><td>6.03</td><td>5.91</td><td>5.81</td><td>5.67</td><td>5.52</td><td>5.36</td><td>5.28</td><td>5.20</td><td>5.12</td><td>5.03</td><td>4.95</td><td>4.86</td></tr><tr><td>9</td><td>10.6</td><td>8.02</td><td>6.99</td><td>6.42</td><td>5.06</td><td>5.80</td><td>5.61</td><td>5.47</td><td>5.35</td><td>5.26</td><td>5.11</td><td>4.96</td><td>4.81</td><td>4.73</td><td>4.65</td><td>4.57</td><td>4.48</td><td>4.40</td><td>4.31</td></tr><tr><td>10</td><td>10.0</td><td>7.56</td><td>6.55</td><td>5.99</td><td>5.64</td><td>5.39</td><td>5.20</td><td>5.06</td><td>4.94</td><td>4.85</td><td>4.71</td><td>4.56</td><td>4.41</td><td>4.33</td><td>4.25</td><td>4.17</td><td>4.08</td><td>4.00</td><td>3.91</td></tr><tr><td>11</td><td>9.65</td><td>7.21</td><td>6.22</td><td>5.67</td><td>5.32</td><td>5.07</td><td>4.89</td><td>4.74</td><td>4.63</td><td>4.54</td><td>4.40</td><td>4.25</td><td>4.10</td><td>4.02</td><td>3.94</td><td>3.86</td><td>3.78</td><td>3.69</td><td>3.60</td></tr><tr><td>12</td><td>9.33</td><td>6.93</td><td>5.95</td><td>5.41</td><td>5.06</td><td>5.82</td><td>4.64</td><td>4.50</td><td>4.39</td><td>4.30</td><td>4.16</td><td>4.01</td><td>3.86</td><td>3.78</td><td>3.70</td><td>3.62</td><td>3.54</td><td>3.45</td><td>3.36</td></tr><tr><td>13</td><td>9.07</td><td>6.70</td><td>5.74</td><td>5.21</td><td>4.86</td><td>4.62</td><td>4.44</td><td>4.30</td><td>4.19</td><td>4.10</td><td>3.96</td><td>3.82</td><td>3.66</td><td>3.59</td><td>3.51</td><td>3.43</td><td>3.34</td><td>3.25</td><td>3.17</td></tr><tr><td>14</td><td>8.86</td><td>6.51</td><td>5.56</td><td>5.04</td><td>4.69</td><td>4.46</td><td>4.28</td><td>4.14</td><td>4.03</td><td>3.94</td><td>3.80</td><td>3.66</td><td>3.51</td><td>3.43</td><td>3.35</td><td>3.27</td><td>3.18</td><td>3.09</td><td>3.00</td></tr><tr><td>15</td><td>8.68</td><td>6.36</td><td>5.42</td><td>4.89</td><td>4.56</td><td>4.32</td><td>4.14</td><td>4.00</td><td>3.89</td><td>3.80</td><td>3.67</td><td>3.52</td><td>3.37</td><td>3.29</td><td>3.21</td><td>3.13</td><td>3.05</td><td>2.96</td><td>2.87</td></tr><tr><td>16</td><td>8.53</td><td>6.23</td><td>5.29</td><td>4.77</td><td>4.44</td><td>4.20</td><td>4.03</td><td>3.89</td><td>3.78</td><td>3.69</td><td>3.55</td><td>3.41</td><td>3.26</td><td>3.18</td><td>3.10</td><td>3.02</td><td>2.93</td><td>2.84</td><td>2.75</td></tr><tr><td>17</td><td>8.40</td><td>6.11</td><td>5.18</td><td>4.67</td><td>4.34</td><td>4.10</td><td>3.93</td><td>3.79</td><td>3.68</td><td>3.59</td><td>3.46</td><td>3.31</td><td>3.16</td><td>3.08</td><td>3.00</td><td>2.92</td><td>2.83</td><td>2.75</td><td>2.65</td></tr><tr><td>18</td><td>8.29</td><td>6.01</td><td>5.09</td><td>4.58</td><td>4.25</td><td>4.01</td><td>3.84</td><td>3.71</td><td>3.60</td><td>3.51</td><td>3.37</td><td>3.23</td><td>3.08</td><td>3.00</td><td>2.92</td><td>2.84</td><td>2.75</td><td>2.66</td><td>2.57</td></tr><tr><td>19</td><td>8.18</td><td>5.93</td><td>5.01</td><td>4.50</td><td>4.17</td><td>3.94</td><td>3.77</td><td>3.63</td><td>3.52</td><td>3.43</td><td>3.30</td><td>3.15</td><td>3.00</td><td>2.92</td><td>2.84</td><td>2.76</td><td>2.67</td><td>2.58</td><td>2.49</td></tr><tr><td>20</td><td>8.10</td><td>5.85</td><td>4.94</td><td>4.43</td><td>4.10</td><td>3.87</td><td>3.70</td><td>3.56</td><td>3.46</td><td>3.37</td><td>3.23</td><td>3.09</td><td>3.00</td><td>2.94</td><td>2.86</td><td>2.78</td><td>2.69</td><td>2.61</td><td>2.52</td></tr><tr><td>21</td><td>8.02</td><td>5.78</td><td>4.87</td><td>4.37</td><td>4.04</td><td>3.81</td><td>3.64</td><td>3.51</td><td>3.40</td><td>3.31</td><td>3.17</td><td>3.03</td><td>2.88</td><td>2.80</td><td>2.72</td><td>2.64</td><td>2.55</td><td>2.46</td><td>2.36</td></tr><tr><td>22</td><td>7.95</td><td>5.72</td><td>4.82</td><td>4.31</td><td>3.99</td><td>3.76</td><td>3.59</td><td>3.45</td><td>3.35</td><td>3.26</td><td>3.12</td><td>2.98</td><td>2.83</td><td>2.75</td><td>2.67</td><td>2.58</td><td>2.50</td><td>2.49</td><td>2.31</td></tr><tr><td>23</td><td>7.88</td><td>5.66</td><td>4.76</td><td>4.26</td><td>3.94</td><td>3.71</td><td>3.54</td><td>3.41</td><td>3.30</td><td>3.21</td><td>3.07</td><td>2.93</td><td>2.78</td><td>2.70</td><td>2.62</td><td>2.54</td><td>2.45</td><td>2.35</td><td>2.26</td></tr><tr><td>24</td><td>7.82</td><td>5.61</td><td>4.72</td><td>4.22</td><td>3.90</td><td>3.67</td><td>3.50</td><td>3.36</td><td>3.26</td><td>3.17</td><td>3.03</td><td>2.89</td><td>2.74</td><td>2.66</td><td>2.58</td><td>2.49</td><td>2.40</td><td>2.31</td><td>2.21</td></tr><tr><td>25</td><td>7.77</td><td>5.57</td><td>4.69</td><td>4.18</td><td>3.85</td><td>3.69</td><td>3.46</td><td>3.32</td><td>3.22</td><td>3.15</td><td>3.09</td><td>2.99</td><td>2.83</td><td>2.70</td><td>2.54</td><td>2.45</td><td>2.36</td><td>2.27</td><td>2.17</td></tr><tr><td>26</td><td>7.72</td><td>5.53</td><td>4.61</td><td>4.14</td><td>3.82</td><td>3.59</td><td>3.42</td><td>3.29</td><td>3.18</td><td>3.09</td><td>2.96</td><td>2.81</td><td>2.66</td><td>2.58</td><td>2.50</td><td>2.42</td><td>2.33</td><td>2.27</td><td>2.13</td></tr><tr><td>27</td><td>7.68</td><td>5.49</td><td>4.60</td><td>4.11</td><td>3.78</td><td>3.56</td><td>3.39</td><td>3.26</td><td>3.15</td><td>3.06</td><td>2.93</td><td>2.78</td><td>2.63</td><td>2.55</td><td>2.47</td><td>2.38</td><td>2.29</td><td>2.20</td><td>2.10</td></tr><tr><td>28</td><td>7.64</td><td>5.45</td><td>4.57</td><td>4.07</td><td>3.75</td><td>3.53</td><td>3.36</td><td>3.23</td><td>3.12</td><td>3.03</td><td>2.90</td><td>2.75</td><td>2.60</td><td>2.52</td><td>2.44</td><td>2.35</td><td>2.26</td><td>2.17</td><td>2.06</td></tr><tr><td>29</td><td>7.60</td><td>5.42</td><td>4.54</td><td>4.04</td><td>3.73</td><td>3.50</td><td>3.33</td><td>3.20</td><td>3.09</td><td>3.00</td><td>2.87</td><td>2.73</td><td>2.57</td><td>2.49</td><td>2.41</td><td>2.33</td><td>2.23</td><td>2.14</td><td>2.03</td></tr><tr><td>30</td><td>7.56</td><td>5.39</td><td>4.51</td><td>4.02</td><td>3.70</td><td>3.47</td><td>3.30</td><td>3.17</td><td>3.07</td><td>2.98</td><td>2.84</td><td>2.70</td><td>2.55</td><td>2.47</td><td>2.39</td><td>2.30</td><td>2.21</td><td>2.11</td><td>2.01</td></tr><tr><td>40</td><td>7.31</td><td>5.18</td><td>4.31</td><td>3.83</td><td>3.51</td><td>3.29</td><td>3.12</td><td>2.99</td><td>2.89</td><td>2.80</td><td>2.66</td><td>2.52</td><td>2.37</td><td>2.29</td><td>2.20</td><td>2.11</td><td>2.02</td><td>2.02</td><td>1.92</td></tr><tr><td>41</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12</td><td>2.03</td><td>1.94</td><td>1.84</td><td>1.73</td><td>1.60</td></tr><tr><td>42</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt;f</td><td>2.03</td><td>1.94</td><td>1.84</td><td>1.73</td><td>1.60</td></tr><tr><td>43</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt;fecel&gt;</td><td>1.94</td><td>1.84</td><td>1.73</td><td>1.60</td><td></td></tr><tr><td>44</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt;ffcel&gt;2.03</td><td rowspan="2">1.94</td><td rowspan="2">1.84</td><td rowspan="2">1.73</td><td rowspan="2">1.60</td><td></td></tr><tr><td>45</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt;fucel&gt;</td><td></td></tr><tr><td>46</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt;fj&gt;1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td>1.38</td></tr><tr><td>47</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt;f j&gt;1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td>1.38</td></tr><tr><td>48</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt;f fcel&gt;1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td></td></tr><tr><td>49</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt;f 1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td>1.38</td></tr><tr><td>50</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt;f i&gt;1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td>1.38</td></tr><tr><td>51</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt; 1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td>1.38</td></tr><tr><td>52</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt; i&gt;1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td>1.38</td></tr><tr><td>53</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt; fcel&gt;1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td></td></tr><tr><td>54</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt; j&gt;1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td>1.38</td></tr><tr><td>55</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt; h&gt;1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td>1.38</td></tr><tr><td>56</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt; l&gt;1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td>1.38</td></tr><tr><td>57</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt; g&gt;1.95</td><td>1.86</td><td>1.76</td><td>1.66</td><td>1.53</td><td>1.38</td></tr><tr><td>58</td><td>7.08</td><td>4.98</td><td>4.13</td><td>3.65</td><td>3.34</td><td>3.12</td><td>2.95</td><td>2.82</td><td>2.72</td><td>2.63</td><td>2.50</td><td>2.35</td><td>2.20</td><td>2.12&lt;</td><td></td><td></td><td></td><td></td><td></td></tr></table>

附表7 均值的检验的样本容量  

<table><tr><td rowspan="3">单边检验
双边检验
β</td><td colspan="68">显 著 性 水 平</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td colspan="34">α=0.005
α=0.01</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0,01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0,01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0,01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td colspan="66">0,01&lt;f cel&gt;</td></tr></table>

<table><tr><td rowspan="9">单边检验
双边检验
β</td><td colspan="35">显 著 性 水 平</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td colspan="34">α=0.005
α=0.01</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td colspan="34">0.01 0.05 0.1 0.2 0.5</td><td>1.4</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>1.4</td><td>16</td><td>13</td><td>12</td><td>10</td><td>7</td><td>14</td><td>11</td><td>10</td><td>9</td><td>6</td><td>12</td><td>9</td><td>8</td><td>7</td><td>10</td><td>8</td><td>7</td><td>5</td><td>1.5</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>1.5</td><td>15</td><td>12</td><td>11</td><td>9</td><td>7</td><td>13</td><td>10</td><td>9</td><td>8</td><td>6</td><td>11</td><td>8</td><td>7</td><td>6</td><td>9</td><td>7</td><td>6</td><td>1.5</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>1.6</td><td>13</td><td>11</td><td>10</td><td>8</td><td>6</td><td>12</td><td>10</td><td>9</td><td>7</td><td>5</td><td>10</td><td>8</td><td>7</td><td>6</td><td>8</td><td>6</td><td>6</td><td>1.6</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>1.7</td><td>12</td><td>10</td><td>9</td><td>8</td><td>6</td><td>11</td><td>9</td><td>8</td><td>7</td><td>9</td><td>7</td><td>6</td><td>5</td><td>8</td><td>6</td><td>5</td><td>1.7</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>1.8</td><td>12</td><td>10</td><td>9</td><td>8</td><td>6</td><td>10</td><td>8</td><td>7</td><td>7</td><td>8</td><td>7</td><td>6</td><td>7</td><td>6</td><td>7</td><td>6</td><td>1.8</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>1.9</td><td>11</td><td>9</td><td>8</td><td>7</td><td>6</td><td>10</td><td>8</td><td>7</td><td>6</td><td>8</td><td>6</td><td>6</td><td>7</td><td>5</td><td>1.9</td><td>1.9</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>δ=|μ1-μ0|
σ</td><td>2.0</td><td>10</td><td>8</td><td>8</td><td>7</td><td>5</td><td>9</td><td>7</td><td>7</td><td>6</td><td>7</td><td>6</td><td>5</td><td>6</td><td>6</td><td>2.0</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>2.1</td><td>10</td><td>8</td><td>7</td><td>7</td><td>8</td><td>7</td><td>6</td><td>6</td><td>7</td><td>6</td><td>6</td><td>6</td><td>6</td><td>6</td><td>2.1</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

附表8 均值差的t检验的样本容量  

<table><tr><td rowspan="3">单边检验
双边检验
β</td><td colspan="35">显 著 性 水 平</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td colspan="34">α=0.005
α=0.01</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>β</td><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>137</td><td>0.20</td><td>0.05</td><td>0.10</td><td>0.15</td><td>0.20</td><td>0.25</td><td>0.30</td><td>0.35</td><td>0.40</td><td>0.45</td><td>0.50</td><td>0.60</td><td>0.70</td><td>0.80</td><td>0.90</td><td>102</td><td>124</td><td>88</td><td>61</td><td>102</td><td>108</td><td>78</td><td>35</td><td>0.40</td><td>0.45</td><td>0.50</td><td>0.60</td><td>0.70</td><td>0.80</td><td>0.90</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>0.50</td><td>0.60</td><td>0.70</td><td>0.80</td><td>0.90</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>0.50</td><td>0.60</td><td>0.70</td><td>0.80&lt;ftd&gt;0.90</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>0.50</td><td>0.60</td><td>0.70</td><td>0.80</td><td>0.90</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>86</td><td>61</td><td>49</td><td>36</td><td>14</td><td>0.65</td><td>0.70</td><td>0.80</td><td>0.90</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>86</td><td>62</td><td>28&lt;ftd&gt;0.45</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>86</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>85</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>85</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>85</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>85</td><td>62</td><td>28</td><td>0.55</td><td>0.60</td><td>0.65</td><td>0.70</td><td>0.80</td><td>0.90</td><td>108</td><td>85</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>85</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>85</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>85</td><td>61</td><td>49</td><td>36</td><td>14</td><td>0.65</td><td>0.70</td><td>0.80</td><td>0.90</td><td>108</td><td>85</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>85</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>85</td><td>61</td><td>49</td><td>36</td><td>14</td><td>0.65</td><td>0.80</td><td>0.90</td><td>108</td><td>85</td><td>62</td><td>28</td><td>0.45</td><td>108</td><td>85</td><td>61</td><td>49</td><td>36</td><td>14</td><td>0.65</td><td>0.80</td><td>0.90</td><td>108</td><td>85</td><td>62</td><td>108</td><td>85</td><td>61</td><td>49</td><td>36</td><td>14</td><td>0.65</td><td>0.80</td><td>0.90</td><td>108</td><td>85</td><td>62</td><td>108</td><td>85</td><td>61</td><td>49</td><td>36</td><td>14</td></tr></table>

续表

<table><tr><td rowspan="3">单边检验
双边检验
β</td><td colspan="35">显 著 性 水 平</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td colspan="34">α=0.005
α=0.01</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td>0.01</td><td>0.05</td><td>0.1</td><td>0.2</td><td>0.5</td><td colspan="34">0</td><td>1.4</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>1.4</td><td>27</td><td>20</td><td>17</td><td>14</td><td>9</td><td>24</td><td>18</td><td>15</td><td>12</td><td>8</td><td>20</td><td>15</td><td>12</td><td>10</td><td>6</td><td>17</td><td>12</td><td>10</td><td>8</td><td>4</td><td>1.5</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>1.5</td><td>24</td><td>18</td><td>15</td><td>13</td><td>8</td><td>21</td><td>16</td><td>14</td><td>11</td><td>7</td><td>18</td><td>13</td><td>11</td><td>9</td><td>5</td><td>15</td><td>11</td><td>9</td><td>7</td><td>4</td><td>1.6</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>1.6</td><td>21</td><td>16</td><td>14</td><td>11</td><td>7</td><td>19</td><td>14</td><td>12</td><td>10</td><td>6</td><td>16</td><td>12</td><td>10</td><td>8</td><td>5</td><td>14</td><td>10</td><td>8</td><td>6</td><td>4</td><td>1.8</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>1.7</td><td>19</td><td>15</td><td>13</td><td>10</td><td>7</td><td>17</td><td>13</td><td>11</td><td>9</td><td>6</td><td>14</td><td>11</td><td>9</td><td>7</td><td>4</td><td>12</td><td>9</td><td>7</td><td>6</td><td>3</td><td>1.9</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>1.8</td><td>17</td><td>13</td><td>11</td><td>10</td><td>6</td><td>15</td><td>12</td><td>10</td><td>8</td><td>5</td><td>13</td><td>10</td><td>8</td><td>6</td><td>4</td><td>11</td><td>8</td><td>7</td><td>5</td><td>1.8</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>1.9</td><td>16</td><td>12</td><td>11</td><td>9</td><td>6</td><td>14</td><td>11</td><td>9</td><td>8</td><td>5</td><td>12</td><td>9</td><td>7</td><td>6</td><td>4</td><td>10</td><td>7</td><td>6</td><td>5</td><td>1.9</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>2.0</td><td>14</td><td>11</td><td>10</td><td>8</td><td>6</td><td>13</td><td>10</td><td>9</td><td>7</td><td>5</td><td>11</td><td>8</td><td>7</td><td>6</td><td>4</td><td>9</td><td>7</td><td>6</td><td>4</td><td>2.0</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>δ=μ1-μ2
σ</td><td>2.1</td><td>13</td><td>10</td><td>9</td><td>8</td><td>5</td><td>12</td><td>9</td><td>8</td><td>7</td><td>5</td><td>10</td><td>8</td><td>6</td><td>5</td><td>3</td><td>8</td><td>6</td><td>5</td><td>4</td><td>2.1</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>2.2</td><td>12</td><td>10</td><td>8</td><td>7</td><td>5</td><td>11</td><td>9</td><td>7</td><td>6</td><td>4</td><td>9</td><td>7</td><td>6</td><td>5</td><td>8</td><td>6</td><td>5</td><td>4</td><td>2.2</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>2.3</td><td>11</td><td>9</td><td>8</td><td>7</td><td>5</td><td>10</td><td>8</td><td>7</td><td>6</td><td>4</td><td>9</td><td>7</td><td>6</td><td>5</td><td>7</td><td>5</td><td>5</td><td>4</td><td>2.3</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>2.4</td><td>11</td><td>9</td><td>8</td><td>6</td><td>5</td><td>10</td><td>8</td><td>7</td><td>6</td><td>4</td><td>8</td><td>6</td><td>5</td><td>4</td><td>7</td><td>5</td><td>4</td><td>4</td><td>2.4</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>2.5</td><td>10</td><td>8</td><td>7</td><td>6</td><td>4</td><td>9</td><td>7</td><td>6</td><td>5</td><td>4</td><td>8</td><td>6</td><td>5</td><td>4</td><td>6</td><td>5</td><td>4</td><td>3</td><td>2.5</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;ecel&gt;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;ecel&gt;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>&lt;ecel&gt;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;fcel&gt;</td><td>&lt;ecel&gt;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>&lt;ecel&gt;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

# 习题答案

# 第一章

1. (1)  $S = \left\{\frac{i}{n} \mid i = 0,1,\dots ,100n\right\}$ , 其中  $n$  为该班的学生数. (2)  $S = \{10,11,\dots \}$ .

(3)  $S = \{00,100,0100,0101,0110,1100,1010,1011,0111,1101,1110,1111\}$ , 其中 0 表示

次品, 1 表示正品. (4)  $S = \{(x,y) \mid x^{2} + y^{2}< 1\}$ .

2. (1)  $A\overline{{B}}\overline{{C}}.$  (2)ABC. (3)AUBUC. (4)ABC. (5)  $\overline{{A}}\overline{{B}}\overline{{C}}$

(6)  $\overline{{A}}\overline{{B}}\cup \overline{{A}}\overline{{C}}\cup \overline{{B}}\overline{{C}}.$  
(7)  $\overline{{A}}\cup \overline{{B}}\cup \overline{{C}}.$  
(8)ABUACUBC.

3. (1)  $P(A\cup B\cup C) = 5 / 8$

(2)  $P(A\cup B) = 11 / 15$ $P(\overline{{A}}\overline{{B}}) = 4 / 15,P(A\cup B\cup C) = 17 / 20,P(\overline{{A}}\overline{{B}}\overline{{C}}) = 3 / 20,$

$$
P(\overline{{A}}\overline{{B}} C) = 7 / 60,P(\overline{{A}}\overline{{B}}\cup C) = 7 / 20.
$$

(3) (i)  $P(A\overline{{B}}) = 1 / 2$  ,(ii)  $P(A\overline{{B}}) = 3 / 8$

4. 略.5. (1)  $\frac{113}{126}$  (2)  $\frac{1}{12}$  6. (1)  $\frac{1}{12}$  (2)  $\frac{1}{20}$  7.  $\frac{252}{2431}$

8. (1)  $\frac{\binom{400}{90}\binom{1100}{110}}{\binom{1500}{200}}.$  (2)  $\frac{\binom{1100}{200}+\binom{400}{1}\binom{1100}{199}}{\binom{1500}{200}}.$  9.  $\frac{13}{21}$  10.0000024.

11. 记  $X$  为最大个数,  $P\{X = 1\} = \frac{6}{16}, P\{X = 2\} = \frac{9}{16}, P\{X = 3\} = \frac{1}{16}$ .

12.  $\frac{1}{1960}$  13. (1)  $\frac{4}{33}$  (2)  $\frac{10}{33}$  14. (1) 0.25. (2)  $\frac{1}{3}$  15.  $\frac{1}{3}$  16. 0.18.

17. (1)  $\frac{28}{45}$  (2)  $\frac{1}{45}$  (3)  $\frac{16}{45}$  (4)  $\frac{1}{5}$  18. 0.3,0.6.

19. (1)  $\frac{n + N(n + m)}{(n + m)(N + M + 1)}$ . (2)  $\frac{53}{99}$ .

20.  $\frac{3}{5}$  21.  $\frac{20}{21}$  22. (1)  $\frac{3}{2} p - \frac{1}{2} p^{2}$ . (2)  $\frac{2p}{p + 1}$ . 23.  $\frac{196}{197}$ . 24. (1) 0.4. (2) 0.4856.

25.  $\frac{9}{13}$  26. (1) 0.785. (2) 0.372. 27. 略.

28. (1) 0.72. (2) 0.98. (3) 0.26.

29. (1) 0.57. (2) 0.0481. (3) 0.0962. (4) 0.6864. 30. 略.

31. (1) 必然错. (2) 必然错. (3) 必然错. (4) 可能对. 32. 0.5043. 33. 略.

34. (1)  $p_{1}p_{2}p_{3} + p_{1}p_{4} - p_{1}p_{2}p_{3}p_{4}$ . (2)  $2p^{2} + 2p^{3} - 5p^{4} + 2p^{5}$ .

35. 0.9984, 3 只开关. 36. 0.6. 37. (1)  $\frac{5}{9}$ . (2)  $\frac{16}{63}$ . (3)  $\frac{16}{35}$ . 38.  $\frac{m}{m + n2^{r}}$ .

39. 0.8731, 0.1268, 0.0001. 40.  $\frac{2\alpha p_{1}}{(3\alpha - 1)p_{1} + 1 - \alpha}$ .

# 第二章

1. 设赔付金额为  $X$  (以万元计), 得

<table><tr><td>X</td><td>20</td><td>5</td><td>0</td></tr><tr><td>p k</td><td>0.000 2</td><td>0.001 0</td><td>0.998 8</td></tr></table>

2. (1) X 3 4 5 Pk 1 3 6 10 10 10

<table><tr><td>X</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td></tr><tr><td>p k</td><td>11 36</td><td>9 36</td><td>7 36</td><td>5 36</td><td>3 36</td><td>1 36</td></tr></table>

3. (1) X 0 1 2 (2)略. Pk 22 12 1 35 35 35

4. (1)  $P\{X = k\} = p q^{k - 1}, k = 1,2,\dots .$

$$
P\{Y = k\} = \binom{k - 1}{r - 1} p^{r}q^{k - r}, k = r,r + 1,\dots .
$$

$$
P\{X = k\} = 0.45\times 0.55^{k - 1}, k = 1,2,\dots ;\sum_{k = 1}^{\infty}P\{X = 2k\} = \frac{11}{31}.
$$

5. (1) X 1 2 3 ... Pk 1 1 2 1 2 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 2 3 (2) Y 1 2 3 (3)  $\frac{8}{27}, \frac{38}{81}$ . Pk 1 1 1 3 3 3

(2) Y 1 2 3 (3)  $\frac{8}{27}, \frac{38}{81}$ . Pk 1 1 1 3 3 3

6. (1) 0.0729. (2) 0.00856. (3) 0.99954. (4) 0.40951.

7. (1) 0.163. (2) 0.355. 8. (1) 0.321. (2) 0.243.

9. (1)  $0.9^{10} = 0.349$ . (2) 0.581. (3) 0.590. (4) 0.343. (5) 0.692.

10. (1)  $\frac{1}{70}$ . (2) 试验 10 次, 他猜对次数  $\geq 3$  的概率仅为万分之三, 此概率太小, 按实际推断原理, 认为他确有区分能力.

11. 0.0025. 12. (1) 0.0298. (2) 0.5665. 13. (1) 0.2231. (2) 0.9179.

14. (1) 0.2388. (2) 20.79 min.

15. 设这批投保人在一年内死亡的人数为  $X$  ,则所求概率为

$$
P\{X\leqslant 10\} = \sum_{k = 0}^{10}{\binom{5000}{k}}0.0015^{k}(1 - 0.0015)^{5000 - k},P\{X\leqslant 10\} \approx 0.8622.
$$

16. 以  $X$  表示汽车站某天该时间段内汽车出事故的辆数,则  $P\{X\geqslant 2\} \approx 0.0047$

17. (1)  $F(x) = \left\{ \begin{array}{l l}{0,} & {x< 0,}\\ {1 - p,} & {0\leqslant x< 1,}\\ {1,} & {x\geqslant 1.} \end{array} \right.\quad (2) F(x) = \left\{ \begin{array}{l l}{0,} & {x< 3,}\\ {\frac{1}{10},} & {3\leqslant x< 4,}\\ {\frac{4}{10},} & {4\leqslant x< 5,}\\ {1,} & {x\geqslant 5.} \end{array} \right.$

18.  $F(x) = \left\{ \begin{array}{ll}0, & x< 0,\\ \frac{x}{a}, & 0\leqslant x< a,\\ 1, & x\geqslant a. \end{array} \right.$

19. (1)  $1 - \mathrm{e}^{-1.2}$  . (2)  $\mathrm{e}^{-1.6}$  . (3)  $\mathrm{e}^{-1.2} - \mathrm{e}^{-1.6}$  . (4)  $1 - \mathrm{e}^{-1.2} + \mathrm{e}^{-1.6}$  . (5) 0.

20. (1)  $\ln 2$  ,1,  $\ln {\frac{5}{4}}$  (2)  $f_{X}(x) = \left\{{\frac{1}{x}},\right.$ $1{<}x{<}\mathsf{e},$  0, 其他.

21. (1)  $F(x) = \left\{ \begin{array}{l l}{0,} & {x< 1,}\\ {2\left(x + \frac{1}{x} -2\right),} & {1\leqslant x< 2,}\\ {1,} & {x\geqslant 2.} \end{array} \right.$

(2)  $F(x) = \left\{ \begin{array}{l l}{0,} & {x< 0,}\\ {\frac{x^{2}}{2},} & {0\leqslant x< 1,}\\ {-1 + 2x - \frac{x^{2}}{2},} & {1\leqslant x< 2,}\\ {1,} & {x\geqslant 2.} \end{array} \right.$

22. (1)  $A = \frac{4}{b\sqrt{\pi b}}$  (2)  $F_{X}(t) = \left\{ \begin{array}{l l}{0,} & {t< 0,}\\ {1 - \mathrm{e}^{-\frac{t}{241}},} & {t\geqslant 0,} \end{array} \right.$ $P\{50< T< 100\} = \mathrm{e}^{-\frac{50}{241}} - \mathrm{e}^{-\frac{100}{241}}.$

23.  $\frac{232}{243}$  24.  $P\{Y = k\} = \binom{5}{k}\mathrm{e}^{-2k}(1 - \mathrm{e}^{-2})^{5 - k},k = 0,1,\dots ,5;$  0.5167. 25.  $\frac{3}{5}$

26. (1)  $P\{2< X\leqslant 5\} = 0.5328,P\{-4< X\leqslant 10\} = 0.9996,P\{|X| > 2\} = 0.6977,P\{X > 3\} = 0.5977,P\{X > 3\} = 0.5977,P\{X > 3\} = 0.5977,P\{X > 3\} = 0.5977,P\{X > 3\} = 0.5977,P\{X > 3\} = 0.5977,P\{X > 3\} = 1.5977,P\{X > 3\} = 1.5977,P\{X > 3\} = 1.5977,P\{X > 3\} = 1.5977,P\{X > 3\} = 1.5977,P\{X > 3\} = 1.5977,P\{X > 3\}$  0.5. (2)  $c = 3$  (3)  $d\leqslant 0.436$

27. (1)  $P\{X\leqslant 105\} = 0.3383,P\{100< X\leqslant 120\} = 0.5952.$  (2) 129.74.

28. 0.0456. 29. 31.20. 30. 0.3204.

31.  $F(x) = \left\{ \begin{array}{l l}{0,}\\ {0.2 + 0.8x / 30,}\\ {1,} \end{array} \right.$ $x< 0$  32.略.

33. Y 0 1 4 9 Pk 1 7 1 11 5 30 5 30

34. (1)  $f_{Y}(y) = \left\{ \begin{array}{l l}{\frac{1}{y}, 1< y< \mathrm{e},}\\ {0, \text{其他}.} \end{array} \right.$  (2)  $f_{Y}(y) = \left\{ \begin{array}{l l}{\frac{1}{2}\mathrm{e}^{-y / 2},} & {y > 0,}\\ {0,} & {y\leqslant 0.} \end{array} \right.$

35. (1)  $f_{Y}(y) = \left\{ \begin{array}{l l}{\frac{1}{y\sqrt{2\pi}}\mathrm{e}^{-(\ln y)^{2} / 2},} & {y > 0,}\\ {0,} & {y\leqslant 0.} \end{array} \right.$

(2)  $f_{Y}(y) = \left\{ \begin{array}{l l}{\frac{1}{2\sqrt{\pi(3 - 1)}}\mathrm{e}^{-(y - 1) / 4},} & {y > 1,}\\ {0,} & {y\leqslant 1.} \end{array} \right.$

(3)  $f_{Y}(y) = \left\{ \begin{array}{l l}{\sqrt{\frac{2}{\pi}}\mathrm{e}^{-y^{2}}}, & {y > 0,}\\ {0,} & {y\leqslant 0.} \end{array} \right.$

36. (1)  $f_{Y}(y) = \frac{1}{3}\frac{1}{\sqrt[3]{y^{2}}} f(\sqrt[3]{y}), \quad y\neq 0.$

(2)  $f_{Y}(y) = \left\{ \begin{array}{l l}{\frac{1}{2\sqrt{y}}\mathrm{e}^{-\sqrt{y}},} & {y > 0,}\\ {0,} & {y\leqslant 0.} \end{array} \right.$

37.  $f_{Y}(y) = \left\{ \begin{array}{l l}{\frac{2}{\pi\sqrt{1 - y^{2}}},} & {0< y< 1,}\\ {0,} & {\text{其他}.} \end{array} \right.$  38.  $f_{W}(w) = \left\{ \begin{array}{l l}{\frac{1}{8}\left(\frac{2}{w}\right)^{1 / 2},} & {162< w< 242,}\\ {0,} & {\text{其他}.} \end{array} \right.$

39.  $f_{\theta}(y) = \frac{9}{10\sqrt{\pi}}\mathrm{e}^{-\frac{81}{100} (y - 37)^{2}}.$

# 第三章

1. (1) 放回抽样的情况:

<table><tr><td>X
Y</td><td>0</td><td>1</td></tr><tr><td rowspan="2">0</td><td>25</td><td>5</td></tr><tr><td>36</td><td>36</td></tr><tr><td rowspan="2">1</td><td>5</td><td>1</td></tr><tr><td>36</td><td>36</td></tr></table>

(2) 不放回抽样的情况:

<table><tr><td>X
Y</td><td>0</td><td>1</td></tr><tr><td rowspan="2">0</td><td>45</td><td>10</td></tr><tr><td>66</td><td>66</td></tr><tr><td rowspan="2">1</td><td>10</td><td>1</td></tr><tr><td>66</td><td>66</td></tr></table>

2. (1)

<table><tr><td>X
Y</td><td>0</td><td>1</td><td>2</td><td>3</td></tr><tr><td>0</td><td>0</td><td>0</td><td>3/35</td><td>2/35</td></tr><tr><td>1</td><td>0</td><td>6/35</td><td>12/35</td><td>2/35</td></tr><tr><td>2</td><td>1/35</td><td>6/35</td><td>3/35</td><td>0</td></tr></table>

$$
P\{X > Y\} = \frac{19}{35},\quad P\{Y = 2X\} = \frac{6}{35},\quad P\{X + Y = 3\} = \frac{4}{7},\quad P\{X< 3 - Y\} = \frac{2}{7}.
$$

3. (1)  $\frac{1}{8}$ . (2)  $\frac{3}{8}$ . (3)  $\frac{27}{32}$ . (4)  $\frac{2}{3}$ .

4. (1)略. (2)  $\frac{\lambda_{1}}{\lambda_{1} + \lambda_{2}}$ . 5.  $F_{X}(x) = \left\{ \begin{array}{ll}1 - \mathrm{e}^{-x}, & x > 0, \\ 0, & \text{其他.} \end{array} \right.$ $F_{Y}(y) = \left\{ \begin{array}{ll}1 - \mathrm{e}^{-y}, & y > 0, \\ 0, & \text{其他.} \end{array} \right.$

6.

<table><tr><td>X
Y</td><td>0</td><td>1</td><td>2</td><td>P{Y=j}</td></tr><tr><td>0</td><td>1/8</td><td>0</td><td>0</td><td>1/8</td></tr><tr><td>1</td><td>1/8</td><td>2/8</td><td>0</td><td>3/8</td></tr><tr><td>2</td><td>0</td><td>2/8</td><td>1/8</td><td>3/8</td></tr><tr><td>3</td><td>0</td><td>0</td><td>1/8</td><td>1/8</td></tr><tr><td>P{X=i}</td><td>1/4</td><td>2/4</td><td>1/4</td><td>1</td></tr></table>

7.  $f_{X}(x) = \left\{ \begin{array}{ll}2.4(2 - x)x^{2}, & 0 \leqslant x \leqslant 1, \\ 0, & \text{其他,} \end{array} \right.$

$f_{Y}(y) = \left\{ \begin{array}{ll}2.4y(3 - 4y + y^{2}), & 0 \leqslant y \leqslant 1, \\ 0, & \text{其他.} \end{array} \right.$

8.  $f_{X}(x) = \left\{ \begin{array}{ll} \mathrm{e}^{-x}, & x > 0, \\ 0, & \text{其他,} \end{array} \right.$ $f_{Y}(y) = \left\{ \begin{array}{ll}y\mathrm{e}^{-y}, & y > 0, \\ 0, & \text{其他.} \end{array} \right.$

9. (1)  $c = \frac{21}{4}$ .

$$
f_{X}(x) = \left\{ \begin{array}{ll} \frac{21}{8} x^{2}(1 - x^{4}), & -1 \leqslant x \leqslant 1, \\ 0, & \text{其他.} \end{array} \right.\) \(f_{Y}(y) = \left\{ \begin{array}{ll} \frac{7}{2} y^{5 / 2}, & 0 \leqslant y \leqslant 1, \\ 0, & \text{其他.} \end{array} \right.\)
$$

10. (1)

<table><tr><td>X</td><td>51</td><td>52</td><td>53</td><td>54</td><td>55</td></tr><tr><td>p k</td><td>0.28</td><td>0.28</td><td>0.22</td><td>0.09</td><td>0.13</td></tr></table>

<table><tr><td>Y</td><td>51</td><td>52</td><td>53</td><td>54</td><td>55</td></tr><tr><td>p k</td><td>0.18</td><td>0.15</td><td>0.35</td><td>0.12</td><td>0.20</td></tr></table>

(2)

<table><tr><td>k</td><td>51</td><td>52</td><td>53</td><td>54</td><td>55</td></tr><tr><td rowspan="2">P{Y=k|X=51}</td><td>6</td><td>7</td><td>5</td><td>5</td><td>5</td></tr><tr><td>28</td><td>28</td><td>28</td><td>28</td><td>28</td></tr></table>

11. (1)  $P\{X = n\} = \frac{14^{n}\mathrm{e}^{-14}}{n!},\quad n = 0,1,2,\dots ,$

$$
P\{Y = m\} = \frac{7.14^{m}\mathrm{e}^{-7.14}}{n!},\quad m = 0,1,2,\dots .
$$

(2)当  $m = 0,1,2,\dots$  时,  $P\{X = n|Y = m\} = \frac{6.86^{n - m}\mathrm{e}^{-6.86}}{(n - m)!},\quad n = m,m + 1,\dots ;$

当  $n = 0,1,2,\dots$  时,  $P\{Y = m|X = n\} = \binom{n}{m}\times 0.51^{m}\times 0.49^{2 - m},\quad m = 0,1,2,\dots ,n.$

$$
P\{Y = m|X = 20\} = \binom{20}{m}\times 0.51^{m}\times 0.49^{20 - m},\quad m = 0,1,2,\dots ,20.
$$

12.

$$
\begin{array}{r l}{\frac{Y=k}{P\{Y=k|X=1\}\left|\begin{array}{l}{1}\\ {1}\end{array}\right.}}&{{}\frac{Y=k}{P\{Y=k|X=2\}\left|\begin{array}{l l l}{1}&{2}\\ {1}&{\frac{1}{2}}\end{array}\right.}}\\ {\frac{Y=k}{P\{Y=k|X=3\}\left|\begin{array}{l l l}{1}&{2}&{3}\\ {3}&{\frac{1}{3}}&{\frac{1}{3}}\end{array}\right.}}&{{}\frac{Y=k}{P\{Y=k|X=4\}\left|\begin{array}{l l l l}{1}&{2}&{3}&{4}\\ {1}&{\frac{1}{4}}&{\frac{1}{4}}&{\frac{1}{4}}\end{array}\right.}}\end{array}
$$

13. (1)当  $0< y\leqslant 1$  时,

$$
f_{X|Y}(x|y) = \left\{ \begin{array}{l l}{\frac{3}{2} x^{2}y^{-3 / 2},} & {-\sqrt{y} < x< \sqrt{y},}\\ {0,} & {x\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}.} \end{array} \right.
$$

$$
f_{X|Y}\left(x\mid y = \frac{1}{2}\right) = \left\{ \begin{array}{l l}{3\sqrt{2} x^{2},} & {-\frac{1}{\sqrt{2}} < x< \frac{1}{\sqrt{2}},}\\ {0,} & {\mathbb{H}\mathbb{H}\mathbb{H}.} \end{array} \right.
$$

(2)当  $-1< x< 1$  时,  $f_{Y|X}(y|x) = \left\{ \begin{array}{l l}{\frac{2y}{1 - x^{4}},} & {x^{2}< y< 1,}\\ {0,} & {y\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}.} \end{array} \right.$

$$
f_{Y|X}\left(y\mid x = \frac{1}{3}\right) = \left\{ \begin{array}{l l}{\frac{81}{40} y,} & {\frac{1}{9} < y< 1,}\\ {0,} & {\mathbb{H}\mathbb{H},} \end{array} \right.\quad f_{Y|X}\left(y\mid x = \frac{1}{2}\right) = \left\{ \begin{array}{l l}{\frac{32}{15} y,} & {\frac{1}{4} < y< 1,}\\ {0,} & {\mathbb{H}\mathbb{H}.} \end{array} \right.
$$

$$
P\left\{Y \geqslant \frac{1}{4} \mid X = \frac{1}{2}\right\} = 1, P\left\{Y \geqslant \frac{3}{4} \mid X = \frac{1}{2}\right\} = \frac{7}{15}.
$$

14. 当  $|y|< 1$  时,  $f_{X|Y}(x|y) = \left\{ \begin{array}{ll} \frac{1}{1 - |y|}, & |y|< x< 1, \\ 0, & x \text{取其他值,} \end{array} \right.$

当  $0< x< 1$  时,  $f_{Y|X}(y|x) = \left\{ \begin{array}{ll} \frac{1}{2x}, & |y|< x, \\ 0, & y \text{取其他值.} \end{array} \right.$

15. (1)  $f(x,y) = \left\{ \begin{array}{ll} x, & 0< y< 1 / x, 0< x< 1, \\ 0, & \text{其他.} \end{array} \right.$

$$
f_{Y}(y) = \left\{ \begin{array}{ll} 1 / 2, & 0< y< 1, \\ 1 / (2y^{2}), & 1 \leqslant y< \infty , \\ 0, & \text{其他.} \end{array} \right. \quad (3) P\{X > Y\} = 1 / 3.
$$

16. (1) 放回抽样时相互独立; 不放回抽样时, 不相互独立. (2) 不相互独立.

17. (1) 略. (2)  $X, Y$  相互独立.

18. (1)  $f(x,y) = \left\{ \begin{array}{ll} \frac{1}{2} \mathrm{e}^{-y / 2}, & 0< x< 1, y > 0, \\ 0, & \text{其他.} \end{array} \right.$

(2)  $1 - \sqrt{2\pi} [\Phi (1) - \Phi (0)] = 0.1445.$

19.  $f(x,y) = \frac{1}{2\pi} \mathrm{e}^{-x^{2} + y^{2} / 2}$ .

$$
\frac{Z \mid 0 \quad 1 \quad 2}{p_{k} \mid \mathrm{e}^{-2} \mathrm{e}^{-1 / 2} - \mathrm{e}^{-2} \quad 1 - \mathrm{e}^{-1 / 2}}
$$

20. (1)  $y > 0$  时,  $f_{X|Y}(x|y) = \left\{ \begin{array}{ll} \lambda \mathrm{e}^{-\lambda x}, & x > 0, \\ 0, & x \leqslant 0. \end{array} \right.$

(2)

$$
\frac{Z \mid 0 \quad 1}{p_{k} \mid \frac{\mu}{\lambda + \mu} \quad \frac{\lambda}{\lambda + \mu}} \qquad F_{Z}(z) = \left\{ \begin{array}{ll} 0, & z< 0, \\ \frac{\mu}{\lambda + \mu}, & 0 \leqslant z< 1, \\ 1, & z \geqslant 1. \end{array} \right.
$$

21. (1)  $Z = X + Y$  的概率密度为

$$
f_{Z}(z) = \left\{ \begin{array}{ll} z^{2}, & 0< z< 1, \\ 2z - z^{2}, & 1 \leqslant z< 2, \\ 0, & \text{其他.} \end{array} \right.
$$

(2)  $Z = X Y$  的概率密度为

$$
f_{Z}(z) = \left\{ \begin{array}{ll} 2(1 - z), & 0< z< 1, \\ 0, & \text{其他.} \end{array} \right.
$$

22.  $f_{Z}(z) = \left\{ \begin{array}{ll}1 - \mathrm{e}^{-z}, & 0< z< 1, \\ (\mathrm{e} - 1)\mathrm{e}^{-z}, & z\geqslant 1, \\ 0, & \text{其他}. \end{array} \right.$

23. (1)  $f_{1}(x) = \left\{ \begin{array}{ll}\frac{x^{3}\mathrm{e}^{-x}}{3!}, & x > 0, \\ 0, & x\leqslant 0. \end{array} \right.$  (2)  $f_{2}(x) = \left\{ \begin{array}{ll}\frac{x^{5}\mathrm{e}^{-x}}{5!}, & x > 0, \\ 0, & x\leqslant 0. \end{array} \right.$

24. (1) 不相互独立. (2)  $f_{Z}(z) = \left\{ \begin{array}{ll}\frac{1}{2} z^{2}\mathrm{e}^{-z}, & z > 0, \\ 0, & \text{其他}. \end{array} \right.$

25.  $Z = X + Y$  的概率密度为

$$
f_{Z}(z) = \left\{ \begin{array}{ll}(z - 2)\mathrm{e}^{2 - z}, & z > 2, \\ 0, & \text{其他}. \end{array} \right.
$$

26.  $Z = Y / X$  的概率密度为

$$
f_{Z}(z) = \left\{ \begin{array}{ll}\frac{1}{(z + 1)^{2}}, & z > 0, \\ 0, & z\leqslant 0. \end{array} \right.
$$

27.  $f_{Z}(z) = \left\{ \begin{array}{ll} - \ln z, & 0< z< 1, \\ 0, & \text{其他}. \end{array} \right.$

29. (1)  $b = \frac{1}{1 - \mathrm{e}^{-1}}.$  (2)  $f_{X}(x) = \left\{ \begin{array}{ll}\frac{\mathrm{e}^{-x}}{1 - \mathrm{e}^{-1}}, & 0< x< 1, \\ 0, & \text{其他}. \end{array} \right.$ $f_{Y}(y) = \left\{ \begin{array}{ll}\mathrm{e}^{-y}, & y > 0, \\ 0, & \text{其他}. \end{array} \right.$

$$
F_{U}(u) = \left\{ \begin{array}{ll}0, & u< 0, \\ \frac{(1 - \mathrm{e}^{-u})^{2}}{1 - \mathrm{e}^{-1}}, & 0\leqslant u< 1, \\ 1 - \mathrm{e}^{-u}, & u\geqslant 1. \end{array} \right.
$$

30.  $0.1587^{4} = 0.00063$

31. (1)  $F_{Z}(z) = \left\{ \begin{array}{ll}(1 - \mathrm{e}^{-2 / 8})^{5}, & z\geqslant 0, \\ 0, & z< 0. \end{array} \right.$  32—35. 略.

(2)  $1 - (1 - \mathrm{e}^{-2})^{5} = 0.5187$

36. (1)  $P\{X = 2|Y = 2\} = 0.2, \quad P\{Y = 3|X = 0\} = \frac{1}{3}$ .

(2)  $\frac{V}{p_{k}}\left| \begin{array}{cccccc}0 & 1 & 2 & 3 & 4 & 5 \\ 0 & 0.04 & 0.16 & 0.28 & 0.24 & 0.28 \end{array} \right.$

(3)  $\frac{U}{p_{k}}\left| \begin{array}{cccccc}0 & 1 & 2 & 3 \\ 0.28 & 0.30 & 0.25 & 0.17 \end{array} \right.$

(4)  $\frac{W}{p_{k}}\left| \begin{array}{cccccc}0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ 0 & 0.02 & 0.06 & 0.13 & 0.19 & 0.24 & 0.19 & 0.12 & 0.05 \end{array} \right.$

# 第四章

1. (1)  $\frac{X}{p_{k}}\left| \begin{array}{cccc}2 & 3 & 4 & 9\\ \frac{1}{8} & \frac{5}{8} & \frac{1}{8} & \frac{1}{8} \end{array} \right.,E(X) = \frac{15}{4}.$

(2)  $\frac{Y}{p_{k}}\left| \begin{array}{cccc}2 & 3 & 4 & 9\\ \frac{2}{30} & \frac{15}{30} & \frac{4}{30} & \frac{9}{30} \end{array} \right.,E(Y) = \frac{73}{15}.$

(3)  $\frac{X}{p_{k}}\left| \begin{array}{ccccccccccccc}1 & 2 & 3 & 4 & 5 & 7 & 8 & 9 & 10 & 11 & 12\\ \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} \end{array} \right.,E(X) = \frac{49}{12}.$

2.1.0556.3.  $\frac{25}{16}$ . 4. 略. 5.  $1500 \mathrm{min}$

6. (1)  $E(X) = -0.2, E(X^{2}) = 2.8, E(3X^{2} + 5) = 13.4$ . (2)  $E[1 / (X + 1)] = \frac{1}{\lambda} (1 - \mathrm{e}^{-\lambda})$ .

7. (1) (i)  $E(Y) = 2$ , (ii)  $E(Y) = 1 / 3$

$$
E(\max \{X_{1}, X_{2}, \dots , X_{n}\}) = \frac{n}{n + 1}, \quad (\text{ii}) E(\min \{X_{1}, X_{2}, \dots , X_{n}\}) = \frac{1}{n + 1}.
$$

8. (1)  $E(X) = 2, E(Y) = 0$ . (2)  $-\frac{1}{15}$ . (3) 5.

9. (1)  $E(X) = \frac{4}{5}, E(Y) = \frac{3}{5}, E(XY) = \frac{1}{2}, E(X^{2} + Y^{2}) = \frac{16}{15}$ .

(2)  $E(X) = 1, E(Y) = 1, E(XY) = 2$ .

10. (1)  $E[X^{2} / (X^{2} + Y^{2})] = \frac{1}{2}$ . (2)  $\sqrt{\frac{\pi}{2}} \sigma$ .

11. 33.64元. 12.  $\frac{\pi}{12} (a^{2} + ab + b^{2})$ . 13. 45 V.

14. (1)  $E(X_{1} + X_{2}) = \frac{3}{4}, E(2X_{1} - 3X_{2}^{2}) = \frac{5}{8}$ . (2)  $E(X_{1}X_{2}) = \frac{1}{8}$ .

15. 1. 16.  $\frac{n + 1}{2}$ . 17. 略. 18.  $E(X) = \sqrt{\frac{\pi}{2}} \sigma , D(X) = \frac{4 - \pi}{2} \sigma^{2}$ .

19.  $E(X) = a\beta , D(X) = a\beta^{2}$ .

20.  $E(X) = \frac{1}{p}, D(X) = \frac{1 - p}{p^{2}}$ . 21.  $E(A) = 8.67, D(A) = 21.42$ .

22. (1)  $E(Y) = 7, D(Y) = 37.25$ .

(2)  $Z_{1} \sim N(2080, 65^{2}), Z_{2} \sim N(80, 1525), P\{X > Y\} = 0.9798, P\{X + Y > 1400\} = 0.1539$ .

23. (1) 1200, 1225. (2)  $1282 \mathrm{kg}$ . 24. 39袋.

25. (1)  $E(XY) = 1 / 4, E(X / Y)$  不存在,  $E[\ln (XY)] = -2, E(|Y - X|) = 1 / 3$ .

(2)  $\rho_{A C} = \sqrt{6 / 7}$ .

26. (1)  $P\{X_{1} = 2,X_{2} = 2,X_{3} = 5\} = 0.00203,E(X_{1}X_{2}X_{3}) = 8,E(X_{1} - X_{2}) = 0,$ $E(X_{1} - 2X_{2}) = -2.$

(2)对于  $E(Z)$  ,在3种情况下都有  $E(Z) = 29$

对于  $D(Z)$  :(i)  $X,Y$  相互独立,则  $D(Z) = 109$  ,(ii)  $X,Y$  不相关,则  $D(Z) = 109$

(iii)  $\rho_{X Y} = 0.25$  ,则  $\operatorname {Cov}(X,Y) = 1.5,D(Z) = 94.$

27. (1)  $X,Y$  不相互独立,也不是不相关的.(2)  $X,Y$  不相互独立,但不相关.

(3)  $X,Y$  不相互独立,但不相关.(4)  $X,Y$  不是不相关的,因而一定也是不相互独立的.

(5)  $X,Y$  相互独立,因此  $X,Y$  也是不相关的.28—30.略.

31.  $E(X) = \frac{2}{3},E(Y) = 0,\operatorname {Cov}(X,Y) = 0.$

32.  $E(X) = E(Y) = \frac{7}{6},\operatorname {Cov}(X,Y) = -\frac{1}{36},\rho_{X Y} = -\frac{1}{11},D(X + Y) = \frac{5}{9}.$  
33.  $\frac{\alpha^{2} - \beta^{2}}{\alpha^{2} + \beta^{2}}.$

34. (1)  $a = 3$  ,min  $\{E(W)\} = 108$  (2)略.35.  $f(x,y) = \frac{1}{3\sqrt{5}\pi}\mathrm{exp}\Big(\frac{-8}{15}\Big(\frac{x^{2}}{3} +\frac{x y}{4\sqrt{3}} +\frac{y^{2}}{4}\Big)\Big).$

36.  $p\geqslant \frac{8}{9}$  37.略.38.(1)  $\frac{1}{2}\ln 2$  (2)a.

# 第五章

1.0.2119.2. (1)0.8944.(2)0.0019.3.(1)0.1802.(2)最多只能有443个数.

4.0.0787.5.0.0062.6.0.1075.7.(1)0.0003.(2)0.5.8.0.9525.

9. (1)  $\overline{{X}}\sim N(2,2,1,4^{2} / 62)$  ,  $P\{\overline{{X}}{<} 2\} = 0.1515$  (2)0.0770.

10.  $1.3427\mathrm{g / km}$  .11.(1)0.8968.(2)0.7498.12.254.13.1537.

14. (1)0.8944.(2)0.1379.

# 第六章

1.0.8293.

2. (1)0.2628.(2)  $P\{\max \{X_{1},X_{2},X_{3},X_{4},X_{5}\} >15\} = 0.2923,P\{\min \{X_{1},X_{2},X_{3},X_{4},X_{5}\} >15\} = 0.2923,P\{\min \{X_{1},X_{2},X_{3},X_{4},X_{5}\} >15\} = 0.2923,P\{\min \{X_{1},X_{2},X_{3},X_{4},X\} >15\} = 0.2923,P\{\min \{X_{1},X_{2},X_{3},X_{4},X\} >15\} = 0.2923,P\{\min \{X_{1},X_{2},X_{3},X_{4},X\} >15\} = 0.2923,P\{\min \{X_{1}X_{2},X_{3},X_{4},X\} >15\} = 0.2923,P\{\min \{X_{1}X_{2},X_{3},X_{4},X\} >15\} = 0.2923,P\{\min \{X_{1}X_{2},X_{3},X_{4},X\} >15\} = 0.$ $X_{5}\} < 10\} = 0.5785.$

3.0.6744.4.(1)  $C = 1 / 3$  (2)  $C = \sqrt{3 / 2}$  .(3)略.

5. (1)  $f(x_{1},x_{2},\dots ,x_{10}) = \prod_{i = 1}^{10}{\frac{1}{\sqrt{2\pi}\sigma}}\mathrm{e}^{-\sigma (x_{i} - x_{i}^{2} / \epsilon_{i}^{2} / 2)},P\{\overline{{X}}{<}\mu_{i}\} = 1 / 2.$  (2)0.431.

6. (1)  $P\{X_{1} = x_{1},X_{2} = x_{2},\dots ,X_{n} = x_{n}\} = p\sum_{i = 1}^{n}x_{i}(1 - p)^{n - \sum_{i = 1}^{n}x_{i}}.$

(2)  $\binom{n}{k}p^{k}(1- p)^{n- k},k=0,1,2,\cdots,n.$

(3)  $E(\overline{{X}}) = p,D(\overline{{X}}) = \frac{1}{n} p(1 - p),E(S^{2}) = p(1 - p).$

7.  $E(\overline{{X}}) = n,D(\overline{{X}}) = n / 5,E(S^{2}) = 2n.$

8. (1)  $X_{1}, X_{2}, \dots , X_{10}$  的联合概率密度为  $\frac{1}{(2\pi\sigma^{2})^{5}}\mathrm{e}^{-\sum_{i = 1}^{10}(x_{i} - \mu)^{2} / (2\sigma^{2})}$ . (2)  $f_{\overline{X}}(x) = \frac{\sqrt{5}}{\sqrt{\pi}\sigma}\mathrm{e}^{-5(x - \mu)^{2} / \sigma^{2}}$ .

9. (1) 0.99. (2)  $D(S^{2}) = 2\sigma^{4} / 15$ . 10. 略. 11. 226.3333.

# 第七章

1.  $\hat{\mu} = 74.002, \hat{\sigma}^{2} = 6\times 10^{-6}, s^{2} = 6.86\times 10^{-6}$ .

2. 矩估计量为 (1)  $\hat{\theta} = \frac{\overline{X}}{\overline{X} - c}$ . (2)  $\hat{\theta} = \left(\frac{\overline{X}}{1 - \overline{X}}\right)^{2}$ . (3)  $\hat{p} = \frac{\overline{X}}{m}$ .

3. 最大似然估计量为 (1)  $\hat{\theta} = \frac{n}{\sum_{i = 1}^{n}\ln X_{i} - n\ln c}$ . (2)  $\hat{\theta} = \frac{n^{2}}{\left(\sum_{i = 1}^{n}\ln X_{i}\right)^{2}}$ . (3)  $\hat{p} = \frac{\overline{X}}{m}$ .

4. (1) 矩估计值和最大似然估计值均为  $\frac{5}{6}$ . (2) 最大似然估计量和矩估计量均为  $\hat{\lambda} = \overline{X}$ . (3)  $\hat{p} = \frac{r}{x}$ .

5. (1)  $c$  与  $\theta$  的最大似然估计值分别为  $\hat{c} = x_{1}, \hat{\theta} = \overline{x} -x_{1}$ .

(2)  $c$  与  $\theta$  的矩估计量分别为  $\hat{c} = \overline{X} -\left[\frac{1}{n}\sum_{i = 1}^{n}(X_{i} - \overline{X})^{2}\right]^{1 / 2}, \hat{\theta} = \left[\frac{1}{n}\sum_{i = 1}^{n}(X_{i} - \overline{X})^{2}\right]^{1 / 2}$ .

6. 0.499. 7. (1) 由最大似然估计的性质知  $P\{X = 0\} = \mathrm{e}^{-\overline{x}}$ . (2) 0.3253.

8. (1)  $\hat{U} = \mathrm{e}^{-1 / \hat{\theta}}$ , 其中  $\hat{\theta} = -n / \sum_{i = 1}^{n}\ln x_{i}$ . (2)  $\hat{\theta} = 1 - \Phi (2 - \overline{x})$ . (3)  $\hat{\beta} = [(3\overline{x}) / m] - 1$ .

9. 略. 10. (1)  $c = \frac{1}{2(n - 1)}$ . (2)  $c = \frac{1}{n}$ . 11. 略. 12. (1)  $T_{1}, T_{3}$  是无偏的. (2)  $T_{3}$  较  $T_{1}$  有效.

13. (1) 略. (2) 提示:  $\hat{\theta} = X_{(n)} = \max \{X_{1}, X_{2}, \dots , X_{n}\} , E(\hat{\theta}) = \frac{n}{n + 1}\theta \neq \theta$ .

14.  $a = \frac{n_{1}}{n_{1} + n_{2}}, b = \frac{n_{2}}{n_{1} + n_{2}}$ . 15. 记  $\frac{1}{\sigma_{0}^{2}} = \sum_{i = 1}^{k}\frac{1}{\sigma_{i}^{2}}, a_{i} = \frac{\sigma_{0}^{2}}{\sigma_{i}^{2}}, i = 1,2, \dots , k$ .

16. (1) (5.608,6.392). (2) (5.558,6.442).

17. (1) (6.675,6.681), (6.8×10-6,6.5×10-5).

(2) (6.661,6.667), (3.8×10-6,5.06×10-5).

18. (7.4,21.1).

19. (1)  $\sigma^{2}$  的置信区间为  $\left[\frac{\sum_{i = 1}^{n}(X_{i} - \mu)^{2}}{\chi_{\alpha / 2}^{2}(n)}, \frac{\sum_{i = 1}^{n}(X_{i} - \mu)^{2}}{\chi_{1 - \alpha / 2}^{2}(n)}\right]$ . (2) (2.239,5.624).

20. (0.010,0.018). 21. (-0.002,0.006). 22. (-6.04,-5.96).

23. (0.222,3.601). 24. (0.101,0.244).

25. (1)  $\sigma$  已知时所求为 6.329,  $\sigma$  未知时所求为 6.356. (2) -0.0012. (3) 2.84.

26. 40 527. 27. 39 岁零 1 个月.

# 第八章

1. 接受  $H_{0}$  .2.接受  $H_{0}$  .3.认为不合格.4.认为显著大于10.

5. 接受  $H_{0}$ , 认为这批罐头是符合规定的. 6. 拒绝  $H_{0}$ , 认为有显著差异. 7. 拒绝  $H_{0}$ .

8. 认为早晨的身高比晚上的要高. 9. 拒绝  $H_{0}$ , 认为  $A$  比  $B$  耐穿.

10. 接受  $H_{0}$ , 认为产量无显著差异. 11. 拒绝  $H_{0}$ , 认为提纯后的群体比原群体整齐.

12. 拒绝  $H_{0}$ , 认为偏大. 13. 接受  $H_{0}$ .

14. 接受  $H_{0}$  .15.接受  $H_{0}$  .16.接受  $H_{0}$

17. (1) 接受  $H_{0}$ , 认为两者方差相等. (2) 接受  $H_{0}^{\prime}$ , 认为所需天数相同.

18. (1) 接受  $H_{0}$ . (2) 拒绝  $H_{0}^{\prime}$ , 认为两者的可理解性有显著差异. 19. 接受  $H_{0}$ .

20. 所需的样本容量  $n \geqslant 7$ . 21. (1) 接受  $H_{0}$ . (2)  $n \geqslant 7$ . 22.  $(\bar{x} -2\bar{y}) / \sqrt{\sigma_{1}^{2} / n_{1} + 4\sigma_{2}^{2} / n_{2}} \geqslant z_{\alpha}$ .

23. 认为服从泊松分布. 24. 接受  $H_{0}$ .

25. (1) 略. (2) 接受  $H_{0}$ , 认为来自正态总体  $N(16,15^{2})$ . 26. 接受  $H_{0}$ .

27. 拒绝  $H_{0}$ , 认为有显著改变. 28. (1)  $\hat{p} = 0.6419$ . (2) 接受  $H_{0}$ .

29. (1)(i)取  $\alpha = 0.05$  时接受  $H_{0}$  ;(ii)取  $\alpha = 0.10$  时拒绝  $H_{0}$  ;(iii)拒绝  $H_{0}$  的最小显著性水平为0.0808.

(2)  $\boldsymbol{\mathscr{p}}$  值  $= 0.4747$  ,接受  $H_{0}$  .(3)  $\boldsymbol{\mathscr{p}}$  值  $= 0.0271$  ,拒绝  $H_{0}$  .(4)  $\boldsymbol{\mathscr{p}}$  值  $= 0.0110$  ,拒绝  $H_{0}$

# 第九章

1. 电池的平均寿命有显著差异;(6.75,18.45),(-7.65,4.05),(-20.25,-8.55).

2. 差异显著;(0.72,4.28),(2.55,6.45),(0.22,3.78). 3. 差异显著. 4. 差异显著.

5. 差异显著. 6. 只有浓度的影响是显著的. 7. 因素  $A$  、因素  $B$  的影响均不显著.

8.  $\hat{y} = 24.6287 + 0.05886x$ .

9. (1) 略. (2)  $\hat{y} = 13.9584 + 12.5503x$ . (3)  $\hat{\sigma}^{2} = 0.0432$ . (4) 拒绝  $H_{0}$ , 认为回归效果显著. (5) (11.82,13.28). (6) (20.03,20.44). (7) (19.66,20.81).

10. (1) 略. (2)  $\hat{y} = -0.104 + 0.988x$ . (3) (13.29,14.17).

11.  $y = -3.85493 + 1.83396x$ .

12. (1) 成绩关于年份的线性回归方程为  $\hat{y} = 105.4826 - 0.0392x$ . (2) 拒绝  $H_{0}$ , 认为回归效果显著. (3) 预测值为  $26.82 \mathrm{min}$ .

13. (1)  $\hat{y} = 1.896 + 0.53846x$ . (2)  $b$  的置信水平为 0.95 的置信区间为 (0.208,0.869).

14. (1)一(2)略.(3)  $\hat{y} = 32.4556\mathrm{e}^{-0.0867319x}$

15. (1) 略. (2)  $\hat{y} = 19.03333 + 1.00857x - 0.02038x^{2}$ .

16. (1)  $\hat{y} = 9.9 + 0.575x_{1} + 0.55x_{2} + 1.15x_{3}$ . (2)  $\hat{y} = 9.9 + 0.575x_{1} + 1.15x_{3}$ .

# 第十、十一章答案略.

# 第十二章

$$
F{\Big(}x{\Big)}_{2}^{1}{\Big)} = {\left\{ \begin{array}{l l}{0,} & {x< 0,}\\ {\frac{1}{2},} & {0\leqslant x< 1,F(x,1) = {\left\{ \begin{array}{l l}{0,} & {x< -1,}\\ {\frac{1}{2},} & {-1\leqslant x< 2,}\\ {1,} & {x\geqslant 2.} \end{array} \right.}} \end{array} \right.}
$$

$$
\begin{array}{r}{F\Big(x_{1},x_{2};\frac{1}{2},1\Big) = \left\{ \begin{array}{l l}{0,} & {x_{1}< 0,}\\ {0,} & {x_{1}\geqslant 0,}\\ {\frac{1}{2},} & {0\leqslant x_{1}< 1,}\\ {\frac{1}{2},} & {x_{1}\geqslant 1,}\\ {1,} & {x_{1}\geqslant 1,} \end{array} \right. - 1\leqslant x_{2}< 2,}\\ {1,} & {x_{1}\geqslant 1,} \end{array}
$$

2.  $\mu_{Y}(t) = F_{X}(x;t),R_{Y}(t_{1},t_{2}) = F_{X}(x,x;t_{1},t_{2})$ .

$$
\mu_{X}(t) = \frac{1}{a t} (1 - \mathrm{e}^{-a t}),t > 0,\quad R_{X}(t_{1},t_{2}) = \frac{1}{a(t_{1} + t_{2})} [1 - \mathrm{e}^{-a(t_{1} + t_{2})}],t_{1},t_{2} > 0.
$$

4.  $\mu_{X}(t) = a,C_{X}(t_{1},t_{2}) = \sigma^{2}$ .

5.  $\mu_{Y}(t) = \mu_{X}(t) + \phi (t),C_{Y}(t_{1},t_{2}) = C_{X}(t_{1},t_{2})$ .

$$
R_{Y}(t_{1},t_{2}) = R_{X}(t_{1} + a,t_{2} + a) - R_{X}(t_{1} + a,t_{2}) - R_{X}(t_{1},t_{2} + a) + R_{X}(t_{1},t_{2}).
$$

7.  $C_{Z}(t_{1},t_{2}) = \sigma_{1}^{2} + (t_{1} + t_{2})\rho \sigma_{1}\sigma_{2} + t_{1}t_{2}\sigma_{2}^{2}$ .

8.  $R_{X}(t_{1},t_{2}) = C_{X}(t_{1},t_{2}) = (1 + t_{1}t_{2})\sigma^{2}$ .

9.  $\mu_{Z}(t) = a(t)\mu_{X}(t) + b(t)\mu_{Y}(t) + c(t)$ ,

$C_{Z}(t_{1},t_{2}) = a(t_{1})a(t_{2})C_{X}(t_{1},t_{2}) + b(t_{1})b(t_{2})C_{Y}(t_{1},t_{2}),t_{1},t_{2}\in T.$  10. 略.

11. (1)  $\sigma^{2}\min \{t_{1},t_{2}\} ,t_{1},t_{2}\geqslant 0$ . (2)  $t_{1}t_{2} + \sigma^{2}\min \{t_{1},t_{2}\} ,t_{1},t_{2}\geqslant 0$ .

(3)  $\sigma^{2}\min \{t_{1},t_{2}\} ,t_{1},t_{2}\geqslant 0$ .

# 第十三章

1. 状态空间  $I = \{1,2,\dots ,N\} ,p_{ij} = P\{X_{n} = j|X_{n - 1} = i\} = \left\{ \begin{array}{ll}1 / i, & 1\leqslant j\leqslant i,\\ 0, & j > i, \end{array} \right.\quad i = 1,2,\dots ,N.$

$$
\begin{array}{r}{P=\left[\begin{array}{l l l l l l}{1}&{}&{}&{}&{}&{}&{}&{}\\ {1/2}&{1/2}&{}&{}&{\mathbf{0}}&{}&{}&{}\\ {\vdots}&{\vdots}&{\ddots}&{}&{}&{}&{}&{}\\ {1/i}&{1/i}&{\cdots}&{1/i}&{}&{}&{}&{}\\ {\vdots}&{\vdots}&{}&{\vdots}&{\ddots}&{}&{}&{}\\ {1/N}&{1/N}&{\cdots}&{1/N}&{\cdots}&{1/N}\end{array}\right].}\end{array}
$$

2. 状态空间  $I = \{1,2,\dots \} ,p_{ij} = \left\{ \begin{array}{ll}p, & j = i + 1,\\ q, & j = i,\\ 0, & \text{其他}. \end{array} \right.$

$$
P = \left[ \begin{array}{l l l l l l}{q} & {p} & 0 & \dots & & \\ 0 & {q} & {p} & 0 & \dots \\ 0 & 0 & {q} & {p} & 0 & \dots \\ \vdots & \vdots & \vdots & \vdots & \vdots \end{array} \right].
$$

3. 状态空间  $I = \{0,1,2,\dots ,N\}$

$$
P = \left[ \begin{array}{ccccccccc}1 & 0 & 0 & 0 & \dots & 0 & 0\\ 0 & 1 - \alpha_{1} & \alpha_{1} & 0 & \dots & 0 & 0\\ 0 & 0 & 1 - \alpha_{2} & \alpha_{2} & \dots & 0 & 0\\ \vdots & \vdots & \vdots & \vdots & & \vdots & \vdots \\ 0 & 0 & 0 & 0 & \dots & 1 - \alpha_{N - 1} & \alpha_{N - 1}\\ 0 & 0 & 0 & 0 & \dots & 0 & 1 \end{array} \right],
$$

其中  $\alpha_{i} = \frac{2i(N - i)}{N(N - 1)}\alpha ,i = 1,2,\dots ,N - 1.$

4. (1)  $1 / 16$  ,(2)略.(3)7/18.(4)0.3993.5—7.略.

8.  $P = \left[ \begin{array}{cc}1 / 2 & 1 / 2 \\ 1 / 3 & 2 / 3 \end{array} \right]$ , 5月1日为晴天的条件下,5月3日为晴天的概率为  $p_{00}(2) = 0.4167;5$  月5日为雨天的概率为  $p_{01}(4) = 0.5995$ .

9.  $m = 1,\pi = (2 / 3,1 / 3)$

10.  $m = 2,\pi_{j} = \frac{1 - p / q}{1 - (p / q)^{3}}\left(\frac{p}{q}\right)^{j - 1},j = 1,2,3.$  
11. 略.

# 第十四章

1. 是.2.略.3.是.

4. 是,  $\mu_{Y}(t) = \lambda L$ ,  $R_{Y}(s,t) = \left\{ \begin{array}{ll}\lambda^{2}L^{2} + \lambda (L - |\tau |), & |\tau |\leqslant L,\\ \lambda^{2}L^{2}, & |\tau | > L, \end{array} \right.$ $\tau = t - s$ ,  $s,t\geqslant 0$ .

5. 具有.6.不是.7.略.8.(1)  $A / 8,A^{2} / 12$  (2)  $A / 8,A^{2} / 12$

9—10. 略.11. (1)略.(2)  $R_{XY}(\tau) = aR_{X}(\tau - \tau_{1})$

12. (1)5. (2)  $S_{X}(\omega) = 4\left[\frac{1}{(\omega - \pi)^{2} + 1} +\frac{1}{(\omega + \pi)^{2} + 1}\right] + \pi [\delta (\omega -3\pi) + \delta (\omega +3\pi)].$

13.  $\frac{1}{2} (\sqrt{2} -1)$  .14.  $S_{X}(\omega) = \frac{4}{T\omega^{2}}\sin^{2}\frac{\omega T}{2}$  .15.  $R_{X}(\tau) = \frac{4}{\pi}\left(1 + \frac{\sin^{2}5\tau}{\tau^{2}}\right)$  16—17.略.

# 第十五章

1. (1)  $(1 - 0.5B)X_{t} = \epsilon_{t}$  .(2)  $X_{t} = (1 - 0.7B - 0.24B^{2})\epsilon_{t}$

(3)  $(1 - 0.5B)X_{t} = (1 - 0.7B - 0.24B^{2})\epsilon_{t}$  .(4)  $(1 - 1.5B + 0.5B^{2})X_{t} = \epsilon_{t}$

(5)  $(1 - B)X_{t} = (1 - 0.5B)\epsilon_{t}$ .

2. (1) ARMA(1,0). (2) ARMA(0,2). (3) ARMA(1,2).

(4) ARMA(2,0). (5) ARMA(1,1).

3. 略. 4.  $\rho_{0} = 1$ ,  $\rho_{1} = \frac{-0.38}{1 + 0.5^{2} + 0.24^{2}}$ ,  $\rho_{k} = 0, k > 2$ .

5—7. 略.

# 选做习题

1.  $\frac{3(1 - \phi_{1})^{5}}{3(1 - \phi_{1})^{5} + 2(1 - \phi_{1})^{5}}$ . 2. (1) 8/11. (2) 4/5. (3) 32/55.

3.  $2p(1 - p)$ . 4. 甲: 6/11,乙:5/11.

5.  $P(A) = 1 / 3, P(B) = 7 / 12, A, B$  相互独立. 6.  $(1 - p) / (2 - p)$ .

7.  $p_{1}p_{2}(1 - p_{3}) + p_{1}(1 - p_{2})p_{3} + (1 - p_{1})p_{2}p_{3} + p_{1}p_{2}p_{3}$ .

8. 以  $F$  表示事件"  $A$  到  $B$  之间为通路",以  $C_{i}$  表示事件"继电器触点  $i$  闭合",  $i = 1,2,3,4,5$ .

$$
P(F) = P(F|C_{1})p_{1} + P(F|\overline{C}_{1})(1 - p_{1}),
$$

$$
P(F|C_{1}) = p_{1}p_{2} + p_{2}p_{3}p_{4} - p_{2}p_{3}p_{4}p_{5}.
$$

$$
P(F|\overline{C}_{1}) = p_{1}p_{2} + p_{2}p_{3}p_{4} - p_{2}p_{3}p_{4}p_{5}.
$$

$$
P(C_{3}|F) = [(1 - q_{1}q_{4} - q_{2}q_{5} + q_{1}q_{2}q_{4}q_{5})p_{3}] / P(F).
$$

9.

<table><tr><td>X</td><td>2</td><td>3</td><td>4</td></tr><tr><td>p k</td><td>p1p2+(1-p1)2</td><td>p1(1-p2)+(1-p1)p1p2</td><td>(1-p1)p1(1-p2)</td></tr></table>

10. (1) (2) 以  $Y$  表示所需测试的次数,

<table><tr><td>X</td><td>2</td><td>3</td><td>4</td><td>5</td><td></td><td>Y</td><td>2</td><td>3</td><td>4</td></tr><tr><td>p k</td><td>1/10</td><td>2/10</td><td>3/10</td><td>4/10</td><td></td><td>p k</td><td>1/10</td><td>3/10</td><td>6/10</td></tr></table>

11. (1) 0.632. (2) 3. 12. 0.989 97. 13. (1)  $\frac{1}{11}$ . (2)  $\frac{3}{55}$ .

14. (1) 0.548 8. (2) 0.573 0.

15. (1)  $F_{X}(x) = \left\{ \begin{array}{ll}\frac{1}{2}\mathrm{e}^{-x}, & x< 0, \\ 1 - \frac{1}{2}\mathrm{e}^{-x}, & x\geqslant 0. \end{array} \right.$

$$
\frac{Y}{p_{k}}\left| \begin{array}{c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c} & -1 & 1 & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ & \frac{1}{2} & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \end{array} \right.
$$

16. (1)  $k = \left\{ \begin{array}{l l}{\lambda^{-1},\lambda ,} & \frac{\#}{\#}\lambda \frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{1}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{\#}\frac{\#}{$  若  $k$  是整数,若  $k$  不是整数.

(2)  $k = \left\{ \begin{array}{l l}{(n + 1)\phi -1,(n + 1)\phi ,} & {\frac{\#}{\#}\left(n + 1\right)\phi}\\ {[(n + 1)\phi ],} & {\frac{\#}{\#}\left(n + 1\right)\phi} \end{array} \right.$  若  $(n + 1)\phi$  是整数, 17.略. 若  $(n + 1)\phi$  不是整数.

18.  $f_{Y}(y) = \left\{ \begin{array}{l l}{2 / 3,} & {0< y< 1,}\\ {1 / 3,} & {1\leqslant y< 2,}\\ {0,} & {\text{其他}.} \end{array} \right.$  19.  $f_{Y}(y) = \left\{ \begin{array}{l l}{0,} & {y\leqslant 0,}\\ {1 / 2,} & {0< y\leqslant 1,}\\ {1 / (2y^{2}),} & {1< y< \infty .} \end{array} \right.$  20.略.

21. (1)

<table><tr><td>X
Y</td><td>1</td><td>2</td><td>3</td><td>...</td><td>P{Y=j}</td></tr><tr><td>0</td><td>0</td><td>1/2²</td><td>1/2³</td><td>...</td><td>1/2</td></tr><tr><td>1</td><td>1/2</td><td>0</td><td>0</td><td>...</td><td>1/2</td></tr><tr><td>P{X=i}</td><td>1/2</td><td>1/2²</td><td>1/2³</td><td>...</td><td>1</td></tr></table>

(2)  $P\{X = 1|Y = 1\} = 1, P\{Y = 2|X = 1\} = 0$ .

22.

<table><tr><td>X
Y</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>...</td><td>P{Y=j}</td></tr><tr><td>2</td><td>e^{-λ}</td><td>λe^{-λ}
1!</td><td>λ²e^{-λ}
2!</td><td>0</td><td>0</td><td>...</td><td>∑k=0λk²e^{-λ}
k!</td></tr><tr><td>3</td><td>0</td><td>0</td><td>0</td><td>λ³e^{-λ}
3!</td><td>0</td><td>...</td><td>λ³e^{-λ}
3!</td></tr><tr><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>λ⁴e^{-λ}
4!</td><td>...</td><td>λ⁴e^{-λ}
4!</td></tr><tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><td>P{X=i}</td><td>e^{-λ}</td><td>λe^{-λ}
1!</td><td>λ²e^{-λ}
2!</td><td>λ³e^{-λ}
3!</td><td>λ⁴e^{-λ}
4!</td><td>...</td><td>1</td></tr></table>

23.  $\binom{n}{k}\left(\frac{\lambda_{1}}{\lambda_{1}+\lambda_{2}}\right)^{k}\left(\frac{\lambda_{2}}{\lambda_{1}+\lambda_{2}}\right)^{n-k}$ .

24. (1)  $P\{X = x,Y = y\} = \frac{\lambda^{x}\mu^{y}\mathrm{e}^{-(x + \mu)}}{x!y!},\quad x,y = 0,1,2,\dots .$

(2)  $P\{X + Y\leqslant 1\} = \mathrm{e}^{-(x + \mu)}(1 + \lambda +\mu)$ .

25. (1)  $f(x,y) = \left\{ \begin{array}{l l}{\frac{4}{\sqrt{3}},} & {0\leqslant y\leqslant \sqrt{3} x,0\leqslant y\leqslant -\sqrt{3}\left(x - 1\right),}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.$

(2)  $F_{Y}(y) = \left\{ \begin{array}{l l}{0,} & {y< 0,}\\ {\frac{4}{\sqrt{3}} y - \frac{4}{3} y^{2},} & {0\leqslant y< \sqrt{3} /2,}\\ {1,} & {y\geqslant \sqrt{3} /2.} \end{array} \right.$

26. (1)  $f_{X}(x) = \left\{ \begin{array}{l l}{\mathrm{e}^{-x},} & {x > 0,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H},} \end{array} \right.f_{Y}(y) = \left\{ \begin{array}{l l}{\frac{1}{(y + 1)^{2}},} & {y > 0,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.$

(2)当  $y > 0$  时,  $f_{X|Y}(x|y) = \left\{ \begin{array}{l l}{x(y + 1)^{2}\mathrm{e}^{-x(y + 1)},} & {x > 0,}\\ {0,} & {x\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H},} \end{array} \right.$

当  $x > 0$  时,  $f_{Y|X}(y|x) = \left\{ \begin{array}{l l}{x\mathrm{e}^{- x y},} & {y > 0,}\\ {0,} & {y\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}\mathbb{H}.} \end{array} \right.$

![\1](概率论与数理统计第五版盛骤_images/概率论与数理统计第五版盛骤_part_9.pdf-0912f019-1cce-45cf-a2df-cefa5cbfbcb7_b462079ee958eb82ee77c6d3f8b8f3440dd4602ff7216098a1a96d32a32786cc.jpg)

(2)  $1 / 2$  .(3)  $5 / 6$

$$
P\{X = k,Y = i\} = \left(\begin{array}{l l}{{k}}\\ {{i}}\end{array}\right)p^{i}(1 - p)^{k - i}\frac{\lambda^{k}\mathrm{e}^{-\lambda}}{k!},\quad k = 0,1,2,\dots ,
$$

29.  $1 / 2$  .30.0.19.31.  $\Phi (\sqrt{2}) - \Phi (0) = 0.4207$

32. (1)0.8897.(2)0.2818.(3)0.9874.

33.  $f_{Z}(z) = \left\{ \begin{array}{l l}{\frac{1}{2\epsilon} [1 - \mathrm{e}^{-\frac{1}{2} (z + \epsilon)^{2}}],} & {-\epsilon < z< \epsilon ,}\\ {\frac{1}{2\epsilon} [\mathrm{e}^{-\frac{1}{2} (z - \epsilon)^{2}} - \mathrm{e}^{-\frac{1}{2} (z + \epsilon)^{2}}],} & {z\geqslant \epsilon ,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.$

34.  $f_{Z}(z) = \left\{ \begin{array}{l l}{-20\ln (20z),} & {0< z< 0.05,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.$

35. (1)  $f_{X}(x) = \left\{ \begin{array}{l l}{\mathrm{e}^{-x},} & {x > 0,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.f_{Y}(y) = \left\{ \begin{array}{l l}{y\mathrm{e}^{-y},} & {y > 0,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.$

(2)  $X,Y$  不是相互独立的.(3)  $f_{X + Y}(z) = \left\{ \begin{array}{l l}{\mathrm{e}^{-z / 2} - \mathrm{e}^{-z},} & {z > 0,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.$

(4)对于  $y > 0,f_{X|Y}(x|y) = \left\{ \begin{array}{l l}{1 / y,} & {0< x< y,}\\ {0,} & {\mathbb{H}\backslash \mathbb{H}.} \end{array} \right.$

(5)  $P\{X > 3|Y< 5\} = 0.03082$ . 
(6)  $P\{X > 3|Y = 5\} = 2 / 5$ .

36. (1)  $n\phi$  .(2)  $n(p + \alpha -\phi \alpha)$

<table><tr><td>X</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td>p_k</td><td>1/15</td><td>2/15</td><td>3/15</td><td>4/15</td><td>5/15</td></tr></table>

(2)  $3 / 5$  .(3)  $Y\sim b(6,3 / 5),E(Y) = 3.6.$

(4)  $P\{Y< 4\} = 0.456,P\{Y > 4\} = 0.233.$  
(5)  $E(Z) = 2$

38.  $\frac{nr}{N}$ . 39. 14.7. 40.  $\frac{\alpha}{\beta(\alpha + 1)} +\frac{2}{\alpha^2}$ . 41. (1)  $\frac{2}{5}$ . (2)  $\frac{4}{3}$ . 42. 0.7852.

43. (1) 略. (2) 不是离散型也不是连续型随机变量, 是混合型随机变量.

(3)  $P\{X = 4\} = 0, P\{X = 3\} = 0.316, P\{X< 4\} = 0.684, P\{X > 6\} = 0.135$ .

44.  $X\sim b(250,0.10),0.1469$ .

45. (1) 值域为 (0,0.75]. (2)  $F_{Y}(y) = \left\{ \begin{array}{ll}0, & y< 0, \\ y, & 0\leqslant y< 0.75, \\ 1, & y\geqslant 0.75. \end{array} \right.$  (3) 略.

46—47. 略. 48. 最大似然估计量  $=$  矩估计量  $= \frac{\overline{X}}{2}$ , 是无偏估计量.

49.  $\hat{\mu}_{1} = \overline{X}, \hat{\mu}_{2} = \overline{Y}, \hat{\sigma}^{2} = \frac{1}{n_{1} + n_{2}}\left[\sum_{i = 1}^{n_{1}}(X_{i} - \overline{X})^{2} + \sum_{i = 1}^{n_{2}}(Y_{i} - \overline{Y})^{2}\right]$ .

50. (1)  $\lambda$  的对数似然方程为  $\sum_{i = 1}^{k}\frac{d_{i}(t_{i} - t_{i - 1})}{\mathrm{e}^{\lambda(t_{i} - t_{i - 1})} - 1} -\sum_{i = 2}^{k}d_{i}t_{i - 1} - s t_{k} = 0$ . (2) 略.

51.  $\hat{\lambda} = \frac{1}{T_{0}}\ln \frac{n}{n - k}$ .

52. (1)  $L(p_{1},p_{2}) = [(1 - p_{1})p_{2}]^{n_{1}}[(1 - p_{2})p_{1}]^{n_{2}}(1 - p_{1}p_{2})^{n_{12}}(p_{1}p_{2})^{s}.$

(2)  $\hat{p}_{1} = 0.7150, \hat{p}_{2} = 0.8290$ .

53. (1)  $\theta$  的最大似然估计值为  $13 / 32, \theta$  的矩估计值为  $5 / 12$ . (2)  $\hat{\beta} = \overline{x} /\alpha$ .

54. (1) 略. (2)  $E(\widehat{X}) = \exp \{\widehat{\mu} +\widehat{\sigma}^{2} / 2\}$ , 其中  $\hat{\mu} = \frac{1}{n}\sum_{i = 1}^{n}\ln x_{i}, \hat{\sigma}^{2} = \frac{1}{n}\sum_{i = 1}^{n}(\ln x_{i} - \hat{\mu})^{2}$ .

(3)  $E(\widehat{X}) = 28.3067$ .

55.  $\hat{\eta} = \left(\frac{T_{m}}{m}\right)^{1 / \beta}$ , 其中  $T_{m} = \sum_{i = 1}^{m}t_{i} + (n - m)t_{m}^{2}$ .

56. (1)  $\hat{\eta} = 214.930$ . (2) 0.841.

57.  $a = \frac{n_{1} - 1}{n_{1} + n_{2} - 2}, b = \frac{n_{2} - 1}{n_{1} + n_{2} - 2}$ . 58. 略. 59. (1) 略. (2)  $\frac{2n\overline{X}}{\chi_{a}^{2}(2n)}$ . (3) 3764.7.

60. (1)—(2) 略. (3)  $h_{m / 2} = (1 - \alpha /2)^{1 / n}, h_{1 - \alpha /2} = (\alpha /2)^{1 / n}$ .

(4)  $((1 - \alpha /2)^{-1 / n}\max \{X_{1},X_{2},\dots ,X_{n}\} ,(\alpha /2)^{-1 / n}\max \{X_{1},X_{2},\dots ,X_{n}\}).$

(5) (4.22,8.78).

61. 拒绝域为  $\chi^{2} = \frac{2n\overline{{x}}}{\theta_{0}}\geqslant \chi_{a / 2}^{2}$  (2n)或  $\chi^{2} = \frac{2n\overline{{x}}}{\theta_{0}}\leqslant \chi_{1 - a / 2}^{2}$  (2n); 拒绝域为  $\chi^{2}\geqslant 39.364$  或  $\chi^{2}\leqslant$

12.401,现在  $\chi^{2} = 24.83$  故接受  $H_{0}$

62. 认为无显著影响.63.拒绝  $H_{0}$ , 认为医生的意见是对的.

64. 认为是有偏爱的.65.认为  $X\sim b(4,\theta)$

66. 认为有显著差异.

67. (1)  $\hat{y} = 13.487 + 1.065x$  (2) 拒绝  $H_{0}$ , 认为回归效果显著. (3)  $\hat{y}\big|_{x = 13} = 27.332$

(4)在  $\scriptstyle x = 13$  处  $\mu (x)$  的置信水平为0.95的置信区间为(26.088,28.576).

(5)在  $\scriptstyle x = 13$  处  $\boldsymbol{Y}$  的新观察值  $\boldsymbol{Y}_{0}$  的置信水平为0.95的预测区间为(23.845,30.819).

68. (1) 略. (2)  $\hat{y} = 774.0125 - 0.35915x$ . (3) 回归效果是非常显著的.

概率论与数理统计 第五版浙江大学 盛骤 谢式千 潘承毅 编

概率论与数理统计附册学习辅导与习题选解 浙大·第五版浙江大学 盛骤 谢式千 潘承毅 编

概率论与数理统计习题全解指南 浙大·第五版浙江大学 盛骤 谢式千 潘承毅 编

第四版被评为2009年度普通高等教育精品教材
[
    {
        "type": "text",
        "text": "象部分并分别标记为\"偏差\"和\"方差\"的特定方式与估计的实际质量无关,因此,让我们看看选择  $\\beta = m_{2}$  和  $\\beta = M_{2}$  的完整均方误差(17.2).用  $M_{2}$  替换  $m_{2}$  会消除项  $(\\langle n_{2}\\rangle - \\mu_{2})^{2} = \\mu_{2}^{2} / n^{2}$  ,但也会使项  $\\operatorname {var}(m_{2})$  增大  $[n / (n - 1)]^{2}$  倍,因此看起来很明显,至少对于大的  $n$  来说,这会使情况变得更糟,而不是更好.更具体地说,假设我们用估计量",
        "page_idx": 0
    },
    {
        "type": "equation",
        "text": "\n$$\n\\beta \\equiv c m_{2} \\tag{17.7}\n$$\n",
        "text_format": "latex",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "代替  $m_{2}$  ,按照正统准则,  $c$  的最优选择是什么?期望平均损失(17.2)现在是",
        "page_idx": 0
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r l} & {\\langle (c m_{2} - \\mu_{2})^{2}\\rangle = c^{2}\\langle m_{2}^{2}\\rangle -2c\\langle m_{2}\\rangle \\mu_{2} + \\mu_{2}^{2}}\\\\ & {\\qquad = \\langle (m_{2} - \\mu_{2})^{2}\\rangle -\\langle m_{2}^{2}\\rangle (\\hat{c} -1)^{2} + \\langle m_{2}^{2}\\rangle (-\\hat{c})^{2},} \\end{array} \\tag{17.8}\n$$\n",
        "text_format": "latex",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "其中",
        "page_idx": 0
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{c} \\equiv \\frac{\\mu_{2}\\langle m_{2}\\rangle}{\\langle m_{2}^{2}\\rangle}. \\tag{17.9}\n$$\n",
        "text_format": "latex",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "显然,(17.7)中的最优估计量是  $c = \\hat{c}$  且(17.8)中的项  $- \\langle m_{2}^{2}\\rangle (\\hat{c} - 1)^{2}$  表示通过使用  $\\hat{\\beta} \\equiv \\hat{c} m_{2}$  代替  $m_{2}$  可得到的均方误差的减小.简短的计算表明",
        "page_idx": 0
    },
    {
        "type": "equation",
        "text": "\n$$\n\\langle m_{2}^{2}\\rangle = n^{-3}(n - 1)\\big[(n^{2} - 2n + 3)\\mu_{2}^{2} + (n - 1)\\mu_{4}\\big], \\tag{17.10}\n$$\n",
        "text_format": "latex",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "其中",
        "page_idx": 0
    },
    {
        "type": "equation",
        "text": "\n$$\n\\mu_{4} \\equiv \\langle (x_{1} - \\langle x_{1}\\rangle)^{4}\\rangle = \\langle x_{1}^{4}\\rangle \\tag{17.11}\n$$\n",
        "text_format": "latex",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "是  $p(x_{1}|\\mu_{2})$  的第四中心矩.我们必须理解为什么这里  $n > 1$  ,因为如果  $n = 1$  ,我们有  $m_{2} = 0$  ,在抽样理论中,单次观察并没有提供有关方差  $\\mu_{2}$  的任何信息.",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "根据(17.5)和(17.10),我们发现  $\\hat{c}$  取决于抽样分布",
        "page_idx": 0
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{c} = \\frac{n^{2}}{n^{2} - 2n + 3 + (n - 1)K} \\tag{17.12}\n$$\n",
        "text_format": "latex",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "的第二和第四中心矩,其中  $K \\equiv \\mu_{4} / \\mu_{2}^{2} \\geqslant 1$  ,我们看到  $\\hat{c}$  是  $K$  的单调递减函数,因此如果  $K \\geqslant 2$  ,(17.12)表明对于所有  $n$  有  $\\hat{c} < 1$  ,这样,要减小总估计误差,我们不是要减小(17.5)中的偏差,反而应该始终增大它!",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "在高斯分布的情况下,  $p(x|\\mu_{2}) \\propto \\exp \\{- x^{2} / 2\\mu_{2}\\}$  ,我们发现  $K = 3$  ,我们很少会有  $K < 3$  ,因为这意味着  $p(x|\\mu_{2})$  对于大  $x$  会比高斯分布更快速度趋于0. 如果  $K = 3$  ,则(17.12)简化为",
        "page_idx": 0
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{c} = \\frac{n}{n + 1}. \\tag{17.13}\n$$\n",
        "text_format": "latex",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "与 (17.6) 比较表明,为了使均方误差最小化,我们不应该消除偏差,而应该将偏差大致翻倍.",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "估计量  $\\hat{\\beta} = \\hat{c} m_{2}$  比  $M_{2}$  好多少?在高斯分布的情况下,  $\\hat{\\beta}$  的均方误差为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "\n$$\n\\langle (\\hat{\\beta} -\\mu_{2})^{2}\\rangle = \\frac{2\\mu_{2}^{2}}{n + 1}. \\tag{17.14}\n$$\n",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "无偏估计  $M_{2}$  对应的选择为",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "\n$$\nc = \\frac{n}{n - 1}, \\tag{17.15}\n$$\n",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "从而得出均方误差",
        "page_idx": 1
    },
    {
        "type": "equation",
        "text": "\n$$\n\\langle (M_{2} - \\mu_{2})^{2}\\rangle = \\mu_{2}^{2}\\left[\\frac{2}{n + 1} -\\frac{2}{n}\\right], \\tag{17.16}\n$$\n",
        "text_format": "latex",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "它是使用  $\\hat{\\beta}$  的误差的2倍多.在实践中,如果不是高斯分布,则尾部比高斯更宽,因此  $K > 3$  ,在这种情况下,差异会更大.",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "到现在为止,似乎我们在为一个很小的事情——对于  $n$  值所做估计值的一点点变化——而争论不休.但是我们看到(17.14)和(17.16)之间的差别一点儿也不小.例如,使用无偏估计量  $M_{2}$  时,你将需要  $n = 203$  个观测值,才能获得有偏估计量  $\\hat{\\beta}$  只需要100个观测值就能获得的均方抽样误差.这是正统统计方法浪费信息的典型方式.在此示例中,无论  $n$  的值是多少,使用正统统计方法实际上都相当于丢弃了一半的数据,因此浪费了一半的时间来获取数据.",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "费希尔经常从信息的角度思考问题,很早就意识到了这一点,但现代正统统计实践者似乎从来没有意识到这一点,因为他们继续使用频率观念思考,根本不考虑信息.有一项计量经济学的工作(Valavanis,1959,第60页),作者非常重视消除偏差,因此他主张不是丢弃一半而是所有的数据以达到目标.",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "为什么正统主义者如此偏重于偏差?我们怀疑主要原因只是他们陷人了自己制造的心理陷阱中.当我们将量  $\\langle \\beta \\rangle - \\alpha$  称为\"偏差\"时,这听起来似乎是不好的,必须不惜一切代价消除它.如果按照毕达哥拉斯形式的(17.2),将其称为\"与方差正交的误差分量\",那么所有人都清楚这两项对误差的贡献是均等的.以增加另一项为代价减少一项是愚蠢的.这只是选择一种带有情感、暗示价值判断的技术术语所付出的代价.正统思想不断陷人这种战术错误.",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "切尔诺夫和摩西(Chernoff & Moses, 1959)曾经给出过一个更有力的例子,显示了无偏估计可能与我们想要的相去甚远。一家公司正准备铺设一根穿过旧金山海湾的电话电缆。他们无法事先确切知道需要多长的电缆,因此必须进行估算。如果他们高估了电缆长度,损失将与要丢弃的多余电缆的长度成正比;但是如果他们低估了电缆长度,电缆的末端会掉进水中,结果可能会造成财务危机。在这里使用无偏估计只能被描述为愚蠢的。这也说明了为什么需要沃尔德类型的决策理论来充分表达理性行为。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "过分强调偏差的另一个原因是基于以下信念:如果我们抽取  $n$  个观测值的  $N$  个连续样本并计算估计量  $\\beta_{1}, \\dots , \\beta_{N}$ ,这些估计的平均值  $\\overline{\\beta} = N^{- 1} \\sum \\beta_{i}$  会在  $N \\rightarrow +\\infty$  时以概率收敛到  $\\langle \\beta \\rangle$ 。因此,在足够长时间的抽取后,无偏估计会给出无限精确的  $\\alpha$  值估计。这种信念几乎从来没有过合理的解释,即使对于物理学家或工程师们进行了良好控制的测量而言也是如此,不仅是由于系统误差未知,而且是由于连续的测量缺乏适用这些极限定理所需要的逻辑独立性。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "在诸如经济学这样不受控制的领域中,情况还要糟糕得多。原则上讲,没有所谓\"渐近抽样性质\"之类的东西,因为\"总体\"总是有限的,并且它在有限时间内不受控制地变化。在这种情况下尝试仅仅使用抽样分布——通常被解释为极限频率——使得人们将自己的全部精力都耗费在无关的幻象上。与推断有关的不是任何想象的(未观察到的)频率,而是我们对于真实情况所知道的实际知识。由于人类信息是我们所拥有的一切,以\"主观\"为理由拒绝这种知识——或任何其他人类信息——会排除任何寻找有用结果的可能性。①",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "即使我们毫无批判地接受这些极限定理,并且虔诚地相信抽样概率也是极限频率,无偏估计量也不是在无限长时间抽样时无限逼近真实值的唯一估计量。许多有偏估计量在极限时逼近真实值  $\\alpha$ ,并且会更快。我们的  $\\hat{\\beta}$  就是一个例子。此外,估计量的渐近行为并不是我们真正关心的,因为真正的问题总是在有限数据集的前提下做得最好。因此,重要的问题不是估计量是否趋于真实值,而是它以多快的速度趋于真实值。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "我们在(6.94)中注意到:很久以前,费希尔通过另一种论证来处理无偏估计。偏差的准则并没有真正的意义,因为它在参数变换时并不具有不变性: $\\alpha$  的无偏估计的平方并不是  $\\alpha^{2}$  的无偏估计。在更高次幂  $\\alpha^{k}$  时,结果的差别可以变得任意大,而问题的表述中并没有告诉我们选择哪一个  $k$  是\"正确的\"。因此,如果你",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "我碰巧选择了不同的  $k$ ,则无偏估计会使我们从相同数据中得出关于  $\\alpha$  的不同结论。但是,许多正统主义者只是简单地忽略这些不确定性(尽管他们不可能不知道它们),并在可能的情况下继续使用无偏估计量。他们知道自己违反了基本的理性原则,却没有意识到自己也在浪费信息。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "但是请注意,在所有这些论证之后,我们并不能得出结论:根据均方误差准则,  $\\hat{\\beta}$  是  $\\mu_{2}$  的最优估计!我们只考虑了有限的一类估计量(17.4),它是通过样本方差(17.7)乘以某个预先指定的常数构造的。我们只能说  $\\hat{\\beta}$  是这一类估计量中最优的。样本的某个其他函数(不是估计量(17.4)的倍数)根据均方误差准则是否可能更优的问题仍然是悬而未决的。正统参数估计方法并不能告诉我们如何找到最优估计量,而只能告诉我们如何比较基于直觉的不同猜测结果。这在(13.21)之后已经提到,其中证明了通过对该问题稍微重新表述可以解决问题。这不可避免地导致了贝叶斯方法,以达到我们真正的目标。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "练习17.1尝试推广抽样理论以处理正统文献及以上讨论中未回答的许多问题。有没有有限样本的最优估计量的一般理论?如果有,偏差在其中有作用吗?根据第13章的分析我们已经知道,这不可能是一种变分理论;但是可以想象一种类似动态规划的理论可能存在。特别是,你能找到一个根据均方误差准则比  $\\hat{\\beta}$  更好的正统估计量吗?或者,可以证明在抽样理论框架内  $\\hat{\\beta}$  已经是最优的吗?",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "与抽样理论在这些问题中的困难相对照,我们在上面和第13章中已经指出:无论是否存在充分统计量,贝叶斯方法都会自动为任何数据集和损失函数构造最优估计量,并且会马上得到一个关于其最优性的简单变分证明。这种最优性不只是在任何受限的函数类中,而是对于所有估计量。而且我们在这样做时没有提及偏差的概念。偏差在贝叶斯理论中没有任何作用。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "17.3 无偏估计的病理",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "仔细检查一下,就会发现无偏估计的一个更令人不安的特征。考虑一下泊松分布:在一个时间单位内,我们观察到  $n$  个事件或\"计数\"的概率为",
        "page_idx": 3
    },
    {
        "type": "equation",
        "text": "\n$$\np(n|l) = \\mathrm{e}^{-l}\\frac{l^{n}}{n!},\\quad n = 0,1,2,\\dots , \\tag{17.17}\n$$\n",
        "text_format": "latex",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "其中参数  $l$  是  $n$  的抽样期望,  $\\langle n \\rangle = l$ . 那么, 什么函数  $f(n)$  能给出  $l$  的无偏估计? 显然, 选择  $f(n) = n$  将实现这一目标. 为了证明它是唯一的, 注意到  $\\langle f(n) \\rangle = l$  就是",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "\n$$\n\\sum_{n = 0}^{\\infty} \\mathrm{e}^{-l} \\frac{l^{n}}{n!} f(n) = l, \\tag{17.18}\n$$\n",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "根据泰勒级数的系数公式, 这需要",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "\n$$\nf(n) = \\frac{\\mathrm{d}^{n}}{\\mathrm{d}l^{n}} \\left\\{l \\mathrm{e}^{l} \\right\\} \\bigg|_{l = 0} = n. \\tag{17.19}\n$$\n",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "这是合理的结果. 但是假设我们想要某一函数  $g(l)$  的无偏估计量. 出于同样的原因, 唯一的解是",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "\n$$\nf(n) = \\frac{\\mathrm{d}^{n}}{\\mathrm{d}l^{n}} \\left\\{\\mathrm{e}^{l} g(l) \\right\\} \\bigg|_{l = 0}. \\tag{17.20}\n$$\n",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "因此,  $l^{2}$  的唯一无偏估计量为",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "\n$$\nf(n)={\\left\\{\\begin{array}{l l}{0,}&{n=0,1,}\\\\ {n(n-1),}&{n>1,}\\end{array}\\right.} \\tag{17.21}\n$$\n",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "这对于  $n = 1$  是荒谬的. 同样, 对于  $n = 1,2$ ,  $l^{3}$  的唯一无偏估计量也是荒谬的, 等等. 在这里, 无偏估计量甚至违背了基本逻辑. 如果观察到  $n = 2$ , 我们被建议估计  $l^{3} = 0$ , 但是如果  $l^{3}$  为 0, 则不可能观察到  $n = 2! \\mathrm{e}^{- l}$  的唯一无偏估计量是",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "\n$$\nf(n)={\\left\\{\\begin{array}{l l}{1,}&{n=1,}\\\\ {0,}&{n>0,}\\end{array}\\right.} \\tag{17.22}\n$$\n",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "这对于所有正数  $n$  来说都是荒谬的.  $1 / l$  的无偏估计量不存在, 它在数学上是病态的. 无偏估计量会在所有数据集上与演绎逻辑发生冲突. 如果它们在这样一个简单的问题中也能产生这样的病态结果, 那么在更复杂的问题中等待我们的将是什么恐怖的后果呢?",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "补救措施",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "相比之下, 对于任何函数  $g(l)$ , 均匀先验的贝叶斯后验均值估计为",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "\n$$\n\\langle g(l) \\rangle = \\frac{1}{n!} \\int_{0}^{+\\infty} \\mathrm{d}l \\mathrm{e}^{-l} l^{n} g(l), \\tag{17.23}\n$$\n",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "对于以上所有示例, 都可以很容易地验证其在数学上表现良好, 结果具有直观上的合理性.  $1 / l$  的贝叶斯估计就是  $1 / n$ , 这里没有病态. 首先会令人惊讶的是,  $\\mathrm{e}^{- l}$  的贝叶斯估计为",
        "page_idx": 4
    },
    {
        "type": "equation",
        "text": "\n$$\nf(n) = 2^{-(n + 1)}. \\tag{17.24}\n$$\n",
        "text_format": "latex",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "为什么不是  $\\mathrm{e}^{- n}$  呢?要明白原因,请注意以下几点。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "(1)  $l$  的后验分布是偏斜的,  $l > n$  的后验概率为",
        "page_idx": 5
    },
    {
        "type": "equation",
        "text": "\n$$\np(l > n) = \\int_{n}^{+\\infty} \\mathrm{d}l \\mathrm{e}^{-l} \\frac{l^n}{n!} = \\mathrm{e}^{-n} \\sum_{m = 0}^{n} \\frac{n^m}{m!}. \\tag{17.25}\n$$\n",
        "text_format": "latex",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "它从  $n = 0$  处的1随着  $n\\rightarrow +\\infty$  单调减少到  $1 / 2$  因此,给定  $n$  ,参数  $l$  总是更可能大于  $n$  而不是小于  $n$",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "(2)  $l$  的后验分布与  $\\mathrm{e}^{-l} l^n$  成正比,主要集中在范围  $n \\pm \\sqrt{n}$  内。但是  $\\mathrm{e}^{-l}$  变化得如此之快,以致在计算其期望值时,对积分  $\\int \\mathrm{d}l \\mathrm{e}^{-2l} l^n$  的大部分贡献来自范围  $n / 2 \\pm \\sqrt{n} /2$ 。因此  $\\mathrm{e}^{-n / 2}$  比  $\\mathrm{e}^{-n}$  更接近正确的估计量。这两种情况都影响数值,以致(17.24)最终成为这些相反趋势之间的平衡。这仍然是贝叶斯定理检测到一个真正复杂的情况并自动纠正它的例子。它相当灵活有效,人们不知道其中发生了什么。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "练习17.2 考虑截断泊松分布:",
        "page_idx": 5
    },
    {
        "type": "equation",
        "text": "\n$$\np(n|l) = \\left[\\frac{1}{\\mathrm{e}^{l} - 1}\\right] \\frac{l^n}{n!}, \\quad n = 1,2, \\dots . \\tag{17.26}\n$$\n",
        "text_format": "latex",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "证明  $l$  的无偏估计量现在对于  $n = 1$  是荒谬的。  $\\mathrm{e}^{- l}$  的无偏估计量对于所有偶数  $n$  是荒谬的,对于所有奇数  $n$  是反常的。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "在已知的许多其他例子中,试图寻找无偏估计会导致类似的病态情况。正统主义者肯德尔和斯图尔特(Kendall & Stuart,1961)指出了其中的几个。但是他们被灌输了很强大的反贝叶斯主义思想,不愿检查相应的贝叶斯主义结果。因此,他们从不知道在所有情况下贝叶斯方法可以轻易地克服困难。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "17.4 抽样方差的基本不等式",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "一个通常与克拉默、拉奥、达尔穆瓦、弗雷歇等人的名字相联系的著名不等式,对于任何具有连续抽样分布的任意估计量或统计量提供了可以达到的抽样方差的下限。结果尽管在数学上很简单,但是很重要,因为它几乎是正统统计所能提供的唯一指导性理论。克拉默(Cramér,1946,第32章)给出了这方面带示例的全面讨论。给定  $n$  个观测数据的数据集  $x \\equiv \\{x_1, \\dots , x_n\\}$  并通过  $\\int \\mathrm{d}x()$  在",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "样本空间上进行积分.对于包含参数  $\\alpha$  的抽样分布  $p(x|\\alpha)$  ,令",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "\n$$\nu(x,\\alpha)\\equiv \\frac{\\partial\\ln p(x|\\alpha)}{\\partial\\alpha}. \\tag{17.27}\n$$\n",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "从数学上讲,我们寻求的结果只是施瓦茨不等式:给定在样本空间上定义的两个函数  $f(x)$  和  $g(x)$  ,记  $(f,g)\\equiv \\int \\mathrm{d}x f(x)g(x)$  ,则  $(f,g)^{2}\\leqslant (f,f)(g,g)$  ,当且仅当  $f(x) = q g(x)$  时等号成立,其中  $q$  是独立于  $x$  但可能依赖于  $\\alpha$  的常数.现在选择",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "\n$$\nf(x)\\equiv u(x,\\alpha)\\sqrt{p(x|\\alpha)},\\qquad g(x)\\equiv [\\beta (x) - \\langle \\beta \\rangle ]\\sqrt{p(x|\\alpha)}. \\tag{17.28}\n$$\n",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "因为  $\\begin{array}{r}{\\langle u\\rangle = \\int \\mathrm{d}x u(x,\\alpha)p(x|\\alpha) = \\partial /\\partial \\alpha [\\int \\mathrm{d}x p(x|\\alpha)] = 0} \\end{array}$  ,我们发现  $(f,g) = \\langle \\beta u\\rangle -$ $\\langle \\beta \\rangle \\langle u\\rangle = \\langle \\beta u\\rangle$  .同样,  $(f,f) = \\operatorname {var}(u)$  ,而  $(g,g) = \\operatorname {var}(\\beta)$  ,因此施瓦茨不等式简化为",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "\n$$\n\\langle \\beta u\\rangle \\leqslant \\sqrt{\\operatorname{var}(\\beta)\\operatorname{var}(u)}. \\tag{17.29}\n$$\n",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "但是  $\\langle \\beta u\\rangle = \\int \\mathrm{d}x \\beta \\partial p(x|\\alpha) / \\partial \\alpha = \\mathrm{d}\\langle \\beta \\rangle /\\mathrm{d}\\alpha = 1 + b'(\\alpha)$  ,其中  $b(\\alpha)\\equiv \\langle \\beta \\rangle - \\alpha$  是估计量的偏差,因此,我们寻求的著名不等式是",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "\n$$\n\\operatorname {var}(\\beta)\\geqslant {\\frac{[1 + b'(\\alpha)]^2}{\\int\\mathrm{d}\\alpha(\\partial\\ln p(x|\\alpha) / \\partial\\alpha)^2p(x|\\alpha)}}. \\tag{17.30}\n$$\n",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "现在,将(17.27)代入等式  $f = q g$  的充分必要条件并更改参数  $\\alpha \\rightarrow l$  ,其中  $l$  由 $q(\\alpha) = - \\partial l / \\partial \\alpha$  定义,我们有",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{\\partial\\ln p(x|\\alpha)}{\\partial\\alpha} = -l'(\\alpha)[\\beta (x) - \\langle \\beta \\rangle ]. \\tag{17.31}\n$$\n",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "通过对  $\\alpha$  进行积分,等式成立的条件变为",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "\n$$\n\\ln p(x|\\alpha) = -l(\\alpha)\\beta (x) + \\int \\mathrm{d}l\\langle \\beta \\rangle +\\frac{\\mathrm{d}\\alpha}{\\mathrm{d}\\alpha}. \\tag{17.32}\n$$\n",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "用更熟悉的记号表示,注意(17.32)中的积分是  $\\alpha$  的函数,让我们称之为  $\\ln Z(\\alpha)$  定义函数  $Z(\\alpha)$  ,同样,(17.32)中的积分常数与  $\\alpha$  无关,但可能依赖于  $x$  因此称它为  $\\ln m(x)$  ,定义函数  $m(x)$  ,有了这些记号的改变,(17.30)中等号成立的充分必要条件就变成了",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "\n$$\np(x|\\alpha) = \\frac{m(x)}{Z(l)}\\exp \\{-l(\\alpha)\\beta (x)\\} . \\tag{17.33}\n$$\n",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "但是我们认出这仅仅是我们在第11章中发现的分布,通过固定  $\\langle \\beta (x)\\rangle$  约束的最大原理,在(17.33)中,分母  $Z(l)$  显然是一个归一化常数,因此等于",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "\n$$\nZ(l) = \\int \\mathrm{d}x m(x)\\exp \\{-l\\beta (x)\\} , \\tag{17.34}\n$$\n",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "而约束只是",
        "page_idx": 7
    },
    {
        "type": "equation",
        "text": "\n$$\n\\langle \\beta \\rangle = -\\frac{\\partial\\ln Z}{\\partial l}, \\tag{17.35}\n$$\n",
        "text_format": "latex",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "与(11.60)相同,这可以立刻推广到  $\\alpha$  和  $\\beta$  是任意维度的向量的情况,指数变成像(11.43)中的  $\\{- \\sum l_{i}(\\alpha)\\beta_{i}(x)\\}$ ,因此我们只是重新发现了第11章的最大熵形式!",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "这些结果使我们了解到一些原理根本上的统一性和相互一致性,这些原理迄今看起来似乎彼此不同,我们在第14章中注意到,与信息相关的充分性概念实际上可以用香农的信息熵来定义,很久以前,皮特曼- 库普曼定理(Koopman,1936;Pitman,1936)就证明了存在充分统计量的条件只是抽样分布具有函数形式(17.32).因此,如果我们使用最大熵原理来分配抽样分布,那么从抽样理论(因为估计量的抽样方差为最小可能值)或贝叶斯理论(因为在应用贝叶斯定理时,我们只需要计算数据的一个函数)推断的角度出发,这会自动生成具有理想性质的分布.",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "的确,如果将最大熵分布视为由拉格朗日乘子  $l_{j}$  参数化的抽样分布,我们会发现充分统计量正是定义分布的约束的数据图像,因此,根据约束集合  $\\{\\langle \\beta_{1}(x)\\rangle ,\\langle \\beta_{2}(x)\\rangle ,\\dots ,\\langle \\beta_{k}(x)\\rangle \\}$  作为概率分布的期望值生成的最大熵分布具有  $k$  个充分统计量,正是  $\\{\\beta_{1}(x),\\dots ,\\beta_{k}(x)\\}$ ,其中  $x$  是观察到的数据集,杰恩斯(Jaynes,1978,B82)证明了这一点,我们将其作为练习让读者重构证明.",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "如果抽样分布不具有(17.33)或其推广的形式,那么就有两种可能性,首先,如果抽样分布对于  $\\alpha$  是连续的,那么下界(17.28)无法达到,似乎没有理论可以确定正确的下界,更不用说构造一个估计量来达到下界了.如果  $\\beta$  是无偏的,(17.30)右侧的最小可能方差与实际  $\\operatorname {var}(\\beta)$  的比被费希尔称为估计量  $\\beta$  的效率,具有效率1的估计量称为有效估计量,如今,它通常被称为\"无偏最小方差\"(unbiased minimum variance,UMV)估计量.①",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "其次,如果  $p(x|\\alpha)$  具有不连续点,克拉默(Cramér,1946,第485页)发现存在能实际上达到比(17.28)更低的方差的估计量,但是,既然施瓦茨不等式不会有任何例外,这怎么可能呢?出于附录B中所述的原因,我们认为这是一个数学错误(如果克拉默将不连续函数作为连续函数序列的极限,那么极限中会出现另一个德尔塔函数项,这将使得(17.30)在无论  $p(x|\\alpha)$  是连续时还是不连续时都是正确的).这是未能认识到德尔塔函数在分析中的必要作用而导致错误的一种典型情况.",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "17.5 周期性:中央公园的天气",
        "text_level": 1,
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "在经济学、气象学、地球物理学、天文学和许多其他领域中,一个很重要的一般性问题是,确定获取的时间序列数据能否为周期性行为提供证据,根据过去观察到的周期很可能在将来继续的假设(即归纳推理),任何明显可辨别的周期性成分(如出生、疾病、降雨、温度、商业周期、股票市场、农作物产量、地震,恒星亮度)都可以为改善对未来行为的预测提供依据,但是,除了预测之外,证明周期性的分析数据的原理仍然存在争议:这是显著性检验还是参数估计问题?不同流派根据同一数据可能会得出相反的结论.",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "在这里,我们将考虑一个来自最新正统文献的推理流程的例子,这也将引入对贝叶斯频谱分析的简单介绍,布卢姆菲尔德(Bloomfield,1976,第110页)给出了一张图,显示纽约中央公园在大约100年中观测到的1月平均温度,由于其峰- 峰幅度约为  $4^{\\circ}\\mathrm{F}$  ,而不规则的\"噪声\"仅约为  $0.5^{\\circ}\\mathrm{F}$  ,因此存在一个大约20年的周期,这在肉眼看来完全是显而易见的,然而,布卢姆菲尔德使用费希尔引人的正统显著性检验,得出的结论却是不存在周期性的显著证据!",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "数据预滤波的愚蠢",
        "text_level": 1,
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "为了理解这一点,我们首先注意到布卢姆菲尔德的图形数据已经通过10年移动平均值进行了\"预滤波\"。这对周期性证据有什么影响?假设原始数据为  $D = \\{y_{1},\\dots ,y_{n}\\}$  ,并考虑离散傅里叶变换",
        "page_idx": 8
    },
    {
        "type": "equation",
        "text": "\n$$\nY(\\omega)\\equiv \\sum_{t = 1}^{n}y_{t}\\mathrm{e}^{\\mathrm{i}\\omega t}. \\tag{17.36}\n$$\n",
        "text_format": "latex",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "对于连续的  $\\omega$  值,这是定义明确并且是周期性的:  $Y(\\omega) = Y(\\omega +2\\pi)$  ,因此,如果将频率限制为  $|\\omega |< \\pi$  ,则不会丢失任何信息,但这也不是很必要,在任意  $n$  个连续和离散的\"奈奎斯特\"频率",
        "page_idx": 8
    },
    {
        "type": "equation",
        "text": "\n$$\n\\omega_{k}\\equiv 2\\pi k / n,\\qquad 0\\leqslant k< n \\tag{17.37}\n$$\n",
        "text_format": "latex",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "上的  $Y(\\omega)$  的值已经包含所有数据的信息,因为根据正交性  $n^{- 1}\\sum_{k}\\mathrm{e}^{\\mathrm{i}\\omega_{k}(s - t)} = \\delta_{s t}$  数据可以通过傅里叶反演从中恢复:",
        "page_idx": 8
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{1}{n}\\sum_{k = 1}^{n}Y(\\omega_{k})\\mathrm{e}^{-\\mathrm{i}\\omega_{k}t} = y_{t},\\qquad 1\\leqslant t\\leqslant n. \\tag{17.38}\n$$\n",
        "text_format": "latex",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "假设将数据替换为过去值的  $m$  年移动平均值, 带滞后  $s$  时间的  $w_{s}$  加权系数:",
        "page_idx": 9
    },
    {
        "type": "equation",
        "text": "\n$$\nz_{t} \\equiv \\sum_{s = 0}^{m - 1} y_{t - s} w_{s}. \\tag{17.39}\n$$\n",
        "text_format": "latex",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "经过一些代数运算, 新的傅里叶变换将是",
        "page_idx": 9
    },
    {
        "type": "equation",
        "text": "\n$$\nZ(\\omega) = \\sum_{t = 1}^{n} z_{t} \\mathrm{e}^{\\mathrm{i} \\omega t} = W(\\omega) Y(\\omega), \\tag{17.40}\n$$\n",
        "text_format": "latex",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "其中",
        "page_idx": 9
    },
    {
        "type": "equation",
        "text": "\n$$\nW(\\omega) \\equiv \\sum_{s = 0}^{m - 1} w_{s} \\mathrm{e}^{\\mathrm{i} \\omega s} \\tag{17.41}\n$$\n",
        "text_format": "latex",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "是加权系数的傅里叶变换, 这只是傅里叶理论的卷积定理, 因此, 对数据进行任何移动平均只是将其傅里叶变换乘以已知函数, 特别是对于均匀加权",
        "page_idx": 9
    },
    {
        "type": "equation",
        "text": "\n$$\nw_{s} = \\frac{1}{m}, \\quad 0 \\leqslant s < m, \\tag{17.42}\n$$\n",
        "text_format": "latex",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "我们有",
        "page_idx": 9
    },
    {
        "type": "equation",
        "text": "\n$$\nW(\\omega) = \\frac{1}{m} \\sum_{s = 0}^{m - 1} \\exp \\{-\\mathrm{i} \\omega s\\} = \\exp \\left\\{-\\frac{\\omega}{2} (m - 1)\\right\\} \\left[\\frac{\\sin(m \\omega / 2)}{m \\sin(\\omega / 2)}\\right]. \\tag{17.43}\n$$\n",
        "text_format": "latex",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "在  $m = 10$  的情况下, 我们发现对于 10 年和 20 年的周期性分别有",
        "page_idx": 9
    },
    {
        "type": "equation",
        "text": "\n$$\nW(2 \\pi / 10) = 0, \\quad W(2 \\pi / 20) = 0.639 \\exp \\{-9 \\pi \\mathrm{i} / 20\\} . \\tag{17.44}\n$$\n",
        "text_format": "latex",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "因此, 对任何时间序列数据取 10 年移动平均值会造成不可挽回的信息损失, 它完全消除了 10 年周期的任何证据, 并将 20 年周期的振幅减小到原来的 0.639, 同时使其相位偏移了  $9 \\pi / 20 \\approx 1.41$  弧度. 此外,  $W(\\omega)$  的幅度在  $\\omega = 2 \\pi / 20$  时减小, 因此表观频率发生了偏移.  $Z(\\omega)$  的峰值出现的频率低于  $Y(\\omega)$  的真实峰值出现的频率. 我们的结论是: 原始数据的周期性大约为 20 年, 其峰- 峰幅度约为  $4 / 0.639 \\approx 6.3(^{\\circ} \\mathrm{F})$ . 这对于肉眼更加明显, 并且与布卢姆菲尔德图中可见的周期性相位相差大约 90 度, 而且真实频率比根据图中估算的频率要高一些. 取移动平均值已经严重破坏和扭曲了数据中的信息.",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "我们多次警告不要在分析数据之前以这种方式预滤波。它唯一可能达到的目的是把数据图装饰得更漂亮。但是如果要通过计算机分析数据,这不会有任何帮助,只会丢弃或扭曲计算机可能从原始数据中提取的某些信息。对于某些目的,它会使滤波后的数据变得完全无用。就我们所知,原始数据可能存在与众所周知的与太阳黑子数11年周期性相对应的大约10年的强周期性。如果是这样,则进行10年移动平均将消除这种周期性的证据。",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "数据的周期图就是功率谱密度:",
        "page_idx": 10
    },
    {
        "type": "equation",
        "text": "\n$$\nP(\\omega) \\equiv \\frac{1}{n} \\left|Y(\\omega)\\right|^2 = \\frac{1}{n} \\sum_{t,s} y_t y_s \\exp \\left\\{\\mathrm{i}\\omega (t - s)\\right\\} . \\tag{17.45}\n$$\n",
        "text_format": "latex",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "注意  $P(0) = (\\sum y_t)^2 = n \\overline{y}^2$  确定数据的均值,而奈奎斯特频率下的周期图的平均值是数据的均方值:",
        "page_idx": 10
    },
    {
        "type": "equation",
        "text": "\n$$\nP(\\omega_k)_{\\mathrm{av}} = \\frac{1}{n} \\sum_{k = 1}^{n} P(\\omega_k) = \\overline{y^2}. \\tag{17.46}\n$$\n",
        "text_format": "latex",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "费希尔提议的周期性检验统计量是周期图的峰值与平均值之比:",
        "page_idx": 10
    },
    {
        "type": "equation",
        "text": "\n$$\nq = \\frac{P(\\omega_k)_{\\mathrm{max}}}{P(\\omega_k)_{\\mathrm{av}}}, \\tag{17.47}\n$$\n",
        "text_format": "latex",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "并根据数据是高斯白噪声的原假设  $H_0$  计算其抽样分布  $p(q|H_0)$ 。从数据中观察到值  $q_0$  之后,我们可以计算所谓的 \" $P$  值\",即以  $H_0$  为条件、仅靠偶然性便会产生相等或更大值的抽样概率:",
        "page_idx": 10
    },
    {
        "type": "equation",
        "text": "\n$$\nP \\equiv p(q > q_0|H_0) = \\int_{q_0}^{+\\infty} \\mathrm{d}qp(q|H_0), \\tag{17.48}\n$$\n",
        "text_format": "latex",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "如果  $P > 0.05$ ,则周期性证据将会以\"未达到  $5\\%$  的显著性水平\"而被拒绝。",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "这种检验只考虑针对没有周期性的\"零假设\"条件下的概率,而没有考虑假设存在周期性的条件下的概率,也没有考虑是否有先验信息表明周期性的预期更合理!我们在第5章中已经对这种推理过程进行了评论。如果一个人没有指定(1)要检验的假设,(2)针对其进行检验的备择假设,(3)问题有什么先验,他怎么可能是在理性地检验任何假设呢?只有确定了以上三点,我们才在问明确的、定义良好的问题。",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "同样令人困惑的是,如果一个人开始时全力反对一种真实现象的存在,他怎么能找到这一现象的证据呢?该检验考虑的唯一假设  $H_0$  是数据来自没有任何周",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "期性成分的\"平稳高斯随机过程\".根据这一假设  $H_{0}$  ,即使噪声像一个正弦波周期,也仍然仅仅是纯粹的偶然——根据正统抽样分布来看,这也不太可能.",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "期性成分的\"平稳高斯随机过程\".根据这一假设  $H_{0}$ ,即使噪声像一个正弦波周期,也仍然仅仅是纯粹的偶然——根据正统抽样分布来看,这也不太可能.在我们能想到的几乎每一个应用中,关于现实世界的先验知识都告诉我们,当说到\"周期性\"时,我们想到的是一些系统性的物理作用在重复.确实,我们对它的兴趣完全是由于我们期待它会重复.因此,我们之所以认为天气有周期性,是因为我们知道天气受到周期性天文现象的影响:地球自转,每年围绕太阳的轨道运动,以及观测到的黑子数的周期性,这都会影响地球上的大气.所以我们要检验的假设  $H_{1}$  跟我们在费希尔假设检验中使用的  $H_{0}$  完全不同.",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "这就是所有正统显著性检验的底层逻辑.为了证明一个存在某种效应的假设  $H_{1}$  ,人们间接地去:发明一个否认此效应的\"原假设\"  $H_{0}$  ,然后以某种方式否证  $H_{0}$  ,其间完全不提及  $H_{1}$  (即仅使用以  $H_{0}$  为条件的概率).让我们看看这一流程如何违背基本逻辑:假设我们认为该效应存在,就应该拒绝  $H_{0}$  ,当然还必须拒绝以  $H_{0}$  为条件的概率,但是这样我们做出效应存在决定的逻辑依据是什么?正统统计在这里逻辑上自相矛盾.",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "杰弗里斯(Jeffreys,1939,第316页)审视了这种自相矛盾的推理,并从另一个角度对此表示惊讶:\"可能为真的假设由于无法预测未发生的可观察的结果而被拒绝.这似乎是一个了不起的流程.从表面上看,可以更合理地将证据视为支持假设的证据,而不是与之相反的证据.\"",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "因此,如果我们说温度是周期性的,意思是存在一些周期性的物理效应在起作用.虽然它的本质可能不能完全确定,但我们可以对此做出一些合理的推测.例如,上述太阳活动的周期性已知是由于太阳黑子数的11年周期性变化而产生的(许多人有充分的理由相信是修正后的22年周期性),这将导致进入大气层的带电粒子数量的周期性变化(观察到的北极光的周期性变化表明了这一点),从而改变离子浓度,并改变雨滴凝结中心的数量,这将导致云层的周期性变化,进而",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "导致温度和降雨的周期性变化。由于普遍的大气环流模式,在地球上的不同位置可能会有很大差异。",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "我们并不是要说我们坚信这一机制是主要的。只是它是可以想到的,而且不违反任何已知的物理定律,但其影响的大小很难单从理论上估计。但是已知这些先验信息,不会使我们对中央公园的温度存在观察到的周期性感到惊讶,并使我们推测7月的温度可能会为存在周期性提供更多的证据。",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "一旦数据为此类周期性提供了轻微的证据,其他观测就可以证实或否定其真实性,并将其他数据(天文、大气电子、鱼类种群等)与许多不同位置的天气数据相关联。仅接受正统统计训练的人会毫不犹豫地认为所有这些现象是\"独立\"的。具有天体物理学与气象学知识的科学家则根本不会这样认为。",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "如果科学期刊的编辑以没有达到  $5\\%$  的显著性检验水平为由拒绝发表第一批细微的证据,那么极可能永远不会有确认性的观测,一个重要发现可能会被延迟一个世纪。物理学家和工程师们在很大程度上摆脱了这个悲惨结局,因为他们几乎从未认真对待过正统统计教条。但是其他从事经济学、人工智能、生物学或医学研究的人不那么幸运,他们过去曾经被费希尔的权威吓倒。",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "我们刚刚指出的立场与费勒(Feller,II,第76~77页)形成鲜明对比,后者对所谓的\"老的错误方法\"进行了评判。假设数据以正弦形式展开为:",
        "page_idx": 12
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{t} = \\sum_{j = 1}^{n}(A_{j}\\cos \\omega_{j}t + B_{j}\\sin \\omega_{j}t). \\tag{17.49}\n$$\n",
        "text_format": "latex",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "我们总是可以这样估计  $y_{t}$  。如果  $\\{y_{t}\\}$  是随机变量,则  $A_{j}$  和  $B_{j}$  似乎也必须是\"随机变量\"。费勒警告我们不要采用老的错误方法:将这样的序列与选择好的频率  $\\{\\omega_{1},\\dots ,\\omega_{n}\\}$  拟合,并假设所有  $A_{j},B_{j}\\sim N(0,\\sigma)$  。如果  $R_{j}^{2} = A_{j}^{2} + B_{j}^{2}$  中的其中一个较大,则可以得出结论存在一个真实周期。他写道:",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "一段时间以来,引入这种形式的模型来检测黑子、小麦价格、诗人的创造力等\"隐藏的周期性\"很时髦。这种隐藏的周期性像中世纪的女巫一样容易被发现,但是,即使再强烈的信念也必须通过统计检验来验证。如果观察到特别大的振幅  $R_{j}$ ,人们希望证明这不是偶然的,因此  $\\omega_{j}$  是一个真实的周期。为了检验这一猜想,我们会问  $R$  的大观测值是否与所有  $n$  个成分都起相同作用的假设合理地兼容。",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "显然,费勒甚至不相信黑子的周期性。一个多世纪以来,没有一位有素养的科学",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "家会对此有什么怀疑.证据非常之多,没有人需要进行\"统计检验\"。他指出,通常的程序是假定  $A_{j},B_{j}$  是iid的正态分布  $N(0,\\sigma)$  .然后  $R_{j}^{2}$  会认为是一个独立的期望值为  $2\\sigma^{2}$  的指数分布.\"如果观测值  $R_{j}^{2}$  显著偏离期望值,习惯上会得出结论:等权重假设是站不住脚的,而  $R_{j}$  代表\"隐藏的周期性\".在这一点上,费希尔认识到我们使用了错误的抽样分布:",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "费希尔揭示了这种推理的谬误,他指出  $n$  次独立观察中的最大值与每个变量分别服从的概率分布不同.在医学统计中,将最坏情况视为好像是随机选择的情况一样对待的错误仍然很常见,但是在此讨论的原因是费希尔显著性检验与覆盖定理之间存在令人惊讶且有趣的联系.",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "费勒然后说,量",
        "page_idx": 13
    },
    {
        "type": "equation",
        "text": "\n$$\nV_{j} = \\frac{R_{j}^{2}}{\\sum R_{j}^{2}},\\qquad 1\\leqslant j\\leqslant n \\tag{17.50}\n$$\n",
        "text_format": "latex",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "是区间(0,1)内被  $n - 1$  个点随机划分为  $n$  段的\"分布\".所有  $V_{j}< a$  的概率由费勒指出的覆盖定理给出.",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "当然,我们的观点是,费勒的\"旧的错误的\"和\"新的正确的\"抽样分布都与推断无关.两个相关的量(表示我们对现象了解的先验信息以及数据的似然函数)甚至没有被提及.",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "无论如何,本次讨论的基本结论是费希尔检验不能检测到纽约中央公园1月温度的明显的20年周期.但是这不是简单的肉眼查看甚至比正统统计教科书中讲授的推断原理更强大的唯一情况.克罗、戴维斯和马克斯菲尔德(Crow,Davis&Maxfield,1960)分析了正统  $F$  检验和  $t$  检验的应用,杰恩斯(Jaynes,1976)也对此进行了研究,得出的结论是:(1)肉眼是比正统双尾检验更可靠的效应指示器,(2)贝叶斯检验能定量确认肉眼看到的定性结果.这也与其他地方讨论的支配性和可容许性概念有关.",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "17.6 贝叶斯分析",
        "text_level": 1,
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "现在,我们来检查相同数据的贝叶斯分析结果.出于教学上的考虑,我们想更详细地解释其基本原理.对于周期性,对应于有关现象的不同信息、不同选择的模型以及有关模型参数的不同先验信息,可能存在各种不同的贝叶斯数据处理方式.我们的贝叶斯模型如下.我们认为由于一些系统性物理作用对天气的影响,",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "温度数据可能具有周期性的分量:",
        "page_idx": 14
    },
    {
        "type": "equation",
        "text": "\n$$\nA\\cos \\omega t + B\\sin \\omega t, \\tag{17.51}\n$$\n",
        "text_format": "latex",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "其中,如前所述,我们可以假设  $|\\omega | \\leqslant \\pi$  (对于年度数据,考虑短于一年的周期是没有意义的)。此外,数据会被可变分量  $e_t$  没染,我们称这种可变分量为\"不规则\"的,因为我们无法控制或预测它们,因此无法考虑它们。这可能是因为我们不知道其真正原因,或者尽管我们知道原因,但是缺少初始条件的数据来做预测。然后,如第7章所述,对真实的先验信息,我们几乎总是可以将具有参数  $(\\mu , \\sigma)$  的高斯抽样分布分配给不规则成分。几乎没有任何实际的问题可以使我们获得更详细的先验信息,以证明更精细的抽样分布更为合理。",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "因此, $\\mu$  是事先未知的\"标称真实平均温度\",可以很容易地从数据中估计出(凭直觉已经可以看到,数据  $\\overline{y}$  的平均值大约等于从所拥有信息中得出的  $\\mu$  的估计值),但这不是我们当前关心的参数,因此将其称为冗余参数。尽管也可以从数据中轻松估计出  $\\sigma$ ,但我们事先也不知道  $\\sigma$ 。这不是我们当前感兴趣的,因此正如第7章中所述,我们也将  $\\sigma$  视为要积分掉的冗余参数。这样,我们的数据模型方程为",
        "page_idx": 14
    },
    {
        "type": "equation",
        "text": "\n$$\ny_t = \\mu + A \\cos \\omega t + B \\sin \\omega t + e_t, \\qquad 1 \\leqslant t \\leqslant n, \\tag{17.52}\n$$\n",
        "text_format": "latex",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "我们的不规则分量的抽样分布是",
        "page_idx": 14
    },
    {
        "type": "equation",
        "text": "\n$$\np(e_1, \\dots , e_n | \\mu \\sigma I) = \\left(\\frac{1}{2\\pi \\sigma^2}\\right)^{n / 2} \\exp \\left\\{-\\frac{1}{2\\sigma^2} \\sum_t e_t^2\\right\\} . \\tag{17.53}\n$$\n",
        "text_format": "latex",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "这样,数据的抽样(密度)分布为",
        "page_idx": 14
    },
    {
        "type": "equation",
        "text": "\n$$\np(y_1, \\dots , y_n | \\mu \\sigma I) = \\left(\\frac{1}{2\\pi \\sigma^2}\\right)^{n / 2} \\exp \\left\\{-\\frac{Q}{2\\sigma^2}\\right\\} , \\tag{17.54}\n$$\n",
        "text_format": "latex",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "带有二次型",
        "page_idx": 14
    },
    {
        "type": "equation",
        "text": "\n$$\nQ(A, B, \\omega) \\equiv \\sum (y_t - \\mu - A \\cos \\omega t - B \\sin \\omega t)^2, \\tag{17.55}\n$$\n",
        "text_format": "latex",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "或者",
        "page_idx": 14
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r l} & {Q = n\\Big[\\overline{{y^{2}}} -2\\overline{{y}}\\mu +\\mu^{2} - 2A\\overline{{y_{t}}}\\cos \\omega t - 2B\\overline{{y_{t}}}\\sin \\omega t + 2\\mu A\\overline{{\\cos\\omega t}}}\\\\ & {\\quad +2\\mu B\\overline{{\\sin\\omega t}} +2A B\\overline{{\\cos\\omega t\\sin\\omega t}} +A^{2}\\overline{{\\cos^{2}\\omega t}} +B^{2}\\overline{{\\sin^{2}\\omega t}}\\Big],} \\end{array} \\tag{17.56}\n$$\n",
        "text_format": "latex",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "其中所有上划线符号均表示  $t$  上的样本均值。这里突然出现了许多在正统统计方法中不存在的细节,但是所有这些细节实际上都与推断有关。在任何非平凡的贝叶斯解中,我们都可能会遇到很多分析细节,因为所有的可能的信息将被考虑在",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "内(这是第1章和第2章中的合情条件的要求).这些细节的绝大部分不为正统统计原理所考虑,也很难用纸笔计算处理.",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "在实践中,贝叶斯主义者学习到,其中的很多细节实际上对最终结果的影响可以忽略不计,因此我们几乎总是可以用纸笔做有针对性的计算,得出很好的近似结果.幸运的是,再复杂的细节也不能吓住计算机,它很容易得到精确解.在当前问题中,(A,B,w)是我们要估计的感兴趣的参数,而(μ,α)是要消除的冗余参数.我们看到(17.56)的9个求和项中,有4个涉及数据y,并且由于这是数据出现的唯一位置,因此这4个求和项是问题中所有5个参数的联合充分统计量.在获得数据之前,可以一次性地对其他5个求和项进行分析求解.",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "现在,我们的先验信息是什么?当然,我们事先知道A,B一定不会超过 $200^{\\circ}\\mathrm{F}$  ,如果温度变化那么大,纽约市将不复存在,任何偶然进人该城市并幸存下来的人都会从该市紧急撤离,因此,纽约市仍然存在的经验事实是与所要提出的问题相关的强有力的信息,它足以保证贝叶斯计算中(A,B)的先验的正常性.同样,我们也没有关于任何周期相位θ=tan- (B/A)的先验信息,因此可以通过  $\\theta$  的均匀先验来表示.",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "我们可以引用一些其他相关先验信息,但是根据第6章练习6.6的结果,我们已知知道,除非有先验信息将可能的范围减小到大约  $30^{\\circ}\\mathrm{F}$  ,否则它对于结论的影响可以忽略不计(如果仅报告精确到三位小数的结论,则绝对可以忽略).因此,让我们看看贝叶斯推断给出的结果,通过本质上与第7章中赫歇尔导出高斯分布基本相同的推导过程,我们可以指定联合先验分布",
        "page_idx": 15
    },
    {
        "type": "equation",
        "text": "\n$$\np(A B|I) = \\frac{1}{2\\pi\\delta^{2}}\\exp \\left\\{-\\frac{A^{2} + B^{2}}{2\\delta^{2}}\\right\\} , \\tag{17.57}\n$$\n",
        "text_format": "latex",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "其中  $\\delta$  的数量级为  $100^{\\circ}\\mathrm{F}$  ,我们预计其确切值不会对结论有明显的影响(尽管如此,这样的正常先验对于防止计算机崩溃可能是必不可少的)",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "现在,贝叶斯定理在此问题上的最一般应用如下.我们首先找到所有5个参数的联合后验分布:",
        "page_idx": 15
    },
    {
        "type": "equation",
        "text": "\n$$\np(A B\\omega \\mu \\sigma |D I) = p(A B\\omega \\mu \\sigma |I)\\frac{p(D|A B\\omega\\mu\\sigma I)}{p(D|I)}. \\tag{17.58}\n$$\n",
        "text_format": "latex",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "然后积分掉冗余参数:",
        "page_idx": 15
    },
    {
        "type": "equation",
        "text": "\n$$\np(A B\\omega |D I) = \\int \\mathrm{d}\\mu \\int \\mathrm{d}\\sigma p(A B\\omega \\mu \\sigma |D I). \\tag{17.59}\n$$\n",
        "text_format": "latex",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "但这比我们目前需要的计算要一般得多,它考虑了先验概率中的任意相关性。实际上,我们总是可以将先验做如下分解:",
        "page_idx": 16
    },
    {
        "type": "equation",
        "text": "\n$$\np(AB\\omega \\mu \\sigma |I) = p(AB\\omega |I)p(\\mu \\sigma |AB\\omega I), \\tag{17.60}\n$$\n",
        "text_format": "latex",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "因此,最一般的解在形式上似乎更简单:",
        "page_idx": 16
    },
    {
        "type": "equation",
        "text": "\n$$\np(AB\\omega |DI) = Cp(AB\\omega |I)L^{*}(A,B,\\omega), \\tag{17.61}\n$$\n",
        "text_format": "latex",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "其中  $c$  是归一化常数,而  $L^{*}$  是拟似然",
        "page_idx": 16
    },
    {
        "type": "equation",
        "text": "\n$$\nL^{*}(A,B,\\omega)\\equiv \\int \\mathrm{d}\\mu \\int \\mathrm{d}\\sigma p(\\mu \\sigma |AB\\omega I)p(D|AB\\omega \\mu \\sigma I). \\tag{17.62}\n$$\n",
        "text_format": "latex",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "在(17.61)中,冗余参数已经不见了,但是在当前的问题中,了解系统周期性参数  $(A,B,\\omega)$  显然不会告诉我们不规则分量参数  $(\\mu ,\\sigma)$  的任何信息,所以后者的先验是",
        "page_idx": 16
    },
    {
        "type": "equation",
        "text": "\n$$\np(\\mu \\sigma |AB\\omega I) = p(\\mu \\sigma |I), \\tag{17.63}\n$$\n",
        "text_format": "latex",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "那么我们关于  $(\\mu ,\\sigma)$  的先验信息是什么呢?当然,出于与\"紧急撤离\"同样的原因,我们也知道,这两个参数都不会超过  $200^{\\circ}\\mathrm{F}$  而且我们也知道  $\\sigma$  不能小到  $10^{- 6^{\\circ}}\\mathrm{F}$  因为毕竟数据是用真实的温度计获取的,没有任何气象学家的温度计能达到该精度(如果可以,它也无法给出达到该精度的可重复读数)。我们也可以忽略这一基于实际的考虑,并认为  $\\sigma$  不可能小至  $10^{- 20^{\\circ}}\\mathrm{F}$  ,因为在统计力学中,温度的概念在该精度上没有定义,从数值上讲,这对于我们的最终结论没有影响,但是仍然可以想象的是,可能需要正常先验才能在所有情况下避免计算机崩溃,因此,为了安全起见,我们将  $\\mu$  的先验设为高斯分布,因为它是一个位置参数,而将  $\\sigma$  的分布设为截断的杰弗里斯先验,因为我们在第12章中已经看到杰弗里斯先验是尺度参数的唯一完全无信息先验:",
        "page_idx": 16
    },
    {
        "type": "equation",
        "text": "\n$$\np(\\mu \\sigma |I)\\propto \\frac{1}{\\sigma\\sqrt{2\\pi\\alpha^{2}}}\\exp \\{-\\mu^{2} / 2\\alpha^{2}\\} ,\\qquad a\\leqslant \\sigma \\leqslant b, \\tag{17.64}\n$$\n",
        "text_format": "latex",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "其中  $\\alpha$  和  $b$  也是  $100^{\\circ}\\mathrm{F}$  的量级,而  $a\\approx 10^{- 6}$  ,我们将它们的阈值设得极为安全,以此期望大多数此类小心翼翼的行为最终将被证明是不必要的。",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "这样,我们的拟似然是",
        "page_idx": 16
    },
    {
        "type": "equation",
        "text": "\n$$\nL^{*}(A,B,\\omega) = \\int_{-\\infty}^{+\\infty}\\mathrm{d}\\mu \\exp \\{-\\mu^{2} / 2\\alpha^{2}\\} \\int_{a}^{b}\\frac{\\mathrm{d}\\sigma}{\\sigma^{n + 1}}\\exp \\{-Q / 2\\sigma^{2}\\} . \\tag{17.65}\n$$\n",
        "text_format": "latex",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "但是现在很明显,对  $\\sigma$  做有限的限制是没有必要的,因为如果  $n > 0$  对  $\\sigma$  的积分会在0和无限大处收敛,并且",
        "page_idx": 16
    },
    {
        "type": "equation",
        "text": "\n$$\n\\int_{0}^{+\\infty}\\frac{\\mathrm{d}\\sigma}{\\sigma^{n + 1}}\\exp \\{-Q / 2\\sigma^{2}\\} = \\frac{1}{2}\\frac{(n / 2 - 1)!}{(Q / 2)^{n / 2}}, \\tag{17.66}\n$$\n",
        "text_format": "latex",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "这一积分对  $\\mu$  也一定收敛. 出于策略考虑, 让我们首先对  $\\mu$  进行积分. 首先将  $Q$  重写为",
        "page_idx": 17
    },
    {
        "type": "equation",
        "text": "\n$$\nQ = n\\left[s^{2} + (\\mu - \\overline{d})^{2}\\right]. \\tag{17.67}\n$$\n",
        "text_format": "latex",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "新编练习17.3(a)  $Q$  的公式与(7.29)在形式上相同, 但是杰恩斯均未定义任一量. 证明  $s^{2}$  可以写成",
        "page_idx": 17
    },
    {
        "type": "equation",
        "text": "\n$$\ns^{2} \\equiv \\overline{d^{2}} - \\overline{d}^{2}, \\tag{17.68}\n$$\n",
        "text_format": "latex",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "其中  $\\overline{d}$  和  $\\overline{d^{2}}$  是定义为",
        "page_idx": 17
    },
    {
        "type": "equation",
        "text": "\n$$\nd_{i} = y_{i} - A \\cos (\\omega t_{i}) - B \\sin (\\omega t_{i}). \\tag{17.69}\n$$\n",
        "text_format": "latex",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "的有效数据的均值和均方.",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "(b)对  $u$  和  $\\sigma$  计算积分以获得边缘密度  $p(AB\\omega |DI)$",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "(c) 不幸的是,  $p(AB\\omega |DI)$  并未汇总数据中关于频率估计的所有信息. 要做到这一点, 我们需要  $p(\\omega |DI)$ . 导出其解析形式.",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "(d) 后验概率  $p(\\omega |DI)$  隐含假设存在共振, 因此将不管这种共振是否存在而估计频率. 你将如何使用概率论和到目前为止的结果来确定是否存在共振?",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "17.7 随机化的愚蠢",
        "text_level": 1,
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "许多人以\"蒙特卡罗积分\"为例介绍随机化方法. 令函数  $y = f(x)$  的存在域为单位正方形  $0 \\leqslant x, y \\leqslant 1$ , 我们希望计算数值积分",
        "page_idx": 17
    },
    {
        "type": "equation",
        "text": "\n$$\n\\theta \\equiv \\int_{0}^{1} \\mathrm{d}x f(x). \\tag{17.70}\n$$\n",
        "text_format": "latex",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "也许函数  $f(x)$  在解析上太复杂了, 或者只是凭经验确定的, 我们没有函数的解析形式. 那么, 让我们在单位平方中随机选择  $n$  个点  $(x, y)$ , 并分别确定其是否位于  $f(x)$  的图下方, 即是否  $y \\leqslant f(x)$ . 设此类点的个数为  $r$ , 然后将积分估计为  $(\\theta)_{\\mathrm{est}} = r / n$ , 并且随着  $n \\rightarrow +\\infty$ , 我们可以期望它接近正确的黎曼积分. 但是它有多精确? 人们总是会假设独立的二项抽样:  $r$  的抽样分布被认为是",
        "page_idx": 17
    },
    {
        "type": "equation",
        "text": "\n$$\np(r|n\\theta) = \\binom{n}{r} \\theta^{r}(1 - \\theta)^{n - r}, \\tag{17.71}\n$$\n",
        "text_format": "latex",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "其 (均值)  $\\pm$  (标准差) 为",
        "page_idx": 17
    },
    {
        "type": "equation",
        "text": "\n$$\n\\theta \\pm \\sqrt{\\frac{\\theta(1 - \\theta)}{n}}. \\tag{17.72}\n$$\n",
        "text_format": "latex",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "如果以抽样分布的宽度表示我们估计的准确性,则可以认为  $(\\theta)_{\\mathrm{est}}$  的合理误差为",
        "page_idx": 18
    },
    {
        "type": "equation",
        "text": "\n$$\n(\\theta)_{\\mathrm{est}} = \\frac{r}{n} \\pm \\sqrt{\\frac{r(n - r)}{n^{3}}}. \\tag{17.73}\n$$\n",
        "text_format": "latex",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "例如,假设  $\\theta$  的真实值为  $1 / 2$ ,并且  $n = 100$ 。那么在观察到  $r = 43$  的情况下,我们可以得出估计",
        "page_idx": 18
    },
    {
        "type": "equation",
        "text": "\n$$\n(\\theta)_{\\mathrm{est}} = 0.43 \\pm \\sqrt{\\frac{0.43 \\times 0.57}{n}} = 0.43 \\pm 0.05, \\tag{17.74}\n$$\n",
        "text_format": "latex",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "或者大约  $11.5\\%$  的精度。但是这种方法的麻烦之处在于只能以  $1 / \\sqrt{n}$  的数量级提高精度。",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "现在,让我们以非随机的方式在均匀网格上获取  $n$  个抽样点:将单位正方形分为  $\\sqrt{n}$  步,在每个网格点获取一个抽样点,然后再次计算曲线下方有多少  $(r)$ 。我们在每个步骤中可能犯的最大误差是",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "因此,积分的最大可能误差为",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "因此,如果  $\\theta \\simeq 0.5$ ,则蒙特卡罗方法中的概然误差大约等于均匀网格抽样方法中的最大可能误差。但是均匀网格方法中的概然误差远小于此:中心极限定理告诉我们,如果在每一步中误差概率都呈矩形分布,则每一步确定  $f(x)$  的期望误差平方是",
        "page_idx": 18
    },
    {
        "type": "equation",
        "text": "\n$$\n\\sqrt{n} \\int_{0}^{\\sqrt{n}} \\mathrm{d}x \\left(x - \\frac{1}{2\\sqrt{n}}\\right)^{2} = \\frac{1}{12n^{2}}. \\tag{17.77}\n$$\n",
        "text_format": "latex",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "如果不同步中的误差是独立的,则总误差的期望平方为",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "积分中概然误差约为",
        "page_idx": 18
    },
    {
        "type": "equation",
        "text": "\n$$\n\\pm \\frac{1}{\\sqrt{12n^{3 / 2}}} \\tag{17.79}\n$$\n",
        "text_format": "latex",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "因此,如果  $n = 100$  且  $\\theta \\simeq 0.5$ ,则蒙特卡罗方法给出的概然误差约为  $0.05$ ,均匀网格抽样的误差为  $0.00913$ ,不到其五分之一。在  $n = 1000$  时,蒙特卡罗概然误差为  $0.0158$ ,均匀网格概然误差为  $0.00162$ ,约为前者的十分之一。在  $n = 100$  点处进行均匀网格抽样计算会产生与在  $n = 3000$  点上做蒙特卡罗抽样相同的概然误差。这与(17.16)后面的陈述相当吻合。罗亚尔和坎伯兰(Royall & Cumberland, 1981)给出了另一个例子,这是特别有说服力的,因为作者不是贝叶斯主义者,并不以揭示随机化的愚蠢为出发点,但得到的结论都是如此。",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "17.8 费希尔:洛桑农业研究所的常识",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "通过研究几个这样的例子,我们提出一个一般原则:每当用一种随机方法做某事时,就会有一种非随机方法能从相同的数据中得到更好的结果,但是这需要更多的思考.也许这一原则并不完全是一个定理,但是我们相信,只要有人愿意做必要的额外思考,它就会得到证实.",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "贝叶斯安全装置",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "我们注意到贝叶斯方法不仅比正统方法更强大,而且更安全(即它们具有内置的自动安全装置,可以防止正统方法可能产生的过于乐观或悲观的结论,以防误导我们).很重要的是理解为什么这是真的.例如,在参数估计中,无论是否存在充分统计量,对数似然函数都是",
        "page_idx": 19
    },
    {
        "type": "equation",
        "text": "\n$$\n\\ln L(\\alpha) = \\sum_{i = 1}^{n}\\ln p(x_{i}|\\alpha) = n\\overline{\\ln p(x_{i}|\\alpha)}, \\tag{17.80}\n$$\n",
        "text_format": "latex",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "其中,我们看到了每个单独数据点上对数似然的平均值.对数似然总是分布在数据的整个可变范围内,因此,如果我们碰巧得到非常差的(散布)数据集,则不可能有很好的估计值,贝叶斯定理会通过返回较宽的后验分布来警告我们.在位置参数  $p(x|\\alpha) = h(x - \\alpha)$  且无信息先验的情况下,  $\\alpha$  的后验分布的宽度实质上为 $(R + W)$",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "如果我们碰巧得到一个很好(尖锐集中)的数据集,则可能会更精确地估计  $\\alpha$  值,贝叶斯定理将利用这一点,返回一个宽度接近于单点似然  $L_{i}(\\alpha) = p(x_{i}|\\alpha)$  和数据量  $n$  确定的下界的后验分布.",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "在正统方法中,精度本质上是我们选择的估计量  $\\beta$  的抽样分布宽度.但这并没有说明数据值域!无论数据值域的大小,基于单个统计量的正统估计都具有相同的精度.更糟糕的是,这种精度完全表示相对于可能但未真正获得的其他数据集的估计量的可变性.但这又将注意力集中在了无关紧要的问题上,忽略了真正相关的问题——未观察到的数据集只是我们想象的缩影.当然,如果我们可以想象它们,那么我们也可以自由想象我们喜欢的任何其他东西.也就是说,给定两个关于未观察到的数据的猜想,我们能通过什么检验来确定哪个正确呢?",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "尽管数学上很简单,但我们强调(17.80)对于证明贝叶斯定理的内在机理至关重要.它阐明了有关贝叶斯方法经常提出的其他几个问题.我们注意到以下是最重要的问题之一.",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "17.9 缺失数据",
        "text_level": 1,
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "对我们来说,这不存在任何问题,无论我们拥有什么数据,贝叶斯方法都使用相同的算法,例如,在根据数据集  $D\\equiv \\{x_{i}\\}$  估计参数  $\\theta$  时,其中指标  $i$  指的是观测时间  $\\{t_{i}\\}$  ,并取在某个集合  $T$  中的值,数据通过似然函数  $L$  影响结果,似然函数定义为",
        "page_idx": 20
    },
    {
        "type": "equation",
        "text": "\n$$\n\\ln L(\\theta) = \\sum_{i\\in T}\\ln p(x_{i}|\\theta), \\tag{17.82}\n$$\n",
        "text_format": "latex",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "其中求和是针对我们拥有的所有数据的,关键是,无论时间  $\\{t_{i}\\}$  是连续且等距的,还是完全不规则且间隔很大的,都没有区别,作为逻辑的概率论告诉我们,(17.82)会得到最优推断,该推断捕获了我们碰巧拥有的数据集中的所有证据,我们可以一劳永逸地编写一个计算机程序,它接受我们提供的任何数据(即任意一组数  $\\{x_{i};t_{i}\\}$  ),然后继续对该数据集进行正确的计算",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "相比之下,请注意在正统统计中会发生什么,在这种情况下,估计必须通过某个\"统计量\"  $\\theta^{*}(x_{i})$  的抽样分布来进行,如果在设定问题时假定的集合  $T$  中缺少任何数据,则有两种方法可以解决问题,第一,理论上正确的流程将认识到,这不仅改变了统计量的抽样分布,而且需要重新考虑整个问题,这会使我们陷入可怕的境地——每一种不同类型的缺失数据或额外数据都可能使我们不得不定义新的样本空间,选择新的统计量  $\\theta^{**}$  并计算新的抽样分布  $p(\\theta^{**}|\\theta)$",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "第二,人们可以发明一种新的特定工具,尝试根据已有数据估计出缺失值,并将其当作真实数据来使用,显然,此过程不仅逻辑上不合理,而且存在很大的不确定性,因为可以用许多不同的方式估计缺失值,这些困难在利特尔和鲁宾的著作(Little&Rubin,1987)中可以直接看到",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "缺失数据问题在正统统计中非常麻烦,以至于有些看到光明并转入贝叶斯阵营的人没有意识到他们实际上已经将这个问题抛在了身后,他们不直接应用诸如(17.82)这样的简单规则(无论使用什么数据,它们都将立即得到正确解),而是出于习惯,遵循正统习俗并发明如上新的特定工具,作为对贝叶斯方法或最大熵方法的\"校正\",并通过更多的计算做出更差的推断,对于那些习惯于正统统计所遇到的困难的人来说,贝叶斯方法在应用中的强大和简单性似乎令人难以置信;人们必须深入且长久地思考,以理解这如何可能",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "作为更一般的评论,几乎在所有这些贝叶斯/正统方法的比较中都可以使用一种简单的策略:如第9章中卡方检验所示的\"放大\"当我们得到一个正统和贝叶斯方法的定量结果时,乍看起来差别可能很小,我们凭常识无法判断哪个更好,但是,我们通常会发现,在一些极端的问题中,这些微小的差别会被放大,甚至",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "会得到定性结论上的差别。这时, 常识将清楚地告诉我们, 哪一种流程给出了合理的结果。确实, 差别通常有可能被放大到, 一种流程明显违反演绎推理原则或导致类似前面对无偏估计所指出的那种病态。现在, 我们将研究另一个非常重要的示例, 其中可以通过放大比较正统方法和贝叶斯方法的结果。",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "17.10 时间序列中的趋势和季节性",
        "text_level": 1,
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "现实世界产生的观测时间序列很少是\"平稳的\", 而是表现出更复杂的行为。在大多数时间序列数据中, 尤其是在人口统计或经济数据中, 非平稳性的最常见形式是呈现某种趋势。许多经济时间序列受趋势支配 (例如, 由于人口稳定增长、通货膨胀或技术进步), 以至于试图研究其他规律性——例如周期性波动或在冲击反应后的回落, 特别是不同时间序列的相关性——的任何尝试, 在我们能安全地处理趋势之前可能会对我们产生误导, 而不是有所帮助。",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "一个故事——也许是伪造的——讲的是, 一名研究人员宣称发现英格兰教会成员与自杀事件数量之间有很强的正相关关系, 并得出远离教会会更安全的结论。当然, 真正的原因是英格兰人口在稳定增长, 所以教会的成员人数、自杀的发生率以及几乎所有其他人口统计学变量都在一起增长。由于几乎普遍存在的倾向是直接跳到相关暗示着因果关系的结论, 这种错误的相关性导致了许多荒谬的结论。",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "数据污染的问题从一开始就一直困扰着我们。我们在第9章中曾指出, 埃德蒙·哈雷 (Edmund Halley, 1693) 在编制第一批死亡率表时是如何处理这一问题的。处理它的关键是要认识到冗余参数在概率论中的作用。",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "同样, 今天的许多时间序列数据受到周期性波动 (经济数据的季节效应, 天气的周期性, 电路的嗡嗡声, 细菌的滋生, 直升机叶片的振动) 的支配, 从而试图提取背后\"信号\"——例如作为从短期数据中得到长期趋势——的尝试都非常困难。我们想对比一下, 尽管存在这种数据污染, 正统统计学和作为逻辑的概率论会分别如何处理提取所需信息的问题。",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "17.10.1 正统方法",
        "text_level": 1,
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "传统的流程不将概率论应用于这个问题。取而代之的是, 人们诉诸我们之前经常提到的那些基于直觉的特定工具。在经济学文献中, 通常将其称为\"去趋势\"和\"季节性调整\"; 在电气工程文献中, 则将其称为\"滤波\"。像所有并非源于第一原理的特定工具一样, 它们捕获了足够的真实性, 可以在某些问题中使用, 但在其他问题上使用时会带来灾难。",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "经济学中几乎通用的去趋势流程是假设数据 (或数据的对数) 为  $y(t) = x(t)+$",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "$B t + \\epsilon (t)$ . 它由我们感兴趣的分量  $x(t)$  、线性\"趋势\"  $B t$  和\"随机误差\"或\"噪声\"  $e(t)$  组成. 我们估计趋势分量, 将其从数据中减去, 然后继续分析所得的\"去趋势后的数据\"是否有其他效应. 但是, 许多人指出, 去趋势可能会引入人为的假象, 从而扭曲其他效应的证据. 去趋势甚至可能会破坏我们关心的数据的相关性. 在中央公园天气的例子中, 我们看到数据滤波也可能会做这种事.",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "同样, 处理季节性影响的传统方法是生成\"做过季节性调整\"的数据, 其中, 人们从真实数据中减去对季节性成分的估计值, 然后尝试分析经过调整的数据是否存在其他效应. 事实上, 我们可以获得的大多数经济时间序列数据可能已经变得近乎无用, 因为它们已经以一种不可逆的方式做过季节性调整, 从而破坏了概率论可能从原始数据中提取的信息. 我们认为必须认识到这一点, 研究人员必须能够获得真实的数据——未受去趋势、季节性调整、预滤波、平滑或任何其他破坏数据中信息处理的因素影响.",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "电气工程师会考虑进行傅里叶分析, 采用\"高通滤波器\"和\"带阻滤波器\"来处理趋势和季节性. 同样, 理念是要产生一个新的时间序列 (滤波器的输出), 从某种意义上代表没有污染效应的真实序列的估计. 选择物理上可实现的\"最优\"滤波器是一个困难且从根本上不确定的问题. 幸运的是, 如果人们事先知道会产生哪种污染, 凭直觉就能发明出足够好的滤波器.",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "17.10.2 贝叶斯方法",
        "text_level": 1,
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "直接应用作为逻辑的概率论使我们得出完全不同的理念. 正确的流程总是根据已知的条件来计算我们感兴趣的未知量的概率. 这意味着我们不会试图从数据中去除趋势或季节性成分: 从根本上讲这是不可能的, 因为无法知道\"真实\"趋势或季节项. 关于它们的任何假设都必然在某种程度上是任意的, 因此几乎可以肯定的是, 会将虚假信息注入经过去趋势或做季节性调整的序列中. 相反, 我们力求考虑我们拥有的所有相关信息, 同时保持实际数据不变, 从最终结论中消除趋势或季节性的影响. 我们为此发展了贝叶斯方法, 并将其与常规方法进行了详细比较.",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "我们将首先分析最简单的模型, 该模型可以通过任一方法完全解决, 从而使我们能够了解这两种流程之间的确切关系. 对此有了理解之后, 扩展到复杂的多元情况将是一种简单的数学推广——本质上, 它只是将数字变为矩阵, 同时保留相同的方程.",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "假设模型仅包含一个正弦波和一个线性趋势项:  $y(t) = A \\sin \\omega t + B t + e(t)$ , 其中  $A$  是要估计的幅度,  $B$  是未知趋势率. 如果数据是月度经济数据, 而正弦",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "波代表年度季节性效应,那么  $\\omega$  将为  $2\\pi /12 \\approx 0.524$  (月  ${}^{- 1}$  ),但是如果我们尝试检测周期为20年的周期,则  $\\omega$  将为  $0.524 / 20 = 0.0262$  。根据这些数据估计未知的  $\\omega$  是频谱分析中的重要问题,这也是中央公园的天气问题中的情况。我们现在考虑  $\\omega$  已知的情况(这通常是出于我们知道出于天文学的原因,季节的周期为一年)。为简洁起见,记  $s_{t} = s(t) \\equiv \\sin (\\omega t)$ ,这样我们的模型方程为",
        "page_idx": 23
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = A s(t) + B t + e(t), \\tag{17.83}\n$$\n",
        "text_format": "latex",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "可用数据  $y \\equiv (y_{1}, \\dots , y_{N})$  是在  $N$  个等间隔时间  $t = 1,2, \\dots , N$  处的值。出于已经充分说明的原因,我们分配噪声分量  $e_{i}$  为独立的方差为  $\\sigma^{2}$  的高斯先验概率密度函数  $e_{t} \\sim N(0, \\sigma)$ ,数据的抽样PDF为",
        "page_idx": 23
    },
    {
        "type": "equation",
        "text": "\n$$\np(y|AB\\sigma) = \\left(\\frac{1}{2\\pi\\sigma^{2}}\\right)^{N / 2} \\exp \\left\\{-\\frac{N}{2\\sigma^{2}} Q(A,B)\\right\\} , \\tag{17.84}\n$$\n",
        "text_format": "latex",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "就像任何高斯分布的计算一样,第一个任务是将二次型重新排列为",
        "page_idx": 23
    },
    {
        "type": "equation",
        "text": "\n$$\nQ(A,B) \\equiv \\frac{1}{N} \\sum_{t}(y_{t} - A s_{t} - B t)^{2} = \\overline{y^{2}} + A^{2}\\overline{s^{2}} + B^{2}\\overline{t^{2}} - 2A\\overline{s y} - 2B\\overline{t y} + 2A B\\overline{s t},\n$$\n",
        "text_format": "latex",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "其中",
        "page_idx": 23
    },
    {
        "type": "equation",
        "text": "\n$$\n\\overline{y^{2}} \\equiv \\frac{1}{N} \\sum_{t = 1}^{N} y_{t}^{2}, \\quad \\overline{s y} \\equiv \\frac{1}{N} \\sum_{t = 1}^{N} s_{t} y_{t}, \\tag{17.86}\n$$\n",
        "text_format": "latex",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "等等表示数据样本的平均值。这些平均值中的三个  $\\left(\\overline{s^{2}}, \\overline{t^{2}}, \\overline{s t}\\right)$  是由\"实验设计\"确定的,可以在获得数据之前知道。实际上,我们几乎有",
        "page_idx": 23
    },
    {
        "type": "equation",
        "text": "\n$$\n\\overline{s^{2}} \\simeq 1 / 2, \\quad \\overline{t^{2}} \\simeq N^{2} / 3, \\tag{17.87}\n$$\n",
        "text_format": "latex",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "它们具有数量级  $O(1 / N)$  的误差。但是  $\\overline{s t}$  是高度可变的,因为它只有在每个抽样点  $s(t) = 1$  时才能达到,所以它肯定小于  $N / 2$ 。通常,由于正负项近似相互抵消, $\\overline{s t}$  远小于此,大约是  $\\overline{s t} \\simeq 1 / \\omega$  的数量级。",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "其他三个平均值  $\\left(\\overline{y^{2}}, \\overline{s y}, \\overline{t y}\\right)$  依赖于数据,并且由于它们是包含数据的仅有的项,因此对我们的问题而言是联合充分统计量,只要有数据就可以计算。",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "假设我们希望估计的是季节性波动振幅大小  $A$ ,而趋势率  $B$  是污染我们数据的冗余参数。我们希望使其影响尽可能消失。我们将通过找到  $A$  和  $B$  的联合后验分布来做到这一点,",
        "page_idx": 23
    },
    {
        "type": "equation",
        "text": "\n$$\np(AB|DI), \\tag{17.88}\n$$\n",
        "text_format": "latex",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "然后对  $B$  进行积分以获得  $A$  的边缘后验分布,",
        "page_idx": 23
    },
    {
        "type": "equation",
        "text": "\n$$\np(A|DI) = \\int \\mathrm{d}B p(AB|DI). \\tag{17.89}\n$$\n",
        "text_format": "latex",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "无论  $B$  的值如何,这个量都将告诉我们所有数据  $D$  和先验信息  $I$  能告诉我们的  $A$  的信息,这就是所谓的\"贝叶斯去趋势\"方法,相反,如果我们想估计  $B$ ,则  $A$  将是冗余参数,将其与(17.88)进行积分以获得边缘后验分布  $p(B|DI)$ ,这就是所谓的\"贝叶斯季节性调整\"方法。",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "在  $A$  和  $B$  为散布先验(即它们的先验密度在高可能区域内没有明显变化)的极限情况下,(17.89)的合适积分公式为",
        "page_idx": 24
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r l} & {\\int_{-\\infty}^{+\\infty}\\mathrm{d}B\\exp \\left\\{-\\frac{N Q(A,B)}{2\\sigma^{2}}\\right\\}}\\\\ & {= (\\frac{\\sqrt{\\pi}}{\\sqrt{\\pi}}\\times \\exp \\left\\{-\\frac{N}{2\\sigma^{2}}\\left[\\frac{\\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{t^{2}}}\\right) - \\left(\\overline{{s t}}\\right)^{2}}{\\overline{{t^{2}}}}\\right]\\left(A - \\hat{A}\\right)^{2}\\right\\} ,} \\end{array} \\tag{17.90}\n$$\n",
        "text_format": "latex",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "其中(常数)独立于  $A$  且",
        "page_idx": 24
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{A} \\equiv \\frac{\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s y}}\\right) - \\left(\\overline{{s t}}\\right)\\left(\\overline{{t y}}\\right)}{\\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{t^{2}}}\\right) - \\left(\\overline{{s t}}\\right)^{2}}, \\tag{17.91}\n$$\n",
        "text_format": "latex",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "因此,  $A$  的边缘后验分布与(17.90)成正比,无论  $B$  的值如何,  $A$  的贝叶斯后验(均值)  $\\pm$  (标准差)估计都是",
        "page_idx": 24
    },
    {
        "type": "equation",
        "text": "\n$$\n(A)_{\\mathrm{est}} = \\hat{A} \\pm \\sigma \\sqrt{\\frac{t^{2}}{N\\left[\\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{t^{2}}}\\right) - \\left(\\overline{{s t}}\\right)^{2}\\right]}} = \\hat{A} \\pm \\frac{\\sigma}{\\sqrt{N\\overline{{s^{2}}}\\left(1 - r^{2}\\right)}}, \\tag{17.92}\n$$\n",
        "text_format": "latex",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "其中",
        "page_idx": 24
    },
    {
        "type": "equation",
        "text": "\n$$\nr \\equiv \\frac{\\overline{{s t}}}{\\sqrt{s^{2}t^{2}}} \\tag{17.93}\n$$\n",
        "text_format": "latex",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "是  $s$  和  $t$  的相关系数",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "一些正统统计学家反对这种积分掉冗余参数的过程——尽管这是由概率论规则确定的唯一正确的流程——理由通常是这样的参数概率无意义,因为这些参数不是\"随机变量\"。更糟糕的是,在积分过程中,我们还引入了一个他们认为是随意的先验(虽然对我们来说,它代表了先验信息的真实状态,该状态与推断相关,但被正统方法忽略了)。但是,独立于所有此类理念上悬而未决的争论,我们可以检查贝叶斯和正统方法的实际效果。",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "对冗余参数积分可以如以下方程所示与去趋势流程相关联,联合后验PDF可以通过两种不同的方式分解为边缘PDF和条件PDF:",
        "page_idx": 24
    },
    {
        "type": "equation",
        "text": "\n$$\np(AB|DI) = p(A|DI)p(B|ADI), \\tag{17.94}\n$$\n",
        "text_format": "latex",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "或者",
        "page_idx": 24
    },
    {
        "type": "equation",
        "text": "\n$$\np(AB|DI) = p(A|BDI)p(B|DI). \\tag{17.95}\n$$\n",
        "text_format": "latex",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "根据 (17.94),我们可以立即得到 (17.89),根据 (17.95),我们看到 (17.89) 可以写成",
        "page_idx": 25
    },
    {
        "type": "equation",
        "text": "\n$$\np(A|D I) = \\int \\mathrm{d}B p(A|B D I)p(B|D I). \\tag{17.96}\n$$\n",
        "text_format": "latex",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "因此  $A$  的边缘PDF是  $B$  已知时条件PDF的加权平均:",
        "page_idx": 25
    },
    {
        "type": "equation",
        "text": "\n$$\np(A|B D I). \\tag{17.97}\n$$\n",
        "text_format": "latex",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "但是如果  $B$  已知,则 (17.97) 依赖于  $A$ ,正好是  $B$  保持固定的 (17.84)。根据 (17.85),这是",
        "page_idx": 25
    },
    {
        "type": "equation",
        "text": "\n$$\np(A|B D I)\\propto \\exp \\left\\{-\\frac{N s^{2}}{2\\sigma^{2}}\\big(A - A^{*}\\big)^{2}\\right\\} , \\tag{17.98}\n$$\n",
        "text_format": "latex",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "其中",
        "page_idx": 25
    },
    {
        "type": "equation",
        "text": "\n$$\nA^{*}\\equiv \\frac{\\overline{{s y}} - B\\overline{{s t}}}{\\overline{{s^{2}}}}. \\tag{17.99}\n$$\n",
        "text_format": "latex",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "这只是人们通过对去趋势数据后  $y(t)_{\\mathrm{det}}\\equiv y(t) - B t$  与  $A s(t)$  进行普通最小二乘拟合的估计",
        "page_idx": 25
    },
    {
        "type": "equation",
        "text": "\n$$\nA^{*} = \\frac{\\left(\\overline{{s y}}\\right)_{\\mathrm{det}}}{\\left(\\overline{{s^{2}}}\\right)}. \\tag{17.100}\n$$\n",
        "text_format": "latex",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "也就是说,  $A^{*}$  是正统主义者将趋势率估计为  $B$  时所做的估计。当然,如果他对  $B$  的估计是完全正确的,那么他的确会找到最优估计。但是他对趋势率的估计中的任何错误都会使他对  $A$  的估计产生偏差。",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "根据 (17.96) 得出的  $A$  的贝叶斯估计不假定任何特定趋势率  $B$ ,它是所有可能的趋势率根据各自的后验概率所做的加权平均。因此,如果趋势率由数据很好地确定,从而 (17.96) 中的概率  $p(B|D I)$  在  $B = B^{*}$  处有一个尖峰,而且正统主义者也碰巧将  $B$  估计为  $B^{*}$ ,那么贝叶斯和正统方法对  $A$  的估计将是一致的。如果趋势率不能由数据很好地确定,则贝叶斯估计是一个很保守的估计,它考虑到了  $B$  的所有可能值,而这可能与正统估计相差很大。",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "尽管正统主义者可能承认我们做了数学上一致的推断,但是这一论证并不能使他相信贝叶斯估计的优越性(通常隐含地基于二次损失函数),因为他是根据不同的标准来评判估计效果的。因此,让我们更仔细地对它们进行比较。",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "17.10.3 贝叶斯和正统估计的比较",
        "text_level": 1,
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "得到贝叶斯估计量(定理证明该结果按照贝叶斯效果标准是最优的)之后,我们可以从正统抽样理论的角度来检查其效果,并将其与正统估计值进行比较。",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "我们引入一种这样做的有用方法,该方法使得我们能清楚地知道两种方法分别在做什么.令  $A_{0}$  和  $B_{0}$  是参数的未知真值,让我们将情况描述为人们已经知道  $A_{0}$  和  $B_{0}$  的值,但是不知道将发现什么数据,他将知道,我们的数据实际上是",
        "page_idx": 26
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{t} = A_{0}s_{t} + B_{0}t + e_{t}, \\tag{17.101}\n$$\n",
        "text_format": "latex",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "我们将计算统计量",
        "page_idx": 26
    },
    {
        "type": "equation",
        "text": "\n$$\n\\overline{{s y}} = A_{0}\\overline{{s^{2}}} +B_{0}\\overline{{s t}} +\\overline{{s e}}, \\tag{17.102}\n$$\n",
        "text_format": "latex",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "其中前两个项是固定的(即与噪声无关),只有最后一项随着不同的噪声样本变化.同样,他知道我们将找到统计量",
        "page_idx": 26
    },
    {
        "type": "equation",
        "text": "\n$$\n\\overline{{t y}} = A_{0}\\overline{{s t}} +B_{0}\\overline{{t^{2}}} +\\overline{{t e}}. \\tag{17.103}\n$$\n",
        "text_format": "latex",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "尽管根据数据知道  $\\overline{{s y}}$  和  $\\overline{{t y}}$  ,但由于  $\\overline{{s e}}$  和  $\\overline{{t e}}$  未知,我们无法求解(17.102)和(17.103)中的  $(A_{0},B_{0})$  .我们不得不继续使用概率论来获得  $A_{0},B_{0}$  的最优估计.将(17.102)和(17.103)代入(17.91),我们发现贝叶斯估计简化为",
        "page_idx": 26
    },
    {
        "type": "equation",
        "text": "\n$$\n\\left(\\hat{A}\\right)_{\\mathrm{Bayes}} = A_{0} + \\frac{\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s e}}\\right) - \\left(\\overline{{s t}}\\right)\\left(\\overline{{t e}}\\right)}{\\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{t^{2}}}\\right) - \\left(\\overline{{s t}}\\right)^{2}}, \\tag{17.104}\n$$\n",
        "text_format": "latex",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "由于  $B_{0}$  已抵消,它与真实趋势率无关,因此,贝叶斯估计确实从结果中完全消除了趋势的影响,没有人能做得比这更彻底,但是未知的误差  $e$  必然会让我们对A的估计产生一些误差,而(17.104)能准确地告诉我们误差是多少.",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "另外,如果正统主义者使用基于任何估计  $\\hat{B}$  、消除趋势后的数据  $[y_{t} - \\hat{B} t]$  的常规最小二乘法估计量(17.100),他将得到",
        "page_idx": 26
    },
    {
        "type": "equation",
        "text": "\n$$\n\\left(\\hat{A}\\right)_{\\mathrm{orthodox}} = A_{0} + \\frac{\\overline{{s e}} + \\left(B_{0} - \\hat{B}\\right)\\overline{{s t}}}{\\overline{{s^{2}}}}, \\tag{17.105}\n$$\n",
        "text_format": "latex",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "趋势率估计  $\\hat{B}$  的任何误差都会导致他对季节性成分的估计的误差,如果按照惯例,使用从原始数据得出的趋势的普通最小二乘估计",
        "page_idx": 26
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{B} = \\frac{\\left(\\overline{{t y}}\\right)}{\\left(\\overline{{t^{2}}}\\right)}, \\tag{17.106}\n$$\n",
        "text_format": "latex",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "(17.105)变成",
        "page_idx": 26
    },
    {
        "type": "equation",
        "text": "\n$$\n\\left(\\hat{A}\\right)_{\\mathrm{orthodox}} = A_{0} + \\frac{\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s e}}\\right) - \\left(\\overline{{t y}}\\right)\\left(\\overline{{s t}}\\right) + B_{0}\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s t}}\\right)}{\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s^{2}}}\\right)} = \\left(1 - r^{2}\\right)A_{0} + \\frac{\\left(\\overline{{s e}}\\right)}{\\left(\\overline{{s^{2}}}\\right)},\n$$\n",
        "text_format": "latex",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "(17.107)",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "其中再次使用了(17.102)和(17.103).因此(17.107)也与真实趋势率  $B_{0}$  完全无关.但是正统统计认为,估计值(17.107)具有负偏差,因为  $\\overline{{s e}}$  \"平均\"为0. 人",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "们可能希望通过与(17.6)中相同的方法对此进行\"校正\":通过乘以适当的系数.但这显然不是最优方法.仅将普通最小二乘估计值乘以一个常数不可能找到最优估计量.",
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "同样,正统主义者在认识到(17.107)的缺陷之后,认知到贝叶斯结果(17.104)从他的角度来看至少具有无偏的优点,但仍然不会因此认为贝叶斯解是最优的.的确,一个受到强大的反贝叶斯主义教育的人不太可能接受这样的现实,而是会说我们从正统的角度出发更仔细思考后应该能纠正(17.107)的缺陷.让我们尝试一下.",
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "17.10.4 改进的正统估计",
        "text_level": 1,
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "回到问题的开始,正统方法推理的过程如下.如果只考虑季节因素而没有意识到趋势,则将导致估计周期性幅度为",
        "page_idx": 27
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{A}^{(0)} = \\frac{\\left(\\overline{{s y}}\\right)}{\\left(\\overline{{s^{2}}}\\right)}, \\tag{17.108}\n$$\n",
        "text_format": "latex",
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "这是常规的回归解.许多不同的推理方法,包括将数据与正弦波  $A s_{t}$  拟合的普通最小二乘法,将导致我们得出这一结果.",
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "但是后来人们意识到(17.108)并不是一个很好的估计,因为它忽略了干扰的趋势效应.根据消除趋势数据后可以得出更好的季节性估计",
        "page_idx": 27
    },
    {
        "type": "equation",
        "text": "\n$$\n(y_{t})_{\\mathrm{det}}\\equiv y_{t} - \\hat{B} t, \\tag{17.109}\n$$\n",
        "text_format": "latex",
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "其中  $\\hat{B}$  是趋势率的估计值,似乎可以很自然地通过普通的对数据拟合直接直线 $B t$  的普通最小二乘法估计它",
        "page_idx": 27
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{B}^{(0)} = \\frac{\\left(\\overline{{t y}}\\right)}{\\left(\\overline{{t^{2}}}\\right)}. \\tag{17.110}\n$$\n",
        "text_format": "latex",
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "使用(17.108)中的去趋势数据(17.109)得出\"校正\"的周期性幅度估计",
        "page_idx": 27
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{A}^{(1)} = \\frac{\\overline{{s y}} - s t\\hat{B}^{(0)}}{\\overline{{s^{2}}}} = \\frac{\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s y}}\\right) - \\left(\\overline{{s t}}\\right)\\left(\\overline{{t y}}\\right)}{\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s^{2}}}\\right)}, \\tag{17.111}\n$$\n",
        "text_format": "latex",
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "这是该问题的常规正统统计结果",
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "但是,现在我们看到这还不是故事的结束.由于  $A$  和  $B$  出于相同的原因进人模型,如果确实应该从去趋势数据  $y_{t} - \\hat{B}^{(0)}t$  估计周期性幅度  $A$  ,则同样应该从已去周期性的数据  $y_{t} - \\hat{A}^{(0)}s_{t}$  估计趋势率  $B$  ,因此,比(17.110)更好的对趋势",
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "的估计将是",
        "page_idx": 28
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{B}^{(1)} = \\frac{\\left(\\overline{{t y}}\\right) - \\left(\\overline{{s t}}\\right)\\hat{A}^{(0)}}{\\left(\\overline{{t^{2}}}\\right)} = \\frac{\\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{t y}}\\right) - \\left(\\overline{{s t}}\\right)\\left(\\overline{{s y}}\\right)}{\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s^{2}}}\\right)}, \\tag{17.112}\n$$\n",
        "text_format": "latex",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "其中使用了(17.108).但是现在有了对趋势的更好估计,我们可以通过使用(17.112)估计比(17.111)更好的季节性成分:",
        "page_idx": 28
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{A}^{(2)} = \\frac{\\left(\\overline{{s y}}\\right) - \\left(\\overline{{s t}}\\right)\\hat{B}^{(1)}}{\\left(\\overline{{s^{2}}}\\right)}. \\tag{17.113}\n$$\n",
        "text_format": "latex",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "这一改进后的季节性幅度估计值将使我们能够更好地估计趋势",
        "page_idx": 28
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{B}^{(2)} = \\frac{\\left(\\overline{{t y}}\\right) - \\left(\\overline{{s t}}\\right)\\hat{A}^{(1)}}{\\left(\\overline{{t^{2}}}\\right)}. \\tag{17.114}\n$$\n",
        "text_format": "latex",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "可以一直这样进行下去",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "因此,如果一贯地应用常规的去趋势流程的推理过程,并不会止于常规结果(17.100).它会导致我们进入估计的反复修正的无限序列,每一个集合  $\\hat{A}^{(n)}$ $\\hat{B}^{(n)}\\big]$  都比前一个  $\\big[\\hat{A}^{(n - 1)},\\hat{B}^{(n - 1)}\\big]$  更好.这个无限序列会不会收敛到最终的\"总体最优\"的估计  $\\big[\\hat{A}^{(\\infty)},\\hat{B}^{(\\infty)}\\big]$  呢?如果是这样,这无疑是从正统统计角度处理余参数的最优方法.但是,我们可以直接计算这一总体最优估计而无须无限次更新序列吗?",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "为了回答这个问题,定义  $n$  阶估计的  $(2\\times 1)$  向量为",
        "page_idx": 28
    },
    {
        "type": "equation",
        "text": "\n$$\nV_{n}\\equiv \\left(\\overset {\\hat{A}^{(n)}}{\\hat{B}^{(n)}}\\right). \\tag{17.115}\n$$\n",
        "text_format": "latex",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "然后,根据(17.111)~(17.113)可以看到,一般的递归关系是",
        "page_idx": 28
    },
    {
        "type": "equation",
        "text": "\n$$\nV_{n + 1} = V_{0} + M V_{n}, \\tag{17.116}\n$$\n",
        "text_format": "latex",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "其中矩阵  $M$  是",
        "page_idx": 28
    },
    {
        "type": "equation",
        "text": "\n$$\nM = \\left( \\begin{array}{c c}{0} & {-\\frac{\\left(\\overline{{s t}}\\right)}{\\left(\\overline{{s^{2}}}\\right)}}\\\\ {\\frac{\\left(\\overline{{s t}}\\right)}{\\left(\\overline{{t^{2}}}\\right)}} & 0 \\end{array} \\right). \\tag{17.117}\n$$\n",
        "text_format": "latex",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "递归关系(17.116)的解是",
        "page_idx": 28
    },
    {
        "type": "equation",
        "text": "\n$$\nV_{n} = (I + M + M^{2} + \\dots +M^{n})V_{0}. \\tag{17.118}\n$$\n",
        "text_format": "latex",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "根据施瓦茨不等式有  $\\left(\\overline{{s t}}\\right)^{2}\\leqslant \\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{t^{2}}}\\right)$  ,  $M$  的特征值小于1,因此当  $n\\rightarrow +\\infty$",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "时, 该无穷级数之和为",
        "page_idx": 29
    },
    {
        "type": "equation",
        "text": "\n$$\nV_{\\infty} = (I - M)^{-1} V_{0}. \\tag{17.119}\n$$\n",
        "text_format": "latex",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "现在我们容易发现",
        "page_idx": 29
    },
    {
        "type": "equation",
        "text": "\n$$\n(I - M)^{-1} = \\frac{1}{\\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{t^{2}}}\\right) - \\left(\\overline{{s t}}\\right)^{2}}\\left(\\begin{array}{c c}{{\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s^{2}}}\\right)}}&{{-\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s t}}\\right)}}\\\\ {{-\\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{s t}}\\right)}}&{{\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s^{2}}}\\right)}}\\end{array}\\right), \\tag{17.120}\n$$\n",
        "text_format": "latex",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "所以我们最终的总体最优的估计是",
        "page_idx": 29
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{A}^{(\\infty)} = \\frac{\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s^{2}}}\\right)\\hat{A}^{(0)} - \\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s t}}\\right)\\hat{B}^{(0)}}{\\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{t^{2}}}\\right) - \\left(\\overline{{s t}}\\right)^{2}} = \\frac{\\left(\\overline{{t^{2}}}\\right)\\left(\\overline{{s y}}\\right) - \\left(\\overline{{s t}}\\right)\\left(\\overline{{t y}}\\right)}{\\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{t^{2}}}\\right) - \\left(\\overline{{s t}}\\right)^{2}}. \\tag{17.121}\n$$\n",
        "text_format": "latex",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "但是这正是我们在 (17.92) 中更简单地计算出的贝叶斯估计结果! 同样, 趋势率的最终最优正统计值是",
        "page_idx": 29
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{B}^{(\\infty)} = \\frac{\\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{t y}}\\right) - \\left(\\overline{{t y}}\\right)\\left(\\overline{{s y}}\\right)}{\\left(\\overline{{s^{2}}}\\right)\\left(\\overline{{t^{2}}}\\right) - \\left(\\overline{{s t}}\\right)^{2}}, \\tag{17.122}\n$$\n",
        "text_format": "latex",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "这正是我们从 (17.88) 中将  $A$  作为冗余参数积分去而得出的贝叶斯估计.",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "这是我们在第 13 章中发现的结论的另一个示例: 如果正统主义者仔细思考他的估计问题, 即使他的理念仍然会导致他拒绝其中的贝叶斯理论原则, 他也不得不使用贝叶斯数学算法. 与所有理念上悬而未决的争论无关, 这种数学形式是由合理性和一致性的基本要求决定的.",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "现在, 我们可以从完全不同的角度看待正统流程和贝叶斯流程之间的关系. 对冗余参数积分的贝叶斯方法为我们以一种巧妙的方式对一系列无限序列的相互更新进行求和. 据我们所知, 尚未有任何正统主义者意识到这是真正发生的事情. 我们刚刚发现的不仅局限于趋势和季节性参数: 它可以毫不费力地推广到更复杂的问题上.",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "正如杰恩斯 (Jaynes, 1976) 之前提到的, 在许多其他情况下, 正统结果在最大程度改善后, 在数学上等同于贝叶斯方法更简单地得出的结果. 这是一个普遍现象. 确实, 贝叶斯方法和最大熵方法太容易了, 以至于正统主义者指责我们试图不劳而获. 这是我们面临的问题之一.",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "因此, 长远来看, 逃避使用贝叶斯定理不会导致不同的最终结果, 而只会使我们通过数倍的工作量才能得到它们.",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "17.10.5 效果的正统准则",
        "text_level": 1,
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "为了尽力了解所有情况, 让我们从不同的角度审视它. 根据正统理论, 估计流程的准确性应根据估计量的抽样分布来判断, 而在贝叶斯理论中它应该根据参",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "数的后验PDF来判断.让我们比较- 下,对于正统方法,注意在(17.104)和(17.107)中,包含噪声量  $e$  的项是以下形式的线性组合:",
        "page_idx": 30
    },
    {
        "type": "equation",
        "text": "\n$$\n\\overline{g}\\overline{e}\\equiv \\frac{1}{N}\\sum_{t = 1}^{N}g_{t}c_{t}. \\tag{17.123}\n$$\n",
        "text_format": "latex",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "那么在噪声的抽样PDF上,我们得到",
        "page_idx": 30
    },
    {
        "type": "equation",
        "text": "\n$$\nE(\\overline{g}\\overline{e}) = \\frac{1}{N}\\sum_{t}g_{t}E(e_{t}) = 0, \\tag{17.124}\n$$\n",
        "text_format": "latex",
        "page_idx": 30
    },
    {
        "type": "equation",
        "text": "\n$$\nE\\left[\\left(\\overline{g}\\overline{e}\\right)^{2}\\right] = \\frac{1}{N}\\sum g_{t}g_{t^{\\prime}}E\\left(e_{t}e_{t^{\\prime}}\\right) = \\overline{g^{2}}\\sigma^{2}, \\tag{17.125}\n$$\n",
        "text_format": "latex",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "最后的等号是由于  $E(e_{t}e_{t^{\\prime}}) = \\sigma^{2}\\delta (t,t^{\\prime})$  ,因此,抽样PDF将通过以下(均值)士(标准差)的方式估计此误差项:",
        "page_idx": 30
    },
    {
        "type": "equation",
        "text": "\n$$\n\\left(\\overline{g}\\overline{e}\\right)_{\\mathrm{est}} = 0\\pm \\sigma \\sqrt{\\overline{g^{2}}}. \\tag{17.126}\n$$\n",
        "text_format": "latex",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "对于贝叶斯估计量(17.104)有",
        "page_idx": 30
    },
    {
        "type": "equation",
        "text": "\n$$\ng_{t} = \\frac{\\left(\\overline{t^{2}}\\right)\\left(s_{t}\\right) - \\left(\\overline{s t}\\right)t}{\\left(\\overline{t^{2}}\\right)\\left(\\overline{s^{2}}\\right) - \\left(\\overline{s t}\\right)^{2}}, \\tag{17.127}\n$$\n",
        "text_format": "latex",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "经过一些算术计算,我们发现",
        "page_idx": 30
    },
    {
        "type": "equation",
        "text": "\n$$\n\\overline{g^{2}} = \\frac{\\left(\\overline{t^{2}}\\right)\\left[\\left(\\overline{s^{2}}\\right)\\left(\\overline{t^{2}}\\right) - \\left(\\overline{s t}\\right)^{2}\\right]}{\\left(\\overline{s^{2}}\\right)\\left(1 - r^{2}\\right)}, \\tag{17.128}\n$$\n",
        "text_format": "latex",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "其中  $r$  是之前定义的相关系数.因此,贝叶斯估计量(17.104)的抽样分布有(均值)士(标准差)",
        "page_idx": 30
    },
    {
        "type": "equation",
        "text": "\n$$\n\\tilde{A}\\pm \\sigma \\sqrt{\\hat{N}s^{2}\\left(1 - r^{2}\\right)}, \\tag{17.129}\n$$\n",
        "text_format": "latex",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "而对于正统估计量,它是",
        "page_idx": 30
    },
    {
        "type": "equation",
        "text": "\n$$\n\\left(1 - r^{2}\\right)\\tilde{A}\\pm \\sigma \\sqrt{\\frac{1 - r^{2}}{N\\left(\\overline{s^{2}}\\right)}}. \\tag{17.130}\n$$\n",
        "text_format": "latex",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "17.11 一般情况",
        "text_level": 1,
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "从几种不同的角度展示贝叶斯结果的性质之后,我们现在将它们推广到相当广泛的一类实用问题.我们假设  $N$  个数据在时间上未必是均匀间隔的,而是从某个时间集合  $\\{t:t_{1},\\dots ,t_{N}\\}$  获取的.噪声分布虽然是高斯分布,但未必是平稳的或(不相关联的)白噪声,并且参数的先验概率未必是独立的.事实证明,考",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "虑到所有这些方面的计算机程序,如果在编写时使用最通用的解析公式,就不会很困难.",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "现在我们有了模型",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{t_{i}} = T(t_{i}) + F(t_{i}) + e(t_{i}), \\quad 1 \\leqslant i \\leqslant N, \\tag{17.131}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "其中我们记  $y_{i} \\equiv y(t_{i})$  等,数据  $D = (y_{1}, \\dots , y_{N})$ ,而  $T(t)$  是(未必是线性的)趋势函数, $F(t)$  是周期性的但未必是正弦的季节性函数, $e(t)$  是不规则分量。为了定义矩阵,我们假设  $T(t)$  对一些线性独立的基函数  $\\Phi_{k}(t)$  (例如勒让德多项式)展开:",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\nT(t) = \\sum \\gamma_{k} \\Phi_{k}(t). \\tag{17.132}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "同样, $F(t)$  以正弦形式展开:",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\nF(t) = \\sum \\left[A_{k} \\cos (k t) + B_{k} \\sin (k t)\\right]. \\tag{17.133}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "所有参数的联合似然为",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\nL(\\gamma , A, B, \\sigma) = p(D \\mid \\gamma A B \\sigma) = \\left(\\frac{1}{2 \\pi \\sigma^{2}}\\right)^{N / 2} \\exp \\left\\{\\frac{1}{2 \\sigma^{2}} \\sum_{i = 1}^{N} \\left[y_{i} - T(t_{i}) - F(t_{i})\\right]^{2} \\right\\} .\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "(17.134)",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "二次型形式可以写成",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\nQ(\\alpha_{k}, \\gamma_{j}) \\equiv \\sum_{i = 1}^{N} \\left[y_{i} - \\sum_{j = 1}^{\\gamma} \\gamma_{j} T_{j}(t_{i}) - \\sum_{k = 1}^{m} \\alpha_{k} F_{k}(t_{i})\\right]^{2}, \\tag{17.135}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "其中,在季节性调整问题中, $m = 12$  且",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\n\\{\\alpha_{1}, \\dots , \\alpha_{m}\\} = \\{A_{0}, A_{1}, \\dots , A_{6}, B_{1}, B_{2}, \\dots , B_{5}\\} . \\tag{17.136}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "同样地,",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\nF_{k}(t) = \\left\\{ \\begin{array}{ll} \\cos (k \\omega t), & 0 \\leqslant k \\leqslant 6, \\\\ \\sin (|k - 6| \\omega t), & 7 \\leqslant k \\leqslant 12. \\end{array} \\right. \\tag{17.137}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "但是,如果我们将  $\\alpha , \\gamma$  组合成  $n = m + r$  维向量:",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r}{q\\equiv (\\alpha_{1},\\cdot \\cdot \\cdot ,\\alpha_{m},\\gamma_{1},\\cdot \\cdot \\cdot ,\\gamma_{r}),} \\end{array} \\tag{17.138}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "并定义函数",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\nG_{k}(t) = \\left\\{ \\begin{array}{ll} F_{k}(t), & 1 \\leqslant k \\leqslant m, \\\\ T_{k}(t), & m + 1 \\leqslant k \\leqslant n, \\end{array} \\right. \\tag{17.139}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "则模型的更紧凑的形式为",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = \\sum_{j = 1}^{n} q_{j} G_{j}(t) + e(t), \\tag{17.140}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "数据向量可表示为",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{i} = \\sum_{j = 1}^{n}q_{j}G_{j}(t_{i}) + e(t_{i}),\\quad 1\\leqslant t\\leqslant N, \\tag{17.141}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "或者",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\ny = Gq + e. \\tag{17.142}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "\"噪声\"值  $e_{i} = e(t_{i})$  具有联合先验概率密度",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\np(e_{1},\\dots ,e_{N}) = \\frac{\\sqrt{\\operatorname*{det}(K)}}{(2\\pi)^{N / 2}}\\exp \\left\\{-\\frac{1}{2} e^{\\mathrm{T}}K e\\right\\} , \\tag{17.143}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "其中  $K^{- 1}$  是  $N\\times N$  噪声先验协方差矩阵.对于\"平稳白噪声\",它简化为",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\n(K^{-1})_{ij} = \\sigma^{2}\\delta_{ij},\\qquad 1\\leqslant i,j\\leqslant N. \\tag{17.144}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "给定  $K$  和参数  $\\{q_{j}\\}$  ,数据的抽样PDF有形式",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\np(y_{1},\\dots ,y_{N}|qK I) = \\frac{\\sqrt{\\operatorname*{det}(K)}}{(2\\pi)^{N / 2}}\\exp \\left\\{-\\frac{1}{2} (y - Gq)^{\\mathrm{T}}K(y - Gq)\\right\\} . \\tag{17.145}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "同样,参数的联合先验PDF的一种非常一般的形式是",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\np(q_{1},\\dots ,q_{n}|I) = \\frac{\\sqrt{\\operatorname*{det}(L)}}{(2\\pi)^{n / 2}}\\exp \\left\\{-\\frac{1}{2} (q - q_{0})^{\\mathrm{T}}L(q - q_{0})\\right\\} , \\tag{17.146}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "其中  $L^{- 1}$  是  $n\\times n$  先验协方差矩阵,  $q_{0}$  是向量的先验估计.我们几乎总是将  $L$  设为对角矩阵:",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\nL_{ij} = \\sigma_{j}^{2}\\delta_{ij},\\quad 1\\leqslant i,j\\leqslant n, \\tag{17.147}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "并且将  $q_{0}$  设为0. 但是没有这些简化假设的一般公式也很容易找到并编程",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "这样,参数  $\\{q_{j}\\}$  的联合后验PDF是",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\np(\\pmb {q}|\\pmb {y}I) = \\frac{\\mathbf{e}^{-Q / 2}}{\\int\\mathrm{d}q_{1}\\cdot\\cdot\\cdot\\mathrm{d}q_{n}\\mathbf{e}^{-Q / 2}}, \\tag{17.148}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "其中  $Q$  是二次型",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\nQ\\equiv (y - Gq)^{\\mathrm{T}}K(y - Gq) + (q - q_{0})^{\\mathrm{T}}L(q - q_{0}), \\tag{17.149}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "我们可以展开为8项:",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\nQ = y^{\\mathrm{T}}K y - y^{\\mathrm{T}}K G q - q^{\\mathrm{T}}G^{\\mathrm{T}}K y + q^{\\mathrm{T}}G^{\\mathrm{T}}K G q + q^{\\mathrm{T}}L q - q^{\\mathrm{T}}L q_{0} - q_{0}^{\\mathrm{T}}L q + q_{0}^{\\mathrm{T}}L q_{0}.\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "(17.150)",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "我们想通过以下形式写出对  $q$  的依赖关系",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\nQ = (\\pmb {q} - \\hat{\\pmb{q}})^{\\mathrm{T}}M(\\pmb {q} - \\hat{\\pmb{q}}) + Q_{0}, \\tag{17.151}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "其中  $Q_{0}$  独立于  $q$ . 将其写出并与 (17.150) 进行比较, 我们有",
        "page_idx": 33
    },
    {
        "type": "equation",
        "text": "\n$$\nM = G^{\\mathrm{T}}K G + L,\n$$\n",
        "text_format": "latex",
        "page_idx": 33
    },
    {
        "type": "equation",
        "text": "\n$$\nM\\hat{q} = G^{\\mathrm{T}}K y + L q_{0}, \\tag{17.152}\n$$\n",
        "text_format": "latex",
        "page_idx": 33
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{q}^{\\mathrm{T}}M\\hat{q} +Q_{0} = y^{\\mathrm{T}}K y + q_{0}^{\\mathrm{T}}L q_{0}.\n$$\n",
        "text_format": "latex",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "因此  $M,q,Q_{0}$  可以唯一确定,由于(17.150)和(17.151)一定是  $q$  的等式",
        "page_idx": 33
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{c}{{\\hat{q}=M^{-1}\\big[G^{\\mathrm{T}}K y+L q_{0}\\big],}}\\\\ {{Q_{0}=y^{\\mathrm{T}}K y+q_{0}^{\\mathrm{T}}L q_{0}-\\hat{q}^{\\mathrm{T}}M\\hat{q}.}}\\end{array} \\tag{17.153}\n$$\n",
        "text_format": "latex",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "(17.148)的分母可以通过(17.151)得到,最终结果是",
        "page_idx": 33
    },
    {
        "type": "equation",
        "text": "\n$$\np(q_{1},\\dots ,q_{n}|y K L I) = \\frac{\\sqrt{\\operatorname*{det}(M)}}{(2\\pi)^{n / 2}}\\exp \\left\\{-\\frac{1}{2}{\\big(} q - \\hat{q}{\\big)}^{\\mathrm{T}}M{\\big(} q - \\hat{q}{\\big)}\\right\\} . \\tag{17.155}\n$$\n",
        "text_format": "latex",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "分量  $q_{1},\\dots ,q_{m}$  是我们希望估计的季节性幅度,而  $(q_{m + 1},\\dots ,q_{n})$  是要消除的趋势冗余参数.根据(17.155),我们想要的边缘PDF是",
        "page_idx": 33
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{l}{{p(q_{1},\\cdots,q_{m}|y K L I)=\\int\\mathrm{d}q_{m+1}\\cdots\\mathrm{d}q_{n}p(q_{1},\\cdots,q_{n}|y K L I)}}\\\\ {{=\\frac{\\sqrt{\\operatorname*{det}(M)}}{(2\\pi)^{n/2}}\\frac{(2\\pi)^{(n-m)/2}}{\\sqrt{\\operatorname*{det}(\\overline{{W}})}}\\exp\\left\\{-\\frac{1}{2}{\\big(}u-\\hat{u}{\\big)}^{\\mathrm{T}}U{\\big(}u-\\hat{u}{\\big)}\\right\\}}}\\\\ {{=\\frac{\\sqrt{\\operatorname*{det}(U)}}{(2\\pi)^{m/2}}\\exp\\left\\{-\\frac{1}{2}{\\big(}u-\\hat{u}{\\big)}^{\\mathrm{T}}U{\\big(}u-\\hat{u}{\\big)}\\right\\},}}\\end{array} \\tag{17.156}\n$$\n",
        "text_format": "latex",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "其中  $U,V,W,u$  由  $(),(),(),()$  定义",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "新编练习17.4杰恩斯从未定义  $U,V,W,u$  ,在(17.155)中,将指数中的所有项相乘,得到适当的子矩阵、向量和标量,然后定义这四个量中的每一个.",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "根据各种概率均归一化的事实,我们发现",
        "page_idx": 33
    },
    {
        "type": "equation",
        "text": "\n$$\n\\operatorname *{det}(M) = \\operatorname *{det}(W)\\operatorname *{det}(U), \\tag{17.157}\n$$\n",
        "text_format": "latex",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "这是一个非凡的定理,除了在  $V = O$  的情况下,根据定义一点儿也看不出来.这是由概率推理证明纯数学定理的另一个很好的例子.",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "因此,最一般的解在计算上由一串基本矩阵运算组成,并且易于编程.总结一下,最终的计算规则是:",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "$K^{- 1}$  是\"噪声\"的  $N\\times N$  先验协方差矩阵;",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "$L^{- 1}$  是参数的  $n\\times n$  先验协方差矩阵;",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "$F$  是模型函数的  $N\\times n$  矩阵.",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "首先计算  $n \\times n$  矩阵",
        "page_idx": 34
    },
    {
        "type": "equation",
        "text": "\n$$\nM \\equiv F^{\\mathrm{T}} K F + L, \\tag{17.158}\n$$\n",
        "text_format": "latex",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "并将其分解为表示感兴趣和不感兴趣的子空间块形式:",
        "page_idx": 34
    },
    {
        "type": "equation",
        "text": "\n$$\nM = \\left( \\begin{array}{cc}U_{0} & V \\\\ V^{\\mathrm{T}} & W_{0} \\end{array} \\right). \\tag{17.159}\n$$\n",
        "text_format": "latex",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "然后计算  $m \\times m$  和  $r \\times r$  重归一化矩阵",
        "page_idx": 34
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r}U \\equiv U_{0} - V W_{0}^{-1} V^{\\mathrm{T}}, \\\\ W \\equiv W_{0} - V^{\\mathrm{T}} U_{0}^{-1} V. \\end{array} \\tag{17.161}\n$$\n",
        "text_format": "latex",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "这在很大程度上由模型定义决定,计算机可以在知道数据之前预先解决所有这些问题,并将结果用于任意的数据集",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "现在,给定  $y$ ,即  $N \\times 1$  数据向量,以及  $q_{0}$ ,即先验估计的  $n \\times 1$  向量,计算机可以计算参数的\"最优\"估计的  $n \\times 1$  向量",
        "page_idx": 34
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{q} = M^{-1} \\left[ F^{\\mathrm{T}} K y + L q_{0} \\right]. \\tag{17.162}\n$$\n",
        "text_format": "latex",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "实际上,它们中的前  $m$  个是我们感兴趣的,除非有人也想要趋势函数的估计,剩下的  $r = n - m$  个分量是不需要的,这样我们可以使用以下结果",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "逆矩阵  $M^{T - 1}$  可以与  $M$  相同的块形式写出:",
        "page_idx": 34
    },
    {
        "type": "equation",
        "text": "\n$$\nM^{-1} = \\left( \\begin{array}{cc}U^{-1} & -U_{0} V W^{-1} \\\\ -W_{0} V^{\\mathrm{T}} U^{-1} & W^{-1} \\end{array} \\right), \\tag{17.163}\n$$\n",
        "text_format": "latex",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "其中,类似于  $U$",
        "page_idx": 34
    },
    {
        "type": "equation",
        "text": "\n$$\nW \\equiv W_{0} - V^{\\mathrm{T}} U_{0}^{-1} V. \\tag{17.164}\n$$\n",
        "text_format": "latex",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "这样, $F^{\\mathrm{T}}$  相对于行具有相同的块形式:",
        "page_idx": 34
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r l r} & {} & {1\\leqslant j\\leqslant m,}\\\\ & {} & {\\left(F^{\\mathrm{T}}\\right)_{j i} = \\left[G_{j}(t_{i})T_{i}(t_{i})\\right],\\qquad} & {1\\leqslant i\\leqslant N,}\\\\ & {} & {m + 1\\leqslant K\\leqslant N,} \\end{array} \\tag{17.165}\n$$\n",
        "text_format": "latex",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "其中  $G_{j}(t)$  是季节性正弦曲线, $T_{k}(t)$  是趋势函数",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "我们几乎总是有  $q_{0} = 0$ ,因此我们\"感兴趣的\"季节性幅度由下式给出:",
        "page_idx": 34
    },
    {
        "type": "equation",
        "text": "\n$$\n\\hat{q} = R K y, \\tag{17.166}\n$$\n",
        "text_format": "latex",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "其中  $R$  是简化的  $m \\times N$  矩阵",
        "page_idx": 34
    },
    {
        "type": "equation",
        "text": "\n$$\nR \\equiv U^{-1} G - U_{0}^{-1} V W^{-1} T, \\tag{17.167}\n$$\n",
        "text_format": "latex",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "其中  $U^{- 1}$  是感兴趣的参数  $\\{q_{1}, \\dots , q_{m} \\}$  的联合后验协方差矩阵。注意, $R$  和  $U^{- 1}$  也由模型确定,因此计算机可以在获取数据之前一劳永逸地对其进行计算。",
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "新编练习17.5 杰恩斯没有完成本节,所以我们只能推测他会在这里写什么.首先看看(17.156):这是所有季节性幅度的联合后验概率,但是振幅与季节性分量本身不是同一件事.季节性成分表示为",
        "page_idx": 35
    },
    {
        "type": "equation",
        "text": "\n$$\nS(t) = \\sum_{k = 1}^{n}q_{k}G_{k}(t), \\tag{17.168}\n$$\n",
        "text_format": "latex",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "它是时间的连续函数.是否可以使用(17.156)和(17.168)计算季节的联合后验概率  $p(S(t)|y K L I)$  呢?换句话说,是否可以使用变量的简单变化加上对剩余  $q$  的边缘化来计算  $p(S(t)|y K L I)$  ?如果不能,将如何计算该联合后验概率?",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "17.12 评注",
        "text_level": 1,
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "让我们尝试总结和理解前两章中提到的事实的底层技术原因.对于20世纪30年代费希尔考虑的相对简单的问题,抽样理论推断方法是令人满意的.这些问题具有以下特征:",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "(a)参数很少;",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "(b)存在充分统计量;",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "(c)没有重要的先验信息;",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "(d)无冗余参数",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "当所有这些条件都满足,并且我们有大量数据(例如  $n \\geqslant 30$  )时,正统方法基本上与贝叶斯方法等价,无论我们偏爱哪种理念,所得出的结论不会有实际差别.但是今天,我们面临着一些或全部条件不满足的重要问题,只有贝叶斯方法能够处理这类问题,而又不会牺牲我们可以获得的许多相关信息,贝叶斯方法更强大:如果没有充分统计量,则出于本章开头所述的原因,它们能从数据中提取更多信息.而且,它们会注意到可能非常重要的先验信息,并轻松处理冗余参数,将其变成重要的财富.",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "如今,人们想知道正统统计逻辑如何可能年复一年地在某些地方被讲授,并被誉为是\"客观的\",而贝叶斯主义者却被指控为具有\"主观性\".正统主义者沉溺于实际并不存在的幻想数据集以及原则上无法观察到的极限频率,并且忽略相关的先验信息,没有资格指责任何人具有\"主观性\".如果没有充分统计量,则基于单一\"统计量\"的正统精度声明不仅会忽略先验信息,而且会忽略数据中与精度相关的所有证据:很难说是\"客观\"流程.如果有辅助统计量,并且正统主义者遵循费希尔的做法,会以辅助统计量为条件做出估计,其结果与基于无信息先验的贝叶斯定理通过更简单的计算得出的相同.贝叶斯定理也将做出一个无可辩",
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "驳的精度声明.",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "我们将在后面的章节中通过几个示例进行说明, 包括区间估计、处理趋势、线性回归、周期检测和时间序列预测。在所有这些情况下, \"正统\"方法可能会错失数据中的重要证据; 由于忽略了强有力的先验信息, 它们也可能得出没有证据支持的结论。我们没有发现贝叶斯方法存在类似失效的情况。确实, 贝叶斯文献中众所周知的最优定理使得人们从一开始就预期会这样。但是从心理学上讲, 实际例子似乎比最优定理更具说服力。",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "从历史上看, 科学推断一直为单变量或双变量高斯抽样分布的情况所主导。这使得人们对该领域产生了扭曲的印象: 高斯情形是\"正统\"或\"抽样理论\"方法最有效的示例, 其中数据前和数据后后流程之间的差异最小。在这种有限证据的基础上, (费希尔) 正统理论试图声称其方法的一般有效性, 并且在不检查结果的情况下, 对贝叶斯方法进行无情的攻击。",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "即使是高斯情形, 也存在重要的问题, 其中抽样理论方法出于技术原因而失效。一个例子是线性回归, 其中两个变量都具有未知方差的误差, 这也许是实验科学家面临的最常见的推断问题。然而因为每个新的数据点都会带来一个新的冗余参数, 抽样理论对此无能为力。正统统计文献没有为我们提供解决此问题的令人满意的方法。例如, 见肯普索恩和福克斯的著作 (Kempthorne & Folks, 1971), 其中为了确定哪些量 (对他们来说) 是\"随机的\", 作者构想了 16 种不同的线性回归模型来描述一个推理问题, 然后他们发现自己处理其中的大多数时十分无助, 并认为\"都很困难\"而放弃。",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "当脱离高斯情形时, 我们仿佛打开一个潘多拉盒子, 其中充满了新的异常、逻辑矛盾、荒谬结果以及超出抽样理论处理能力的技术难题。虔诚的正统主义者肯德尔和斯图尔特 (Kendall & Stuart, 1961) 已经记下了其中几个例子。",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "这些例子表明了假定估计质量完全可以根据估计量的抽样分布来判断的基本错误。这只是出于数学对称性的原因对较简单的高斯情形才是正确的。一般来说, 正如费希尔指出的那样, 由于具有不同的构型 (值域), 有着相同估计量的不同样本对参数值确定非常不同的精度。但是费希尔的补救措施——以辅助统计量为条件——几乎是不可能的。即使是在可能的情况下, 我们在第 8 章中也已经看到它在数学上等价于使用贝叶斯定理。关于这一点, 对于\"学生\"  $t$  分布的情形, 杰弗里斯在 20 世纪 30 年代已经做出了证明。在我的文章 (Jaynes, 1976) 中, 我们针对正统主义者视为\"病态的\"的柯西分布进行了详细说明。",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "正统文献的作者们始终没有认识到的是, 所有这些困难都可以通过统一使用单一的贝叶斯方法而毫不费力地解决。实际上, 一旦贝叶斯分析为我们提供了正",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "确的答案, 我们就可以研究它, 直观地理解为什么它是对的, 并带着这种更深入的了解, 明白正统主义者接受的某个特定工具能如何找到该正确答案.",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "我们将在后面的章节中通过对上述回归问题以及柯西抽样分布的一些推断问题的解进行说明. 据我们所知, 在任何正统统计文献中都找不到这些解.",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "但是, 我们悲伤地看到, 在当前许多贝叶斯文献中, 正统的包积极少被抛弃. 例如, 一篇贝叶斯方面的文章典型的开头是: \"令  $X$  是具有密度函数  $p(x|\\theta)$  的随机变量, 其中参数  $\\theta$  的值是未知的. 假定该参数族包含  $X$  的真实分布……\" 或者, 有人将均匀先验  $p(\\theta |I)$  描述为\"  $\\theta$  被认为具有均匀分布\". 这样获得的解析解无疑将是一个有效的贝叶斯结果, 但人们仍然坚持使用\"随机变量\"和\"真实分布\"这样的正统虚构物.  $\\theta$  只是一个未知常数, 它根本没有\"分布\". \"分布\"的是我们对  $\\theta$  的知识状态: 执着的思维投射谬误再次污染了整个概率论, 使得经验不足的读者对我们真正所做的事情产生误解. 同样糟糕的是, 那些犯这种错误的人似乎并不知道这会将应用限制在贝叶斯解可能有用的实际情况的一小部分中. 在绝大多数实际应用中, 没有所谓\"随机变量\"(如何定义\"随机性\"?) 也没有\"真实分布\"(如何定义? 我们可以采用哪种检验方法来确定某个分布是否\"真实\"?), 但是作为逻辑的概率论适用于所有问题.",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "与正统检验不同, 贝叶斯后验概率或几率比可以定量地告诉我们, 考虑手上所有而不只是数据证据之后, 证据对于某种效应有多强.",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "萨维奇 (Savage, 1962, 第 63~67 页) 通过冗长的严格推理的论证, 仅使用抽样概率给出了贝叶斯算法的理论依据. 这里阐述的贝叶斯论证——他拒绝将其称为\"必要的\"——可以直接地根据第一原理得出相同的结论.",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "这些比较表明, 为了成功处理当前的实际问题, 抛弃传统和权威已经至关重要, 因为传统和权威在整个 20 世纪里都在阻碍我们的进步. 令人遗憾的是, 正统的方法与术语仍然在被继续向年轻的统计学家、经济学家、生物学家、心理学家和医学研究者传授, 数十年来, 这已经严重损害了这些领域的发展.",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "然而, 我们所见之处到处都有希望的光芒. 在物理学中, 布雷特索斯特 (Bret- thorst, 1988) 处理了核磁共振数据, 通过贝叶斯方法从数据中提取了更多信息, 远远超过之前专门的傅里叶分析所能获取的. 在计量经济学中, 阿诺德·泽尔纳教授是一所规模庞大、活跃且持续发展的贝叶斯分析学院的创始人, 该学院已经发表大量研究成果. 在医学诊断领域, 伟大的医师威廉·奥斯勒爵士 (1849—1919) 很早就指出: 医学是不确定性的科学与概率的艺术. 近年来, 一些人已经开始认真对待这一言论. 李·卢斯特德 (Lee Lusted, 1968) 用流程图和源代码给出了贝",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "叶斯计算机诊断 6 种重要医学状况的示例, 以及关于医学检验的大量定性知识.  $①$  彼得·芝士曼 (Peter Cheeseman, 1988) 一直在开发基于贝叶斯原则的医学诊断专家系统.",
        "page_idx": 38
    },
    {
        "type": "text",
        "text": "第18章  $A_{p}$  分布与连续法则",
        "text_level": 1,
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "在每位非贝叶斯主义者身体里,都有一位试图逃出的贝叶斯主义者.",
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "——丹尼斯·林德利(Dennis V. Lindley)",
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "到现在为止,我们已经赋予我们的机器人相当普遍的推断原理,它可以借此将信息转化为先验概率,并将后验概率转化为确定的最终决策,因此现在已经能够解决很多问题,但是它仍然相当低效,当我们给它一个新问题时,它必须回到自己的记忆中(我们用  $X$  或  $I$  表示的命题,代表了它所学到的一切)它必须先扫描整个记忆,以查找与该问题相关的内容,然后才能开始处理问题,随着机器人年龄的增长,这将成为越来越耗时的过程.",
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "但是人类的大脑不会这样做,我们的大脑中内置了一些机制,可以总结过去的结论,使得我们无须记得导致我们得出这些结论的细节,我们想看看是否有可能给予机器人某种确定的机制,使得它可以存储一般性结论而不是孤立的事实.",
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "18.1 旧机器人的记忆存储",
        "text_level": 1,
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "现在注意与这个问题密切相关的另一件事情,假设你有一枚硬币,并且允许你仔细检查它,在仔细检查之后,你相信这是一枚无偏硬币:它是标准圆形,有正面和反面,并且重心在正常的位置,这时要求你给该硬币在第一次抛掷时分配正面朝上的概率,我敢肯定你会说  $1 / 2$  ,现在,假设你要为火星上曾经有生命这一命题分配概率,我不知道你对此有何看法,但是根据我知道的所有信息,我同样会说概率大约为  $1 / 2$  ,虽然我为这两个命题分配了相同的\"外部\"概率,但是我对于它们有着截然不同的\"内部\"状态.",
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "要明白这一点,请想象在获得新信息后的结果,假设我们将硬币抛掷了5次,每次都反面朝上,你问我下一次抛掷正面朝上的概率是多少,我还是会说  $1 / 2$  但是,如果你再告诉我一个有关火星的事实,我会准备好完全改变我的概率分配.有某种东西使得我的信念在硬币的问题上非常稳定,但是在有关火星生命的问题上非常不稳定.①",
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "这似乎是对作为逻辑的概率论的致命打击。也许我们需要为一个命题关联的不仅是一个代表合理信念程度的数,而是两个数:一个代表合理信念程度,另一个代表面对新证据时的稳定性。因此,需要一种二值理论。在20世纪50年代初期,我在一次伯克利统计研讨会上发表演讲,阐述了这一观点。",
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "但是现在,经过深思熟虑,我认为存在一种机制,使得我们的现有理论能自动包含所有这些东西。到目前为止,我们要求机器人考虑的所有命题都是具有二值逻辑的\"亚里士多德\"命题:它们必须非真即假。假设我们引入一种不同类型的新命题。尽管这个命题是真或假都没有意义,但是我们仍然要说机器人将一个实数与之关联,并且它遵循概率论规则。这些命题有时很难用口头表达。但是我们注意到,如果对于问题中所有将要使用的命题给定以  $X$  为条件的概率,那么我们已经说明了  $X$  的所有有关信息(尽管当然不包含它对我们的意义和重要性,那将关乎我们对该问题是否感兴趣)。因此,我们引入一个新的命题  $A_{p}$ ,定义为",
        "page_idx": 40
    },
    {
        "type": "equation",
        "text": "\n$$\nP(A|A_{p}E) \\equiv p, \\tag{18.1}\n$$\n",
        "text_format": "latex",
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "其中  $E$  是任何其他证据。如果对  $A_{p}$  做口头陈述,它将是类似这样的东西:",
        "page_idx": 40
    },
    {
        "type": "equation",
        "text": "\n$$\nA_{p} \\equiv \\text{无论你被告知什么其他证据}, A \\text{的概率都是} p. \\tag{18.2}\n$$\n",
        "text_format": "latex",
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "现在,  $A_{p}$  是一个奇怪的命题,如果我们允许机器人用这种命题进行推理,贝叶斯定理保证  $A_{p}$  可以移到左边:  $P(A_{p}|E)$ 。我们是在这里做什么?似乎是在谈论\"概率的概率\"。",
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "在更好地理解其意义之前,让我们采用能避免产生错误印象的更谨慎的表示法。我们并不声称  $P(A_{p}|E)$  是通常意义上的\"真实概率\",它只是遵守概率论数学规则的一个数。或许在获取一些使用经验之后,我们会更加清楚这一概念的正确含义。因此,让我们避免使用符号  $p$ 。为了强调其更抽象的性质,我们使用括号记号  $(A_{p}|E)$  表示此类量,并将其简单称为\"给定  $E$  的  $A_{p}$  的密度\"。",
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "我们通过一个等式来定义  $A_{p}$ 。如果你问这意味着什么,我们将写出更多的等式来回答。因此,让我们写出这些等式:如果  $X$  关于  $A$  除了\" $A$  可能为真也可能为假\"外什么也没说,那么对于第12章中的\"完全无知的总体\"有",
        "page_idx": 40
    },
    {
        "type": "equation",
        "text": "\n$$\n(A_{p}|X) = 1, \\quad 0 \\leqslant p \\leqslant 1. \\tag{18.3}\n$$\n",
        "text_format": "latex",
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "第12章的变换群论证适用于此问题。有了以上结果,我们就可以使用贝叶斯定理来计算给定其他条件的  $A_{p}$  的密度。具体是",
        "page_idx": 40
    },
    {
        "type": "equation",
        "text": "\n$$\n(A_{p}|EX) = (A_{p}|X) \\frac{P(E|A_{p}X)}{P(E|X)} = \\frac{P(E|A_{p})}{P(E|X)}. \\tag{18.4}\n$$\n",
        "text_format": "latex",
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "现在",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\nP(A|E) = \\int_{0}^{1} \\mathrm{d}p(A A_{p}|E). \\tag{18.5}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "命题  $A_{p}$  是互斥且穷尽的(实际上,每个  $A_{p}$  都与其他  $A_{q}$  完全矛盾),因此我们可以这样做.我们将完全不考虑  $A_{p}$  是一种有趣的命题而应用所有概率论规则.我们相信这些规则是处理这种命题的一致性方法,但是,现在我们认识到一致性是这些规则的纯粹结构性属性,它不能依赖于我们可能对命题附加的特定语义.因此,现在可以通过乘法规则分解(18.5)的被积函数:",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\nP(A|E) = \\int_{0}^{1} \\mathrm{d}p P(A|A_{p}E)(A_{p}|E). \\tag{18.6}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "但是根据  $A_{p}$  的定义(18.1),第一个因子正好是  $p$ ,所以",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\nP(A|E) = \\int_{0}^{1} \\mathrm{d}p p(A_{p}|E). \\tag{18.7}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "我们的机器人分配给命题  $A$  的概率正好是  $A_{p}$  密度的一阶矩.因此,  $A_{p}$  的密度应该包含机器人有关  $A$  的状态的更多信息,而不仅仅是  $A$  的概率.我们的推测是,此类命题的引入不仅能解决上述两个问题,并且为我们提供了计算概率的强大分析工具.",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "18.2 相关性",
        "text_level": 1,
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "要明白为什么会提出这种猜想,让我们注意一些关于相关性的引理.假设证据  $E$  由两部分组成,即  $E = E_{a}E_{b}$  ,其中  $E_{a}$  与  $A$  相关,并且在给定  $E_{a}$  的情况下,  $E_{b}$  与之不相关:",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\nP(A|E) = P(A|E_{a}E_{b}) = P(A|E_{a}). \\tag{18.8}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "在给定  $E_{a}$  的情况下,",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\nP(E_{b}|A E_{a}) = P(E_{b}|E_{a})\\frac{P(A|E_{b}E_{a})}{P(A|E_{a})} = P(E_{b}|E_{a}), \\tag{18.9}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "根据贝叶斯定理,可以得出  $A$  也一定与  $E_{b}$  不相关.我们将此性质称为\"弱无关性\"。这是否意味着  $E_{b}$  与  $A_{p}$  不相关?显然不是,因为(18.8)只是说  $(A_{p}|E_{a})$  和  $(A_{p}|E_{a}E_{b})$  的一阶矩是相同的。但是假定对于给定的  $E_{b}$ ,(18.8)可能独立于  $E_{a}$  成立,这称为\"强无关性\"。这时我们有",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\nP(A|E) = \\int_{0}^{1} \\mathrm{d}p p(A_{p}|E_{a}E_{b}) = \\int_{0}^{1} \\mathrm{d}p p(A_{p}|E_{a}). \\tag{18.10}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "但是,如果这要对所有  $(A_{p}|E_{a})$  成立,则被积函数必须相同:",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\n(A_{p}|E_{a}E_{b}) = (A_{p}|E_{a}), \\tag{18.11}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "根据贝叶斯定理可以得出,正如(18.9)一样,  $A_{p}$  与  $E_{b}$  不相关:",
        "page_idx": 42
    },
    {
        "type": "equation",
        "text": "\n$$\nP(E_{b}|A_{p}E_{a}) = P(B_{b}|E_{a}) \\tag{18.12}\n$$\n",
        "text_format": "latex",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "对于所有  $E_{a}$  成立.",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "现在,假设我们的机器人获得了一份新证据  $F$  ,这将如何改变其关于  $A$  的知识状态呢?可以按照之前所做的那样通过贝叶斯定理直接展开,但是这次让我们使用  $A_{p}$  :",
        "page_idx": 42
    },
    {
        "type": "equation",
        "text": "\n$$\nP(A|EF) = \\int_{0}^{1}\\mathrm{d}pp\\left(A_{p}|EF\\right) = \\int_{0}^{1}\\mathrm{d}pp\\left(A_{p}|E\\right)\\frac{P(F|A_{p}E)}{P(F|E)}. \\tag{18.13}\n$$\n",
        "text_format": "latex",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "在这一似然比中,可以剔除与  $A_{p}$  不相关的  $E$  的任何部分,因为根据贝叶斯定理,它等于",
        "page_idx": 42
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{P(F|A_{p}E_{a}E_{b})}{P(F|E_{a}E_{b})} = \\frac{P(F|A_{p}E_{a})\\left[\\frac{P(E_{b}|FA_{p}E_{a})}{P(E_{b}|A_{p}E_{a})}\\right]}{P(F|E_{a})\\left[\\frac{P(E_{b}|FA_{p}E_{a})}{P(E_{b}|E_{a})}\\right]} = \\frac{P(F|A_{p}E_{a})}{P(F|E_{a})}, \\tag{18.14}\n$$\n",
        "text_format": "latex",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "其中使用了 (18.12).",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "现在,如果  $E_{a}$  仍然包含与  $A_{p}$  不相关的部分,我们可以重复此过程.想象进行尽可能多次后,  $E$  剩余的  $E_{aa}$  部分根本不包含与  $A_{p}$  不相关的任何内容.因此, $E_{aa}$  一定仅是关于  $A$  的某一陈述.但是,根据  $A_{p}$  的定义 (18.1),我们看到  $A_{p}$  在分子中自动消去了  $E_{aa}$  :  $(F|A_{p}E_{aa}) = (F|A_{p})$  .因此,我们将 (18.13)简化为",
        "page_idx": 42
    },
    {
        "type": "equation",
        "text": "\n$$\nP(A|EF) = \\frac{1}{P(F|E_{aa})}\\int_{0}^{1}\\mathrm{d}pp\\left(A_{p}|E\\right)p\\left(F|A_{p}\\right). \\tag{18.15}\n$$\n",
        "text_format": "latex",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "该论证的不足之处在于,我们还没有证明总是有可能将  $E$  分解为一个完全相关与完全不相关的两个部分.但是,容易证明在许多应用中这是可能的.因此我们只说以下结果适用于先验信息\"完全可分解\"的情况.虽然没有说这是最普遍的情况,但我们确实知道这是可能的情况.",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "18.3 令人惊讶的结果",
        "text_level": 1,
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "现在,  $(F|E_{aa})$  是我们要消去的项.它实际上只是一个归一化因子,我们可以按照第4章的方法通过计算  $A$  的几率而不是概率消去它.这只是",
        "page_idx": 42
    },
    {
        "type": "equation",
        "text": "\n$$\nO(A|EF) = \\frac{P(A|EF)}{P(\\overline{A}|EF)} = \\frac{\\int_{0}^{1}\\mathrm{d}pp\\left(A_{p}|E\\right)P(F|A_{p})}{\\int_{0}^{1}\\mathrm{d}p\\left(A_{p}|E\\right)P(F|A_{p})(1 - p)}. \\tag{18.16}\n$$\n",
        "text_format": "latex",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "重要的是,表征先验信息的命题  $E$  现在只在密度  $(A_{p}|E)$  中出现,这意味着机器人为了推断出新信息的作用而需要的  $E$  的唯一性质是密度  $(A_{p}|E)$  .机器人学过的与命题  $A$  相关的所有信息可能包含成百万上千万个孤立的事实,但是当它接收",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "到新信息时, 它不必回到整个记忆中搜索与  $A$  相关的每个小细节. 从过去的经验中得到关于  $A$  的所有信息包含在一个汇总函数  $(A_{p}|E)$  中.",
        "page_idx": 43
    },
    {
        "type": "text",
        "text": "因此, 对于每个要推断的命题  $A$ , 机器人可以存储一个如图 18- 1 所示的密度函数  $(A_{p}|E)$ . 每当接收到新信息  $F$  时, 就会计算  $(A_{p}|EF)$ , 然后可以删除先前的信息  $(A_{p}|E)$ , 而只存储  $(A_{p}|EF)$ . 通过此流程, 我们将在以后有关  $A$  的推断中考虑其经验的所有细节.",
        "page_idx": 43
    },
    {
        "type": "image",
        "img_path": "images/09b6bbbf90003878c41c563c7d065277a1d6219b527e54e4cdc59f6c5b201a9c.jpg",
        "image_caption": [
            "图18-1  $A_{p}$  的分布"
        ],
        "image_footnote": [],
        "page_idx": 43
    },
    {
        "type": "text",
        "text": "这表明在进行归纳推理的机器中, 存储问题可能比仅进行演绎推理的机器更简单. 这并不意味着机器人可以抛弃所有过去的经验, 因为总是有可能会出现一些必须从头进行推理的新命题. 无论何时发生这种情况, 当然都必须回到原始数据中搜索与该命题相关的每条信息.",
        "page_idx": 43
    },
    {
        "type": "text",
        "text": "稍作反思, 我们都会同意这正是我们大脑的思维方式. 如果被问到某个命题的合情性有多大, 我们不会转去回忆有关该命题的所有细节. 我们会回想起对此命题的思想状态. 我们中有多少人还记得使我们相信  $\\mathrm{d}\\sin (x) / \\mathrm{d}x = \\cos (x)$  的最初论证? 但是, 与机器人不同的是, 当遇到一些全新的命题  $Z$  时, 我们没有能力进行完整的历史数据搜索.",
        "page_idx": 43
    },
    {
        "type": "text",
        "text": "让我们再看一下 (18.15). 如果新信息  $F$  要使  $A$  的概率发生显著变化, 我们可以从该积分中看到需要什么. 如果密度  $(A_{p}|E)$  在  $p$  的一个特定值处已经非常尖锐地达到峰值, 那么要使得概率有显著的改变, 则  $P(F|A_{p})$  将不得不在  $p$  的其他某个值处更加尖锐地达到峰值. 另外, 如果  $(A_{p}|E)$  非常宽, 则  $P(F|A_{p})$  中的任何小峰都会使机器人分配给  $A$  的概率发生较大变化.",
        "page_idx": 43
    },
    {
        "type": "text",
        "text": "因此, 当证据  $E$  确定时, 机器人心理状态的稳定性基本上取决于  $(A_{p}|E)$  的",
        "page_idx": 43
    },
    {
        "type": "text",
        "text": "宽度. 似乎没有任何一个数可以完全描述这种稳定性. 另外, 当它积累了足够的证据使  $(A_{p}|E)$  在  $p$  的某个值处达到很好的峰值时, 该分布的方差就成为机器人心理状态稳定程度的一个很好的衡量指标. 它收集到的信息越多, 其  $A_{p}$  分布将越窄, 任何新证据将越难改变这种心理状态.",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "现在我们可以看看硬币问题与火星问题的区别. 在硬币问题中, 根据先验知识, 我们的  $(A_{p}|E)$  密度用类似于图 18- 2(a) 所示的曲线表示. 对于火星上是否曾经存在生命的问题而言, 我们的知识状态是用图 18- 2(b) 所示的  $(A_{p}|E)$  密度定性描述的. 在这两种情况下, 一阶矩都是相同的, 所以我给两者都分配了概率  $1 / 2$ , 但是我对这两个命题的了解程度差别很大, 这种差别用  $(A_{p}|E)$  密度表示.",
        "page_idx": 44
    },
    {
        "type": "image",
        "img_path": "images/1cbcc7ad213d496b84b4bce1a3e9d8c522cf7745dca394aa3d57f013f6ee8c85.jpg",
        "image_caption": [
            "图18-2两个  $A_{p}$  分布具有相同的一阶矩, 但是表示非常不同的知识状态"
        ],
        "image_footnote": [],
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "在其他场景下也出现过类似的想法. 在我开始思考这一问题时, 曾见过一篇报刊文章, 标题为\"大脑存储人的最内在思想\". 它是这样开头的:",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "你曾经想过、做过或说过的所有事情——每个意识的完整记录——都会记录在你大脑的综合计算机中. 你虽然永远只会回忆起其中很小的一部分, 但也永远不会丢失它. 这些是蒙特利尔神经病学研究所所长与领先的神经外科医师威德·彭菲尔德博士的发现. 人们已经认识到大脑存储经验的能力, 其中很多处于意识之下, 但是这种功能的范围由彭菲尔德博士发现并记录.",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "现在, 有几个对癫痫患者进行实验的例子. 对大脑中某个位置的刺激会使人回想起过去的某一种经验, 而患者以前无法回忆这些经验. 在文章的结尾, 彭菲尔德博士说道:",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "这不是通常意义上的记忆, 尽管它可能与此有关. 没有人能自己回忆起如此丰富的细节. 一个人可能会学习一首歌, 最终能完美地歌唱, 但是不可能详细回忆起听过的每一首歌的细节. 一个人能够记住的大多数东西是概括和总结. 如果不是这样, 我们可能会发现自己为太多的细节感到困惑.",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "这对于我们理解  $A_{p}$  密度在概念上意味着什么正是一种提示.",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "18.4 外层和内层机器人",
        "text_level": 1,
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "我们从大量证据(以上只是其中的一小部分)中了解到, 大脑具有两种不同的功能: 意识与潜意识. 它们以一种相互配合的方式共同工作. 潜意识可能在整个生命过程持续地工作. 它以我们无法控制的方式解决问题并将信息传达给意识. 每位对于难题做过原创思考的人都经历过这一点. 许多人(亨利·庞加莱、雅克·阿达马、罗温·哈密顿、弗里曼·戴森)曾经记录下这种经验, 其他人可以读到. 与潜意识的交流在我们看来是不知从何而来的突然灵感, 产生于我们放松而又根本没有有意识地思考这一问题的时候. 在一瞬间, 我们忽然理解了长时间困扰我们的问题. ①",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "如果人脑可以在两个不同的层次运作, 那么我们的机器人也可以. 我们不用考虑\"概率的概率\", 而是两种不同层次的推理: 与外部世界接触并对其进行推理的\"外层机器人\"; 以及一个\"内层机器人\", 负责观察外层机器人的活动并对其进行思考. 我们在本章之前使用的常规概率公式表示外层机器人的推理.  $A_{p}$  密度表示工作的内层机器人. 但是我们希望我们的机器人相比人类大脑具有一种优势. 外层机器人不必被迫等待来自内层机器人的灵感, 它应该有权随意调用内层机器人的服务.",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "通过这种方式看待  $A_{p}$  分布, 可以减少概念上的混乱. 思考现实世界的外层机器人使用亚里士多德命题. 内层机器人在思考外层机器人的活动时, 使用的不是关于外部世界的亚里士多德命题. 但是在其关于外层机器人的思想的情况下, 它们仍然是亚里士多德命题, 因此, 它们当然遵循同样的概率论规则. \"概率的概率\"的说法没有抓住重点, 因为这两种概率处于不同的层次.",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "有了这些东西, 我们的想象力就可以远远超越它. 内层机器人可以比仅仅计算和存储  $A_{p}$  密度有更多的功能. 它可能具有我们尚未想到的功能. 此外, 是否",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "可能存在一个“更内层”的机器人，它与现实世界隔了两层，并能思考内层机器人的活动呢？我们为什么不能拥有具有嵌套层次结构的此类机器人？为什么不能有多个并行的层次结构，每个对应不同的场景？",
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "这些问题可能显得很奇怪，但是当我们注意到在计算机和编程方法的发展中已经演化出了相同的层次结构之后，一切就变得很自然。我们目前的微型计算机在三个不同的层次进行操作：内层的“BIOS”代码直接与硬件打交道；中层“COM- MAND SHELL”在外内层之间发送信息和指令，同时保护内层免受外层影响；提供“高级”指令的外层程序员，代表着机器活动的有意识的最终目的。此外，大规模并行计算机体系结构也已经发展了数年。",
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "在计算机的进化中，这代表了不可避免的自然劳动分工。在人类大脑的进化中发生类似的劳动分工，我们也不应该感到惊讶。大脑具有内部“BIOS”层，可以通过某种方式直接控制人体的生物“硬件”（例如心跳速度和激素分泌水平），“COM- MAND SHELL”层从意识中接收“高级”指令，将它们转换为执行诸如步行或拉小提琴之类复杂活动所需的详细指令，但无须意识注意到所有细节。这样，通过在目前尚未完全理解的大脑组织的某些方面，我们可以看到计算机未来发展的端倪，特别是关于我们的推理机器人。",
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "嵌套层次结构的机器人——每个都在不同的层次思考命题——的想法在某种程度上类似于伯特兰·罗素的“类型理论”。这是他在写《数学原理》时为了避免某些悖论而引入的。它们之间可能有某种联系。但是这种在20世纪初期发展起来的佩亚诺和庞加莱称为“逻辑斯谛”的工作，在今天却被认为是有缺陷和令人困惑的——怪异与自相矛盾的定义泛滥，缺乏信息的观念——似乎最安全的方法是完全废弃这项工作，并从头开始构建。在构建过程中，我们应当考虑对于信息作用的理解以及克罗内克的警告。这在计算机时代非常合适，可构造性是判断新定义的集合或其他数学对象是否有意义或实际有用的首要标准。",
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "来自丹尼斯·林德利的开篇引用（这是他在20世纪80年代初期在一次贝叶斯研讨会上的演讲中说的）与这些考虑以及我们在第5章中关于视觉感知的论述非常吻合。在那里，我们注意到，任何与贝叶斯原则相冲突的推理方式都会使得该生物处于确定的生存劣势，因此根据达尔文的自然选择理论，生物会自动产生以贝叶斯方式推理的大脑。外脑由于与外界的接触而受到错误的灌输，可能受到损害——甚至会变成反贝叶斯主义者，不过受到保护的内脑仍然会是原始的贝叶斯主义者。因此，林德利的一句玩笑话可能确实是真的。",
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "但是，我们在这里正处于知识的边界上，因此上述材料一定是对一个可能较大的全新领域（如果你愿意，可以称其为疯狂的推测）的初步探索，而不是在阐",
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "述得到公认的理论. 记着这些注意事项, 让我们研究一些遵循上述思考方式的具体例子. 这些例子也可以独立地进行论证.",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "18.5 应用",
        "text_level": 1,
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "假设开展一项\"随机\"实验. 我们希望根据过去的实验结果尽可能准确地预测未来结果. 为了使问题明确, 我们引入以下命题.",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "$X \\equiv$  对于每次试验, 我们都允许两个先验假设:  $A$  真或者  $A$  假.",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "假定每次试验背后的\"因果机制\"都相同. 这意味着 (1) 在第  $n$  次试验中分配给  $A$  的概率不依赖于  $n$ ; (2) 过去的试验结果在所有时间内都相关. 因此, 为了预测试验 100 的结果, 对试验 1 与试验 99 的结果的了解同样重要. 没有其他先验证据.",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "$N_{n} \\equiv$  过去  $N$  次试验中  $n$  次为真.",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "$M_{m} \\equiv$  未来  $M$  次试验中  $m$  次为真.",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "$X$  的文字陈述也有同样模棱两可的问题, 并且曾经引发了很多问题和争议. 我们在这里想强调的要点是: 除非不仅给出文字陈述, 还给出数学等式, 我们就还没有精确定义先验信息. 这些等式表明我们如何通过指定先验概率将其转化为数学问题. 在当前问题中,  $X$  的这种更精确的陈述与以前一样是",
        "page_idx": 47
    },
    {
        "type": "equation",
        "text": "\n$$\n\\left(A_{p} \\mid X\\right) = 1, \\quad 0 \\leqslant p \\leqslant 1, \\tag{18.17}\n$$\n",
        "text_format": "latex",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "其中, 作为该问题先验信息的一部分, 我们理解可以将相同的  $A_{p}$  分布用于所有试验的计算. 我们要求的是  $P\\left(M_{m} \\mid N_{n}\\right)$ . 首先请注意, 通过多次重复应用与 (9.34) 相同的乘法与加法规则, 我们有二项分布",
        "page_idx": 47
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{l}{{P(N_{n}|A_{p})=\\binom{N}{n}p^{n}(1-p)^{N-n},}}\\\\ {{P(M_{m}|A_{p})=\\binom{M}{m}p^{m}(1-p)^{M-m},}}\\end{array} \\tag{18.18}\n$$\n",
        "text_format": "latex",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "(18.18)",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "我们看到, 尽管  $A_{p}$  正如我们引入它时那样看来像一个不太站得住脚的武断陈述, 但是这实际上是几乎所有现行教科书介绍概率的方式. 人们假设事件具有某种内在的、\"绝对的\"或\"物理的\"概率, 我们无法精确确定其数值. 然而, 没有人怀疑这种\"绝对\"概率的存在. 例如, 克拉默 (Cramér, 1946, 第 154 页) 将其作为基本公理. 这就像我们的  $A_{p}$  陈述一样武断. 实际上, 我们认为这就是我们的  $A_{p}$ . 我们在现行教科书中看到的等式都与上面两个类似. 只要  $p$  是给定的数, 更适当的记号法就会表明在右侧的概率符号中隐藏着  $A_{p}$ .",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "从数学上说, 我们在这里所做的工作与现行教科书的主要差别是: (1) 我们认识到无论其中是否隐藏了  $A_{p}$ , 右边的概率都存在; (2) 根据考克斯定理, 我们",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "不怕使用贝叶斯定理来处理任何命题,包括  $A_{p}$  在内。正统主义者拒绝随意使用贝叶斯定理,因而让自己丧失了概率论中最强大的原理。当对一个推断问题研究足够长的时间后,有时甚至是通过几十年来的一系列特定工具来研究之后,人们才被迫得出通过贝叶斯定理只需要几行就能推导得到的结果。这通常是指机器人与外部世界之间的\"外层\"概率。现在我们将看到贝叶斯定理在处理\"内层\"概率方面同样强大且必不可少。",
        "page_idx": 48
    },
    {
        "type": "text",
        "text": "现在我们需要确定先验概率  $P(N_{n}|X)$  。这已经由  $(A_{p}|X)$  确定,因为将命题分解为互斥假设的技巧使我们得到",
        "page_idx": 48
    },
    {
        "type": "equation",
        "text": "\n$$\nP(N_{n}|X)=\\int_{0}^{1}\\mathrm{d}p\\left(N_{n}A_{p}|X\\right)=\\int_{0}^{1}\\mathrm{d}p P(N_{n}|A_{p})(A_{p}|X)=\\binom{N}{n}\\int_{0}^{1}\\mathrm{d}p p^{n}(1-p)^{N-n}\n$$\n",
        "text_format": "latex",
        "page_idx": 48
    },
    {
        "type": "text",
        "text": "我们必须计算的积分是完全  $\\beta$  函数:",
        "page_idx": 48
    },
    {
        "type": "equation",
        "text": "\n$$\n\\int_{0}^{1}\\mathrm{d}x x^{r}(1 - x)^{s} = \\frac{r!s!}{(r + s + 1)!}. \\tag{18.20}\n$$\n",
        "text_format": "latex",
        "page_idx": 48
    },
    {
        "type": "text",
        "text": "这样,我们得到",
        "page_idx": 48
    },
    {
        "type": "equation",
        "text": "\n$$\nP(N_{n}|X) = \\left\\{ \\begin{array}{ll}\\frac{1}{N + 1}, & 0\\leqslant n\\leqslant N, \\\\ 0, & N< n, \\end{array} \\right. \\tag{18.21}\n$$\n",
        "text_format": "latex",
        "page_idx": 48
    },
    {
        "type": "text",
        "text": "这正是最大熵的均匀分布。我们可以类似地计算  $P(M_{m}|X)$  。现在可以根据贝叶斯定理来得到(18.18)的反转:",
        "page_idx": 48
    },
    {
        "type": "equation",
        "text": "\n$$\n(A_{p}|N_{n}) = (A_{p}|X)\\frac{P(N_{n}|A_{p})}{P(N_{p}|X)} = (N + 1)P(N_{n}|A_{p}), \\tag{18.22}\n$$\n",
        "text_format": "latex",
        "page_idx": 48
    },
    {
        "type": "text",
        "text": "所以最后,期望计算的概率是",
        "page_idx": 48
    },
    {
        "type": "equation",
        "text": "\n$$\nP(M_{n}|N_{n}) = \\int_{0}^{1}\\mathrm{d}p\\left(M_{m}A_{p}|N_{n}\\right) = \\int_{0}^{1}\\mathrm{d}p P\\left(M_{m}|A_{p}N_{n}\\right)\\left(A_{p}|N_{n}\\right). \\tag{18.23}\n$$\n",
        "text_format": "latex",
        "page_idx": 48
    },
    {
        "type": "text",
        "text": "因为根据  $A_{p}$  的定义有  $P(M_{m}|A_{p}N_{n}) = P(M_{m}|A_{p})$  ,所以我们已经得出了积分项中的所有部分。将它们代入(18.23),我们再次得到一个欧拉积分,结果是",
        "page_idx": 48
    },
    {
        "type": "equation",
        "text": "\n$$\nP(M_{m}|N_{n}) = \\frac{\\binom{n + m}{n}\\binom{N + M - n - m}{N - n}}{\\binom{N + M + 1}{M}}. \\tag{18.24}\n$$\n",
        "text_format": "latex",
        "page_idx": 48
    },
    {
        "type": "text",
        "text": "注意,这与抽样理论的超几何分布(3.22)不同。让我们先看看  $M = m = 1$  的特殊情况,这将简化为假设前面  $N$  次试验中  $n$  次为真,下一次试验  $A$  为真的概率。结果是",
        "page_idx": 48
    },
    {
        "type": "equation",
        "text": "\n$$\nP(A|N_{n}) = \\frac{n + 1}{N + 2}. \\tag{18.25}\n$$\n",
        "text_format": "latex",
        "page_idx": 48
    },
    {
        "type": "text",
        "text": "我们认识到这正是拉普拉斯连续法则。我们在  $(6.29) \\sim (6.46)$  中根据从坛子中抽取球的问题得到此规则并进行了简要讨论。现在,我们需要在更广泛的背景下更加仔细地讨论它。",
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "18.6 拉普拉斯连续法则",
        "text_level": 1,
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "该规则在概率论中具有极高的地位。自从拉普拉斯在1774年首次提出该规则以来,它一直是概率论中最容易理解和误用的规则之一。在几乎所有概率论书中,都会非常简短地提及该规则,主要是为了警告读者不要使用它。但是我们必须尽力去理解它,因为在设计推理机器人时,拉普拉斯规则就像贝叶斯定理一样,是最重要的构造性规则之一。它是将原始信息转化为概率的\"新\"规则(即无差别原则及其推广,最大熵原理之外的规则)。它为我们提供了概率与频率之间最重要的联系之一。",
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "可怜的老拉普拉斯被嘲笑了一个多世纪,因为他举例说明了该规则是通过计算给定太阳在过去5000年每天都升起且明天照样升起的概率来确定的。人们得到一个相当大的概率(  $5000 \\times 365.2426 + 1 = 1826214:1$  的几率)支持明天太阳照样升起。就我们所知,现代概率论学家毫无例外地认为这纯粹是荒谬的。甚至凯恩斯(Keynes,1921)和杰弗里斯(Jeffreys,1939)也对拉普拉斯连续法则进行了批评。",
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "我们必须承认,我们没有看到拉普拉斯连续法则有任何荒谬之处。我们强烈建议你独立地做一些文献检索工作,并阅读其中一些作者对此提出的反对意见。你将看到每次都发生了相同的事情。首先,拉普拉斯是在脱离上下文的情况下被引用的;其次,为了证明连续法则的荒谬性,作者将其应用于不适用的情况,其中存在连续法则没有考虑到的其他先验信息。",
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "但是,如果你回过头来亲自阅读拉普拉斯的著作(Laplace,1812),就会发现在日出章节的下一句中,他警告读者不要对此产生误解:",
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "但是这个数值对于那些根据整体现象明白了日夜与季节变化的原理,",
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "意识到目前没有任何东西可以阻止它继续发生的人来说要大得多。",
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "他用这种尴尬的话语向读者指出,连续法则只是基于事件在  $N$  次试验中发生过  $n$  次的信息而得出的概率,而我们的天体力学知识则代表了很多的额外信息。当",
        "page_idx": 49
    }
]
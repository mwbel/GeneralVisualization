#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç³»ç»ŸåŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•å­¦ç§‘åˆ†ç±»ã€è·¯ç”±å’Œæ¨¡æ¿åŠ è½½åŠŸèƒ½
"""

import sys
import os
import json
from typing import Dict, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

def test_config_loading():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    print("ğŸ”§ æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½...")
    
    try:
        from config.discipline_router import classify_prompt
        print("âœ… discipline_router.py å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        config_path = os.path.join(os.path.dirname(__file__), "config", "discipline_map.json")
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            print(f"âœ… discipline_map.json åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(config)} ä¸ªå­¦ç§‘")
            return True
        else:
            print("âŒ discipline_map.json æ–‡ä»¶ä¸å­˜åœ¨")
            return False
            
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
        return False

def test_prompt_templates():
    """æµ‹è¯•Promptæ¨¡æ¿åŠ è½½"""
    print("\nğŸ“ æµ‹è¯•Promptæ¨¡æ¿åŠ è½½...")
    
    try:
        from ai_engine.prompt_manager import prompt_manager
        
        # è·å–æ¨¡æ¿åˆ—è¡¨
        templates = prompt_manager.get_template_list()
        print(f"âœ… æˆåŠŸåŠ è½½ {len(templates)} ä¸ªæ¨¡æ¿")
        
        # æ˜¾ç¤ºæ¨¡æ¿ä¿¡æ¯
        for template in templates:
            print(f"  - {template['name']} ({template['category']}) - {template['word_count']} è¯")
        
        return len(templates) > 0
        
    except Exception as e:
        print(f"âŒ æ¨¡æ¿åŠ è½½å¤±è´¥: {str(e)}")
        return False

def test_classification_routing():
    """æµ‹è¯•å­¦ç§‘åˆ†ç±»å’Œè·¯ç”±åŠŸèƒ½"""
    print("\nğŸ¯ æµ‹è¯•å­¦ç§‘åˆ†ç±»å’Œè·¯ç”±åŠŸèƒ½...")
    
    try:
        from config.discipline_router import classify_prompt
        
        # æµ‹è¯•ç”¨ä¾‹
        test_cases = [
            {
                "input": "è¯·ç”Ÿæˆä¸€ä¸ªå±•ç¤ºè¡Œåˆ—å¼å‡ ä½•æ„ä¹‰çš„3Då¯è§†åŒ–",
                "expected_discipline": "Mathematics",
                "expected_subfield": "LinearAlgebra"
            },
            {
                "input": "æˆ‘æƒ³çœ‹æ­£æ€åˆ†å¸ƒå’Œæ³Šæ¾åˆ†å¸ƒçš„å¯¹æ¯”å›¾",
                "expected_discipline": "Statistics",
                "expected_subfield": "Distributions"
            },
            {
                "input": "ç”Ÿæˆå¤ªé˜³åœ°çƒæœˆçƒçš„è½¨é“æ¼”ç¤º",
                "expected_discipline": "Physics",
                "expected_subfield": "Astronomy"
            },
            {
                "input": "æ˜¾ç¤ºäººä½“å¾ªç¯ç³»ç»Ÿçš„3Dç»“æ„",
                "expected_discipline": "Biology",
                "expected_subfield": "Anatomy"
            },
            {
                "input": "åˆ›å»ºä¸€ä¸ªé€šç”¨çš„æ•°æ®å¯è§†åŒ–å›¾è¡¨",
                "expected_discipline": "General",
                "expected_subfield": "GenericVisualization"
            }
        ]
        
        success_count = 0
        for i, case in enumerate(test_cases, 1):
            result = classify_prompt(case["input"])
            
            print(f"\næµ‹è¯•ç”¨ä¾‹ {i}: {case['input'][:30]}...")
            print(f"  é¢„æœŸ: {case['expected_discipline']} -> {case['expected_subfield']}")
            print(f"  å®é™…: {result['discipline']} -> {result['subfield']}")
            print(f"  æ¨¡æ¿: {result['template']}")
            print(f"  æ¨èæ¨¡å‹: {result['models']}")
            
            if (result['discipline'] == case['expected_discipline'] and 
                result['subfield'] == case['expected_subfield']):
                print("  âœ… åˆ†ç±»æ­£ç¡®")
                success_count += 1
            else:
                print("  âš ï¸ åˆ†ç±»ä¸å®Œå…¨åŒ¹é…")
        
        print(f"\nåˆ†ç±»å‡†ç¡®ç‡: {success_count}/{len(test_cases)} ({success_count/len(test_cases)*100:.1f}%)")
        return success_count > 0
        
    except Exception as e:
        print(f"âŒ åˆ†ç±»è·¯ç”±æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_template_optimization():
    """æµ‹è¯•æ¨¡æ¿ä¼˜åŒ–åŠŸèƒ½"""
    print("\nâš¡ æµ‹è¯•æ¨¡æ¿ä¼˜åŒ–åŠŸèƒ½...")
    
    try:
        from ai_engine.prompt_manager import get_optimized_prompt
        
        # æµ‹è¯•æ¨¡æ¿ä¼˜åŒ–
        user_input = "ç”Ÿæˆä¸€ä¸ª3Däº¤äº’å¼çš„è¡Œåˆ—å¼å‡ ä½•å¯è§†åŒ–ï¼Œè¦æ±‚æœ‰åŠ¨ç”»æ•ˆæœå’Œé¢œè‰²é…è‰²"
        template_name = "visual_math_linear_algebra_prompt"
        
        optimized_prompt = get_optimized_prompt(template_name, user_input)
        
        if optimized_prompt and optimized_prompt != "æ¨¡æ¿æœªæ‰¾åˆ°":
            print("âœ… æ¨¡æ¿ä¼˜åŒ–æˆåŠŸ")
            print(f"ä¼˜åŒ–åçš„Prompté•¿åº¦: {len(optimized_prompt)} å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¼˜åŒ–å†…å®¹
            optimization_indicators = ["3Dæ•ˆæœ", "äº¤äº’åŠŸèƒ½", "åŠ¨ç”»æ•ˆæœ", "é¢œè‰²è®¾è®¡"]
            found_optimizations = [ind for ind in optimization_indicators if ind in optimized_prompt]
            
            if found_optimizations:
                print(f"âœ… æ£€æµ‹åˆ°ä¼˜åŒ–å†…å®¹: {', '.join(found_optimizations)}")
                return True
            else:
                print("âš ï¸ æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„ä¼˜åŒ–å†…å®¹")
                return False
        else:
            print("âŒ æ¨¡æ¿ä¼˜åŒ–å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ æ¨¡æ¿ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_code_generation():
    """æµ‹è¯•ä»£ç ç”ŸæˆåŠŸèƒ½"""
    print("\nğŸš€ æµ‹è¯•ä»£ç ç”ŸæˆåŠŸèƒ½...")
    
    try:
        from ai_engine.code_generator import generate_code
        
        # æµ‹è¯•ä»£ç ç”Ÿæˆ
        user_input = "ç”Ÿæˆä¸€ä¸ªç®€å•çš„3Dæ•£ç‚¹å›¾"
        
        result = generate_code(
            user_input=user_input,
            preferred_model="gpt-4",
            complexity_override="medium"
        )
        
        if result and result.get("success"):
            print("âœ… ä»£ç ç”ŸæˆæˆåŠŸ")
            print(f"ç”Ÿæˆçš„ä»£ç é•¿åº¦: {len(result.get('code', ''))} å­—ç¬¦")
            print(f"ä½¿ç”¨çš„å­¦ç§‘: {result.get('discipline', 'Unknown')}")
            print(f"ä½¿ç”¨çš„æ¨¡æ¿: {result.get('template', 'Unknown')}")
            print(f"æ¨èæ¨¡å‹: {result.get('recommended_models', [])}")
            
            # æ£€æŸ¥ä»£ç æ˜¯å¦åŒ…å«åŸºæœ¬å…ƒç´ 
            code = result.get('code', '')
            if 'import' in code and 'plotly' in code.lower():
                print("âœ… ä»£ç åŒ…å«å¿…è¦çš„å¯¼å…¥è¯­å¥")
                return True
            else:
                print("âš ï¸ ä»£ç å¯èƒ½ä¸å®Œæ•´")
                return False
        else:
            print("âŒ ä»£ç ç”Ÿæˆå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ ä»£ç ç”Ÿæˆæµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_system_integration():
    """æµ‹è¯•ç³»ç»Ÿé›†æˆ"""
    print("\nğŸ”— æµ‹è¯•ç³»ç»Ÿé›†æˆ...")
    
    try:
        # æµ‹è¯•å®Œæ•´çš„å·¥ä½œæµç¨‹
        from config.discipline_router import classify_prompt
        from ai_engine.prompt_manager import get_optimized_prompt
        from ai_engine.code_generator import AICodeGenerator
        
        # åˆ›å»ºä»£ç ç”Ÿæˆå™¨å®ä¾‹
        generator = AICodeGenerator()
        
        # æ¨¡æ‹Ÿå®Œæ•´æµç¨‹
        user_input = "åˆ›å»ºä¸€ä¸ªå±•ç¤ºæ­£æ€åˆ†å¸ƒæ¦‚ç‡å¯†åº¦å‡½æ•°çš„äº¤äº’å¼å›¾è¡¨"
        
        # 1. åˆ†ç±»è·¯ç”±
        classification = classify_prompt(user_input)
        print(f"âœ… åˆ†ç±»ç»“æœ: {classification['discipline']} -> {classification['subfield']}")
        
        # 2. æ¨¡æ¿ä¼˜åŒ–
        optimized_prompt = get_optimized_prompt(classification['template'], user_input)
        print(f"âœ… æ¨¡æ¿ä¼˜åŒ–å®Œæˆï¼Œé•¿åº¦: {len(optimized_prompt)} å­—ç¬¦")
        
        # 3. æ¨¡å‹é€‰æ‹©
        selected_model = generator._select_optimal_model(
            routing_result=classification,
            preferred_model="gpt-4",
            complexity_override="medium"
        )
        print(f"âœ… é€‰æ‹©æ¨¡å‹: {selected_model}")
        
        # 4. ä»£ç ç”Ÿæˆï¼ˆæ¨¡æ‹Ÿï¼‰
        routing_result = {"classification": classification}
        generated_code = generator._simulate_ai_generation(
            optimized_prompt, 
            selected_model,
            routing_result
        )
        print(f"âœ… ä»£ç ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(generated_code)} å­—ç¬¦")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿé›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¼€å§‹ç³»ç»ŸåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("é…ç½®æ–‡ä»¶åŠ è½½", test_config_loading),
        ("Promptæ¨¡æ¿åŠ è½½", test_prompt_templates),
        ("å­¦ç§‘åˆ†ç±»è·¯ç”±", test_classification_routing),
        ("æ¨¡æ¿ä¼˜åŒ–", test_template_optimization),
        ("ä»£ç ç”Ÿæˆ", test_code_generation),
        ("ç³»ç»Ÿé›†æˆ", test_system_integration)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {str(e)}")
            results.append((test_name, False))
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    
    passed = 0
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»ä½“é€šè¿‡ç‡: {passed}/{len(results)} ({passed/len(results)*100:.1f}%)")
    
    if passed == len(results):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿéƒ¨ç½²æˆåŠŸï¼")
    elif passed >= len(results) * 0.8:
        print("\nâœ… å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œç³»ç»ŸåŸºæœ¬å¯ç”¨")
    else:
        print("\nâš ï¸ å¤šä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥ç³»ç»Ÿé…ç½®")
    
    return passed == len(results)

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)